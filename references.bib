@article{2005InverseMeasurements,
  title         = {Inverse Problems and Interpretation of Measurements},
  year          = 2005,
  journal       = {Applied Mathematical Sciences (Switzerland)},
  publisher     = {Springer},
  volume        = 160,
  pages         = {1--5},
  doi           = {10.1007/0-387-27132-5{\_}1},
  issn          = {2196968x},
  keywords      = {Forward Problem, Initial Temperature Distribution, Inverse Problem, Inverse Scattering Problem, Sommerfeld Radiation Condition}
}
@article{2005StatisticalTheory,
  title         = {Statistical Inversion Theory},
  year          = 2005,
  journal       = {Applied Mathematical Sciences (Switzerland)},
  publisher     = {Springer},
  volume        = 160,
  pages         = {49--114},
  doi           = {10.1007/0-387-27132-5{\_}3},
  issn          = {2196968x},
  keywords      = {Gaussian Density, Impulse Noise, Inverse Problem, Markov Chain Monte Carlo Method, Posterior Distribution}
}
@article{2023TransformerATLAS,
  title         = {{Transformer Neural Networks for Identifying Boosted Higgs Bosons decaying into {\$}b{\textbackslash}bar{\{}b{\}}{\$} and {\$}c{\textbackslash}bar{\{}c{\}}{\$} in ATLAS}},
  year          = 2023,
  month         = 8,
  url           = {https://cds.cern.ch/record/2866601},
  keywords      = {Btagging}
}
@article{Altarelli:1977zs,
    author = "Altarelli, Guido and Parisi, G.",
    title = "{Asymptotic Freedom in Parton Language}",
    reportNumber = "LPTENS-77-6",
    doi = "10.1016/0550-3213(77)90384-4",
    journal = "Nucl. Phys. B",
    volume = "126",
    pages = "298--318",
    year = "1977"
}
@article{Canelli:2025ybb,
    author = "Canelli, Florencia and others",
    title = "{A Practical Guide to Unbinned Unfolding}",
    eprint = "2507.09582",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    month = "7",
    year = "2025"
}
@article{H1:2021wkz,
    author = "Andreev, V. and others",
    collaboration = "H1",
    title = "{Measurement of Lepton-Jet Correlation in Deep-Inelastic Scattering with the H1 Detector Using Machine Learning for Unfolding}",
    eprint = "2108.12376",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "DESY 21-130",
    doi = "10.1103/PhysRevLett.128.132002",
    journal = "Phys. Rev. Lett.",
    volume = "128",
    number = "13",
    pages = "132002",
    year = "2022"
}
@article{Shmakov:2024gkd,
    author = "Shmakov, Alexander and Greif, Kevin Thomas and Fenton, Michael James and Ghosh, Aishik and Baldi, Pierre and Whiteson, Daniel",
    title = "{Full event particle-level unfolding with variable-length latent variational diffusion}",
    eprint = "2404.14332",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    doi = "10.21468/SciPostPhys.18.4.117",
    journal = "SciPost Phys.",
    volume = "18",
    number = "4",
    pages = "117",
    year = "2025"
}
@article{aad_measurement_2011,
  title         = {Measurement of inclusive jet and dijet cross sections in~proton-proton collisions at 7~{TeV} centre-of-mass energy with~the~{ATLAS} detector},
  author        = {Aad, G. and Abbott, B. and Abdallah, J. and Abdelalim, A. A. and Abdesselam, A. and Abdinov, O. and Abi, B. and Abolins, M. and Abramowicz, H. and Abreu, H. and Acerbi, E. and Acharya, B. S. and Ackers, M. and Adams, D. L. and Addy, T. N. and Adelman, J. and Aderholz, M. and Adomeit, S. and Adorisio, C. and Adragna, P. and Adye, T. and Aefsky, S. and Aguilar-Saavedra, J. A. and Aharrouche, M. and Ahlen, S. P. and Ahles, F. and Ahmad, A. and Ahmed, H. and Ahsan, M. and Aielli, G. and Akdogan, T. and \AA{}kesson, T. P. A. and Akimoto, G. and Akimov, A. V. and Aktas, A. and Alam, M. S. and Alam, M. A. and Albrand, S. and Aleksa, M. and Aleksandrov, I. N. and Aleppo, M. and Alessandria, F. and Alexa, C. and Alexander, G. and Alexandre, G. and Alexopoulos, T. and Alhroob, M. and Aliev, M. and Alimonti, G. and Alison, J. and Aliyev, M. and Allport, P. P. and Allwood-Spiers, S. E. and Almond, J. and Aloisio, A. and Alon, R. and Alonso, A. and Alonso, J. and Alviggi, M. G. and Amako, K. and Amaral, P. and Ambrosio, G. and Amelung, C. and Ammosov, V. V. and Amorim, A. and Amor\'{o}s, G. and Amram, N. and Anastopoulos, C. and Andeen, T. and Anders, C. F. and Anderson, K. J. and Andreazza, A. and Andrei, V. and Andrieux, M.-L. and Anduaga, X. S. and Angerami, A. and Anghinolfi, F. and Anjos, N. and Annovi, A. and Antonaki, A. and Antonelli, M. and Antonelli, S. and Antos, J. and Antunovic, B. and Anulli, F. and Aoun, S. and Arabidze, G. and Aracena, I. and Arai, Y. and Arce, A. T. H. and Archambault, J. P. and Arfaoui, S. and Arguin, J.-F. and Argyropoulos, T. and Arik, E. and Arik, M. and Armbruster, A. J. and Arms, K. E. and Armstrong, S. R. and Arnaez, O. and Arnault, C. and Artamonov, A. and Arutinov, D. and Asai, M. and Asai, S. and Asfandiyarov, R. and Ask, S. and \AA{}sman, B. and Asner, D. and Asquith, L. and Assamagan, K. and Astbury, A. and Astvatsatourov, A. and Atoian, G. and Aubert, B. and Auerbach, B. and Auge, E. and Augsten, K. and Aurousseau, M. and Austin, N. and Avolio, G. and Avramidou, R. and Axen, D. and Ay, C. and Azuelos, G. and Azuma, Y. and Baak, M. A. and Baccaglioni, G. and Bacci, C. and Bach, A. M. and Bachacou, H. and Bachas, K. and Bachy, G. and Backes, M. and Badescu, E. and Bagnaia, P. and Bai, Y. and Bailey, D. C. and Bain, T. and Baines, J. T. and Baker, O. K. and Baker, M. D. and Baker, S. and Dos Santos Pedrosa, F. Baltasar and Banas, E. and Banerjee, P. and Banerjee, Sw. and Banfi, D. and Bangert, A. and Bansal, V. and Baranov, S. P. and Baranov, S. and Barashkou, A. and Barbaro Galtieri, A. and Barber, T. and Barberio, E. L. and Barberis, D. and Barbero, M. and Bardin, D. Y. and Barillari, T. and Barisonzi, M. and Barklow, T. and Barlow, N. and Barnett, B. M. and Barnett, R. M. and Baroncelli, A. and Barone, M. and Barr, A. J. and Barreiro, F. and Barreiro Guimar\~{a}es~da~Costa, J. and Barrillon, P. and Bartoldus, R. and Bartsch, D. and Bates, R. L. and Batkova, L. and Batley, J. R. and Battaglia, A. and Battistin, M. and Battistoni, G. and Bauer, F. and Bawa, H. S. and Bazalova, M. and Beare, B. and Beau, T. and Beauchemin, P. H. and Beccherle, R. and Bechtle, P. and Beck, G. A. and Beck, H. P. and Beckingham, M. and Becks, K. H. and Beddall, A. J. and Beddall, A. and Bednyakov, V. A. and Bee, C. and Begel, M. and Harpaz, S. Behar and Behera, P. K. and Beimforde, M. and Belanger-Champagne, C. and Belhorma, B. and Bell, P. J. and Bell, W. H. and Bella, G. and Bellagamba, L. and Bellina, F. and Bellomo, G. and Bellomo, M. and Belloni, A. and Belotskiy, K. and Beltramello, O. and Ami, S. Ben and Benary, O. and Benchekroun, D. and Benchouk, C. and Bendel, M. and Benedict, B. H. and Benekos, N. and Benhammou, Y. and Benincasa, G. P. and Benjamin, D. P. and Benoit, M. and Bensinger, J. R. and Benslama, K. and Bentvelsen, S. and Beretta, M. and Berge, D. and Bergeaas Kuutmann, E. and Berger, N. and Berghaus, F. and Berglund, E. and Beringer, J. and Bernardet, K. and Bernat, P. and Bernhard, R. and Bernius, C. and Berry, T. and Bertin, A. and Bertinelli, F. and Bertolucci, F. and Bertolucci, S. and Besana, M. I. and Besson, N. and Bethke, S. and Bhimji, W. and Bianchi, R. M. and Bianco, M. and Biebel, O. and Biesiada, J. and Biglietti, M. and Bilokon, H. and Binder, M. and Bindi, M. and Binet, S. and Bingul, A. and Bini, C. and Biscarat, C. and Bischof, R. and Bitenc, U. and Black, K. M. and Blair, R. E. and Blanchard, J.-B. and Blanchot, G. and Blocker, C. and Blocki, J. and Blondel, A. and Blum, W. and Blumenschein, U. and Boaretto, C. and Bobbink, G. J. and Bocci, A. and Bocian, D. and Bock, R. and Boddy, C. R. and Boehler, M. and Boek, J. and Boelaert, N. and B\"{o}ser, S. and Bogaerts, J. A. and Bogouch, A. and Bohm, C. and Bohm, J. and Boisvert, V. and Bold, T. and Boldea, V. and Bondarenko, V. G. and Bondioli, M. and Boonekamp, M. and Boorman, G. and Booth, C. N. and Booth, P. and Booth, J. R. A. and Bordoni, S. and Borer, C. and Borisov, A. and Borissov, G. and Borjanovic, I. and Borroni, S. and Bos, K. and {The ATLAS Collaboration}},
  year          = 2011,
  month         = feb,
  journal       = {The European Physical Journal C},
  volume        = 71,
  number        = 2,
  pages         = 1512,
  doi           = {10.1140/epjc/s10052-010-1512-2},
  issn          = {1434-6052},
  url           = {https://doi.org/10.1140/epjc/s10052-010-1512-2},
  urldate       = {2025-07-13},
  abstract      = {Jet cross sections have been measured for the first time in proton-proton collisions at a centre-of-mass energy of 7~TeV using the ATLAS detector. The measurement uses an integrated luminosity of 17~nb -1 recorded at the Large Hadron Collider. The anti-ktalgorithm is used to identify jets, with two jet resolution parameters, R=0.4 and 0.6. The dominant uncertainty comes from the jet energy scale, which is determined to within 7\% for central jets above 60~GeV transverse momentum. Inclusive single-jet differential cross sections are presented as functions of jet transverse momentum and rapidity. Dijet cross sections are presented as functions of dijet mass and the angular variable~\ensuremath{\chi}. The results are compared to expectations based on next-to-leading-order QCD, which agree with the data, providing a validation of the theory in a new kinematic regime.},
  language      = {en},
  keywords      = {Accelerator Physics, Experimental Nuclear Physics, Experimental Particle Physics, High-Energy Astrophysics, Nuclear and Particle Physics, Particle Physics}
}
@inproceedings{acosta2024npu,
  title         = {Multidimensional Deconvolution with Profiling},
  author        = {Acosta, Fernando Torales and Desai, Krish and Mikuni, Vinicius and Nachman, Benjamin and Pan, Jingjing},
  year          = 2024,
  booktitle     = {Ml4ps},
  number        = 177,
  maintitle     = {NeurIPS}
}
@article{Adam-Bourdarios2015TheChallenge,
  title         = {The Higgs Machine Learning Challenge},
  author        = {Adam-Bourdarios, C. and Cowan, G. and Germain-Renaud, C. and Guyon, I. and K{\'{e}}gl, B. and Rousseau, D.},
  year          = 2015,
  month         = 12,
  journal       = {Journal of Physics: Conference Series},
  publisher     = {IOP Publishing},
  volume        = 664,
  number        = 7,
  pages         = {072015},
  doi           = {10.1088/1742-6596/664/7/072015},
  issn          = {1742-6596},
  url           = {https://iopscience.iop.org/article/10.1088/1742-6596/664/7/072015 https://iopscience.iop.org/article/10.1088/1742-6596/664/7/072015/meta}
}
@inproceedings{adye_unfolding_2011,
  title         = {Unfolding algorithms and tests using {RooUnfold}},
  author        = {Adye, Tim},
  year          = 2011,
  booktitle     = {{Phystat} 2011},
  publisher     = {Cern},
  address       = {Geneva},
  pages         = {313--318},
  doi           = {10.5170/cern-2011-006.313},
  note          = {\_eprint: 1105.1160},
  keywords      = {BETA, statistical analysis}
}
@book{agostini_bayesian_2003,
  title         = {{Bayesian} {Reasoning} {In} {Data} {Analysis}: {A} {Critical} {Introduction}},
  shorttitle    = {{Bayesian} {Reasoning} {In} {Data} {Analysis}},
  author        = {Agostini, Giulio D.},
  year          = 2003,
  publisher     = {World Scientific Publishing Company},
  address       = {River Edge, NJ},
  isbn          = {978-981-238-356-3},
  abstract      = {This book provides a multi-level introduction to Bayesian reasoning (as opposed to "conventional statistics") and its applications to data analysis. The basic ideas of this "new" approach to the quantification of uncertainty are presented using examples from research and everyday life. Applications covered include: parametric inference; combination of results; treatment of uncertainty due to systematic errors and background; comparison of hypotheses; unfolding of experimental distributions; upper/lower bounds in frontier-type measurements. Approximate methods for routine use are derived and are shown often to coincide -- under well-defined assumptions! -- with "standard" methods, which can therefore be seen as special cases of the more general Bayesian methods. In dealing with uncertainty in measurements, modern metrological ideas are utilized, including the ISO classification of uncertainty into type A and type B. These are shown to fit well into the Bayesian framework.},
  language      = {English}
}
@article{Albergo2019Flow-basedSHANAHAN,
  title         = {Flow-based generative models for Markov chain Monte Carlo in lattice field theory FLOW-BASED GENERATIVE MODELS for MARKOV CHAIN ... M. S. ALBERGO, G. KANWAR, and P. E. SHANAHAN},
  author        = {Albergo, M. S. and Kanwar, G. and Shanahan, P. E.},
  year          = 2019,
  month         = 8,
  journal       = {Physical Review D},
  publisher     = {American Physical Society},
  volume        = 100,
  number        = 3,
  doi           = {10.1103/physrevd.100.034515},
  issn          = 24700029
}
@article{albert_antares_2025,
  title         = {The {ANTARES} detector: {Two} decades of neutrino searches in the {Mediterranean} {Sea}},
  shorttitle    = {The {ANTARES} detector},
  author        = {Albert, A. and Alves, S. and Andr\'{e}, M. and Ardid, M. and Ardid, S. and Aubert, J. - J. and Aublin, J. and Baret, B. and Basa, S. and Becherini, Y. and Belhorma, B. and Benfenati, F. and Bertin, V. and Biagi, S. and Boumaaza, J. and Bouta, M. and Bouwhuis, M. C. and Br\^{a}nza\c{s}, H. and Bruijn, R. and Brunner, J. and Busto, J. and Caiffi, B. and Calvo, D. and Campion, S. and Capone, A. and Carenini, F. and Carr, J. and Carretero, V. and Cartraud, T. and Celli, S. and Cerisy, L. and Chabab, M. and Moursli, R. Cherkaoui El and Chiarusi, T. and Circella, M. and Coelho, J. A. B. and Coleiro, A. and Coniglione, R. and Coyle, P. and Creusot, A. and D\'{\i}az, A. F. and De Martino, B. and Rosso, I. Del and Distefano, C. and Palma, I. Di and Donzaud, C. and Dornic, D. and Drouhin, D. and Eberl, T. and Eddymaoui, A. and van Eeden, T. and van Eijk, D. and Hedri, S. El and Khayati, N. El and Enzenh\"{o}fer, A. and Fermani, P. and Ferrara, G. and Filippini, F. and Fusco, L. and Gagliardini, S. and Garc\'{\i}a-M\'{e}ndez, J. and Oliver, C. Gatius and Gay, P. and Gei\ss{}elbrecht, N. and Glotin, H. and Gozzini, R. and Ruiz, R. Gracia and Graf, K. and Guidi, C. and Haegel, L. and van Haren, H. and Heijboer, A. J. and Hello, Y. and Hennig, L. and Hern\'{a}ndez-Rey, J. J. and H\"{o}\ss{}l, J. and Huang, F. and Illuminati, G. and Jisse-Jung, B. and de Jong, M. and de Jong, P. and Kadler, M. and Kalekin, O. and Katz, U. and Kouchner, A. and Kreykenbohm, I. and Kulikovskiy, V. and Lahmann, R. and Lamoureux, M. and Lazo, A. and Lef\`{e}vre, D. and Leonora, E. and Levi, G. and Stum, S. Le and Loucatos, S. and Manczak, J. and Marcelin, M. and Margiotta, A. and Marinelli, A. and Mart\'{\i}nez-Mora, J. A. and Migliozzi, P. and Moussa, A. and Muller, R. and Navas, S. and Nezri, E. and Fearraigh, B. \'{O} and Oukacha, E. and P\u{a}un, A. M. and P\u{a}v\u{a}la\c{s}, G. E. and Pe\~{n}a-Mart\'{\i}nez, S. and Perrin-Terrin, M. and Piattelli, P. and Poir\`{e}, C. and Popa, V. and Pradier, T. and Randazzo, N. and Real, D. and Riccobene, G. and Romanov, A. and Losa, A. S\'{a}nchez and Saina, A. and Greus, F. Salesa and Samtleben, D. F. E. and Sanguineti, M. and Sapienza, P. and Sch\"{u}ssler, F. and Seneca, J. and Spurio, M. and Stolarczyk, Th. and Taiuti, M. and Tayalati, Y. and Vallage, B. and Vannoye, G. and Van Elewyck, V. and Viola, S. and Vivolo, D. and Wilms, J. and Zavatarelli, S. and Zegarelli, A. and Zornoza, J. D. and Z\'{u}\~{n}iga, J.},
  year          = 2025,
  month         = jun,
  journal       = {Physics Reports},
  volume        = {1121-1124},
  pages         = {1--46},
  doi           = {10.1016/j.physrep.2025.04.001},
  issn          = {0370-1573},
  url           = {https://www.sciencedirect.com/science/article/pii/S0370157325001450},
  urldate       = {2025-07-13},
  abstract      = {Interest for studying cosmic neutrinos using deep-sea detectors has increased after the discovery of a diffuse flux of cosmic neutrinos by the IceCube collaboration and the possibility of wider multi-messenger studies with the observations of gravitational waves. The ANTARES detector was the first neutrino telescope in seawater, operating successfully in the Mediterranean Sea for more than a decade and a half. All challenges related to the operation in the deep sea were accurately addressed by the collaboration. Deployment and connection operations became smoother over time; data taking and constant re-calibration of the detector due to the variable environmental conditions were fully automated. A wealth of results on the subject of astroparticle physics, particle physics and multi-messenger astronomy have been obtained, despite the relative modest size of the detector, paving the way to a new generation of larger undersea detectors. This review summarizes the efforts by the ANTARES collaboration that made the possibility to operate neutrino telescopes in seawater a reality and the results obtained in this endeavor.},
  keywords      = {Multimessenger astrophysics, Neutrino astrophysics, Neutrino detectors, Neutrino physics}
}
@article{Algren2023FlowReweighting,
  title         = {Flow Away your Differences: Conditional Normalizing Flows as an Improvement to Reweighting},
  author        = {Algren, Malte and Golling, Tobias and Guth, Manuel and Pollard, Chris and Raine, John Andrew},
  year          = 2023,
  month         = 4,
  url           = {https://arxiv.org/pdf/2304.14963},
  arxivid       = {2304.14963}
}
@article{allison_recent_2016,
  title         = {Recent developments in {Geant4}},
  author        = {Allison, J. and Amako, K. and Apostolakis, J. and Arce, P. and Asai, M. and Aso, T. and Bagli, E. and Bagulya, A. and Banerjee, S. and Barrand, G. and Beck, B. R. and Bogdanov, A. G. and Brandt, D. and Brown, J. M. C. and Burkhardt, H. and Canal, Ph. and Cano-Ott, D. and Chauvie, S. and Cho, K. and Cirrone, G. A. P. and Cooperman, G. and Cort\'{e}s-Giraldo, M. A. and Cosmo, G. and Cuttone, G. and Depaola, G. and Desorgher, L. and Dong, X. and Dotti, A. and Elvira, V. D. and Folger, G. and Francis, Z. and Galoyan, A. and Garnier, L. and Gayer, M. and Genser, K. L. and Grichine, V. M. and Guatelli, S. and Gu\`{e}ye, P. and Gumplinger, P. and Howard, A. S. and H\v{r}ivn\'{a}\v{c}ov\'{a}, I. and Hwang, S. and Incerti, S. and Ivanchenko, A. and Ivanchenko, V. N. and Jones, F. W. and Jun, S. Y. and Kaitaniemi, P. and Karakatsanis, N. and Karamitros, M. and Kelsey, M. and Kimura, A. and Koi, T. and Kurashige, H. and Lechner, A. and Lee, S. B. and Longo, F. and Maire, M. and Mancusi, D. and Mantero, A. and Mendoza, E. and Morgan, B. and Murakami, K. and Nikitina, T. and Pandola, L. and Paprocki, P. and Perl, J. and Petrovi\'{c}, I. and Pia, M. G. and Pokorski, W. and Quesada, J. M. and Raine, M. and Reis, M. A. and Ribon, A. and Risti\'{c} Fira, A. and Romano, F. and Russo, G. and Santin, G. and Sasaki, T. and Sawkey, D. and Shin, J. I. and Strakovsky, I. I. and Taborda, A. and Tanaka, S. and Tom\'{e}, B. and Toshito, T. and Tran, H. N. and Truscott, P. R. and Urban, L. and Uzhinsky, V. and Verbeke, J. M. and Verderi, M. and Wendt, B. L. and Wenzel, H. and Wright, D. H. and Wright, D. M. and Yamashita, T. and Yarba, J. and Yoshida, H.},
  year          = 2016,
  month         = nov,
  journal       = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  volume        = 835,
  pages         = {186--225},
  doi           = {10.1016/j.nima.2016.06.125},
  issn          = {0168-9002},
  url           = {https://www.sciencedirect.com/science/article/pii/S0168900216306957},
  urldate       = {2025-07-13},
  abstract      = {Geant4 is a software toolkit for the simulation of the passage of particles through matter. It is used by a large number of experiments and projects in a variety of application domains, including high energy physics, astrophysics and space science, medical physics and radiation protection. Over the past several years, major changes have been made to the toolkit in order to accommodate the needs of these user communities, and to efficiently exploit the growth of computing power made available by advances in technology. The adaptation of Geant4 to multithreading, advances in physics, detector modeling and visualization, extensions to the toolkit, including biasing and reverse Monte Carlo, and tools for physics and release validation are discussed here.},
  keywords      = {Computing, High energy physics, Nuclear physics, Radiation, Simulation}
}
@book{alma9914845810606531,
  title         = {Elementary Particles},
  author        = {Altarelli, G},
  year          = 2008,
  publisher     = {Springer},
  address       = {Berlin ; Heidelberg},
  series        = 1,
  volume        = 4,
  isbn          = {3-540-74202-6},
  edition       = 1,
  langid        = {english}
}
@article{Milton:2025mug,
    author = "Milton, Ryan and Mikuni, Vinicius and Lee, Trevin and Arratia, Miguel and Wamorkar, Tanvi and Nachman, Benjamin",
    title = "{Tools for unbinned unfolding}",
    eprint = "2503.09720",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    doi = "10.1088/1748-0221/20/05/P05034",
    journal = "JINST",
    volume = "20",
    number = "05",
    pages = "P05034",
    year = "2025"
}
@article{Arratia:2021otl,
    author = "Arratia, Miguel and others",
    title = "{Publishing unbinned differential cross section results}",
    eprint = "2109.13243",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    reportNumber = "CP3-21-54",
    doi = "10.1088/1748-0221/17/01/P01024",
    journal = "JINST",
    volume = "17",
    number = "01",
    pages = "P01024",
    year = "2022"
}
@article{ATLAS:2010jvh,
    author = "Aad, G. and others",
    collaboration = "ATLAS",
    title = "{Charged-particle multiplicities in pp interactions measured with the ATLAS detector at the LHC}",
    eprint = "1012.5104",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "CERN-PH-EP-2010-079",
    doi = "10.1088/1367-2630/13/5/053033",
    journal = "New J. Phys.",
    volume = "13",
    pages = "053033",
    year = "2011"
}
@article{ATLAS:2020ccu,
    author = "Aad, Georges and others",
    collaboration = "ATLAS",
    title = "{Measurements of top-quark pair single- and double-differential cross-sections in the all-hadronic channel in $pp$ collisions at $\sqrt{s}=13~\textrm{TeV}$ using the ATLAS detector}",
    eprint = "2006.09274",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "CERN-EP-2020-063",
    doi = "10.1007/JHEP01(2021)033",
    journal = "JHEP",
    volume = "01",
    pages = "033",
    year = "2021"
}
@article{CMS:2014eaj,
    author = "Khachatryan, Vardan and others",
    collaboration = "CMS",
    title = "{Search for quark contact interactions and extra spatial dimensions using dijet angular distributions in proton{\textendash}proton collisions at $\sqrt s =$ 8 TeV}",
    eprint = "1411.2646",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "CMS-EXO-12-050, CERN-PH-EP-2014-261",
    doi = "10.1016/j.physletb.2015.04.042",
    journal = "Phys. Lett. B",
    volume = "746",
    pages = "79--99",
    year = "2015"
}
@article{ATLAS:2022zbu,
    author = "Aad, Georges and others",
    collaboration = "ATLAS",
    title = "{Measurements of the suppression and correlations of dijets in Pb+Pb collisions at sNN=5.02 TeV}",
    eprint = "2205.00682",
    archivePrefix = "arXiv",
    primaryClass = "nucl-ex",
    reportNumber = "CERN-EP-2022-046",
    doi = "10.1103/PhysRevC.107.054908",
    journal = "Phys. Rev. C",
    volume = "107",
    number = "5",
    pages = "054908",
    year = "2023",
    note = "[Erratum: Phys.Rev.C 109, 029901 (2024)]"
}
@techreport{D'Agostini:265717,
      author        = "D'Agostini, Giulio",
      title         = "{A multidimensional unfolding method based on Bayes'
                       Theorem}",
      institution   = "DESY",
      reportNumber  = "DESY-94-099",
      address       = "Hamburg",
      year          = "1994",
      url           = "https://cds.cern.ch/record/265717",
}
@article{Aguilar-Saavedra:2014kpa,
    author = "Aguilar-Saavedra, J. A. and Amidei, D. and Juste, A. and Perez-Victoria, M.",
    title = "{Asymmetries in top quark pair production at hadron colliders}",
    eprint = "1406.1798",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    reportNumber = "CERN-PH-TH-2014-101",
    doi = "10.1103/RevModPhys.87.421",
    journal = "Rev. Mod. Phys.",
    volume = "87",
    pages = "421--455",
    year = "2015"
}
@article{CMS:2011xqa,
    collaboration = "CMS",
    title = "{Measurement of the Charge Asymmetry in Top Quark Pair Production}",
    reportNumber = "CMS-PAS-TOP-11-014, CMS-PAS-TOP-11-014",
    year = "2011"
}
@article{Altarelli:1981ax,
  title         = {Partons in Quantum Chromodynamics},
  author        = {Altarelli, Guido},
  year          = 1982,
  journal       = {Physics Reports},
  volume        = 81,
  number        = 1,
  pages         = 1,
  doi           = {10.1016/0370-1573(82)90127-2},
  issn          = {0370-1573},
  urldate       = {2025-07-18},
  abstract      = {An overall view of the physics of QCD in the perturbative domain is presented in a form that could be of use both as an introduction to the subject with its main lines of current development and as a reference review text for more expert readers as well.},
  annotation    = {862 citations (INSPIRE 2025/7/18)\\ 824 citations w/o self (INSPIRE 2025/7/18)\\ Citations: 464 (Crossref) [2025-07-18]\\ Citations: 346 (SemanticScholar) [2025-07-18]},
  file          = {/Users/t-krishdesai/Zotero/storage/GSVAUH5C/Altarelli - 1982 - Partons in quantum chromodynamics.pdf}
}
@article{Altheimer2012JetBenchmarks,
  title         = {Jet substructure at the Tevatron and LHC: New results, new tools, new benchmarks},
  author        = {Altheimer, A. and Arora, S. and Asquith, L. and Brooijmans, G. and Butterworth, J. and Campanelli, M. and Chapleau, B. and Cholakian, A. E. and Chou, J. P. and Dasgupta, M. and Davison, A. and Dolen, J. and Ellis, S. D. and Essig, R. and Fan, J. J. and Field, R. and Fregoso, A. and Gallicchio, J. and Gershtein, Y. and Gomes, A. and Haas, A. and Halkiadakis, E. and Halyo, V. and Hoeche, S. and Hook, A. and Hornig, A. and Huang, P. and Izaguirre, E. and Jankowiak, M. and Kribs, G. and Krohn, D. and Larkoski, A. J. and Lath, A. and Lee, C. and Lee, S. J. and Loch, P. and Maksimovic, P. and Martinez, M. and Miller, D. W. and Plehn, T. and Prokofiev, K. and Rahmat, R. and Rappoccio, S. and Safonov, A. and Salam, G. P. and Schumann, S. and Schwartz, M. D. and Schwartzman, A. and Seymour, M. and Shao, J. and Sinervo, P. and Son, M. and Soper, D. E. and Spannowsky, M. and Stewart, I. W. and Strassler, M. and Strauss, E. and Takeuchi, M. and Thaler, J. and Thomas, S. and Tweedie, B. and Sierra, R. Vasquez and Vermilion, C. K. and Villaplana, M. and Vos, M. and Wacker, J. and Walker, D. and Walsh, J. R. and Wang, L. T. and Wilbur, S. and Zhu, W.},
  year          = 2012,
  month         = 6,
  journal       = {Journal of Physics G: Nuclear and Particle Physics},
  volume        = 39,
  number        = 6,
  doi           = {10.1088/0954-3899/39/6/063001},
  issn          = {09543899},
  arxivid       = {1201.0008}
}
@article{Amsler2008MonteTechniques,
  title         = {Monte Carlo techniques},
  author        = {Amsler, C. and Doser, M. and Antonelli, M. and Asner, D. M. and Babu, K. S. and Baer, H. and Band, H. R. and Barnett, R. M. and Bergren, E. and Beringer, J. and Bernardi, G. and Bertl, W. and Bichsel, H. and Biebel, O. and Bloch, P. and Blucher, E. and Blusk, S. and Cahn, R. N. and Carena, M. and Caso, C. and Ceccucci, A. and Chakraborty, D. and Chen, M. C. and Chivukula, R. S. and Cowan, G. and Dahl, O. and D'Ambrosio, G. and Damour, T. and de Gouv{\^{e}}a, A. and DeGrand, T. and Dobrescu, B. and Drees, M. and Edwards, D. A. and Eidelman, S. and Elvira, V. D. and Erler, J. and Ezhela, V. V. and Feng, J. L. and Fetscher, W. and Fields, B. D. and Foster, B. and Gaisser, T. K. and Garren, L. and Gerber, H. J. and Gerbier, G. and Gherghetta, T. and Giudice, G. F. and Goodman, M. and Grab, C. and Gritsan, A. V. and Grivaz, J. F. and Groom, D. E. and Gr{\"{u}}newald, M. and Gurtu, A. and Gutsche, T. and Haber, H. E. and Hagiwara, K. and Hagmann, C. and Hayes, K. G. and Hern{\'{a}}ndez-Rey, J. J. and Hikasa, K. and Hinchliffe, I. and H{\"{o}}cker, A. and Huston, J. and Igo-Kemenes, P. and Jackson, J. D. and Johnson, K. F. and Junk, T. and Karlen, D. and Kayser, B. and Kirkby, D. and Klein, S. R. and Knowles, I. G. and Kolda, C. and Kowalewski, R. V. and Kreitz, P. and Krusche, B. and Kuyanov, Yu V. and Kwon, Y. and Lahav, O. and Langacker, P. and Liddle, A. and Ligeti, Z. and Lin, C. J. and Liss, T. M. and Littenberg, L. and Liu, J. C. and Lugovsky, K. S. and Lugovsky, S. B. and Mahlke, H. and Mangano, M. L. and Mannel, T. and Manohar, A. V. and Marciano, W. J. and Martin, A. D. and Masoni, A. and Milstead, D. and Miquel, R. and M{\"{o}}nig, K. and Murayama, H. and Nakamura, K. and Narain, M. and Nason, P. and Navas, S. and Nevski, P. and Nir, Y. and Olive, K. A. and Pape, L. and Patrignani, C. and Peacock, J. A. and Piepke, A. and Punzi, G. and Quadt, A. and Raby, S. and Raffelt, G. and Ratcliff, B. N. and Renk, B. and Richardson, P. and Roesler, S. and Rolli, S. and Romaniouk, A. and Rosenberg, L. J. and Rosner, J. L. and Sachrajda, C. T. and Sakai, Y. and Sarkar, S. and Sauli, F. and Schneider, O. and Scott, D. and Seligman, W. G. and Shaevitz, M. H. and Sj{\"{o}}strand, T. and Smith, J. G. and Smoot, G. F. and Spanier, S. and Spieler, H. and Stahl, A. and Stanev, T. and Stone, S. L. and Sumiyoshi, T. and Tanabashi, M. and Terning, J. and Titov, M. and Tkachenko, N. P. and T{\"{o}}rnqvist, N. A. and Tovey, D. and Trilling, G. H. and Trippe, T. G. and Valencia, G. and van Bibber, K. and Vincter, M. G. and Vogel, P. and Ward, D. R. and Watari, T. and Webber, B. R. and Weiglein, G. and Wells, J. D. and Whalley, M. and Wheeler, A. and Wohl, C. G. and Wolfenstein, L. and Womersley, J. and Woody, C. L. and Workman, R. L. and Yamamoto, A. and Yao, W. M. and Zenin, O. V. and Zhang, J. and Zhu, R. Y. and Zyla, P. A. and Harper, G. and Lugovsky, V. S. and Schaffner, P.},
  year          = 2008,
  month         = 9,
  journal       = {Physics Letters, Section B: Nuclear, Elementary Particle and High-Energy Physics},
  volume        = 667,
  number        = {1-5},
  pages         = {1--6},
  doi           = {10.1016/j.physletb.2008.07.018},
  issn          = {03702693}
}
@article{AnanthaPadmanabha2021SolvingNetworks,
  title         = {Solving inverse problems using conditional invertible neural networks},
  author        = {Anantha Padmanabha, Govinda and Zabaras, Nicholas},
  year          = 2021,
  month         = 5,
  journal       = {Journal of Computational Physics},
  publisher     = {Academic Press},
  volume        = 433,
  pages         = 110194,
  doi           = {10.1016/j.jcp.2021.110194},
  issn          = {0021-9991},
  arxivid       = {2007.15849},
  keywords      = {Conditional invertible neural network, Flow-based generative model, High-dimensional, Inverse surrogate modeling, Multiphase flow}
}
@article{andreassen_omnifold_2020,
  title         = {{OmniFold}: {A} {Method} to {Simultaneously} {Unfold} {All} {Observables}},
  shorttitle    = {OmniFold},
  author        = {Andreassen, Anders and Komiske, Patrick T. and Metodiev, Eric M. and Nachman, Benjamin and Thaler, Jesse},
  year          = 2020,
  month         = may,
  journal       = {Physical Review Letters},
  volume        = 124,
  number        = 18,
  pages         = 182001,
  doi           = {10.1103/PhysRevLett.124.182001},
  url           = {https://link.aps.org/doi/10.1103/PhysRevLett.124.182001},
  urldate       = {2025-07-13},
  note          = {Publisher: American Physical Society},
  abstract      = {Collider data must be corrected for detector effects (``unfolded'') to be compared with many theoretical calculations and measurements from other experiments. Unfolding is traditionally done for individual, binned observables without including all information relevant for characterizing the detector response. We introduce OmniFold, an unfolding method that iteratively reweights a simulated dataset, using machine learning to capitalize on all available information. Our approach is unbinned, works for arbitrarily high-dimensional data, and naturally incorporates information from the full phase space. We illustrate this technique on a realistic jet substructure example from the Large Hadron Collider and compare it to standard binned unfolding methods. This new paradigm enables the simultaneous measurement of all observables, including those not yet invented at the time of the analysis.}
}
@article{Anguita2004ModelClassifier,
  title         = {Model selection in top quark tagging with a support vector classifier},
  author        = {Anguita, Davide and Ridella, Sandro and Rivieccio, Fabio and Zunino, Rodolfo and Amerio, Silvia and Lazzizzera, Ignazio},
  year          = 2004,
  journal       = {IEEE Conf.Proc.},
  volume        = 3,
  number        = 3,
  pages         = {2059--2064},
  doi           = {10.1109/ijcnn.2004.1380934},
  isbn          = {0780383591},
  issn          = 10987576
}
@article{Araz2025GraphLHC,
  title         = {Graph theory inspired anomaly detection at the LHC},
  author        = {Araz, Jack Y. and Athanasakos, Dimitrios and Ploskon, Mateusz and Ringer, Felix},
  year          = 2025,
  month         = 6,
  url           = {https://arxiv.org/pdf/2506.19920},
  arxivid       = {2506.19920},
  keywords      = {hep-ex, hep-ph, physics.data-an}
}
@misc{arjovsky_towards_2017,
  title         = {Towards {Principled} {Methods} for {Training} {Generative} {Adversarial} {Networks}},
  author        = {Arjovsky, Martin and Bottou, L\'{e}on},
  year          = 2017,
  month         = jan,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1701.04862},
  url           = {http://arxiv.org/abs/1701.04862},
  urldate       = {2025-07-17},
  note          = {arXiv:1701.04862 [stat]},
  abstract      = {The goal of this paper is not to introduce a single algorithm or method, but to make theoretical steps towards fully understanding the training dynamics of generative adversarial networks. In order to substantiate our theoretical analysis, we perform targeted experiments to verify our assumptions, illustrate our claims, and quantify the phenomena. This paper is divided into three sections. The first section introduces the problem at hand. The second section is dedicated to studying and proving rigorously the problems including instability and saturation that arize when training generative adversarial networks. The third section examines a practical and theoretically grounded direction towards solving these problems, while introducing new tools to study them.},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning}
}
@misc{arjovsky_wasserstein_2017,
  title         = {Wasserstein {GAN}},
  author        = {Arjovsky, Martin and Chintala, Soumith and Bottou, L\'{e}on},
  year          = 2017,
  month         = dec,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1701.07875},
  url           = {http://arxiv.org/abs/1701.07875},
  urldate       = {2025-07-17},
  note          = {arXiv:1701.07875 [stat]},
  abstract      = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning}
}
@article{arnison_transverse_1982,
  title         = {Transverse momentum spectra for charged particles at the {CERN} proton-antiproton collider},
  author        = {Arnison, G. and Astbury, A. and Aubert, B. and Bacci, C. and Bernabei, R. and B\'{e}zaguet, A. and B\"{o}ck, R. and Bowcock, T. J. V. and Calvetti, M. and Carroll, T. and Catz, P. and Centro, S. and Ceradini, F. and Cittolin, S. and Cnops, A. M. and Cochet, C. and Colas, J. and Corden, M. and Dallman, D. and D'Angelo, S. and DeBeer, M. and Della Negra, M. and Demoulin, M. and Denegri, D. and DiBitonto, D. and Dobryznski, L. and Dowell, J. D. and Edwards, M. and Eggert, K. and Eisenhandler, E. and Ellis, N. and Erhard, P. and Faissner, H. and Fontaine, G. and Fournier, J. P. and Frey, R. and Fr\"{u}hwirth, R. and Garvey, J. and Geer, S. and Ghesqui\`{e}re, C. and Ghez, P. and Giboni, K. L. and Gibson, W. R. and Giraud-Heraud, Y. and Givernaud, A. and Gonidec, A. and Grayer, G. and Gutierrez, P. and Haidan, R. and Hansl-Kozanecka, T. and Haynes, W. J. and Hertzberger, L. O. and Hodges, C. and Hoffmann, D. and Hoffmann, H. and Holthuizen, D. J. and Homer, R. J. and Honma, A. and Jank, W. and Kalmus, P. I. P. and Karimaki, V. and Keeler, R. and Kenyon, I. and Kernan, A. and Kinnunen, R. and Kowalski, H. and Kozanecki, W. and Kryn, D. and Lacava, F. and Laugier, J. P. and Lees, J. P. and Lehmann, H. and Leuchs, R. and Leveque, A. and Linglin, D. and Locci, E. and Markiewicz, T. and Maurin, G. and McMahon, T. and Mendiburu, J. P. and Minard, M. N. and Moricca, M. and Muller, F. and Nandi, A. K. and Naumann, L. and Norton, A. and Orkin-Lecourtois, A. and Paoluzi, L. and Piano Mortari, G. and Pimi\"{a}, M. and Placci, A. and Radermacher, E. and Ransdell, J. and Reithler, H. and Revol, J. P. and Rich, J. and Rijsenbeek, M. and Roberts, C. and Rubbia, C. and Sadoulet, B. and Sajot, G. and Salvi, G. and Salvini, G. and Sass, J. and Saudraix, J. and Savoy-Navarro, A. and Schinzel, D. and Scott, W. and Shah, T. P. and Spiro, M. and Strauss, J. and Sumorok, K. and Szoncso, F. and Tao, C. and Thompson, G. and Timmer, J. and Tscheslog, E. and Tuominiemi, J. and Vialle, J. P. and Vrana, J. and Vuillemin, V. and Wahl, H. and Watkins, P. and Wilson, J. and Yvert, M. and Zurfluh, E.},
  year          = 1982,
  month         = dec,
  journal       = {Physics Letters B},
  volume        = 118,
  number        = 1,
  pages         = {167--172},
  doi           = {10.1016/0370-2693(82)90623-2},
  issn          = {0370-2693},
  url           = {https://www.sciencedirect.com/science/article/pii/0370269382906232},
  urldate       = {2025-07-14},
  abstract      = {We have measured transverse momentum spectra up to 10 GeV/c for charged particles produced centrally in proton-antiproton collisions at 540 GeV in the centre of mass at the CERN collider. Our results are compared with data at ISR energies and with the predictions of a QCD model. The charged particle spectrum shows a clear dependence on charged track multiplicity.}
}
@article{arratia_optimizing_2022,
  title         = {Optimizing observables with machine learning for better unfolding},
  author        = {Arratia, Miguel and Britzger, Daniel and Long, Owen and Nachman, Benjamin},
  year          = 2022,
  month         = jul,
  journal       = {Journal of Instrumentation},
  volume        = 17,
  number        = {07},
  pages         = {P07009},
  doi           = {10.1088/1748-0221/17/07/p07009},
  issn          = {1748-0221},
  url           = {https://dx.doi.org/10.1088/1748-0221/17/07/P07009},
  urldate       = {2025-07-13},
  note          = {Publisher: IOP Publishing},
  abstract      = {Most measurements in particle and nuclear physics use matrix-based unfolding algorithms to correct for detector effects. In nearly all cases, the observable is defined analogously at the particle and detector level. We point out that while the particle-level observable needs to be physically motivated to link with theory, the detector-level need not be and can be optimized. We show that using deep learning to define detector-level observables has the capability to improve the measurement when combined with standard unfolding methods.},
  language      = {en}
}
@article{Arratia2025TowardsEvents,
  title         = {Towards Unfolding All Particles in High Q2 DIS Events},
  author        = {Arratia, M. and Milton, R. and Mikuni, V. and Nachman, B. and Pan, J. and Torales Acosta, F. and Wamorkar, T},
  year          = 2025,
  month         = 3,
  journal       = {H1 Prelim},
  volume        = 25,
  number        = {031},
  url           = {https://www-h1.desy.de/h1/www/publications/htmlsplit/H1prelim-25-031.long.html}
}
@article{atlas_collaboration_measurement_2024,
  title         = {Measurement of jet substructure in boosted \$t{\textbackslash}overline\{t\}\$ events with the {ATLAS} detector using \$140{\textbackslash}text\{ \}{\textbackslash}text\{ \}\{{\textbackslash}mathrm\{fb\}\}{\textasciicircum}\{{\textbackslash}ensuremath\{-\}1\}\$ of 13 {TeV} \$pp\$ collisions},
  author        = {{ATLAS Collaboration} and Aad, G. and Abbott, B. and Abeling, K. and Abicht, N.J. and Abidi, S.H. and Aboulhorma, A. and Abramowicz, H. and Abreu, H. and Abulaiti, Y. and Abusleme Hoffman, A. C. and Acharya, B. S. and Adam Bourdarios, C. and Adamczyk, L. and Adamek, L. and Addepalli, S. V. and Addison, M. J. and Adelman, J. and Adiguzel, A. and Adye, T. and Affolder, A. A. and Afik, Y. and Agaras, M. N. and Agarwala, J. and Aggarwal, A. and Agheorghiesei, C. and Ahmad, A. and Ahmadov, F. and Ahmed, W. S. and Ahuja, S. and Ai, X. and Aielli, G. and Aikot, A. and Ait Tamlihat, M. and Aitbenchikh, B. and Aizenberg, I. and Akbiyik, M. and \AA{}kesson, T. P. A. and Akimov, A. V. and Akiyama, D. and Akolkar, N. N. and Al Khoury, K. and Alberghi, G. L. and Albert, J. and Albicocco, P. and Albouy, G. L. and Alderweireldt, S. and Aleksa, M. and Aleksandrov, I. N. and Alexa, C. and Alexopoulos, T. and Alfonsi, F. and Algren, M. and Alhroob, M. and Ali, B. and Ali, H. M. J. and Ali, S. and Alibocus, S. W. and Aliev, M. and Alimonti, G. and Alkakhi, W. and Allaire, C. and Allbrooke, B. M. M. and Allen, J. F. and Allendes Flores, C. A. and Allport, P. P. and Aloisio, A. and Alonso, F. and Alpigiani, C. and Alvarez Estevez, M. and Alvarez Fernandez, A. and Alves Cardoso, M. and Alviggi, M. G. and Aly, M. and Amaral Coutinho, Y. and Ambler, A. and Amelung, C. and Amerl, M. and Ames, C. G. and Amidei, D. and Amor Dos Santos, S. P. and Amos, K. R. and Ananiev, V. and Anastopoulos, C. and Andeen, T. and Anders, J. K. and Andrean, S. Y. and Andreazza, A. and Angelidakis, S. and Angerami, A. and Anisenkov, A. V. and Annovi, A. and Antel, C. and Anthony, M. T. and Antipov, E. and Antonelli, M. and Anulli, F. and Aoki, M. and Aoki, T. and Aparisi Pozo, J. A. and Aparo, M. A. and Aperio Bella, L. and Appelt, C. and Apyan, A. and Aranzabal, N. and Arcangeletti, C. and Arce, A. T. H. and Arena, E. and Arguin, J-F. and Argyropoulos, S. and Arling, J.-H. and Arnaez, O. and Arnold, H. and Artoni, G. and Asada, H. and Asai, K. and Asai, S. and Asbah, N. A. and Assamagan, K. and Astalos, R. and Atashi, S. and Atkin, R. J. and Atkinson, M. and Atmani, H. and Atmasiddha, P. A. and Augsten, K. and Auricchio, S. and Auriol, A. D. and Austrup, V. A. and Avolio, G. and Axiotis, K. and Azuelos, G. and Babal, D. and Bachacou, H. and Bachas, K. and Bachiu, A. and Backman, F. and Badea, A. and Bagnaia, P. and Bahmani, M. and Bailey, A. J. and Bailey, V. R. and Baines, J. T. and Baines, L. and Bakalis, C. and Baker, O. K. and Bakos, E. and Bakshi Gupta, D. and Balakrishnan, V. and Balasubramanian, R. and Baldin, E. M. and Balek, P. and Ballabene, E. and Balli, F. and Baltes, L. M. and Balunas, W. K. and Balz, J. and Banas, E. and Bandieramonte, M. and Bandyopadhyay, A. and Bansal, S. and Barak, L. and Barakat, M. and Barberio, E. L. and Barberis, D. and Barbero, M. and Barel, M. Z. and Barends, K. N. and Barillari, T. and Barisits, M-S. and Barklow, T. and Baron, P. and Baron Moreno, D. A. and Baroncelli, A. and Barone, G. and Barr, A. J. and Barr, J. D. and Barranco Navarro, L. and Barreiro, F. and Barreiro Guimar\~{a}es da Costa, J. and Barron, U. and Barros Teixeira, M. G. and Barsov, S. and Bartels, F. and Bartoldus, R. and Barton, A. E. and Bartos, P. and Basan, A. and Baselga, M. and Bassalat, A. and Basso, M. J. and Basson, C. R. and Bates, R. L. and Batlamous, S. and Batley, J. R. and Batool, B. and Battaglia, M. and Battulga, D. and Bauce, M. and Bauer, M. and Bauer, P. and Bazzano Hurrell, L. T. and Beacham, J. B. and Beau, T. and Beauchemin, P. H. and Becherer, F. and Bechtle, P. and Beck, H. P. and Becker, K. and Beddall, A. J. and Bednyakov, V. A. and Bee, C. P. and Beemster, L. J. and Beermann, T. A. and Begalli, M. and Begel, M. and Behera, A. and Behr, J. K. and Beirer, J. F. and Beisiegel, F. and Belfkir, M. and Bella, G. and Bellagamba, L. and Bellerive, A. and Bellos, P. and Beloborodov, K. and Belyaev, N. L. and Benchekroun, D. and Bendebba, F. and Benhammou, Y. and Benoit, M. and Bensinger, J. R. and Bentvelsen, S. and Beresford, L. and Beretta, M. and Bergeaas Kuutmann, E. and Berger, N. and Bergmann, B. and Beringer, J. and Bernardi, G. and Bernius, C. and Bernlochner, F. U. and Bernon, F. and Berry, T. and Berta, P. and Berthold, A. and Bertram, I. A. and Bethke, S. and Betti, A. and Bevan, A. J. and Bhamjee, M. and Bhatta, S. and Bhattacharya, D. S. and Bhattarai, P. and Bhopatkar, V. S. and Bi, R. and Bianchi, R. M. and Bianco, G. and Biebel, O. and Bielski, R. and Biglietti, M. and Billoud, T. R. V. and Bindi, M. and Bingul, A. and Bini, C. and Biondini, A. and Birch-sykes, C. J. and Bird, G. A. and Birman, M. and Biros, M. and Biryukov, S. and Bisanz, T. and Bisceglie, E. and Biswal, J. P. and Biswas, D. and Bitadze, A. and Bj\o{}rke, K. and Bloch, I. and Blocker, C. and Blue, A. and Blumenschein, U. and Blumenthal, J. and Bobbink, G. J. and Bobrovnikov, V. S. and Boehler, M. and Boehm, B. and Bogavac, D. and Bogdanchikov, A. G. and Bohm, C. and Boisvert, V. and Bokan, P. and Bold, T. and Bomben, M. and Bona, M. and Boonekamp, M. and Booth, C. D. and Borb\'{e}ly, A. G. and Bordulev, I. S. and Borecka-Bielska, H. M. and Borgna, L. S. and Borissov, G. and Bortoletto, D. and Boscherini, D. and Bosman, M. and Bossio Sola, J. D. and Bouaouda, K. and Bouchhar, N. and Boudreau, J. and Bouhova-Thacker, E. V. and Boumediene, D. and Bouquet, R. and Boveia, A. and Boyd, J. and Boye, D. and Boyko, I. R. and Bracinik, J. and Brahimi, N. and Brandt, G. and Brandt, O. and Braren, F. and Brau, B. and Brau, J. E. and Brener, R. and Brenner, L. and Brenner, R. and Bressler, S. and Britton, D. and Britzger, D. and Brock, I. and Brooijmans, G. and Brooks, W. K. and Brost, E. and Brown, L. M. and Bruce, L. E. and Bruckler, T. L. and Bruckman de Renstrom, P. A. and Br\"{u}ers, B. and Bruni, A. and Bruni, G. and Bruschi, M. and Bruscino, N. and Buanes, T. and Buat, Q. and Buchin, D. and Buckley, A. G. and Bulekov, O. and Bullard, B. A. and Burdin, S. and Burgard, C. D. and Burger, A. M. and Burghgrave, B. and Burlayenko, O. and Burr, J. T. P. and Burton, C. D. and Burzynski, J. C. and Busch, E. L. and B\"{u}scher, V. and Bussey, P. J. and Butler, J. M. and Buttar, C. M. and Butterworth, J. M. and Buttinger, W. and Buxo Vazquez, C. J. and Buzykaev, A. R. and Cabrera Urb\'{a}n, S. and Cadamuro, L. and Caforio, D. and Cai, H. and Cai, Y. and Cairo, V. M. M. and Cakir, O. and Calace, N. and Calafiura, P. and Calderini, G. and Calfayan, P. and Callea, G. and Caloba, L. P. and Calvet, D. and Calvet, S. and Calvet, T. P. and Calvetti, M. and Camacho Toro, R. and Camarda, S. and Camarero Munoz, D. and Camarri, P. and Camerlingo, M. T. and Cameron, D. and Camincher, C. and Campanelli, M. and Camplani, A. and Canale, V. and Canesse, A. and Cantero, J. and Cao, Y. and Capocasa, F. and Capua, M. and Carbone, A. and Cardarelli, R. and Cardenas, J. C. J. and Cardillo, F. and Carli, T. and Carlino, G. and Carlotto, J. I. and Carlson, B. T. and Carlson, E. M. and Carminati, L. and Carnelli, A. and Carnesale, M. and Caron, S. and Carquin, E. and Carr\'{a}, S. and Carratta, G. and Carrio Argos, F. and Carter, J. W. S. and Carter, T. M. and Casado, M. P. and Caspar, M. and Castiglia, E. G. and Castillo, F. L. and Castillo Garcia, L. and Castillo Gimenez, V. and Castro, N. F. and Catinaccio, A. and Catmore, J. R. and Cavaliere, V. and Cavalli, N. and Cavasinni, V. and Cekmecelioglu, Y. C. and Celebi, E. and Celli, F. and Centonze, M. S. and Cepaitis, V. and Cerny, K. and Cerqueira, A. S. and Cerri, A. and Cerrito, L. and Cerutti, F. and Cervato, B. and Cervelli, A. and Cesarini, G. and Cetin, S. A. and Chadi, Z. and Chakraborty, D. and Chan, J. and Chan, W. Y. and Chapman, J. D. and Chapon, E. and Chargeishvili, B. and Charlton, D. G. and Charman, T. P. and Chatterjee, M. and Chauhan, C. and Chekanov, S. and Chekulaev, S. V. and Chelkov, G. A. and Chen, A. and Chen, B. and Chen, B. and Chen, H. and Chen, H. and Chen, J. and Chen, J. and Chen, M. and Chen, S. and Chen, S. J. and Chen, X. and Chen, X. and Chen, Y. and Cheng, C. L. and Cheng, H. C. and Cheong, S. and Cheplakov, A. and Cheremushkina, E. and Cherepanova, E. and Cherkaoui El Moursli, R. and Cheu, E. and Cheung, K. and Chevalier, L. and Chiarella, V. and Chiarelli, G. and Chiedde, N. and Chiodini, G. and Chisholm, A. S. and Chitan, A. and Chitishvili, M. and Chizhov, M. V. and Choi, K. and Chomont, A. R. and Chou, Y. and Chow, E. Y. S. and Chowdhury, T. and Chu, K. L. and Chu, M. C. and Chu, X. and Chudoba, J. and Chwastowski, J. J. and Cieri, D. and Ciesla, K. M. and Cindro, V. and Ciocio, A. and Cirotto, F. and Citron, Z. H. and Citterio, M. and Ciubotaru, D. A. and Ciungu, B. M. and Clark, A. and Clark, P. J. and Clavijo Columbie, J. M. and Clawson, S. E. and Clement, C. and Clercx, J. and Coadou, Y. and Cobal, M. and Coccaro, A. and Barrue, R. F. Coelho and Coelho Lopes De Sa, R. and Coelli, S. and Cohen, H. and Coimbra, A. E. C. and Cole, B. and Collot, J. and Conde Mui\~{n}o, P. and Connell, M. P. and Connell, S. H. and Connelly, I. A. and Conroy, E. I. and Conventi, F. and Cooke, H. G. and Cooper-Sarkar, A. M. and Cordeiro Oudot Choi, A. and Cormier, F. and Corpe, L. D. and Corradi, M. and Corriveau, F. and Cortes-Gonzalez, A. and Costa, M. J. and Costanza, F. and Costanzo, D. and Cote, B. M. and Cowan, G. and Cranmer, K. and Cremonini, D. and Cr\'{e}p\'{e}-Renaudin, S. and Crescioli, F. and Cristinziani, M. and Cristoforetti, M. and Croft, V. and Crosby, J. E. and Crosetti, G. and Cueto, A. and Cuhadar Donszelmann, T. and Cui, H. and Cui, Z. and Cunningham, W. R. and Curcio, F. and Czodrowski, P. and Czurylo, M. M. and De Sousa, M. J. Da Cunha Sargedas and Da Fonseca Pinto, J. V. and Da Via, C. and Dabrowski, W. and Dado, T. and Dahbi, S. and Dai, T. and Dal Santo, D. and Dallapiccola, C. and Dam, M. and D'amen, G. and D'Amico, V. and Damp, J. and Dandoy, J. R. and Daneri, M. F. and Danninger, M. and Dao, V. and Darbo, G. and Darmora, S. and Das, S. J. and D'Auria, S. and David, C. and Davidek, T. and Davis-Purcell, B. and Dawson, I. and Day-hall, H. A. and De, K. and De Asmundis, R. and De Biase, N. and De Castro, S. and De Groot, N. and de Jong, P. and De la Torre, H. and De Maria, A. and De Salvo, A. and De Sanctis, U. and De Santo, A. and De Vivie De Regie, J. B. and Dedovich, D. V. and Degens, J. and Deiana, A. M. and Del Corso, F. and Del Peso, J. and Del Rio, F. and Deliot, F. and Delitzsch, C. M. and Della Pietra, M. and Della Volpe, D. and Dell'Acqua, A. and Dell'Asta, L. and Delmastro, M. and Delsart, P. A. and Demers, S. and Demichev, M. and Denisov, S. P. and D'Eramo, L. and Derendarz, D. and Derue, F. and Dervan, P. and Desch, K. and Deutsch, C. and Di Bello, F. A. and Di Ciaccio, A. and Di Ciaccio, L. and Di Domenico, A. and Di Donato, C. and Di Girolamo, A. and Di Gregorio, G. and Di Luca, A. and Di Micco, B. and Di Nardo, R. and Diaconu, C. and Diamantopoulou, M. and Dias, F. A. and Vale, T. Dias Do and Diaz, M. A. and Diaz Capriles, F. G. and Didenko, M. and Diehl, E. B. and Diehl, L. and D\'{\i}ez Cornell, S. and Diez Pardos, C. and Dimitriadi, C. and Dimitrievska, A. and Dingfelder, J. and Dinu, I-M. and Dittmeier, S. J. and Dittus, F. and Djama, F. and Djobava, T. and Djuvsland, J. I. and Doglioni, C. and Dohnalova, A. and Dolejsi, J. and Dolezal, Z. and Dona, K. M. and Donadelli, M. and Dong, B. and Donini, J. and D'Onofrio, A. and D'Onofrio, M. and Dopke, J. and Doria, A. and Dos Santos Fernandes, N. and Dougan, P. and Dova, M. T. and Doyle, A. T. and Draguet, M. A. and Dreyer, E. and Drivas-koulouris, I. and Drobac, A. S. and Drozdova, M. and Du, D. and du Pree, T. A. and Dubinin, F. and Dubovsky, M. and Duchovni, E. and Duckeck, G. and Ducu, O. A. and Duda, D. and Dudarev, A. and Duden, E. R. and D'uffizi, M. and Duflot, L. and D\"{u}hrssen, M. and D\"{u}lsen, C. and Dumitriu, A. E. and Dunford, M. and Dungs, S. and Dunne, K. and Duperrin, A. and Yildiz, H. Duran and D\"{u}ren, M. and Durglishvili, A. and Dwyer, B. L. and Dyckes, G. I. and Dyndal, M. and Dysch, S. and Dziedzic, B. S. and Earnshaw, Z. O. and Eberwein, G. H. and Eckerova, B. and Eggebrecht, S. and Purcino De Souza, E. Egidio and Ehrke, L. F. and Eigen, G. and Einsweiler, K. and Ekelof, T. and Ekman, P. A. and El Farkh, S. and El Ghazali, Y. and El Jarrari, H. and El Moussaouy, A. and Ellajosyula, V. and Ellert, M. and Ellinghaus, F. and Elliot, A. A. and Ellis, N. and Elmsheuser, J. and Elsing, M. and Emeliyanov, D. and Enari, Y. and Ene, I. and Epari, S. and Erdmann, J. and Erland, P. A. and Errenst, M. and Escalier, M. and Escobar, C. and Etzion, E. and Evans, G. and Evans, H. and Evans, L. S. and Evans, M. O. and Ezhilov, A. and Ezzarqtouni, S. and Fabbri, F. and Fabbri, L. and Facini, G. and Fadeyev, V. and Fakhrutdinov, R. M. and Falciano, S. and Falda Ulhoa Coelho, L. F. and Falke, P. J. and Faltova, J. and Fan, C. and Fan, Y. and Fang, Y. and Fanti, M. and Faraj, M. and Farazpay, Z. and Farbin, A. and Farilla, A. and Farooque, T. and Farrington, S. M. and Fassi, F. and Fassouliotis, D. and Faucci Giannelli, M. and Fawcett, W. J. and Fayard, L. and Federic, P. and Federicova, P. and Fedin, O. L. and Fedotov, G. and Feickert, M. and Feligioni, L. and Fellers, D. E. and Feng, C. and Feng, M. and Feng, Z. and Fenton, M. J. and Fenyuk, A. B. and Ferencz, L. and Ferguson, R. A. M. and Fernandez Luengo, S. I. and Fernoux, M. J. V. and Ferrando, J. and Ferrari, A. and Ferrari, P. and Ferrari, R. and Ferrere, D. and Ferretti, C. and Fiedler, F. and Filip\v{c}i\v{c}, A. and Filmer, E. K. and Filthaut, F. and Fiolhais, M. C. N. and Fiorini, L. and Fisher, W. C. and Fitschen, T. and Fitzhugh, P. M. and Fleck, I. and Fleischmann, P. and Flick, T. and Flores, M. and Flores Castillo, L. R. and Flores Sanz De Acedo, L. and Follega, F. M. and Fomin, N. and Foo, J. H. and Forland, B. C. and Formica, A. and Forti, A. C. and Fortin, E. and Fortman, A. W. and Foti, M. G. and Fountas, L. and Fournier, D. and Fox, H. and Francavilla, P. and Francescato, S. and Franchellucci, S. and Franchini, M. and Franchino, S. and Francis, D. and Franco, L. and Franconi, L. and Franklin, M. and Frattari, G. and Freegard, A. C. and Freund, W. S. and Frid, Y. Y. and Friend, J. and Fritzsche, N. and Froch, A. and Froidevaux, D. and Frost, J. A. and Fu, Y. and Fujimoto, M. and Fullana Torregrosa, E. and Fung, K. Y. and De Simas Filho, E. Furtado and Furukawa, M. and Fuster, J. and Gabrielli, A. and Gabrielli, A. and Gadow, P. and Gagliardi, G. and Gagnon, L. G. and Gallas, E. J. and Gallop, B. J. and Gan, K. K. and Ganguly, S. and Gao, J. and Gao, Y. and Garay Walls, F. M. and Garcia, B. and Garc\'{\i}a, C. and Garcia Alonso, A. and Garcia Caffaro, A. G. and Garc\'{\i}a Navarro, J. E. and Garcia-Sciveres, M. and Gardner, G. L. and Gardner, R. W. and Garelli, N. and Garg, D. and Garg, R. B. and Gargan, J. M. and Garner, C. A. and Gasiorowski, S. J. and Gaspar, P. and Gaudio, G. and Gautam, V. and Gauzzi, P. and Gavrilenko, I. L. and Gavrilyuk, A. and Gay, C. and Gaycken, G. and Gazis, E. N. and Geanta, A. A. and Gee, C. M. and Gemme, C. and Genest, M. H. and Gentile, S. and Gentry, A. D. and George, S. and George, W. F. and Geralis, T. and Gessinger-Befurt, P. and Geyik, M. E. and Ghani, M. and Ghneimat, M. and Ghorbanian, K. and Ghosal, A. and Ghosh, A. and Ghosh, A. and Giacobbe, B. and Giagu, S. and Giani, T. and Giannetti, P. and Giannini, A. and Gibson, S. M. and Gignac, M. and Gil, D. T. and Gilbert, A. K. and Gilbert, B. J. and Gillberg, D. and Gilles, G. and Gillwald, N. E. K. and Ginabat, L. and Gingrich, D. M. and Giordani, M. P. and Giraud, P. F. and Giugliarelli, G. and Giugni, D. and Giuli, F. and Gkialas, I. and Gladilin, L. K. and Glasman, C. and Gledhill, G. R. and Glem\v{z}a, G. and Glisic, M. and Gnesi, I. and Go, Y. and Goblirsch-Kolb, M. and Gocke, B. and Godin, D. and Gokturk, B. and Goldfarb, S. and Golling, T. and Gololo, M. G. D. and Golubkov, D. and Gombas, J. P. and Gomes, A. and Gomes Da Silva, G. and Gomez Delegido, A. J. and Gon\c{c}alo, R. and Gonella, G. and Gonella, L. and Gongadze, A. and Gonnella, F. and Gonski, J. L. and Gonz\'{a}lez Andana, R. Y. and Gonz\'{a}lez de la Hoz, S. and Gonzalez Fernandez, S. and Gonzalez Lopez, R. and Gonzalez Renteria, C. and Gonzalez Rodrigues, M. V. and Gonzalez Suarez, R. and Gonzalez-Sevilla, S. and Gonzalvo Rodriguez, G. R. and Goossens, L. and Gorini, B. and Gorini, E. and Gori\v{s}ek, A. and Gosart, T. C. and Goshaw, A. T. and Gostkin, M. I. and Goswami, S. and Gottardo, C. A. and Gotz, S. A. and Gouighri, M. and Goumarre, V. and Goussiou, A. G. and Govender, N. and Grabowska-Bold, I. and Graham, K. and Gramstad, E. and Grancagnolo, S. and Grandi, M. and Grant, C. M. and Gravila, P. M. and Gravili, F. G. and Gray, H. M. and Greco, M. and Grefe, C. and Gregor, I. M. and Grenier, P. and Grieco, C. and Grillo, A. A. and Grimm, K. and Grinstein, S. and Grivaz, J.-F. and Gross, E. and Grosse-Knetter, J. and Grud, C. and Grundy, J. C. and Guan, L. and Guan, W. and Gubbels, C. and Guerrero Rojas, J. G. R. and Guerrieri, G. and Guescini, F. and Gugel, R. and Guhit, J. A. M. and Guida, A. and Guillemin, T. and Guilloton, E. and Guindon, S. and Guo, F. and Guo, J. and Guo, L. and Guo, Y. and Gupta, R. and Gurbuz, S. and Gurdasani, S. S. and Gustavino, G. and Guth, M. and Gutierrez, P. and Gutierrez Zagazeta, L. F. and Gutschow, C. and Gwenlan, C. and Gwilliam, C. B. and Haaland, E. S. and Haas, A. and Habedank, M. and Haber, C. and Hadavand, H. K. and Hadef, A. and Hadzic, S. and Hahn, J. J. and Haines, E. H. and Haleem, M. and Haley, J. and Hall, J. J. and Hallewell, G. D. and Halser, L. and Hamano, K. and Hamer, M. and Hamity, G. N. and Hampshire, E. J. and Han, J. and Han, K. and Han, L. and Han, L. and Han, S. and Han, Y. F. and Hanagaki, K. and Hance, M. and Hangal, D. A. and Hanif, H. and Hank, M. D. and Hankache, R. and Hansen, J. B. and Hansen, J. D. and Hansen, P. H. and Hara, K. and Harada, D. and Harenberg, T. and Harkusha, S. and Harris, M. L. and Harris, Y. T. and Harrison, J. and Harrison, N. M. and Harrison, P. F. and Hartman, N. M. and Hartmann, N. M. and Hasegawa, Y. and Hasib, A. and Haug, S. and Hauser, R. and Hawkes, C. M. and Hawkings, R. J. and Hayashi, Y. and Hayashida, S. and Hayden, D. and Hayes, C. and Hayes, R. L. and Hays, C. P. and Hays, J. M. and Hayward, H. S. and He, F. and He, M. and He, Y. and He, Y. and Heatley, N. B. and Hedberg, V. and Heggelund, A. L. and Hehir, N. D. and Heidegger, C. and Heidegger, K. K. and Heidorn, W. D. and Heilman, J. and Heim, S. and Heim, T. and Heinlein, J. G. and Heinrich, J. J. and Heinrich, L. and Hejbal, J. and Helary, L. and Held, A. and Hellesund, S. and Helling, C. M. and Hellman, S. and Henderson, R. C. W. and Henkelmann, L. and Henriques Correia, A. M. and Herde, H. and Hern\'{a}ndez Jim\'{e}nez, Y. and Herrmann, L. M. and Herrmann, T. and Herten, G. and Hertenberger, R. and Hervas, L. and Hesping, M. E. and Hessey, N. P. and Hibi, H. and Hillier, S. J. and Hinds, J. R. and Hinterkeuser, F. and Hirose, M. and Hirose, S. and Hirschbuehl, D. and Hitchings, T. G. and Hiti, B. and Hobbs, J. and Hobincu, R. and Hod, N. and Hodgkinson, M. C. and Hodkinson, B. H. and Hoecker, A. and Hofer, J. and Holm, T. and Holzbock, M. and Hommels, L. B. A. H. and Honan, B. P. and Hong, J. and Hong, T. M. and Hooberman, B. H. and Hopkins, W. H. and Horii, Y. and Hou, S. and Howard, A. S. and Howarth, J. and Hoya, J. and Hrabovsky, M. and Hrynevich, A. and Hryn'ova, T. and Hsu, P. J. and Hsu, S.-C. and Hu, Q. and Hu, Y. F. and Huang, S. and Huang, X. and Huang, Y. and Huang, Y. and Huang, Z. and Hubacek, Z. and Huebner, M. and Huegging, F. and Huffman, T. B. and Hugli, C. A. and Huhtinen, M. and Huiberts, S. K. and Hulsken, R. and Huseynov, N. and Huston, J. and Huth, J. and Hyneman, R. and Iacobucci, G. and Iakovidis, G. and Ibragimov, I. and Iconomidou-Fayard, L. and Iengo, P. and Iguchi, R. and Iizawa, T. and Ikegami, Y. and Ilic, N. and Imam, H. and Ince Lezki, M. and Ingebretsen Carlson, T. and Introzzi, G. and Iodice, M. and Ippolito, V. and Irwin, R. K. and Ishino, M. and Islam, W. and Issever, C. and Istin, S. and Ito, H. and Iturbe Ponce, J. M. and Iuppa, R. and Ivina, A. and Izen, J. M. and Izzo, V. and Jacka, P. and Jackson, P. and Jacobs, R. M. and Jaeger, B. P. and Jagfeld, C. S. and Jain, G. and Jain, P. and J\"{a}kel, G. and Jakobs, K. and Jakoubek, T. and Jamieson, J. and Janas, K. W. and Javurkova, M. and Jeanneau, F. and Jeanty, L. and Jejelava, J. and Jenni, P. and Jessiman, C. E. and J\'{e}z\'{e}quel, S. and Jia, C. and Jia, J. and Jia, X. and Jia, X. and Jia, Z. and Jiang, Y. and Jiggins, S. and Jimenez Pena, J. and Jin, S. and Jinaru, A. and Jinnouchi, O. and Johansson, P. and Johns, K. A. and Johnson, J. W. and Jones, D. M. and Jones, E. and Jones, P. and Jones, R. W. L. and Jones, T. J. and Joos, H. L. and Joshi, R. and Jovicevic, J. and Ju, X. and Junggeburth, J. J. and Junkermann, T. and Juste Rozas, A. and Juzek, M. K. and Kabana, S. and Kaczmarska, A. and Kado, M. and Kagan, H. and Kagan, M. and Kahn, A. and Kahn, A. and Kahra, C. and Kaji, T. and Kajomovitz, E. and Kakati, N. and Kalaitzidou, I. and Kalderon, C. W. and Kamenshchikov, A. and Kang, N. J. and Kar, D. and Karava, K. and Kareem, M. J. and Karentzos, E. and Karkanias, I. and Karkout, O. and Karpov, S. N. and Karpova, Z. M. and Kartvelishvili, V. and Karyukhin, A. N. and Kasimi, E. and Katzy, J. and Kaur, S. and Kawade, K. and Kawale, M. P. and Kawamoto, T. and Kay, E. F. and Kaya, F. I. and Kazakos, S. and Kazanin, V. F. and Ke, Y. and Keaveney, J. M. and Keeler, R. and Kehris, G. V. and Keller, J. S. and Kelly, A. S. and Kempster, J. J. and Kennedy, K. E. and Kennedy, P. D. and Kepka, O. and Kerridge, B. P. and Kersten, S. and Ker\v{s}evan, B. P. and Keshri, S. and Keszeghova, L. and Ketabchi Haghighat, S. and Khandoga, M. and Khanov, A. and Kharlamov, A. G. and Kharlamova, T. and Khoda, E. E. and Khoo, T. J. and Khoriauli, G. and Khubua, J. and Khwaira, Y. A. R. and Kilgallon, A. and Kim, D. W. and Kim, Y. K. and Kimura, N. and Kingston, M. K. and Kirchhoff, A. and Kirfel, C. and Kirfel, F. and Kirk, J. and Kiryunin, A. E. and Kitsaki, C. and Kivernyk, O. and Klassen, M. and Klein, C. and Klein, L. and Klein, M. H. and Klein, M. and Klein, S. B. and Klein, U. and Klimek, P. and Klimentov, A. and Klioutchnikova, T. and Kluit, P. and Kluth, S. and Kneringer, E. and Knight, T. M. and Knue, A. and Kobayashi, R. and Kobylianskii, D. and Koch, S. F. and Kocian, M. and Kody\v{s}, P. and Koeck, D. M. and Koenig, P. T. and Koffas, T. and Kolb, M. and Koletsou, I. and Komarek, T. and K\"{o}neke, K. and Kong, A. X. Y. and Kono, T. and Konstantinidis, N. and Konya, B. and Kopeliansky, R. and Koperny, S. and Korcyl, K. and Kordas, K. and Koren, G. and Korn, A. and Korn, S. and Korolkov, I. and Korotkova, N. and Kortman, B. and Kortner, O. and Kortner, S. and Kostecka, W. H. and Kostyukhin, V. V. and Kotsokechagia, A. and Kotwal, A. and Koulouris, A. and Kourkoumeli-Charalampidi, A. and Kourkoumelis, C. and Kourlitis, E. and Kovanda, O. and Kowalewski, R. and Kozanecki, W. and Kozhin, A. S. and Kramarenko, V. A. and Kramberger, G. and Kramer, P. and Krasny, M. W. and Krasznahorkay, A. and Kraus, J. W. and Kremer, J. A. and Kresse, T. and Kretzschmar, J. and Kreul, K. and Krieger, P. and Krishnamurthy, S. and Krivos, M. and Krizka, K. and Kroeninger, K. and Kroha, H. and Kroll, J. and Kroll, J. and Krowpman, K. S. and Kruchonak, U. and Kr\"{u}ger, H. and Krumnack, N. and Kruse, M. C. and Krzysiak, J. A. and Kuchinskaia, O. and Kuday, S. and Kuehn, S. and Kuesters, R. and Kuhl, T. and Kukhtin, V. and Kulchitsky, Y. and Kuleshov, S. and Kumar, M. and Kumari, N. and Kupco, A. and Kupfer, T. and Kupich, A. and Kuprash, O. and Kurashige, H. and Kurchaninov, L. L. and Kurdysh, O. and Kurochkin, Y. A. and Kurova, A. and Kuze, M. and Kvam, A. K. and Kvita, J. and Kwan, T. and Kyriacou, N. G. and Laatu, L. A. O. and Lacasta, C. and Lacava, F. and Lacker, H. and Lacour, D. and Lad, N. N. and Ladygin, E. and Laforge, B. and Lagouri, T. and Lahbabi, F. Z. and Lai, S. and Lakomiec, I. K. and Lalloue, N. and Lambert, J. E. and Lammers, S. and Lampl, W. and Lampoudis, C. and Lancaster, A. N. and Lan\c{c}on, E. and Landgraf, U. and Landon, M. P. J. and Lang, V. S. and Langenberg, R. J. and Langrekken, O. K. B. and Lankford, A. J. and Lanni, F. and Lantzsch, K. and Lanza, A. and Lapertosa, A. and Laporte, J. F. and Lari, T. and Lasagni Manghi, F. and Lassnig, M. and Latonova, V. and Laudrain, A. and Laurier, A. and Lawlor, S. D. and Lawrence, Z. and Lazzaroni, M. and Le, B. and Le Boulicaut, E. M. and Leban, B. and Lebedev, A. and LeBlanc, M. and Ledroit-Guillon, F. and Lee, A. C. A. and Lee, S. C. and Lee, S. and Lee, T. F. and Leeuw, L. L. and Lefebvre, H. P. and Lefebvre, M. and Leggett, C. and Lehmann Miotto, G. and Leigh, M. and Leight, W. A. and Leinonen, W. and Leisos, A. and Leite, M. A. L. and Leitgeb, C. E. and Leitner, R. and Leney, K. J. C. and Lenz, T. and Leone, S. and Leonidopoulos, C. and Leopold, A. and Leroy, C. and Les, R. and Lester, C. G. and Levchenko, M. and Lev\^{e}que, J. and Levin, D. and Levinson, L. J. and Lewicki, M. P. and Lewis, D. J. and Li, A. and Li, B. and Li, C. and Li, C-Q. and Li, H. and Li, H. and Li, H. and Li, H. and Li, H. and Li, K. and Li, L. and Li, M. and Li, Q. Y. and Li, S. and Li, S. and Li, T. and Li, X. and Li, Z. and Li, Z. and Li, Z. and Li, Z. and Liang, S. and Liang, Z. and Liberatore, M. and Liberti, B. and Lie, K. and Lieber Marin, J. and Lien, H. and Lin, K. and Lindley, R. E. and Lindon, J. H. and Lipeles, E. and Lipniacka, A. and Lister, A. and Little, J. D. and Liu, B. and Liu, B. X. and Liu, D. and Liu, J. B. and Liu, J. K. K. and Liu, K. and Liu, M. and Liu, M. Y. and Liu, P. and Liu, Q. and Liu, X. and Liu, Y. and Liu, Y. L. and Liu, Y. W. and Llorente Merino, J. and Lloyd, S. L. and Lobodzinska, E. M. and Loch, P. and Loffredo, S. and Lohse, T. and Lohwasser, K. and Loiacono, E. and Lokajicek, M. and Lomas, J. D. and Long, J. D. and Longarini, I. and Longo, L. and Longo, R. and Lopez Paz, I. and Lopez Solis, A. and Lorenz, J. and Lorenzo Martinez, N. and Lory, A. M. and L\"{o}schcke Centeno, G. and Loseva, O. and Lou, X. and Lou, X. and Lounis, A. and Love, J. and Love, P. A. and Lu, G. and Lu, M. and Lu, S. and Lu, Y. J. and Lubatti, H. J. and Luci, C. and Lucio Alves, F. L. and Lucotte, A. and Luehring, F. and Luise, I. and Lukianchuk, O. and Lundberg, O. and Lund-Jensen, B. and Luongo, N. A. and Lutz, M. S. and Lynn, D. and Lyons, H. and Lysak, R. and Lytken, E. and Lyubushkin, V. and Lyubushkina, T. and Lyukova, M. M. and Ma, H. and Ma, K. and Ma, L. L. and Ma, Y. and Mac Donell, D. M. and Maccarrone, G. and MacDonald, J. C. and Machado De Abreu Farias, P. C. and Madar, R. and Mader, W. F. and Madula, T. and Maeda, J. and Maeno, T. and Maerker, M. and Maguire, H. and Maiboroda, V. and Maio, A. and Maj, K. and Majersky, O. and Majewski, S. and Makovec, N. and Maksimovic, V. and Malaescu, B. and Malecki, Pa. and Maleev, V. P. and Malek, F. and Mali, M. and Malito, D. and Mallik, U. and Maltezos, S. and Malyukov, S. and Mamuzic, J. and Mancini, G. and Manco, G. and Mandalia, J. P. and Mandi\'{c}, I. and Manhaes de Andrade Filho, L. and Maniatis, I. M. and Manjarres Ramos, J. and Mankad, D. C. and Mann, A. and Mansoulie, B. and Manzoni, S. and Marantis, A. and Marchiori, G. and Marcisovsky, M. and Marcon, C. and Marinescu, M. and Marjanovic, M. and Marshall, E. J. and Marshall, Z. and Marti-Garcia, S. and Martin, T. A. and Martin, V. J. and Martin dit Latour, B. and Martinelli, L. and Martinez, M. and Martinez Agullo, P. and Martinez Outschoorn, V. I. and Martinez Suarez, P. and Martin-Haugh, S. and Martoiu, V. S. and Martyniuk, A. C. and Marzin, A. and Mascione, D. and Masetti, L. and Mashimo, T. and Masik, J. and Maslennikov, A. L. and Massa, L. and Massarotti, P. and Mastrandrea, P. and Mastroberardino, A. and Masubuchi, T. and Mathisen, T. and Matousek, J. and Matsuzawa, N. and Maurer, J. and Ma\v{c}ek, B. and Maximov, D. A. and Mazini, R. and Maznas, I. and Mazza, M. and Mazza, S. M. and Mazzeo, E. and Mc Ginn, C. and Mc Gowan, J. P. and Mc Kee, S. P. and McDonald, E. F. and McDougall, A. E. and Mcfayden, J. A. and McGovern, R. P. and Mchedlidze, G. and Mckenzie, R. P. and Mclachlan, T. C. and Mclaughlin, D. J. and McLean, K. D. and McMahon, S. J. and McNamara, P. C. and Mcpartland, C. M. and McPherson, R. A. and Mehlhase, S. and Mehta, A. and Melini, D. and Mellado Garcia, B. R. and Melo, A. H. and Meloni, F. and Mendes Jacques Da Costa, A. M. and Meng, H. Y. and Meng, L. and Menke, S. and Mentink, M. and Meoni, E. and Merlassino, C. and Merola, L. and Meroni, C. and Merz, G. and Meshkov, O. and Metcalfe, J. and Mete, A. S. and Meyer, C. and Meyer, J-P. and Middleton, R. P. and Mijovi\'{c}, L. and Mikenberg, G. and Mikestikova, M. and Miku\v{z}, M. and Mildner, H. and Milic, A. and Milke, C. D. and Miller, D. W. and Miller, L. S. and Milov, A. and Milstead, D. A. and Min, T. and Minaenko, A. A. and Minashvili, I. A. and Mince, L. and Mincer, A. I. and Mindur, B. and Mineev, M. and Mino, Y. and Mir, L. M. and Miralles Lopez, M. and Mironova, M. and Mishima, A. and Missio, M. C. and Mitra, A. and Mitsou, V. A. and Mitsumori, Y. and Miu, O. and Miyagawa, P. S. and Mkrtchyan, T. and Mlinarevic, M. and Mlinarevic, T. and Mlynarikova, M. and Mobius, S. and Moder, P. and Mogg, P. and Mohammed, A. F. and Mohapatra, S. and Mokgatitswane, G. and Moleri, L. and Mondal, B. and Mondal, S. and M\"{o}nig, K. and Monnier, E. and Monsonis Romero, L. and Montejo Berlingen, J. and Montella, M. and Montereali, F. and Monticelli, F. and Monzani, S. and Morange, N. and De Carvalho, A. L. Moreira and Moreno Ll\'{a}cer, M. and Moreno Martinez, C. and Morettini, P. and Morgenstern, S. and Morii, M. and Morinaga, M. and Morley, A. K. and Morodei, F. and Morvaj, L. and Moschovakos, P. and Moser, B. and Mosidze, M. and Moskalets, T. and Moskvitina, P. and Moss, J. and Moyse, E. J. W. and Mtintsilana, O. and Muanza, S. and Mueller, J. and Muenstermann, D. and M\"{u}ller, R. and Mullier, G. A. and Mullin, A. J. and Mullin, J. J. and Mungo, D. P. and Munoz Perez, D. and Munoz Sanchez, F. J. and Murin, M. and Murray, W. J. and Murrone, A. and Muse, J. M. and Mu\v{s}kinja, M. and Mwewa, C. and Myagkov, A. G. and Myers, A. J. and Myers, A. A. and Myers, G. and Myska, M. and Nachman, B. P. and Nackenhorst, O. and Nag, A. and Nagai, K. and Nagano, K. and Nagle, J. L. and Nagy, E. and Nairz, A. M. and Nakahama, Y. and Nakamura, K. and Nakkalil, K. and Nanjo, H. and Narayan, R. and Narayanan, E. A. and Naryshkin, I. and Naseri, M. and Nasri, S. and Nass, C. and Navarro, G. and Navarro-Gonzalez, J. and Nayak, R. and Nayaz, A. and Nechaeva, P. Y. and Nechansky, F. and Nedic, L. and Neep, T. J. and Negri, A. and Negrini, M. and Nellist, C. and Nelson, C. and Nelson, K. and Nemecek, S. and Nessi, M. and Neubauer, M. S. and Neuhaus, F. and Neundorf, J. and Newhouse, R. and Newman, P. R. and Ng, C. W. and Ng, Y. W. Y. and Ngair, B. and Nguyen, H. D. N. and Nickerson, R. B. and Nicolaidou, R. and Nielsen, J. and Niemeyer, M. and Niermann, J. and Nikiforou, N. and Nikolaenko, V. and Nikolic-Audit, I. and Nikolopoulos, K. and Nilsson, P. and Ninca, I. and Nindhito, H. R. and Ninio, G. and Nisati, A. and Nishu, N. and Nisius, R. and Nitschke, J-E. and Nkadimeng, E. K. and Nobe, T. and Noel, D. L. and Nommensen, T. and Norfolk, M. B. and Norisam, R. R. B. and Norman, B. J. and Novak, J. and Novak, T. and Novotny, L. and Novotny, R. and Nozka, L. and Ntekas, K. and Nunes De Moura Junior, N. M. J. and Nurse, E. and Ocariz, J. and Ochi, A. and Ochoa, I. and Oerdek, S. and Offermann, J. T. and Ogrodnik, A. and Oh, A. and Ohm, C. C. and Oide, H. and Oishi, R. and Ojeda, M. L. and O'Keefe, M. W. and Okumura, Y. and Seabra, L. F. Oleiro and Olivares Pino, S. A. and Oliveira Damazio, D. and Oliveira Goncalves, D. and Oliver, J. L. and Olszewski, A. and \"{O}ncel, \"{O}. O. and O'Neill, A. P. and Onofre, A. and Onyisi, P. U. E. and Oreglia, M. J. and Orellana, G. E. and Orestano, D. and Orlando, N. and Orr, R. S. and O'Shea, V. and Osojnak, L. M. and Ospanov, R. and Otero y Garzon, G. and Otono, H. and Ott, P. S. and Ottino, G. J. and Ouchrif, M. and Ouellette, J. and Ould-Saada, F. and Owen, M. and Owen, R. E. and Oyulmaz, K. Y. and Ozcan, V. E. and Ozturk, N. and Ozturk, S. and Pacey, H. A. and Pacheco Pages, A. and Padilla Aranda, C. and Padovano, G. and Pagan Griso, S. and Palacino, G. and Palazzo, A. and Palestini, S. and Pan, J. and Pan, T. and Panchal, D. K. and Pandini, C. E. and Panduro Vazquez, J. G. and Pandya, H. D. and Pang, H. and Pani, P. and Panizzo, G. and Paolozzi, L. and Papadatos, C. and Parajuli, S. and Paramonov, A. and Paraskevopoulos, C. and Paredes Hernandez, D. and Park, T. H. and Parker, M. A. and Parodi, F. and Parrish, E. W. and Parrish, V. A. and Parsons, J. A. and Parzefall, U. and Pascual Dias, B. and Pascual Dominguez, L. and Pasqualucci, E. and Passaggio, S. and Pastore, F. and Pasuwan, P. and Patel, P. and Patel, U. M. and Pater, J. R. and Pauly, T. and Pearkes, J. and Pedersen, M. and Pedro, R. and Peleganchuk, S. V. and Penc, O. and Pender, E. A. and Peng, H. and Penski, K. E. and Penzin, M. and Peralva, B. S. and Peixoto, A. P. Pereira and Pereira Sanchez, L. and Perepelitsa, D. V. and Perez Codina, E. and Perganti, M. and Perini, L. and Pernegger, H. and Perrin, O. and Peters, K. and Peters, R. F. Y. and Petersen, B. A. and Petersen, T. C. and Petit, E. and Petousis, V. and Petridou, C. and Petrukhin, A. and Pettee, M. and Pettersson, N. E. and Petukhov, A. and Petukhova, K. and Pezoa, R. and Pezzotti, L. and Pezzullo, G. and Pham, T. M. and Pham, T. and Phillips, P. W. and Piacquadio, G. and Pianori, E. and Piazza, F. and Piegaia, R. and Pietreanu, D. and Pilkington, A. D. and Pinamonti, M. and Pinfold, J. L. and Pereira, B. C. Pinheiro and Pinto Pinoargote, A. E. and Pintucci, L. and Piper, K. M. and Pirttikoski, A. and Pizzi, D. A. and Pizzimento, L. and Pizzini, A. and Pleier, M.-A. and Plesanovs, V. and Pleskot, V. and Plotnikova, E. and Poddar, G. and Poettgen, R. and Poggioli, L. and Pokharel, I. and Polacek, S. and Polesello, G. and Poley, A. and Polifka, R. and Polini, A. and Pollard, C. S. and Pollock, Z. B. and Polychronakos, V. and Pompa Pacchi, E. and Ponomarenko, D. and Pontecorvo, L. and Popa, S. and Popeneciu, G. A. and Poreba, A. and Portillo Quintero, D. M. and Pospisil, S. and Postill, M. A. and Postolache, P. and Potamianos, K. and Potepa, P. A. and Potrap, I. N. and Potter, C. J. and Potti, H. and Poulsen, T. and Poveda, J. and Pozo Astigarraga, M. E. and Prades Ibanez, A. and Pretel, J. and Price, D. and Primavera, M. and Principe Martin, M. A. and Privara, R. and Procter, T. and Proffitt, M. L. and Proklova, N. and Prokofiev, K. and Proto, G. and Protopopescu, S. and Proudfoot, J. and Przybycien, M. and Przygoda, W. W. and Puddefoot, J. E. and Pudzha, D. and Pyatiizbyantseva, D. and Qian, J. and Qichen, D. and Qin, Y. and Qiu, T. and Quadt, A. and Queitsch-Maitland, M. and Quetant, G. and Quinn, R. P. and Rabanal Bolanos, G. and Rafanoharana, D. and Ragusa, F. and Rainbolt, J. L. and Raine, J. A. and Rajagopalan, S. and Ramakoti, E. and Ran, K. and Rapheeha, N. P. and Rasheed, H. and Raskina, V. and Rassloff, D. F. and Rave, S. and Ravina, B. and Ravinovich, I. and Raymond, M. and Read, A. L. and Readioff, N. P. and Rebuzzi, D. M. and Redlinger, G. and Reed, A. S. and Reeves, K. and Reidelsturz, J. A. and Reikher, D. and Rej, A. and Rembser, C. and Renardi, A. and Renda, M. and Rendel, M. B. and Renner, F. and Rennie, A. G. and Rescia, A. L. and Resconi, S. and Ressegotti, M. and Rettie, S. and Reyes Rivera, J. G. and Reynolds, E. and Rezanova, O. L. and Reznicek, P. and Ribaric, N. and Ricci, E. and Richter, R. and Richter, S. and Richter-Was, E. and Ridel, M. and Ridouani, S. and Rieck, P. and Riedler, P. and Riefel, E. M. and Rijssenbeek, M. and Rimoldi, A. and Rimoldi, M. and Rinaldi, L. and Rinn, T. T. and Rinnagel, M. P. and Ripellino, G. and Riu, I. and Rivadeneira, P. and Rivera Vergara, J. C. and Rizatdinova, F. and Rizvi, E. and Roberts, B. A. and Roberts, B. R. and Robertson, S. H. and Robinson, D. and Robles Gajardo, C. M. and Robles Manzano, M. and Robson, A. and Rocchi, A. and Roda, C. and Rodriguez Bosca, S. and Rodriguez Garcia, Y. and Rodriguez Rodriguez, A. and Rodr\'{\i}guez Vera, A. M. and Roe, S. and Roemer, J. T. and Roepe-Gier, A. R. and Roggel, J. and R\o{}hne, O. and Rojas, R. A. and Roland, C. P. A. and Roloff, J. and Romaniouk, A. and Romano, E. and Romano, M. and Romero Hernandez, A. C. and Rompotis, N. and Roos, L. and Rosati, S. and Rosser, B. J. and Rossi, E. and Rossi, E. and Rossi, L. P. and Rossini, L. and Rosten, R. and Rotaru, M. and Rottler, B. and Rougier, C. and Rousseau, D. and Rousso, D. and Roy, A. and Roy-Garand, S. and Rozanov, A. and Rozen, Y. and Ruan, X. and Rubio Jimenez, A. and Ruby, A. J. and Ruelas Rivera, V. H. and Ruggeri, T. A. and Ruggiero, A. and Ruiz-Martinez, A. and Rummler, A. and Rurikova, Z. and Rusakovich, N. A. and Russell, H. L. and Russo, G. and Rutherfoord, J. P. and Rutherford Colmenares, S. and Rybacki, K. and Rybar, M. and Rye, E. B. and Ryzhov, A. and Sabater Iglesias, J. A. and Sabatini, P. and Sabetta, L. and Sadrozinski, H. F-W. and Safai Tehrani, F. and Safarzadeh Samani, B. and Safdari, M. and Saha, S. and Sahinsoy, M. and Saimpert, M. and Saito, M. and Saito, T. and Salamani, D. and Salnikov, A. and Salt, J. and Salvador Salas, A. and Salvatore, D. and Salvatore, F. and Salzburger, A. and Sammel, D. and Sampsonidis, D. and Sampsonidou, D. and S\'{a}nchez, J. and Sanchez Pineda, A. and Sanchez Sebastian, V. and Sandaker, H. and Sander, C. O. and Sandesara, J. A. and Sandhoff, M. and Sandoval, C. and Sankey, D. P. C. and Sano, T. and Sansoni, A. and Santi, L. and Santoni, C. and Santos, H. and Santpur, S. N. and Santra, A. and Saoucha, K. A. and Saraiva, J. G. and Sardain, J. and Sasaki, O. and Sato, K. and Sauer, C. and Sauerburger, F. and Sauvan, E. and Savard, P. and Sawada, R. and Sawyer, C. and Sawyer, L. and Sayago Galvan, I. and Sbarra, C. and Sbrizzi, A. and Scanlon, T. and Schaarschmidt, J. and Schacht, P. and Schaefer, D. and Sch\"{a}fer, U. and Schaffer, A. C. and Schaile, D. and Schamberger, R. D. and Scharf, C. and Schefer, M. M. and Schegelsky, V. A. and Scheirich, D. and Schenck, F. and Schernau, M. and Scheulen, C. and Schiavi, C. and Schioppa, E. J. and Schioppa, M. and Schlag, B. and Schleicher, K. E. and Schlenker, S. and Schmeing, J. and Schmidt, M. A. and Schmieden, K. and Schmitt, C. and Schmitt, S. and Schoeffel, L. and Schoening, A. and Scholer, P. G. and Schopf, E. and Schott, M. and Schovancova, J. and Schramm, S. and Schroeder, F. and Schroer, T. and Schultz-Coulon, H-C. and Schumacher, M. and Schumm, B. A. and Schune, Ph. and Schuy, A. J. and Schwartz, H. R. and Schwartzman, A. and Schwarz, T. A. and Schwemling, Ph. and Schwienhorst, R. and Sciandra, A. and Sciolla, G. and Scuri, F. and Sebastiani, C. D. and Sedlaczek, K. and Seema, P. and Seidel, S. C. and Seiden, A. and Seidlitz, B. D. and Seitz, C. and Seixas, J. M. and Sekhniaidze, G. and Sekula, S. J. and Selem, L. and Semprini-Cesari, N. and Sengupta, D. and Senthilkumar, V. and Serin, L. and Serkin, L. and Sessa, M. and Severini, H. and Sforza, F. and Sfyrla, A. and Shabalina, E. and Shaheen, R. and Shahinian, J. D. and Shaked Renous, D. and Shan, L. Y. and Shapiro, M. and Sharma, A. and Sharma, A. S. and Sharma, P. and Sharma, S. and Shatalov, P. B. and Shaw, K. and Shaw, S. M. and Shcherbakova, A. and Shen, Q. and Sherwood, P. and Shi, L. and Shi, X. and Shimmin, C. O. and Shinner, J. D. and Shipsey, I. P. J. and Shirabe, S. and Shiyakova, M. and Shlomi, J. and Shochet, M. J. and Shojaii, J. and Shope, D. R. and Shrestha, B. and Shrestha, S. and Shrif, E. M. and Shroff, M. J. and Sicho, P. and Sickles, A. M. and Sideras Haddad, E. and Sidoti, A. and Siegert, F. and Sijacki, Dj. and Sikora, R. and Sili, F. and Silva, J. M. and Silva Oliveira, M. V. and Silverstein, S. B. and Simion, S. and Simoniello, R. and Simpson, E. L. and Simpson, H. and Simpson, L. R. and Simpson, N. D. and Simsek, S. and Sindhu, S. and Sinervo, P. and Singh, S. and Sinha, S. and Sinha, S. and Sioli, M. and Siral, I. and Sitnikova, E. and Sivoklokov, S. Yu. and Sj\"{o}lin, J. and Skaf, A. and Skorda, E. and Skubic, P. and Slawinska, M. and Smakhtin, V. and Smart, B. H. and Smiesko, J. and Smirnov, S. Yu. and Smirnov, Y. and Smirnova, L. N. and Smirnova, O. and Smith, A. C. and Smith, E. A. and Smith, H. A. and Smith, J. L. and Smith, R. and Smizanska, M. and Smolek, K. and Snesarev, A. A. and Snider, S. R. and Snoek, H. L. and Snyder, S. and Sobie, R. and Soffer, A. and Solans Sanchez, C. A. and Soldatov, E. Yu. and Soldevila, U. and Solodkov, A. A. and Solomon, S. and Soloshenko, A. and Solovieva, K. and Solovyanov, O. V. and Solovyev, V. and Sommer, P. and Sonay, A. and Song, W. Y. and Sonneveld, J. M. and Sopczak, A. and Sopio, A. L. and Sopkova, F. and Sothilingam, V. and Sottocornola, S. and Soualah, R. and Soumaimi, Z. and South, D. and Soybelman, N. and Spagnolo, S. and Spalla, M. and Sperlich, D. and Spigo, G. and Spinali, S. and Spiteri, D. P. and Spousta, M. and Staats, E. J. and Stabile, A. and Stamen, R. and Stampekis, A. and Standke, M. and Stanecka, E. and Stange, M. V. and Stanislaus, B. and Stanitzki, M. M. and Stapf, B. and Starchenko, E. A. and Stark, G. H. and Stark, J. and Starko, D. M. and Staroba, P. and Starovoitov, P. and St\"{a}rz, S. and Staszewski, R. and Stavropoulos, G. and Steentoft, J. and Steinberg, P. and Stelzer, B. and Stelzer, H. J. and Stelzer-Chilton, O. and Stenzel, H. and Stevenson, T. J. and Stewart, G. A. and Stewart, J. R. and Stockton, M. C. and Stoicea, G. and Stolarski, M. and Stonjek, S. and Straessner, A. and Strandberg, J. and Strandberg, S. and Stratmann, M. and Strauss, M. and Strebler, T. and Strizenec, P. and Str\"{o}hmer, R. and Strom, D. M. and Strom, L. R. and Stroynowski, R. and Strubig, A. and Stucci, S. A. and Stugu, B. and Stupak, J. and Styles, N. A. and Su, D. and Su, S. and Su, W. and Su, X. and Sugizaki, K. and Sulin, V. V. and Sullivan, M. J. and Sultan, D. M. S. and Sultanaliyeva, L. and Sultansoy, S. and Sumida, T. and Sun, S. and Sun, S. and Gudnadottir, O. Sunneborn and Sur, N. and Sutton, M. R. and Suzuki, H. and Svatos, M. and Swiatlowski, M. and Swirski, T. and Sykora, I. and Sykora, M. and Sykora, T. and Ta, D. and Tackmann, K. and Taffard, A. and Tafirout, R. and Tafoya Vargas, J. S. and Takeva, E. P. and Takubo, Y. and Talby, M. and Talyshev, A. A. and Tam, K. C. and Tamir, N. M. and Tanaka, A. and Tanaka, J. and Tanaka, R. and Tanasini, M. and Tao, Z. and Tapia Araya, S. and Tapprogge, S. and Tarek Abouelfadl Mohamed, A. and Tarem, S. and Tariq, K. and Tarna, G. and Tartarelli, G. F. and Tas, P. and Tasevsky, M. and Tassi, E. and Tate, A. C. and Tateno, G. and Tayalati, Y. and Taylor, G. N. and Taylor, W. and Teagle, H. and Tee, A. S. and Teixeira De Lima, R. and Teixeira-Dias, P. and Teoh, J. J. and Terashi, K. and Terron, J. and Terzo, S. and Testa, M. and Teuscher, R. J. and Thaler, A. and Theiner, O. and Themistokleous, N. and Theveneaux-Pelzer, T. and Thielmann, O. and Thomas, D. W. and Thomas, J. P. and Thompson, E. A. and Thompson, P. D. and Thomson, E. and Tian, Y. and Tikhomirov, V. and Tikhonov, Yu. A. and Timoshenko, S. and Timoshyn, D. and Ting, E. X. L. and Tipton, P. and Tlou, S. H. and Tnourji, A. and Todome, K. and Todorova-Nova, S. and Todt, S. and Togawa, M. and Tojo, J. and Tok\'{a}r, S. and Tokushuku, K. and Toldaiev, O. and Tombs, R. and Tomoto, M. and Tompkins, L. and Topolnicki, K. W. and Torrence, E. and Torres, H. and Torr\'{o} Pastor, E. and Toscani, M. and Tosciri, C. and Tost, M. and Tovey, D. R. and Traeet, A. and Trandafir, I. S. and Trefzger, T. and Tricoli, A. and Trigger, I. M. and Trincaz-Duvoid, S. and Trischuk, D. A. and Trocm\'{e}, B. and Troncon, C. and Truong, L. and Trzebinski, M. and Trzupek, A. and Tsai, F. and Tsai, M. and Tsiamis, A. and Tsiareshka, P. V. and Tsigaridas, S. and Tsirigotis, A. and Tsiskaridze, V. and Tskhadadze, E. G. and Tsopoulou, M. and Tsujikawa, Y. and Tsukerman, I. I. and Tsulaia, V. and Tsuno, S. and Tsur, O. and Tsuri, K. and Tsybychev, D. and Tu, Y. and Tudorache, A. and Tudorache, V. and Tuna, A. N. and Turchikhin, S. and Turk Cakir, I. and Turra, R. and Turtuvshin, T. and Tuts, P. M. and Tzamarias, S. and Tzanis, P. and Tzovara, E. and Ukegawa, F. and Ulloa Poblete, P. A. and Umaka, E. N. and Unal, G. and Unal, M. and Undrus, A. and Unel, G. and Urban, J. and Urquijo, P. and Usai, G. and Ushioda, R. and Usman, M. and Uysal, Z. and Vacavant, L. and Vacek, V. and Vachon, B. and Vadla, K. O. H. and Vafeiadis, T. and Vaitkus, A. and Valderanis, C. and Valdes Santurio, E. and Valente, M. and Valentinetti, S. and Valero, A. and Valiente Moreno, E. and Vallier, A. and Valls Ferrer, J. A. and Van Arneman, D. R. and Van Daalen, T. R. and Van Der Graaf, A. and Van Gemmeren, P. and Van Rijnbach, M. and Van Stroud, S. and Van Vulpen, I. and Vanadia, M. and Vandelli, W. and Vandenbroucke, M. and Vandewall, E. R. and Vannicola, D. and Vannoli, L. and Vari, R. and Varnes, E. W. and Varni, C. and Varol, T. and Varouchas, D. and Varriale, L. and Varvell, K. E. and Vasile, M. E. and Vaslin, L. and Vasquez, G. A. and Vasyukov, A. and Vazeille, F. and Vazquez Schroeder, T. and Veatch, J. and Vecchio, V. and Veen, M. J. and Veliscek, I. and Veloce, L. M. and Veloso, F. and Veneziano, S. and Ventura, A. and Ventura Gonzalez, S. and Verbytskyi, A. and Verducci, M. and Vergis, C. and Verissimo De Araujo, M. and Verkerke, W. and Vermeulen, J. C. and Vernieri, C. and Vessella, M. and Vetterli, M. C. and Vgenopoulos, A. and Viaux Maira, N. and Vickey, T. and Vickey Boeriu, O. E. and Viehhauser, G. H. A. and Vigani, L. and Villa, M. and Villaplana Perez, M. and Villhauer, E. M. and Vilucchi, E. and Vincter, M. G. and Virdee, G. S. and Vishwakarma, A. and Visibile, A. and Vittori, C. and Vivarelli, I. and Vladimirov, V. and Voevodina, E. and Vogel, F. and Vokac, P. and Volkotrub, Yu. and Von Ahnen, J. and Von Toerne, E. and Vormwald, B. and Vorobel, V. and Vorobev, K. and Vos, M. and Voss, K. and Vossebeld, J. H. and Vozak, M. and Vozdecky, L. and Vranjes, N. and Vranjes Milosavljevic, M. and Vreeswijk, M. and Vuillermet, R. and Vujinovic, O. and Vukotic, I. and Wada, S. and Wagner, C. and Wagner, J. M. and Wagner, W. and Wahdan, S. and Wahlberg, H. and Wakida, M. and Walder, J. and Walker, R. and Walkowiak, W. and Wall, A. and Wamorkar, T. and Wang, A. Z. and Wang, C. and Wang, C. and Wang, H. and Wang, J. and Wang, R.-J. and Wang, R. and Wang, R. and Wang, S. M. and Wang, S. and Wang, T. and Wang, W. T. and Wang, W. and Wang, X. and Wang, X. and Wang, X. and Wang, Y. and Wang, Y. and Wang, Z. and Wang, Z. and Wang, Z. and Warburton, A. and Ward, R. J. and Warrack, N. and Watson, A. T. and Watson, H. and Watson, M. F. and Watton, E. and Watts, G. and Waugh, B. M. and Weber, C. and Weber, H. A. and Weber, M. S. and Weber, S. M. and Wei, C. and Wei, Y. and Weidberg, A. R. and Weik, E. J. and Weingarten, J. and Weirich, M. and Weiser, C. and Wells, C. J. and Wenaus, T. and Wendland, B. and Wengler, T. and Wenke, N. S. and Wermes, N. and Wessels, M. and Wharton, A. M. and White, A. S. and White, A. and White, M. J. and Whiteson, D. and Wickremasinghe, L. and Wiedenmann, W. and Wiel, C. and Wielers, M. and Wiglesworth, C. and Wilbern, D. J. and Wilkens, H. G. and Williams, D. M. and Williams, H. H. and Williams, S. and Willocq, S. and Wilson, B. J. and Windischhofer, P. J. and Winkel, F. I. and Winklmeier, F. and Winter, B. T. and Winter, J. K. and Wittgen, M. and Wobisch, M. and Wolffs, Z. and Wollrath, J. and Wolter, M. W. and Wolters, H. and Wongel, A. F. and Worm, S. D. and Wosiek, B. K. and Wo\'{z}niak, K. W. and Wozniewski, S. and Wraight, K. and Wu, C. and Wu, J. and Wu, M. and Wu, M. and Wu, S. L. and Wu, X. and Wu, Y. and Wu, Z. and Wuerzinger, J. and Wyatt, T. R. and Wynne, B. M. and Xella, S. and Xia, L. and Xia, M. and Xiang, J. and Xie, M. and Xie, X. and Xin, S. and Xiong, J. and Xu, D. and Xu, H. and Xu, L. and Xu, R. and Xu, T. and Xu, Y. and Xu, Z. and Xu, Z. and Yabsley, B. and Yacoob, S. and Yamaguchi, Y. and Yamashita, E. and Yamauchi, H. and Yamazaki, T. and Yamazaki, Y. and Yan, J. and Yan, S. and Yan, Z. and Yang, H. J. and Yang, H. T. and Yang, S. and Yang, T. and Yang, X. and Yang, X. and Yang, Y. and Yang, Y. and Yang, Z. and Yao, W-M. and Yap, Y. C. and Ye, H. and Ye, H. and Ye, J. and Ye, S. and Ye, X. and Yeh, Y. and Yeletskikh, I. and Yeo, B. K. and Yexley, M. R. and Yin, P. and Yorita, K. and Younas, S. and Young, C. J. S. and Young, C. and Yu, C. and Yu, Y. and Yuan, M. and Yuan, R. and Yue, L. and Zaazoua, M. and Zabinski, B. and Zaid, E. and Zakareishvili, T. and Zakharchuk, N. and Zambito, S. and Zamora Saa, J. A. and Zang, J. and Zanzi, D. and Zaplatilek, O. and Zeitnitz, C. and Zeng, H. and Zeng, J. C. and Zenger, D. T. and Zenin, O. and \v{Z}eni\v{s}, T. and Zenz, S. and Zerradi, S. and Zerwas, D. and Zhai, M. and Zhang, B. and Zhang, D. F. and Zhang, J. and Zhang, J. and Zhang, K. and Zhang, L. and Zhang, P. and Zhang, R. and Zhang, S. and Zhang, T. and Zhang, X. and Zhang, X. and Zhang, Y. and Zhang, Y. and Zhang, Z. and Zhang, Z. and Zhao, H. and Zhao, P. and Zhao, T. and Zhao, Y. and Zhao, Z. and Zhemchugov, A. and Zheng, J. and Zheng, K. and Zheng, X. and Zheng, Z. and Zhong, D. and Zhou, B. and Zhou, H. and Zhou, N. and Zhou, Y. and Zhu, C. G. and Zhu, J. and Zhu, Y. and Zhu, Y. and Zhuang, X. and Zhukov, K. and Zhulanov, V. and Zimine, N. I. and Zinsser, J. and Ziolkowski, M. and \v{Z}ivkovi\'{c}, L. and Zoccoli, A. and Zoch, K. and Zorbas, T. G. and Zormpa, O. and Zou, W. and Zwalinski, L.},
  year          = 2024,
  month         = jun,
  journal       = {Physical Review D},
  volume        = 109,
  number        = 11,
  pages         = 112016,
  doi           = {10.1103/PhysRevD.109.112016},
  url           = {https://link.aps.org/doi/10.1103/PhysRevD.109.112016},
  urldate       = {2025-07-13},
  note          = {Publisher: American Physical Society},
  abstract      = {Measurements of the substructure of top-quark jets are presented, using 140 fb1 of 13 TeV ��⁢�� collision data recorded with the ATLAS detector at the LHC. Top-quark jets reconstructed with the anti-���� algorithm with a radius parameter �� =1.0 are selected in top-quark pair (��⁢\textasciimacron{}��) events where one top quark decays semileptonically and the other hadronically, or where both top quarks decay hadronically. The top-quark jets are required to have transverse momentum ��T {\textgreater}350 GeV, yielding large samples of data events with jet ��T values between 350 and 600 GeV. One- and two-dimensional differential cross sections for eight substructure variables, defined using only the charged components of the jets, are measured in a particle-level phase space by correcting for the smearing and acceptance effects induced by the detector. The differential cross sections are compared with the predictions of several Monte Carlo simulations in which top-quark pair-production quantum chromodynamic matrix-element calculations at next-to-leading-order precision in the strong coupling constant ��S are passed to leading-order parton shower and hadronization generators. The Monte Carlo predictions for measures of the broadness, and also the two-body structure, of the top-quark jets are found to be in good agreement with the measurements, while variables sensitive to the three-body structure of the top-quark jets exhibit some tension with the measured distributions.},
  file          = {Full Text PDF:/Users/t-krishdesai/Zotero/storage/U57JJXCD/ATLAS Collaboration et al. - 2024 - Measurement of jet substructure in boosted \$toverline t \$ events with the ATLAS detector using \$140.pdf:application/pdf}
}
@article{ATLAS:2012yve,
  title         = {Observation of a new particle in the search for the Standard Model Higgs boson with the ATLAS detector at the LHC},
  author        = {Aad, Georges and others},
  year          = 2012,
  journal       = {Phys. Lett. B},
  volume        = 716,
  pages         = {1--29},
  doi           = {10.1016/j.physletb.2012.08.020},
  collaboration = {Atlas},
  eprint        = {1207.7214},
  archiveprefix = {arXiv},
  primaryclass  = {hep-ex},
  reportnumber  = {Cern-ph-ep-2012-218}
}
@misc{augustine_survey_2024,
  title         = {A {Survey} on {Universal} {Approximation} {Theorems}},
  author        = {Augustine, Midhun T.},
  year          = 2024,
  month         = jul,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2407.12895},
  url           = {http://arxiv.org/abs/2407.12895},
  urldate       = {2025-07-15},
  note          = {arXiv:2407.12895 [cs] version: 1},
  abstract      = {This paper discusses various theorems on the approximation capabilities of neural networks (NNs), which are known as universal approximation theorems (UATs). The paper gives a systematic overview of UATs starting from the preliminary results on function approximation, such as Taylor's theorem, Fourier's theorem, Weierstrass approximation theorem, Kolmogorov - Arnold representation theorem, etc. Theoretical and numerical aspects of UATs are covered from both arbitrary width and depth.},
  keywords      = {Computer Science - Machine Learning, Computer Science - Systems and Control, Electrical Engineering and Systems Science - Systems and Control}
}
@article{AveryCrossRates,
  title         = {Cross section, Flux, Luminosity, Scattering Rates},
  author        = {Avery, Paul and Korytov, Andrey}
}
@article{baak_interpolation_2015,
  title         = {Interpolation between multi-dimensional histograms using a new non-linear moment morphing method},
  author        = {Baak, M. and Gadatsch, S. and Harrington, R. and Verkerke, W.},
  year          = 2015,
  month         = jan,
  journal       = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  volume        = 771,
  pages         = {39--48},
  doi           = {10.1016/j.nima.2014.10.033},
  issn          = {0168-9002},
  url           = {https://www.sciencedirect.com/science/article/pii/S0168900214011814},
  urldate       = {2025-07-14},
  abstract      = {A prescription is presented for the interpolation between multi-dimensional distribution templates based on one or multiple model parameters. The technique uses a linear combination of templates, each created using fixed values of the model׳s parameters and transformed according to a specific procedure, to model a non-linear dependency on model parameters and the dependency between them. By construction the technique scales well with the number of input templates used, which is a useful feature in modern day particle physics, where a large number of templates are often required to model the impact of systematic uncertainties.},
  keywords      = {Analysis, Distribution, Histogram, Interpolation, Simulation}
}
@article{Baldi2014SearchingLearning,
  title         = {Searching for exotic particles in high-energy physics with deep learning},
  author        = {Baldi, P. and Sadowski, P. and Whiteson, D.},
  year          = 2014,
  month         = 7,
  journal       = {Nature Communications},
  publisher     = {Nature Publishing Group},
  volume        = 5,
  number        = 1,
  pages         = {1--9},
  doi           = {10.1038/ncomms5308;techmeta=129,141;subjmeta=25,419,483,639,640,766;kwrd=applied+physics,particle+physics,theoretical+physics},
  issn          = 20411723,
  url           = {https://www.nature.com/articles/ncomms5308},
  arxivid       = {1402.4735},
  keywords      = {Applied physics, Particle physics, Theoretical physics}
}
@article{Baldi2015EnhancedLearning,
  title         = {{Enhanced Higgs boson to {$\tau$}+{$\tau$}- search with deep learning}},
  author        = {Baldi, P. and Sadowski, P. and Whiteson, D.},
  year          = 2015,
  month         = 3,
  journal       = {Physical Review Letters},
  publisher     = {American Physical Society},
  volume        = 114,
  number        = 11,
  pages         = 111801,
  doi           = {10.1103/physrevlett.114.111801/figures/3/thumbnail},
  issn          = 10797114,
  url           = {https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.114.111801}
}
@article{CMS:2017yer,
    author = "Sirunyan, Albert M and others",
    collaboration = "CMS",
    title = "{Measurements of jet charge with dijet events in pp collisions at $\sqrt{s}=8$ TeV}",
    eprint = "1706.05868",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "CMS-SMP-15-003, CERN-EP-2017-085",
    doi = "10.1007/JHEP10(2017)131",
    journal = "JHEP",
    volume = "10",
    pages = "131",
    year = "2017"
}
@article{CMS:2020plq,
    author = "Sirunyan, Albert M and others",
    collaboration = "CMS",
    title = "{Measurement of quark- and gluon-like jet fractions using jet charge in PbPb and pp collisions at 5.02 TeV}",
    eprint = "2004.00602",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "CMS-HIN-18-018, CERN-EP-2020-019",
    doi = "10.1007/JHEP07(2020)115",
    journal = "JHEP",
    volume = "07",
    pages = "115",
    year = "2020"
}
@article{Larkoski:2024uoc,
    author = "Larkoski, Andrew J.",
    title = "{QCD masterclass lectures on jet physics and machine learning}",
    eprint = "2407.04897",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    doi = "10.1140/epjc/s10052-024-13341-0",
    journal = "Eur. Phys. J. C",
    volume = "84",
    number = "10",
    pages = "1117",
    year = "2024"
}
@article{Baldenegro:2024pfb,
    author = "Baldenegro, Cristian and Soto-Ontoso, Alba and Soyez, Gregory",
    title = "{Secondary Lund jet plane as a gluon-enriched sample}",
    eprint = "2412.14247",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    doi = "10.1007/JHEP07(2025)088",
    journal = "JHEP",
    volume = "07",
    pages = "088",
    year = "2025"
}
@article{AbdulKhalek:2021gbh,
    author = "Abdul Khalek, R. and others",
    title = "{Science Requirements and Detector Concepts for the Electron-Ion Collider}: {EIC Yellow Report}",
    eprint = "2103.05419",
    archivePrefix = "arXiv",
    primaryClass = "physics.ins-det",
    reportNumber = "BNL-220990-2021-FORE, JLAB-PHY-21-3198, LA-UR-21-20953",
    doi = "10.1016/j.nuclphysa.2022.122447",
    journal = "Nucl. Phys. A",
    volume = "1026",
    pages = "122447",
    year = "2022"
}
@inproceedings{Accardi:2022oog,
    author = "Accardi, A. and others",
    title = "{Opportunities for precision QCD physics in hadronization at Belle II -- a snowmass whitepaper}",
    booktitle = "{Snowmass 2021}",
    eprint = "2204.02280",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    month = "4",
    year = "2022"
}
@article{ATLAS:2015rlw,
    author = "Aad, Georges and others",
    collaboration = "ATLAS",
    title = "{Measurement of jet charge in dijet events from $\sqrt{s}$=8  TeV pp collisions with the ATLAS detector}",
    eprint = "1509.05190",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "CERN-PH-EP-2015-207",
    doi = "10.1103/PhysRevD.93.052003",
    journal = "Phys. Rev. D",
    volume = "93",
    number = "5",
    pages = "052003",
    year = "2016"
}
@article{Li:2019dre,
    author = "Li, Hai Tao and Vitev, Ivan",
    title = "{Jet charge modification in dense QCD matter}",
    eprint = "1908.06979",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    reportNumber = "LA-UR-19-30442",
    doi = "10.1103/PhysRevD.101.076020",
    journal = "Phys. Rev. D",
    volume = "101",
    pages = "076020",
    year = "2020"
}
@article{CMS:2020plq,
    author = "Sirunyan, Albert M and others",
    collaboration = "CMS",
    title = "{Measurement of quark- and gluon-like jet fractions using jet charge in PbPb and pp collisions at 5.02 TeV}",
    eprint = "2004.00602",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "CMS-HIN-18-018, CERN-EP-2020-019",
    doi = "10.1007/JHEP07(2020)115",
    journal = "JHEP",
    volume = "07",
    pages = "115",
    year = "2020"
}
@misc{chollet2015keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  howpublished={\url{https://keras.io}},
}
@INPROCEEDINGS{7410480,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification}, 
  year={2015},
  volume={},
  number={},
  pages={1026-1034},
  keywords={Training;Computational modeling;Adaptation models;Testing;Gaussian distribution;Biological neural networks},
  doi={10.1109/ICCV.2015.123}}

@article{Baldi2021DeepScience,
  title         = {Deep Learning in Science},
  author        = {Baldi, Pierre},
  year          = 2021,
  month         = 4,
  journal       = {Deep Learning in Science},
  publisher     = {Cambridge University Press},
  doi           = {10.1017/9781108955652},
  isbn          = 9781108955652,
  url           = {https://www.cambridge.org/core/books/deep-learning-in-science/5A620F1E5DB54A7FB1D3E3C1A80E0860}
}
@misc{bandieramonte_fastcalogan_2023,
  title         = {{FastCaloGAN}: {A} {FAST} {SIMULATION} {OF} {THE} {ATLAS} {CALORIMETER} {WITH} {GANs}},
  shorttitle    = {FastCaloGAN},
  author        = {Bandieramonte, Marilena and Faucci Giannelli, Michele and Corchia, Federico Andrea and Zhang, Rui and Beirer, Joshua Falco and Duehrssen-Debling, Michael and Young, Christopher and Day-Hall, Henry and Salamani, Dalila and Sorenson, Josef Daniel and Lari, Tommaso},
  year          = 2023,
  url           = {https://cds.cern.ch/record/2857787},
  urldate       = {2025-07-17}
}
@article{Bank2023Autoencoders,
  title         = {Autoencoders},
  author        = {Bank, Dor and Koenigstein, Noam and Giryes, Raja},
  year          = 2023,
  month         = 1,
  journal       = {Machine Learning for Data Science Handbook: Data Mining and Knowledge Discovery Handbook, Third Edition},
  publisher     = {Springer, Cham},
  pages         = {353--374},
  doi           = {10.1007/978-3-031-24628-9{\_}16},
  isbn          = {978-3-031-24628-9},
  url           = {https://link.springer.com/chapter/10.1007/978-3-031-24628-9_16},
  arxivid       = {2003.05991}
}
@article{Bardeen:1978yd,
  title         = {Deep-Inelastic Scattering beyond the Leading Order in Asymptotically Free Gauge Theories},
  author        = {Bardeen, William A. and Buras, A. J. and Duke, D. W. and Muta, T.},
  year          = 1978,
  journal       = {Physical Review D},
  publisher     = {American Physical Society},
  volume        = 18,
  number        = 11,
  pages         = 3998,
  doi           = {10.1103/PhysRevD.18.3998},
  urldate       = {2025-07-18},
  abstract      = {We calculate the full order-g2 corrections to the coefficient functions which determine the Q2 dependence of the moments of deep-inelastic structure functions. The calculation is performed in the minimal-subtraction scheme of 't Hooft. The results are combined with the recent two-loop calculations of anomalous dimensions by Floratos, Ross, and Sachrajda to give the full g{\textasciimacron}2 corrections to the leading order of asymptotic freedom. We present results for Cn(1,g{\textasciimacron}2) relevant for electroproduction and neutrino reactions for both nonsinglet and singlet combinations of the structure functions. Phenomenological consequences of the full g{\textasciimacron}2 corrections to the nonsinglet structure function are discussed. The corrections to the Gross-Llewellyn Smith and Bjorken sum rules are estimated to be of the order of 15\%.},
  annotation    = {1846 citations (INSPIRE 2025/7/18)\\ 1799 citations w/o self (INSPIRE 2025/7/18)\\ Citations: 819 (Crossref) [2025-07-18]\\ Citations: 780 (SemanticScholar) [2025-07-18]},
  file          = {/Users/t-krishdesai/Zotero/storage/DJTL538R/Bardeen et al. - 1978 - Deep-inelastic scattering beyond the leading order in asymptotically free gauge theories.pdf}
}
@article{Baron2020ExtendingMethod,
  title         = {Extending the Fully Bayesian Unfolding with Regularization Using a Combined Sampling Method},
  author        = {Baro\v{n}, Petr and Kvita, Ji\v{r}\'{\i}},
  year          = 2020,
  month         = 12,
  journal       = {Symmetry 2020, Vol. 12, Page 2100},
  publisher     = {Multidisciplinary Digital Publishing Institute},
  volume        = 12,
  number        = 12,
  pages         = 2100,
  doi           = {10.3390/sym12122100},
  issn          = {2073-8994},
  url           = {https://www.mdpi.com/2073-8994/12/12/2100/htm https://www.mdpi.com/2073-8994/12/12/2100},
  keywords      = {Bayes theorem, MCMC, regularization, unfolding}
}
@article{Belis2024MachinePhysics,
  title         = {Machine learning for anomaly detection in particle physics},
  author        = {Belis, Vasilis and Odagiu, Patrick and Aarrestad, Thea Klaeboe},
  year          = 2024,
  month         = 12,
  journal       = {Reviews in Physics},
  publisher     = {Elsevier},
  volume        = 12,
  pages         = 100091,
  doi           = {10.1016/j.revip.2024.100091},
  issn          = {2405-4283},
  url           = {https://www.sciencedirect.com/science/article/pii/S2405428324000017},
  arxivid       = {2312.14190},
  keywords      = {Anomaly detection, Model-independent, Outlier detection, Particle physics, Quantum machine learning}
}
@article{bellagente_go_2022,
  title         = {Go with the {Flow}: {Normalising} {Flows} applications for {High} {Energy} {Physics}},
  shorttitle    = {Go with the {Flow}},
  author        = {Bellagente, Marco},
  year          = 2022,
  doi           = {10.11588/heidok.00031386},
  url           = {https://archiv.ub.uni-heidelberg.de/volltextserver/id/eprint/31386},
  urldate       = {2025-07-15},
  note          = {Publisher: Heidelberg University Library},
  keywords      = {530 Physics}
}
@article{bellagente_how_2020,
  title         = {How to {GAN} away detector effects},
  author        = {Bellagente, Marco and Butter, Anja and Kasieczka, Gregor and Plehn, Tilman and Winterhalder, Ramon},
  year          = 2020,
  month         = apr,
  journal       = {SciPost Physics},
  volume        = 8,
  number        = 4,
  pages         = {070},
  doi           = {10.21468/SciPostPhys.8.4.070},
  issn          = {2542-4653},
  url           = {https://scipost.org/10.21468/SciPostPhys.8.4.070},
  urldate       = {2025-07-17},
  abstract      = {SciPost Journals Publication Detail SciPost Phys. 8, 070 (2020) How to GAN away detector effects},
  language      = {en}
}
@article{Bellagente2020InvertibleAgain,
  title         = {Invertible Networks or Partons to Detector and Back Again},
  author        = {Bellagente, Marco and Butter, Anja and Kasieczka, Gregor and Plehn, Tilman and Rousselot, Armand and Winterhalder, Ramon and Ardizzone, Lynton and K{\"{o}}the, Ullrich},
  year          = 2020,
  month         = 11,
  journal       = {SciPost Phys.},
  publisher     = {SciPost Foundation},
  volume        = 9,
  number        = 5,
  pages         = {074},
  doi           = {10.21468/scipostphys.9.5.074},
  issn          = 25424653,
  arxivid       = {2006.06685}
}
@article{belle_collaboration_precision_2013,
  title         = {Precision {Measurement} of {Charged} {Pion} and {Kaon} {Differential} {Cross} {Sections} in \$\{e\}{\textasciicircum}\{+\}\{e\}{\textasciicircum}\{{\textbackslash}ensuremath\{-\}\}\$ {Annihilation} at \${\textbackslash}sqrt\{s\}{\textbackslash}mathbf\{=\}10.52{\textbackslash}text\{ \}{\textbackslash}text\{ \}{\textbackslash}mathrm\{{GeV}\}\$},
  author        = {{Belle Collaboration} and Leitgab, M. and Seidl, R. and Grosse Perdekamp, M. and Vossen, A. and Adachi, I. and Aihara, H. and Asner, D. M. and Aulchenko, V. and Aushev, T. and Bakich, A. M. and Bhuyan, B. and Bondar, A. and Bozek, A. and Bra\v{c}ko, M. and Brodzicka, J. and Browder, T. E. and Chekelian, V. and Chen, A. and Chen, P. and Cheon, B. G. and Chilikin, K. and Cho, K. and Chobanova, V. and Choi, Y. and Cinabro, D. and Dalseno, J. and Dr\'{a}sal, Z. and Dutta, D. and Eidelman, S. and Epifanov, D. and Farhat, H. and Fast, J. E. and Gaur, V. and Gabyshev, N. and Gillard, R. and Giordano, F. and Goh, Y. M. and Golob, B. and Haba, J. and Hayasaka, K. and Hayashii, H. and Hoshi, Y. and Hou, W.-S. and Hsiung, Y. B. and Hyun, H. J. and Iijima, T. and Ishikawa, A. and Itoh, R. and Jacobs, W. W. and Julius, T. and Kang, J. H. and Kapusta, P. and Kato, E. and Kawasaki, T. and Kim, H. J. and Kim, H. O. and Kim, J. B. and Kim, J. H. and Kim, M. J. and Klucar, J. and Ko, B. R. and Kody\v{s}, P. and Kouzes, R. T. and Kri\v{z}an, P. and Krokovny, P. and Kumar, R. and Kumita, T. and Kwon, Y.-J. and Lange, J. S. and Lee, S.-H. and Li, Y. and Liu, Z. Q. and Liventsev, D. and Matvienko, D. and Miyabayashi, K. and Miyata, H. and Mizuk, R. and Moll, A. and Muramatsu, N. and Nakano, E. and Nakao, M. and Natkaniec, Z. and Nayak, M. and Nedelkovska, E. and Ng, C. and Nisar, N. K. and Nitoh, O. and Ogawa, A. and Ogawa, S. and Ohshima, T. and Okuno, S. and Olsen, S. L. and Oswald, C. and Pakhlov, P. and Park, H. and Park, H. K. and Pedlar, T. K. and Pestotnik, R. and Petri\v{c}, M. and Piilonen, L. E. and R\"{o}hrken, M. and Sahoo, H. and Sakai, Y. and Sandilya, S. and Santelj, L. and Sanuki, T. and Sato, Y. and Schneider, O. and Schnell, G. and Schwanda, C. and Senyo, K. and Seon, O. and Sevior, M. E. and Shapkin, M. and Shen, C. P. and Shibata, T.-A. and Shiu, J.-G. and Shwartz, B. and Sibidanov, A. and Simon, F. and Smerkol, P. and Sohn, Y.-S. and Sokolov, A. and Solovieva, E. and Stari\v{c}, M. and Sumihama, M. and Sumiyoshi, T. and Tatishvili, G. and Teramoto, Y. and Tsuboyama, T. and Uchida, M. and Uglov, T. and Unno, Y. and Uno, S. and Usov, Y. and Van Hulse, C. and Varner, G. and Vorobyev, V. and Wagner, M. N. and Wang, C. H. and Wang, J. and Wang, M.-Z. and Wang, P. and Watanabe, M. and Watanabe, Y. and Williams, K. M. and Won, E. and Yamashita, Y. and Zhilich, V. and Zhulanov, V.},
  year          = 2013,
  month         = aug,
  journal       = {Physical Review Letters},
  volume        = 111,
  number        = 6,
  pages         = {062002},
  doi           = {10.1103/PhysRevLett.111.062002},
  url           = {https://link.aps.org/doi/10.1103/PhysRevLett.111.062002},
  urldate       = {2025-07-13},
  note          = {Publisher: American Physical Society},
  abstract      = {Measurements of inclusive differential cross sections for charged pion and kaon production in annihilation have been carried out at a center-of-mass energy of . The measurements were performed with the Belle detector at the KEKB collider using a data sample containing events, where . We present charge-integrated differential cross sections for as a function of the relative hadron energy from 0.2 to 0.98. The combined statistical and systematic uncertainties for () are 4\% (4\%) at and 15\% (24\%) at . The cross sections are the first measurements of the dependence of pion and kaon production for as well as the first precision cross section measurements at a center-of-mass energy far below the resonance used by the experiments at LEP and SLC.}
}
@article{Bellm2017HerwigNote,
  title         = {Herwig 7.1 Release Note},
  author        = {Bellm, Johannes and Gieseke, Stefan and Grellscheid, David and Kirchgae{\ss}er, Patrick and Loshaj, Frash\"{e}r and Nail, Graeme and Papaefstathiou, Andreas and Pl{\"{a}}tzer, Simon and Podskubka, Radek and Rauch, Michael and Reuschle, Christian and Richardson, Peter and Schichtel, Peter and Seymour, Michael H. and Si{\'{o}}dmok, Andrzej and Webster, Stephen},
  year          = 2017,
  month         = 5,
  url           = {http://arxiv.org/abs/1705.06919},
  arxivid       = {1705.06919}
}
@book{belsley_regression_2005,
  title         = {Regression {Diagnostics}: {Identifying} {Influential} {Data} and {Sources} of {Collinearity}},
  shorttitle    = {Regression {Diagnostics}},
  author        = {Belsley, David A. and Kuh, Edwin and Welsch, Roy E.},
  year          = 2005,
  month         = feb,
  publisher     = {John Wiley \& Sons},
  isbn          = {978-0-471-72514-5},
  note          = {Google-Books-ID: GECBEUJVNe0C},
  abstract      = {The Wiley-Interscience Paperback Series consists of selected books that have been made more accessible to consumers in an effort to increase global appeal and general circulation. With these new unabridged softcover volumes, Wiley hopes to extend the lives of these works by making them available to future generations of statisticians, mathematicians, and scientists. "The title of the book more or less sums up the contents. It appears to me to represent a real breakthrough in the art of dealing in `unconventional' data. . . . I found the whole book both readable and enjoyable. It is suitable for data analysts, academic statisticians, and professional software writers." –Journal of the Royal Statistical Society "The book assumes a working knowledge of all of the principal results and techniques used in least squares multiple regression, as expressed in vector and matrix notation. Given this background, the book is clear and easy to use. . . . The techniques are illustrated in great detail with practical data sets from econometrics." –Short Book Reviews, International Statistical Institute Regression Diagnostics: Identifying Influential Data and Sources of Collinearity provides practicing statisticians and econometricians with new tools for assessing quality and reliability of regression estimates. Diagnostic techniques are developed that aid in the systematic location of data points that are unusual or inordinately influential; measure the presence and intensity of collinear relations among the regression data; and help to identify variables involved in each and pinpoint estimated coefficients potentially most adversely affected. The book emphasizes diagnostics and includes suggestions for remedial action},
  language      = {en},
  keywords      = {Mathematics / General, Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes}
}
@article{berger_simplified_2023,
  title         = {Simplified likelihoods using linearized systematic uncertainties},
  author        = {Berger, N.},
  year          = 2023,
  month         = apr,
  journal       = {Journal of High Energy Physics},
  volume        = 2023,
  number        = 4,
  pages         = 84,
  doi           = {10.1007/jhep04(2023)084},
  issn          = {1029-8479},
  url           = {https://doi.org/10.1007/JHEP04(2023)084},
  urldate       = {2025-07-14},
  abstract      = {This paper presents a simplified likelihood framework designed to facilitate the reuse, reinterpretation and combination of LHC experimental results. The framework is based on the same underlying structure as the widely used HistFactory format, but with systematic uncertainties considered at linear order only. This simplification leads to large gains in computing performance for the evaluation and maximization of the likelihood function, compared to the original statistical model. The framework accurately describes non-Gaussian effects from low event counts, as well as correlated uncertainties in combinations. While primarily targeted towards binned descriptions of the data, it is also applicable to unbinned models.},
  language      = {en},
  keywords      = {Applied Probability, Bayesian Inference, Beyond Standard Model, Hadron-Hadron Scattering, Higgs Physics, Parametric Inference, Statistical Theory and Methods, Stochastic Modelling, Stochastic Modelling in Statistics, Supersymmetry}
}
@misc{Berger2017LectureATLAS,
  title         = {Lecture on Statistical analysis methods by ATLAS},
  author        = {Berger, Nicolas},
  year          = 2017,
  month         = 9,
  pages         = {17--29},
  url           = {https://cds.cern.ch/record/2285058},
  arxivid       = {1701.07240},
  keywords      = {Bphys, Eweak, Exotics, Higgs, Qcd, Susy, Top}
}
@article{bevan_support_2017,
  title         = {Support vector machines and generalisation in {HEP}},
  author        = {Bevan, Adrian and Go\~{n}i, Rodrigo Gamboa and Stevenson, Tom and Stevenson, Tom},
  year          = 2017,
  journal       = {J. Phys. Conf. Ser.},
  volume        = 898,
  number        = 7,
  pages         = {072021},
  doi           = {10.1088/1742-6596/898/7/072021},
  note          = {\_eprint: 1702.04686},
  editor        = {Mount, Richard and Tull, Craig},
  keywords      = {BETA, CERN LHC Coll, Higgs particle --{\textgreater} tau+ tau-, background: suppression, benchmark, computer, data analysis method, numerical calculations, performance, programming}
}
@article{bhattacherjee_study_2019,
  title         = {Study of energy deposition patterns in hadron calorimeter for prompt and displaced jets using convolutional neural network},
  author        = {Bhattacherjee, Biplob and Mukherjee, Swagata and Sengupta, Rhitaja},
  year          = 2019,
  month         = nov,
  journal       = {Journal of High Energy Physics},
  volume        = 2019,
  number        = 11,
  pages         = 156,
  doi           = {10.1007/jhep11(2019)156},
  issn          = {1029-8479},
  url           = {https://doi.org/10.1007/JHEP11(2019)156},
  urldate       = {2025-07-15},
  abstract      = {Sophisticated machine learning techniques have promising potential in search for physics beyond Standard Model in Large Hadron Collider (LHC). Convolutional neural networks (CNN) can provide powerful tools for differentiating between patterns of calorimeter energy deposits by prompt particles of Standard Model and long-lived particles predicted in various models beyond the Standard Model. We demonstrate the usefulness of CNN by using a couple of physics examples from well motivated BSM scenarios predicting long-lived particles giving rise to displaced jets. Our work suggests that modern machine- learning techniques have potential to discriminate between energy deposition patterns of prompt and long-lived particles, and thus, they can be useful tools in such searches.},
  language      = {en},
  keywords      = {Accelerator Physics, Artificial Intelligence, Computational Intelligence, High-Energy Astrophysics, Jets, Machine Learning, Particle Physics}
}
@article{bierlich_comprehensive_2022,
  title         = {A comprehensive guide to the physics and usage of {PYTHIA} 8.3},
  author        = {Bierlich, Christian and Chakraborty, Smita and Desai, Nishita and Gellersen, Leif and Helenius, Ilkka and Ilten, Philip and L\"{o}nnblad, Leif and Mrenna, Stephen and Prestel, Stefan and Preuss, Christian Tobias and Sj\"{o}strand, Torbj\"{o}rn and Skands, Peter and Utheim, Marius and Verheyen, Rob},
  year          = 2022,
  month         = nov,
  journal       = {SciPost Physics Codebases},
  pages         = 8,
  doi           = {10.21468/SciPostPhysCodeb.8},
  url           = {https://scipost.org/10.21468/SciPostPhysCodeb.8},
  urldate       = {2025-07-13},
  abstract      = {This manual describes the Pythia event generator, the most recent version of an evolving physics tool used to answer fundamental questions in particle physics. The program is most often used to generate high-energy-physics collision ``events'', i.e.~sets of particles produced in association with the collision of two incoming high-energy particles, but has several uses beyond that. The guiding philosophy is to produce and re-produce properties of experimentally obtained collisions as accurately as possible. The program includes a wide ranges of reactions within and beyond the Standard Model, and extending to heavy ion physics. Emphasis is put on phenomena where strong interactions play a major role. The manual contains both pedagogical and practical components. All included physics models are described in enough detail to allow the user to obtain a cursory overview of used assumptions and approximations, enabling an informed evaluation of the program output. A number of the most central algorithms are described in enough detail that the main results of the program can be reproduced independently, allowing further development of existing models or the addition of new ones. Finally, a chapter dedicated fully to the user is included towards the end, providing pedagogical examples of standard use cases, and a detailed description of a number of external interfaces. The program code, the online manual, and the latest version of this print manual can be found on the Pythia web page: https://www.pythia.org/.}
}
@book{big-oh,
  title         = {The Art of Computer Programming; Vol. 1: Fundamental Algorithms},
  author        = {Donald~E. Knuth},
  year          = 1973,
  publisher     = {Addison-Wesley},
  address       = {Reading, Massachusetts}
}
@article{bilionis_free_2012,
  title         = {Free energy computations by minimization of {Kullback}–{Leibler} divergence: {An} efficient adaptive biasing potential method for sparse representations},
  shorttitle    = {Free energy computations by minimization of {Kullback}–{Leibler} divergence},
  author        = {Bilionis, I. and Koutsourelakis, P. S.},
  year          = 2012,
  month         = may,
  journal       = {Journal of Computational Physics},
  volume        = 231,
  number        = 9,
  pages         = {3849--3870},
  doi           = {10.1016/j.jcp.2012.01.033},
  issn          = {0021-9991},
  url           = {https://www.sciencedirect.com/science/article/pii/S0021999112000630},
  urldate       = {2025-07-16},
  abstract      = {The present paper proposes an adaptive biasing potential technique for the computation of free energy landscapes. It is motivated by statistical learning arguments and unifies the tasks of biasing the molecular dynamics to escape free energy wells and estimating the free energy function, under the same objective of minimizing the Kullback–Leibler divergence between appropriately selected densities. It offers rigorous convergence diagnostics even though history dependent, non-Markovian dynamics are employed. It makes use of a greedy optimization scheme in order to obtain sparse representations of the free energy function which can be particularly useful in multidimensional cases. It employs embarrassingly parallelizable sampling schemes that are based on adaptive Sequential Monte Carlo and can be readily coupled with legacy molecular dynamics simulators. The sequential nature of the learning and sampling scheme enables the efficient calculation of free energy functions parametrized by the temperature. The characteristics and capabilities of the proposed method are demonstrated in three numerical examples.},
  keywords      = {Adaptive biasing potential, Atomistic simulations, Free energy computations, Sequential Monte Carlo, Statistical learning}
}
@misc{blobel_unfolding_2002,
  title         = {An {Unfolding} {Method} for {High} {Energy} {Physics} {Experiments}},
  author        = {Blobel, Volker},
  year          = 2002,
  month         = aug,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.hep-ex/0208022},
  url           = {http://arxiv.org/abs/hep-ex/0208022},
  urldate       = {2025-07-17},
  note          = {arXiv:hep-ex/0208022},
  abstract      = {Finite detector resolution and limited acceptance require to apply unfolding methods in high energy physics experiments. Information on the detector resolution is usually given by a set of Monte Carlo events. Based on the experience with a widely used unfolding program (RUN) a modified method has been developed. The first step of the method is a maximum likelihood fit of the Monte Carlo distributions to the measured distribution in one, two or three dimensions; the finite statistic of the Monte Carlo events is taken into account by the use of Barlows method with a new method of solution. A clustering method is used before to combine bins in sparsely populated areas. In the second step a regularization is applied to the solution, which introduces only a small bias. The regularization parameter is determined from the data after a diagonalization and rotation procedure.},
  keywords      = {High Energy Physics - Experiment}
}
@inproceedings{blobel_unfolding_2011,
  title         = {Unfolding {Methods} in {Particle} {Physics}},
  author        = {Blobel, Volker},
  year          = 2011,
  booktitle     = {{Phystat} 2011},
  publisher     = {Cern},
  address       = {Geneva},
  pages         = {240--251},
  doi           = {10.5170/cern-2011-006.240},
  keywords      = {BETA, acceptance, data analysis method, detector: resolution, statistical analysis, talk: Geneva 2011/01/17}
}
@article{Bogatskiy2020LorentzPhysics,
  title         = {Lorentz Group Equivariant Neural Network for Particle Physics},
  author        = {Bogatskiy, Alexander and Anderson, Brandon and Offermann, Jan T. and Roussi, Marwah and Miller, David W. and Kondor, Risi},
  year          = 2020,
  month         = 6,
  journal       = {37th International Conference on Machine Learning, ICML 2020},
  publisher     = {International Machine Learning Society (IMLS)},
  volume        = {PartF168147-2},
  pages         = {969--979},
  isbn          = 9781713821120,
  url           = {https://arxiv.org/pdf/2006.04780},
  arxivid       = {2006.04780}
}
@article{Bohm2025IntroductionPhysicists,
  title         = {Introduction to Statistics and Data Analysis for Physicists},
  author        = {Bohm, Gerhard and Zech, G\"{u}nter},
  year          = 2025,
  month         = 8,
  journal       = {Introduction to Statistics and Data Analysis for Physicists},
  publisher     = {World Scientific},
  doi           = {10.1142/14343}
}
@article{bozson_unfolding_2018,
  title         = {Unfolding with {Gaussian} {Processes}},
  author        = {Bozson, Adam and Cowan, Glen and Span\`{o}, Francesco},
  year          = 2018,
  month         = nov,
  note          = {\_eprint: 1811.01242},
  keywords      = {Beta}
}
@article{brehmer_guide_2018,
  title         = {A guide to constraining effective field theories with machine learning},
  author        = {Brehmer, Johann and Cranmer, Kyle and Louppe, Gilles and Pavez, Juan},
  year          = 2018,
  month         = sep,
  journal       = {Physical Review D},
  volume        = 98,
  number        = 5,
  pages         = {052004},
  doi           = {10.1103/PhysRevD.98.052004},
  url           = {https://link.aps.org/doi/10.1103/PhysRevD.98.052004},
  urldate       = {2025-07-15},
  note          = {Publisher: American Physical Society},
  abstract      = {We develop, discuss, and compare several inference techniques to constrain theory parameters in collider experiments. By harnessing the latent-space structure of particle physics processes, we extract extra information from the simulator. This augmented data can be used to train neural networks that precisely estimate the likelihood ratio. The new methods scale well to many observables and high-dimensional parameter spaces, do not require any approximations of the parton shower and detector response, and can be evaluated in microseconds. Using weak-boson-fusion Higgs production as an example process, we compare the performance of several techniques. The best results are found for likelihood ratio estimators trained with extra information about the score, the gradient of the log likelihood function with respect to the theory parameters. The score also provides sufficient statistics that contain all the information needed for inference in the neighborhood of the Standard Model. These methods enable us to put significantly stronger bounds on effective dimension-six operators than the traditional approach based on histograms. They also outperform generic machine learning methods that do not make use of the particle physics structure, demonstrating their potential to substantially improve the new physics reach of the Large Hadron Collider legacy results.}
}
@article{Brehmer2020EffectiveLearning,
  title         = {Effective LHC measurements with matrix elements and machine learning},
  author        = {Brehmer, J and Cranmer, K and Espejo, I and Kling, F and Louppe, G and Pavez, J},
  year          = 2020,
  journal       = {Journal of Physics: Conference Series},
  publisher     = {IOP Publishing},
  volume        = 1525,
  pages         = 12118,
  doi           = {10.1088/1742-6596/1525/1/012118}
}
@article{brewer_entropic_2009,
  title         = {Entropic {Priors} and {Bayesian} {Model} {Selection}},
  author        = {Brewer, Brendon J. and Francis, Matthew J.},
  year          = 2009,
  month         = dec,
  journal       = {AIP Conference Proceedings},
  volume        = 1193,
  number        = 1,
  pages         = {179--186},
  doi           = {10.1063/1.3275612},
  issn          = {0094-243x},
  url           = {https://doi.org/10.1063/1.3275612},
  urldate       = {2025-07-14},
  abstract      = {We demonstrate that the principle of maximum relative entropy (ME), used judiciously, can ease the specification of priors in model selection problems. The resulting effect is that models that make sharp predictions are disfavoured, weakening the usual Bayesian ``Occam's Razor.'' This is illustrated with a simple example involving what Jaynes called a ``sure thing'' hypothesis. Jaynes' resolution of the situation involved introducing a large number of alternative ``sure thing'' hypotheses that were possible before we observed the data. However, in more complex situations, it may not be possible to explicitly enumerate large numbers of alternatives. The entropic priors formalism produces the desired result without modifying the hypothesis space or requiring explicit enumeration of alternatives; all that is required is a good model for the prior predictive distribution for the data. This idea is illustrated with a simple rigged-lottery example, and we outline how this idea may help to resolve a recent debate amongst cosmologists: is dark energy a cosmological constant, or has it evolved with time in some way? And how shall we decide, when the data are in?}
}
@article{britzger_linear_2022,
  title         = {The {Linear} {Template} {Fit}},
  author        = {Britzger, Daniel},
  year          = 2022,
  month         = aug,
  journal       = {The European Physical Journal C},
  volume        = 82,
  number        = 8,
  pages         = 731,
  doi           = {10.1140/epjc/s10052-022-10581-w},
  issn          = {1434-6052},
  url           = {https://doi.org/10.1140/epjc/s10052-022-10581-w},
  urldate       = {2025-07-14},
  abstract      = {The estimation of parameters from data is a common problem in many areas of the physical sciences, and frequently used algorithms rely on sets of simulated data which are fit to data. In this article, an analytic solution for simulation-based parameter estimation problems is presented. The matrix formalism, termed the Linear Template Fit, calculates the best estimators for the parameters of interest. It combines a linear regression with the method of least squares. The algorithm uses only predictions calculated for a few values of the parameters of interest, which have been made available prior to its execution. The Linear Template Fit is particularly suited for performance-critical applications and parameter estimation problems with computationally intense simulations, which are otherwise often limited in their usability for statistical inference. Equations for error propagation are discussed in detail and are given in closed analytic form. For the solution of problems with a nonlinear dependence on the parameters of interest, the Quadratic Template Fit is introduced. As an example application, a determination of the strong coupling constant from inclusive jet cross section data at the CERN Large Hadron Collider is studied and compared with previously published results.},
  language      = {en},
  keywords      = {Applied Statistics, Linear Models and Regression, Model Building and Simulation, Non-parametric Inference, Parametric Inference, Statistical Theory and Methods}
}
@misc{brock_large_2019,
  title         = {Large {Scale} {GAN} {Training} for {High} {Fidelity} {Natural} {Image} {Synthesis}},
  author        = {Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
  year          = 2019,
  month         = feb,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1809.11096},
  url           = {http://arxiv.org/abs/1809.11096},
  urldate       = {2025-07-17},
  note          = {arXiv:1809.11096 [cs]},
  abstract      = {Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple "truncation trick," allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.5 and Frechet Inception Distance (FID) of 7.4, improving over the previous best IS of 52.52 and FID of 18.6.},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning}
}
@article{Brodsky2013PhysicsBeams,
  title         = {Physics opportunities of a fixed-target experiment using LHC beams},
  author        = {Brodsky, S. J. and Fleuret, F. and Hadjidakis, C. and Lansberg, J. P.},
  year          = 2013,
  month         = 1,
  journal       = {Physics Reports},
  publisher     = {North-Holland},
  volume        = 522,
  number        = 4,
  pages         = {239--255},
  doi           = {10.1016/j.physrep.2012.10.001},
  issn          = {0370-1573},
  keywords      = {Fixed-target experiment, LHC beam}
}
@article{buckley_constraints_2025,
  title         = {Constraints {On} {New} {Theories} {Using} {Rivet} : {CONTUR} version 3 release note},
  shorttitle    = {Constraints {On} {New} {Theories} {Using} {Rivet}},
  author        = {Buckley, Andy and Butterworth, Jon and Egan, Joseph and Gutschow, Christian and Jeon, Sihyun and Habedank, Martin and Procter, Tomasz and Wang, Peng and Yeh, Yoran and Yue, Luzhan},
  year          = 2025,
  month         = may,
  journal       = {arXiv e-prints},
  pages         = {arXiv:2505.09272},
  doi           = {10.48550/arXiv.2505.09272},
  url           = {https://ui.adsabs.harvard.edu/abs/2025arXiv250509272B/abstract},
  urldate       = {2025-07-13},
  abstract      = {The CONTUR toolkit exploits RIVET and its library of more than a thousand energy-frontier differential cross-section measurements from the Large Hadron Collider to allow rapid limit-setting and consistency checks for new physics models. In this note we summarise the main changes in the new CONTUR 3 major release series. These include additional statistical treatments, efficiency improvements, new plotting utilities and many new measurements and Standard Model predictions.},
  language      = {en}
}
@misc{buhmann_hadrons_2021,
  title         = {Hadrons, {Better}, {Faster}, {Stronger}},
  author        = {Buhmann, Erik and Diefenbacher, Sascha and Eren, Engin and Gaede, Frank and Hundhausen, Daniel and Kasieczka, Gregor and Korcari, William and Kr\"{u}ger, Katja and McKeown, Peter and Rustige, Lennart},
  year          = 2021,
  month         = dec,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2112.09709},
  url           = {http://arxiv.org/abs/2112.09709},
  urldate       = {2025-07-17},
  note          = {arXiv:2112.09709 [physics]},
  abstract      = {Motivated by the computational limitations of simulating interactions of particles in highly-granular detectors, there exists a concerted effort to build fast and exact machine-learning-based shower simulators. This work reports progress on two important fronts. First, the previously investigated WGAN and BIB-AE generative models are improved and successful learning of hadronic showers initiated by charged pions in a segment of the hadronic calorimeter of the International Large Detector (ILD) is demonstrated for the first time. Second, we consider how state-of-the-art reconstruction software applied to generated shower energies affects the obtainable energy response and resolution. While many challenges remain, these results constitute an important milestone in using generative models in a realistic setting.},
  keywords      = {High Energy Physics - Experiment, High Energy Physics - Phenomenology, Physics - Data Analysis, Statistics and Probability, Physics - Instrumentation and Detectors}
}
@misc{builtjes_attention_2025,
  title         = {Attention to the strengths of physical interactions: {Transformer} and graph-based event classification for particle physics experiments},
  shorttitle    = {Attention to the strengths of physical interactions},
  author        = {Builtjes, Luc and Caron, Sascha and Moskvitina, Polina and Nellist, Clara and Austri, Roberto Ruiz de and Verheyen, Rob and Zhang, Zhongyi},
  year          = 2025,
  month         = jan,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2211.05143},
  url           = {http://arxiv.org/abs/2211.05143},
  urldate       = {2025-07-17},
  note          = {arXiv:2211.05143 [hep-ph]},
  abstract      = {A major task in particle physics is the measurement of rare signal processes. Even modest improvements in background rejection, at a fixed signal efficiency, can significantly enhance the measurement sensitivity. Building on prior research by others that incorporated physical symmetries into neural networks, this work extends those ideas to include additional physics-motivated features. Specifically, we introduce energy-dependent particle interaction strengths, derived from leading-order SM predictions, into modern deep learning architectures, including Transformer Architectures (Particle Transformer), and Graph Neural Networks (Particle Net). These interaction strengths, represented as the SM interaction matrix, are incorporated into the attention matrix (transformers) and edges (graphs). Our results in event classification show that the integration of all physics-motivated features improves background rejection by \$10{\textbackslash}\%-40{\textbackslash}\%\$ over baseline models, with an additional gain of approximately \$10{\textbackslash}\%\$ (absolute) due to the SM interaction matrix. This study also provides one of the broadest comparisons of event classifiers to date, demonstrating how various architectures perform across this task. A simplified statistical analysis demonstrates that these enhanced architectures yield significant improvements in signal significance compared to a graph network baseline.},
  keywords      = {High Energy Physics - Experiment, High Energy Physics - Phenomenology}
}
@article{burton_mixture_2021,
  title         = {Mixture {Density} {Network} {Estimation} of {Continuous} {Variable} {Maximum} {Likelihood} {Using} {Discrete} {Training} {Samples}},
  author        = {Burton, Charles and Stubbs, Spencer and Onyisi, Peter},
  year          = 2021,
  month         = jul,
  journal       = {The European Physical Journal C},
  volume        = 81,
  number        = 7,
  pages         = 662,
  doi           = {10.1140/epjc/s10052-021-09469-y},
  issn          = {1434-6044, 1434-6052},
  url           = {http://arxiv.org/abs/2103.13416},
  urldate       = {2025-07-15},
  note          = {arXiv:2103.13416 [physics]},
  abstract      = {Mixture Density Networks (MDNs) can be used to generate probability density functions of model parameters \${\textbackslash}boldsymbol\{{\textbackslash}theta\}\$ given a set of observables \${\textbackslash}mathbf\{x\}\$. In some applications, training data are available only for discrete values of a continuous parameter \${\textbackslash}boldsymbol\{{\textbackslash}theta\}\$. In such situations a number of performance-limiting issues arise which can result in biased estimates. We demonstrate the usage of MDNs for parameter estimation, discuss the origins of the biases, and propose a corrective method for each issue.},
  keywords      = {Computer Science - Machine Learning, High Energy Physics - Experiment, Physics - Data Analysis, Statistics and Probability}
}
@article{butter_how_2019,
  title         = {How to {GAN} {LHC} events},
  author        = {Butter, Anja and Plehn, Tilman and Winterhalder, Ramon},
  year          = 2019,
  month         = dec,
  journal       = {SciPost Physics},
  volume        = 7,
  number        = 6,
  pages         = {075},
  doi           = {10.21468/SciPostPhys.7.6.075},
  issn          = {2542-4653},
  url           = {https://scipost.org/10.21468/SciPostPhys.7.6.075},
  urldate       = {2025-07-17},
  abstract      = {SciPost Journals Publication Detail SciPost Phys. 7, 075 (2019) How to GAN LHC events},
  language      = {en}
}
@article{Butter2025GenerativeMapping,
  title         = {Generative unfolding with distribution mapping},
  author        = {Butter, Anja and Diefenbacher, Sascha and Huetsch, Nathan and Mikuni, Vinicius and Nachman, Benjamin and Schweitzer, Sofia Palacios and Plehn, Tilman},
  year          = 2025,
  month         = 6,
  journal       = {SciPost Phys.},
  publisher     = {SciPost Foundation},
  volume        = 18,
  number        = 6,
  pages         = 200,
  doi           = {10.21468/scipostphys.18.6.200},
  issn          = 25424653
}
@article{Sjostrand:2014zea,
    author = {Sj{\"o}strand, Torbj{\"o}rn and Ask, Stefan and Christiansen, Jesper R. and Corke, Richard and Desai, Nishita and Ilten, Philip and Mrenna, Stephen and Prestel, Stefan and Rasmussen, Christine O. and Skands, Peter Z.},
    title = "{An introduction to PYTHIA 8.2}",
    eprint = "1410.3012",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    reportNumber = "LU-TP-14-36, MCNET-14-22, CERN-PH-TH-2014-190, FERMILAB-PUB-14-316-CD, DESY-14-178, SLAC-PUB-16122",
    doi = "10.1016/j.cpc.2015.01.024",
    journal = "Comput. Phys. Commun.",
    volume = "191",
    pages = "159--177",
    year = "2015"
}
@article{TheATLAScollaboration:2014rfk,
    title = "{ATLAS Pythia 8 tunes to 7 TeV data}",
    reportNumber = "ATL-PHYS-PUB-2014-021",
    month = "11",
    year = "2014"
}
@article{Mertens:2015kba,
    author = "Mertens, Alexandre",
    editor = "Fiala, L. and Lokajicek, M. and Tumova, N.",
    title = "{New features in Delphes 3}",
    doi = "10.1088/1742-6596/608/1/012045",
    journal = "J. Phys. Conf. Ser.",
    volume = "608",
    number = "1",
    pages = "012045",
    year = "2015"
}
@article{Cacciari:2008gp,
    author = "Cacciari, Matteo and Salam, Gavin P. and Soyez, Gregory",
    title = "{The anti-$k_t$ jet clustering algorithm}",
    eprint = "0802.1189",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    reportNumber = "LPTHE-07-03",
    doi = "10.1088/1126-6708/2008/04/063",
    journal = "JHEP",
    volume = "04",
    pages = "063",
    year = "2008"
}
@article{CMS:2017yfk,
    author = "Sirunyan, A. M. and others",
    collaboration = "CMS",
    title = "{Particle-flow reconstruction and global event description with the CMS detector}",
    eprint = "1706.04965",
    archivePrefix = "arXiv",
    primaryClass = "physics.ins-det",
    reportNumber = "CMS-PRF-14-001, CERN-EP-2017-110",
    doi = "10.1088/1748-0221/12/10/P10003",
    journal = "JINST",
    volume = "12",
    number = "10",
    pages = "P10003",
    year = "2017"
}
@article{Bahr:2008pv,
    author = "Bahr, M. and others",
    title = "{Herwig++ Physics and Manual}",
    eprint = "0803.0883",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    reportNumber = "CERN-PH-TH-2008-038, CAVENDISH-HEP-08-03, KA-TP-05-2008, DCPT-08-22, IPPP-08-11, CP3-08-05",
    doi = "10.1140/epjc/s10052-008-0798-9",
    journal = "Eur. Phys. J. C",
    volume = "58",
    pages = "639--707",
    year = "2008"
}
@article{Sjostrand:2007gs,
    author = "Sjostrand, Torbjorn and Mrenna, Stephen and Skands, Peter Z.",
    title = "{A Brief Introduction to PYTHIA 8.1}",
    eprint = "0710.3820",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    reportNumber = "CERN-LCGAPP-2007-04, LU-TP-07-28, FERMILAB-PUB-07-512-CD-T",
    doi = "10.1016/j.cpc.2008.01.036",
    journal = "Comput. Phys. Commun.",
    volume = "178",
    pages = "852--867",
    year = "2008"
}
@article{Cacciari2008TheAlgorithm,
  title         = {The Anti-k(t) jet clustering algorithm},
  author        = {Cacciari, Matteo and Salam, Gavin P. and Soyez, Gregory},
  year          = 2008,
  month         = 4,
  journal       = {Jhep},
  volume        = {04},
  number        = 4,
  pages         = {063},
  doi           = {10.1088/1126-6708/2008/04/063},
  issn          = 11266708,
  arxivid       = {0802.1189},
  keywords      = {Hadronic colliders, Jets, QCD}
}
@article{Cacciari2012FastJetManual,
  title         = {FastJet User Manual},
  author        = {Cacciari, Matteo and Salam, Gavin P. and Soyez, Gregory},
  year          = 2012,
  month         = 3,
  journal       = {Eur. Phys. J.},
  publisher     = {Springer New York LLC},
  volume        = {C 72},
  number        = 3,
  pages         = 1896,
  doi           = {10.1140/epjc/s10052-012-1896-2},
  issn          = 14346052
}
@article{Cam1986AsymptoticTheory,
  title         = {Asymptotic Methods in Statistical Decision Theory},
  author        = {Cam, Lucien Le},
  year          = 1986,
  publisher     = {Springer New York},
  address       = {New York, NY},
  series        = {Springer Series in Statistics},
  doi           = {10.1007/978-1-4612-4946-7},
  isbn          = {978-1-4612-9369-9},
  url           = {http://link.springer.com/10.1007/978-1-4612-4946-7}
}
@article{Carleo2019MachineSciences,
  title         = {Machine learning and the physical sciences},
  author        = {Carleo, Giuseppe and Cirac, Ignacio and Cranmer, Kyle and Daudet, Laurent and Schuld, Maria and Tishby, Naftali and Vogt-Maranto, Leslie and Zdeborov{\'{a}}, Lenka},
  year          = 2019,
  month         = 12,
  journal       = {Rev.Mod.Phys.},
  publisher     = {American Physical Society},
  volume        = 91,
  number        = 4,
  doi           = {10.1103/revmodphys.91.045002},
  issn          = 15390756,
  arxivid       = {1903.10563}
}
@article{caron_trackformers_2025,
  title         = {{TrackFormers}: {In} {Search} of {Transformer}-{Based} {Particle} {Tracking} for the {High}-{Luminosity} {LHC} {Era}},
  shorttitle    = {TrackFormers},
  author        = {Caron, Sascha and Dobreva, Nadezhda and S\'{a}nchez, Antonio Ferrer and Mart\'{\i}n-Guerrero, Jos\'{e} D. and Odyurt, Uraz and Bazan, Roberto Ruiz de Austri and Wolffs, Zef and Zhao, Yue},
  year          = 2025,
  month         = apr,
  journal       = {The European Physical Journal C},
  volume        = 85,
  number        = 4,
  pages         = 460,
  doi           = {10.1140/epjc/s10052-025-14156-3},
  issn          = {1434-6052},
  url           = {http://arxiv.org/abs/2407.07179},
  urldate       = {2025-07-17},
  note          = {arXiv:2407.07179 [hep-ex]},
  abstract      = {High-Energy Physics experiments are facing a multi-fold data increase with every new iteration. This is certainly the case for the upcoming High-Luminosity LHC upgrade. Such increased data processing requirements forces revisions to almost every step of the data processing pipeline. One such step in need of an overhaul is the task of particle track reconstruction, a.k.a., tracking. A Machine Learning-assisted solution is expected to provide significant improvements, since the most time-consuming step in tracking is the assignment of hits to particles or track candidates. This is the topic of this paper. We take inspiration from large language models. As such, we consider two approaches: the prediction of the next word in a sentence (next hit point in a track), as well as the one-shot prediction of all hits within an event. In an extensive design effort, we have experimented with three models based on the Transformer architecture and one model based on the U-Net architecture, performing track association predictions for collision event hit points. In our evaluation, we consider a spectrum of simple to complex representations of the problem, eliminating designs with lower metrics early on. We report extensive results, covering both prediction accuracy (score) and computational performance. We have made use of the REDVID simulation framework, as well as reductions applied to the TrackML data set, to compose five data sets from simple to complex, for our experiments. The results highlight distinct advantages among different designs in terms of prediction accuracy and computational performance, demonstrating the efficiency of our methodology. Most importantly, the results show the viability of a one-shot encoder-classifier based Transformer solution as a practical approach for the task of tracking.},
  keywords      = {Computer Science - Machine Learning, High Energy Physics - Experiment}
}
@book{carpio_inverse_2008,
  title         = {Inverse {Problems} and {Imaging}},
  author        = {Carpio, Ana and Dorn, Oliver and Moscoso, Miguel and Natterer, Frank and Papanicolaou, George C. and Rap\'{u}n, Maria Luisa and Teta, Alessandro},
  year          = 2008,
  publisher     = {Springer},
  address       = {Berlin, Heidelberg},
  series        = {Lecture {Notes} in {Mathematics}},
  volume        = 1943,
  doi           = {10.1007/978-3-540-78547-7},
  isbn          = {978-3-540-78545-3 978-3-540-78547-7},
  url           = {http://link.springer.com/10.1007/978-3-540-78547-7},
  urldate       = {2025-07-13},
  copyright     = {http://www.springer.com/tdm},
  editor        = {Bonilla, Luis L. and Morel, J. -M. and Takens, F. and Teissier, B.},
  keywords      = {X-ray tomography, computed tomography (CT), electromagnetic and optical imaging, image reconstruction, inverse problems, topological derivatives}
}
@article{Hausdorff1921,
author = {Hausdorff, F.,},
journal = {Mathematische Zeitschrift},
keywords = {Generalized Hausdorff matrices; interpolation problem; moment problem; Müntz's theorem},
language = {ger},
pages = {74-109},
title = {Summationsmethoden und Momentfolgen I.},
url = {http://eudml.org/doc/167613},
volume = {9},
year = {1921},
}
@article{ATLAS:2011lgt,
    author = "Aad, Georges and others",
    collaboration = "ATLAS",
    title = "{Jet energy measurement with the ATLAS detector in proton-proton collisions at $\sqrt{s}=7$ TeV}",
    eprint = "1112.6426",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "CERN-PH-EP-2011-191",
    doi = "10.1140/epjc/s10052-013-2304-2",
    journal = "Eur. Phys. J. C",
    volume = "73",
    number = "3",
    pages = "2304",
    year = "2013"
}
@article{ATLAS:2014bjq,
    author = "Aad, Georges and others",
    collaboration = "ATLAS",
    title = "{Measurement of the cross-section of high transverse momentum vector bosons reconstructed as single jets and studies of jet substructure in $pp$ collisions at ${\sqrt{s}}$ = 7 TeV with the ATLAS detector}",
    eprint = "1407.0800",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "CERN-PH-EP-2014-123",
    doi = "10.1088/1367-2630/16/11/113013",
    journal = "New J. Phys.",
    volume = "16",
    number = "11",
    pages = "113013",
    year = "2014"
}
@article{carrazza_lund_2019,
  title         = {Lund jet images from generative and cycle-consistent adversarial networks},
  author        = {Carrazza, Stefano and Dreyer, Fr\'{e}d\'{e}ric A.},
  year          = 2019,
  month         = nov,
  journal       = {The European Physical Journal C},
  volume        = 79,
  number        = 11,
  pages         = 979,
  doi           = {10.1140/epjc/s10052-019-7501-1},
  issn          = {1434-6044, 1434-6052},
  url           = {http://link.springer.com/10.1140/epjc/s10052-019-7501-1},
  urldate       = {2025-07-17},
  abstract      = {Abstract We introduce a generative model to simulate radiation patterns within a jet using the Lund jet plane. We show that using an appropriate neural network architecture with a stochastic generation of images, it is possible to construct a generative model which retrieves the underlying two-dimensional distribution to within a few percent. We compare our model with several alternative state-of-the-art generative techniques. Finally, we show how a mapping can be created between different categories of jets, and use this method to retroactively change simulation settings or the underlying process on an existing sample. These results provide a framework for significantly reducing simulation times through fast inference of the neural network as well as for data augmentation of physical measurements.},
  language      = {en}
}
@article{Catani:1992ua,
  title         = {Resummation of Large Logarithms in e+ E- Event Shape Distributions},
  author        = {Catani, S. and Trentadue, L. and Turnock, G. and Webber, B. R.},
  year          = 1993,
  journal       = {Nucl. Phys. B},
  volume        = 407,
  pages         = {3--42},
  doi           = {10.1016/0550-3213(93)90271-p},
  abstract      = {We describe a method for the resummation of leading and next-to-leading large logarithms to all orders in QCD perturbation theory, applicable to e + e - event shape distributions that have the property of exponentiation near the two-jet region. After a general discussion of the conditions for exponentiation and the evaluation of matrix elements and phase space to next-to-leading logarithmic accuracy, we give details of the application of the method to the thrust and heavy jet mass distributions. We show how the resummed expressions can be matched with known second-order results to obtain improved predictions throughout the whole of phase space, and how to suppress spurious higher-order terms generated by resummation outside the physical region. We also give the necessary ingredients for the improvement of third-order predictions by resummation when they become available.},
  keywords      = {(2jet): final state,annihilation: electron positron,BETA,electron positron: annihilation,electroproduction: jet,event shape analysis,final state: (2jet),jet: electroproduction,jet: thrust,leading logarithm approximation,quantum chromodynamics: perturbation theory},
  annotation    = {608 citations (INSPIRE 2025/7/18)\\ 569 citations w/o self (INSPIRE 2025/7/18)\\ Citations: 363 (Crossref) [2025-07-18]\\ Citations: 363 (SemanticScholar) [2025-07-18]}
}
@article{caticha_entropic_2004,
  title         = {Entropic {Priors}},
  author        = {Caticha, Ariel and Preuss, Roland},
  year          = 2004,
  month         = apr,
  journal       = {AIP Conference Proceedings},
  volume        = 707,
  number        = 1,
  pages         = {371--380},
  doi           = {10.1063/1.1751380},
  issn          = {0094-243x},
  url           = {https://doi.org/10.1063/1.1751380},
  urldate       = {2025-07-14},
  abstract      = {The method of Maximum (relative) Entropy (ME) is used to translate the information contained in the known form of the likelihood into a prior distribution for Bayesian inference. The argument is guided by intuition gained from the successful use of ME methods in statistical mechanics. For experiments that cannot be repeated the resulting ``entropic prior'' is formally identical with the Einstein fluctuation formula. For repeatable experiments, however, the expected value of the entropy of the likelihood turns out to be relevant information that must be included in the analysis. As an example the entropic prior for a Gaussian likelihood is calculated.}
}
@article{chan_unbinned_2023,
  title         = {Unbinned profiled unfolding},
  author        = {Chan, Jay and Nachman, Benjamin},
  year          = 2023,
  month         = jul,
  journal       = {Physical Review D},
  volume        = 108,
  number        = 1,
  pages         = {016002},
  doi           = {10.1103/PhysRevD.108.016002},
  url           = {https://link.aps.org/doi/10.1103/PhysRevD.108.016002},
  urldate       = {2025-07-13},
  note          = {Publisher: American Physical Society},
  abstract      = {Unfolding is an important procedure in particle physics experiments that corrects for detector effects and provides differential cross section measurements that can be used for a number of downstream tasks, such as extracting fundamental physics parameters. Traditionally, unfolding is done by discretizing the target phase space into a finite number of bins and is limited in the number of unfolded variables. Recently, there have been a number of proposals to perform unbinned unfolding with machine learning. However, none of these methods (like most unfolding methods) allow for simultaneously constraining (profiling) nuisance parameters. We propose a new machine learning-based unfolding method that results in an unbinned differential cross section and can profile nuisance parameters. The machine learning loss function is the full likelihood function, based on binned inputs at detector level. We first demonstrate the method with simple Gaussian examples and then show the impact on a simulated Higgs boson cross section measurement.}
}
@article{chen_physics-guided_2022,
  title         = {Physics-guided mixture density networks for uncertainty quantification},
  author        = {Chen, Jie and Yu, Yang and Liu, Yongming},
  year          = 2022,
  month         = dec,
  journal       = {Reliability Engineering \& System Safety},
  volume        = 228,
  pages         = 108823,
  doi           = {10.1016/j.ress.2022.108823},
  issn          = {0951-8320},
  url           = {https://www.sciencedirect.com/science/article/pii/S0951832022004422},
  urldate       = {2025-07-15},
  abstract      = {This paper proposes a Physics-guided Mixture Density Network (PgMDN) model for uncertainty quantification of regression-type analysis. It integrates a Mixture Density Network for probabilistic modeling and physics knowledge as regularizations. This model can handle arbitrary distribution of data (e.g., strongly non-Gaussian, multi-mode, and truncated distributions). The physics knowledge from parameters and their partial derivatives is used as equality/ inequality constraints. The training of physics-guided machine learning is formulated as a constrained optimization problem. The constrained optimization problem is transformed to an unconstrained one using a dynamic penalty function algorithm. Thus, the commonly used backpropagation algorithm can be used to train the neural network. With the physics constraints, the required training data size can be reduced, and the overfitting problem can be mitigated. This paper demonstrates the application of the PgMDN using a numerical example, an engineering problem for fatigue stress-life curve estimation, an engineering problem for natural frequency prediction of bridges, and an engineering problem for fatigue life prediction of corroded steel reinforcing bars. Some discussions are given to illustrate the effectiveness of incorporating the physics knowledge when data are sparse, the improvement of the dynamic penalty function method compared with the static method, and the benefits achieved from the distribution mixture compared with a single Gaussian distribution.},
  keywords      = {Constrained optimization, Neural network, Physics-guided machine learning, Probabilistic, Uncertainty quantification}
}
@article{Chen2014HiggsTrees,
  title         = {Higgs Boson Discovery with Boosted Trees},
  author        = {Chen, Tianqi and He, Tong},
  year          = 2014,
  journal       = {Hepml\@nips}
}
@article{Chen2020BoostedLearning,
  title         = {Boosted W and Z tagging with jet charge and deep learning},
  author        = {Chen, Yu Chen Janice and Chiang, Cheng Wei and Cottin, Giovanna and Shih, David},
  year          = 2020,
  month         = 3,
  journal       = {Physical Review D},
  publisher     = {American Physical Society},
  volume        = 101,
  number        = 5,
  pages         = {053001},
  doi           = {10.1103/physrevd.101.053001/figures/20/medium},
  issn          = 24700029,
  url           = {https://journals.aps.org/prd/abstract/10.1103/PhysRevD.101.053001},
  arxivid       = {1908.08256},
  keywords      = {doi:10.1103/PhysRevD.101.053001 url:https://doi.org/10.1103/PhysRevD.101.053001}
}
@article{chiefa_parton_2025,
  title         = {Parton distributions confront {LHC} {Run} {II} data: a quantitative appraisal},
  shorttitle    = {Parton distributions confront {LHC} {Run} {II} data},
  author        = {Chiefa, Amedeo and Costantini, Mark N. and Cruz-Martinez, Juan and Nocera, Emanuele R. and Rabemananjara, Tanjona R. and Rojo, Juan and Sharma, Tanishq and Stegeman, Roy and Ubiali, Maria},
  year          = 2025,
  month         = jul,
  journal       = {Journal of High Energy Physics},
  volume        = 2025,
  number        = 7,
  pages         = 67,
  doi           = {10.1007/jhep07(2025)067},
  issn          = {1029-8479},
  url           = {https://doi.org/10.1007/JHEP07(2025)067},
  urldate       = {2025-07-13},
  abstract      = {We present a systematic comparison of theoretical predictions and various high-precision experimental measurements, specifically of differential cross sections performed by the LHC run II for Drell-Yan gauge boson, top-quark pair, single-inclusive jet and di-jet production, and by HERA for single-inclusive jet and di-jet production. Theoretical predictions are computed at next-to-next-to-leading order (NNLO) accuracy in perturbative Quantum Chromodynamics. The most widely employed sets of Parton Distribution Functions (PDFs) are used, and PDF, strong coupling, and missing higher order uncertainties are taken into account. We quantitatively assess the predictive power of each PDF set and the contribution of the different sources of experimental and theoretical uncertainty to the agreement between data and predictions. We show that control over all of these aspects is crucial to precision physics studies, such as the determination of Standard Model parameters at the LHC.},
  language      = {en},
  keywords      = {Experimental Nuclear Physics, Experimental Particle Physics, Nuclear and Particle Physics, Particle Physics, Parton Distributions, Specific QCD Phenomenology, Theoretical Nuclear Physics, Theoretical Particle Physics}
}
@misc{choudalakis_fully_2012,
  title         = {Fully {Bayesian} {Unfolding}},
  author        = {Choudalakis, Georgios},
  year          = 2012,
  month         = may,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1201.4612},
  url           = {http://arxiv.org/abs/1201.4612},
  urldate       = {2025-07-14},
  note          = {arXiv:1201.4612 [physics]},
  abstract      = {Bayesian inference is applied directly to the problem of unfolding. The outcome is a posterior probability density for the spectrum before smearing, defined in the multi-dimensional space of all possible spectra. Regularization consists in choosing a non-constant prior. Despite some similarity, the fully bayesian unfolding (FBU) method, presented here, should not be confused with D'Agostini's iterative method.},
  keywords      = {Physics - Data Analysis, Statistics and Probability}
}
@article{ChungA,
  title         = {A HYBRID LSMR ALGORITHM FOR LARGE-SCALE TIKHONOV REGULARIZATION \textasteriskcentered},
  author        = {Chung, Julianne and Palmer, Katrina},
  doi           = {10.1137/140975024},
  url           = {http://www.siam.org/journals/sisc/37-5/97502.html},
  keywords      = {65F22, 65F30, Tikhonov regularization, hybrid regularization, ill-posed inverse problems AMS subject classifications 65F20, iterative methods}
}
@article{zbMATH03227378,
 author = {Tikhonov, A. N.},
 title = {Solution of incorrectly formulated problems and the regularization method},
 fjournal = {Soviet Mathematics. Doklady},
 journal = {Sov. Math., Dokl.},
 issn = {0197-6788},
 volume = {5},
 pages = {1035--1038},
 year = {1963},
 language = {English},
 zbMATH = {3227378},
 Zbl = {0141.11001}
}
@inproceedings{Blobel:2002pu,
    author = "Blobel, Volker",
    title = "{An Unfolding method for high-energy physics experiments}",
    booktitle = "{Conference on Advanced Statistical Techniques in Particle Physics}",
    eprint = "hep-ex/0208022",
    archivePrefix = "arXiv",
    reportNumber = "DESY-02-078",
    pages = "258--267",
    month = "8",
    year = "2002"
}
@article{Clason2021RegularizationProblems,
  title         = {Regularization of Inverse Problems},
  author        = {Clason, Christian},
  year          = 2021,
  month         = 2,
  url           = {http://arxiv.org/abs/2001.00617},
  arxivid       = {2001.00617v2}
}
@misc{clevert_fast_2016,
  title         = {Fast and {Accurate} {Deep} {Network} {Learning} by {Exponential} {Linear} {Units} ({ELUs})},
  author        = {Clevert, Djork-Arn\'{e} and Unterthiner, Thomas and Hochreiter, Sepp},
  year          = 2016,
  month         = feb,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1511.07289},
  url           = {http://arxiv.org/abs/1511.07289},
  urldate       = {2025-07-15},
  note          = {arXiv:1511.07289 [cs]},
  abstract      = {We introduce the "exponential linear unit" (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values. However, ELUs have improved learning characteristics compared to the units with other activation functions. In contrast to ReLUs, ELUs have negative values which allows them to push mean unit activations closer to zero like batch normalization but with lower computational complexity. Mean shifts toward zero speed up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect. While LReLUs and PReLUs have negative values, too, they do not ensure a noise-robust deactivation state. ELUs saturate to a negative value with smaller inputs and thereby decrease the forward propagated variation and information. Therefore, ELUs code the degree of presence of particular phenomena in the input, while they do not quantitatively model the degree of their absence. In experiments, ELUs lead not only to faster learning, but also to significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers. On CIFAR-100 ELUs networks significantly outperform ReLU networks with batch normalization while batch normalization does not improve ELU networks. ELU networks are among the top 10 reported CIFAR-10 results and yield the best published result on CIFAR-100, without resorting to multi-view evaluation or model averaging. On ImageNet, ELU networks considerably speed up learning compared to a ReLU network with the same architecture, obtaining less than 10\% classification error for a single crop, single model network.},
  keywords      = {Computer Science - Machine Learning}
}
@article{cms_collaboration_measurement_2011,
  title         = {Measurement of the differential cross section for isolated prompt photon production in \$pp\$ collisions at 7 {TeV}},
  author        = {{CMS Collaboration} and Chatrchyan, S. and Khachatryan, V. and Sirunyan, A. M. and Tumasyan, A. and Adam, W. and Bergauer, T. and Dragicevic, M. and Er\"{o}, J. and Fabjan, C. and Friedl, M. and Fr\"{u}hwirth, R. and Ghete, V. M. and Hammer, J. and H\"{a}nsel, S. and Hoch, M. and H\"{o}rmann, N. and Hrubec, J. and Jeitler, M. and Kiesenhofer, W. and Krammer, M. and Liko, D. and Mikulec, I. and Pernicka, M. and Rahbaran, B. and Rohringer, H. and Sch\"{o}fbeck, R. and Strauss, J. and Taurok, A. and Teischinger, F. and Trauner, C. and Wagner, P. and Waltenberger, W. and Walzel, G. and Widl, E. and Wulz, C.-E. and Mossolov, V. and Shumeiko, N. and Suarez Gonzalez, J. and Bansal, S. and Benucci, L. and De Wolf, E. A. and Janssen, X. and Luyckx, S. and Maes, T. and Mucibello, L. and Ochesanu, S. and Roland, B. and Rougny, R. and Selvaggi, M. and Van Haevermaet, H. and Van Mechelen, P. and Van Remortel, N. and Blekman, F. and Blyweert, S. and D'Hondt, J. and Gonzalez Suarez, R. and Kalogeropoulos, A. and Maes, M. and Olbrechts, A. and Van Doninck, W. and Van Mulders, P. and Van Onsem, G. P. and Villella, I. and Charaf, O. and Clerbaux, B. and De Lentdecker, G. and Dero, V. and Gay, A. P. R. and Hammad, G. H. and Hreus, T. and Marage, P. E. and Raval, A. and Thomas, L. and Vander Marcken, G. and Vander Velde, C. and Vanlaer, P. and Adler, V. and Cimmino, A. and Costantini, S. and Grunewald, M. and Klein, B. and Lellouch, J. and Marinov, A. and Mccartin, J. and Ryckbosch, D. and Thyssen, F. and Tytgat, M. and Vanelderen, L. and Verwilligen, P. and Walsh, S. and Zaganidis, N. and Basegmez, S. and Bruno, G. and Caudron, J. and Ceard, L. and Cortina Gil, E. and De Favereau De Jeneret, J. and Delaere, C. and Favart, D. and Giammanco, A. and Gr\'{e}goire, G. and Hollar, J. and Lemaitre, V. and Liao, J. and Militaru, O. and Nuttens, C. and Ovyn, S. and Pagano, D. and Pin, A. and Piotrzkowski, K. and Schul, N. and Beliy, N. and Caebergs, T. and Daubie, E. and Alves, G. A. and Brito, L. and De Jesus Damiao, D. and Pol, M. E. and Souza, M. H. G. and Ald\'{a} J\'{u}nior, W. L. and Carvalho, W. and Da Costa, E. M. and De Oliveira Martins, C. and Fonseca De Souza, S. and Matos Figueiredo, D. and Mundim, L. and Nogima, H. and Oguri, V. and Prado Da Silva, W. L. and Santoro, A. and Silva Do Amaral, S. M. and Sznajder, A. and Bernardes, C. A. and Dias, F. A. and Dos Anjos Costa, T. and Tomei, T. R. Fernandez Perez and Gregores, E. M. and Lagana, C. and Marinho, F. and Mercadante, P. G. and Novaes, S. F. and Padula, Sandra S. and Darmenov, N. and Genchev, V. and Iaydjiev, P. and Piperov, S. and Rodozov, M. and Stoykova, S. and Sultanov, G. and Tcholakov, V. and Trayanov, R. and Vutova, M. and Dimitrov, A. and Hadjiiska, R. and Karadzhinova, A. and Kozhuharov, V. and Litov, L. and Mateev, M. and Pavlov, B. and Petkov, P. and Bian, J. G. and Chen, G. M. and Chen, H. S. and Jiang, C. H. and Liang, D. and Liang, S. and Meng, X. and Tao, J. and Wang, J. and Wang, J. and Wang, X. and Wang, Z. and Xiao, H. and Xu, M. and Zang, J. and Zhang, Z. and Ban, Y. and Guo, S. and Guo, Y. and Li, W. and Mao, Y. and Qian, S. J. and Teng, H. and Zhu, B. and Zou, W. and Cabrera, A. and Gomez Moreno, B. and Ocampo Rios, A. A. and Osorio Oliveros, A. F. and Sanabria, J. C. and Godinovic, N. and Lelas, D. and Lelas, K. and Plestina, R. and Polic, D. and Puljak, I. and Antunovic, Z. and Dzelalija, M. and Kovac, M. and Brigljevic, V. and Duric, S. and Kadija, K. and Luetic, J. and Morovic, S. and Attikis, A. and Galanti, M. and Mousa, J. and Nicolaou, C. and Ptochos, F. and Razis, P. A. and Finger, M. and Finger, M. and Assran, Y. and Ellithi Kamel, A. and Khalil, S. and Mahmoud, M. A. and Radi, A. and Hektor, A. and Kadastik, M. and M\"{u}ntel, M. and Raidal, M. and Rebane, L. and Tiko, A. and Azzolini, V. and Eerola, P. and Fedi, G. and Voutilainen, M. and Czellar, S. and H\"{a}rk\"{o}nen, J. and Heikkinen, A. and Karim\"{a}ki, V. and Kinnunen, R. and Kortelainen, M. J. and Lamp\'{e}n, T. and Lassila-Perini, K. and Lehti, S. and Lind\'{e}n, T. and Luukka, P. and M\"{a}enp\"{a}\"{a}, T. and Tuominen, E. and Tuominiemi, J. and Tuovinen, E. and Ungaro, D. and Wendland, L. and Banzuzi, K. and Karjalainen, A. and Korpela, A. and Tuuva, T. and Sillou, D. and Besancon, M. and Choudhury, S. and Dejardin, M. and Denegri, D. and Fabbro, B. and Faure, J. L. and Ferri, F. and Ganjour, S. and Gentit, F. X. and Givernaud, A. and Gras, P. and Hamel de Monchenault, G. and Jarry, P. and Locci, E. and Malcles, J. and Marionneau, M. and Millischer, L. and Rander, J. and Rosowsky, A. and Shreyber, I. and Titov, M. and Verrecchia, P. and Baffioni, S. and Beaudette, F. and Benhabib, L. and Bianchini, L. and Bluj, M. and Broutin, C. and Busson, P. and Charlot, C. and Dahms, T. and Dobrzynski, L. and Elgammal, S. and Granier de Cassagnac, R. and Haguenauer, M. and Min\'{e}, P. and Mironov, C. and Ochando, C. and Paganini, P. and Sabes, D. and Salerno, R. and Sirois, Y. and Thiebaux, C. and Wyslouch, B. and Zabi, A. and Agram, J.-L. and Andrea, J. and Bloch, D. and Bodin, D. and Brom, J.-M. and Cardaci, M. and Chabert, E. C. and Collard, C. and Conte, E. and Drouhin, F. and Ferro, C. and Fontaine, J.-C. and Gel\'{e}, D. and Goerlach, U. and Greder, S. and Juillot, P. and Karim, M. and Le Bihan, A.-C. and Mikami, Y. and Van Hove, P. and Fassi, F. and Mercier, D. and Baty, C. and Beauceron, S. and Beaupere, N. and Bedjidian, M. and Bondu, O. and Boudoul, G. and Boumediene, D. and Brun, H. and Chasserat, J. and Chierici, R. and Contardo, D. and Depasse, P. and El Mamouni, H. and Fay, J. and Gascon, S. and Ille, B. and Kurca, T. and Le Grand, T. and Lethuillier, M. and Mirabito, L. and Perries, S. and Sordini, V. and Tosi, S. and Tschudi, Y. and Verdier, P. and Viret, S. and Lomidze, D. and Anagnostou, G. and Beranek, S. and Edelhoff, M. and Feld, L. and Heracleous, N. and Hindrichs, O. and Jussen, R. and Klein, K. and Merz, J. and Mohr, N. and Ostapchuk, A. and Perieanu, A. and Raupach, F. and Sammet, J. and Schael, S. and Sprenger, D. and Weber, H. and Weber, M. and Wittmer, B. and Ata, M. and Dietz-Laursonn, E. and Erdmann, M. and Hebbeker, T. and Heidemann, C. and Hinzmann, A. and Hoepfner, K. and Klimkovich, T. and Klingebiel, D. and Kreuzer, P. and Lanske, D. and Lingemann, J. and Magass, C. and Merschmeyer, M. and Meyer, A. and Papacz, P. and Pieta, H. and Reithler, H. and Schmitz, S. A. and Sonnenschein, L. and Steggemann, J. and Teyssier, D. and Bontenackels, M. and Cherepanov, V. and Davids, M. and Duda, M. and Fl\"{u}gge, G. and Geenen, H. and Giffels, M. and Haj Ahmad, W. and Heydhausen, D. and Hoehle, F. and Kargoll, B. and Kress, T. and Kuessel, Y. and Linn, A. and Nowack, A. and Perchalla, L. and Pooth, O. and Rennefeld, J. and Sauerland, P. and Stahl, A. and Tornier, D. and Zoeller, M. H. and Aldaya Martin, M. and Behrenhoff, W. and Behrens, U. and Bergholz, M. and Bethani, A. and Borras, K. and Cakir, A. and Campbell, A. and Castro, E. and Dammann, D. and Eckerlin, G. and Eckstein, D. and Flossdorf, A. and Flucke, G. and Geiser, A. and Hauk, J. and Jung, H. and Kasemann, M. and Katsas, P. and Kleinwort, C. and Kluge, H. and Knutsson, A. and Kr\"{a}mer, M. and Kr\"{u}cker, D. and Kuznetsova, E. and Lange, W. and Lohmann, W. and Mankel, R. and Marienfeld, M. and Melzer-Pellmann, I.-A. and Meyer, A. B. and Mnich, J. and Mussgiller, A. and Olzem, J. and Petrukhin, A. and Pitzl, D. and Raspereza, A. and Rosin, M. and Schmidt, R. and Schoerner-Sadenius, T. and Sen, N. and Spiridonov, A. and Stein, M. and Tomaszewska, J. and Walsh, R. and Wissing, C. and Autermann, C. and Blobel, V. and Bobrovskyi, S. and Draeger, J. and Enderle, H. and Gebbert, U. and G\"{o}rner, M. and Hermanns, T. and Kaschube, K. and Kaussen, G. and Kirschenmann, H. and Klanner, R. and Lange, J. and Mura, B. and Naumann-Emme, S. and Nowak, F. and Pietsch, N. and Sander, C. and Schettler, H. and Schleper, P. and Schlieckau, E. and Schr\"{o}der, M. and Schum, T. and Stadie, H. and Steinbr\"{u}ck, G. and Thomsen, J. and Barth, C. and Bauer, J. and Berger, J. and Buege, V. and Chwalek, T. and De Boer, W. and Dierlamm, A. and Dirkes, G. and Feindt, M. and Gruschke, J. and Hackstein, C. and Hartmann, F. and Heinrich, M. and Held, H. and Hoffmann, K. H. and Honc, S. and Katkov, I. and Komaragiri, J. R. and Kuhr, T. and Martschei, D. and Mueller, S. and M\"{u}ller, Th. and Niegel, M. and Oberst, O. and Oehler, A. and Ott, J. and Peiffer, T. and Quast, G. and Rabbertz, K. and Ratnikov, F. and Ratnikova, N. and Renz, M. and Saout, C. and Scheurer, A. and Schieferdecker, P. and Schilling, F.-P. and Schott, G. and Simonis, H. J. and Stober, F. M. and Troendle, D. and Wagner-Kuhr, J. and Weiler, T. and Zeise, M. and Zhukov, V. and Ziebarth, E. B. and Daskalakis, G. and Geralis, T. and Kesisoglou, S. and Kyriakis, A. and Loukas, D. and Manolakos, I. and Markou, A. and Markou, C. and Mavrommatis, C. and Ntomari, E. and Petrakou, E. and Gouskos, L. and Mertzimekis, T. J. and Panagiotou, A. and Saoulidou, N. and Stiliaris, E. and Evangelou, I. and Foudas, C. and Kokkas, P. and Manthos, N. and Papadopoulos, I. and Patras, V. and Triantis, F. A. and Aranyi, A. and Bencze, G. and Boldizsar, L. and Hajdu, C. and Hidas, P. and Horvath, D. and Kapusi, A. and Krajczar, K. and Sikler, F. and Veres, G. I. and Vesztergombi, G. and Beni, N. and Molnar, J. and Palinkas, J. and Szillasi, Z. and Veszpremi, V. and Raics, P. and Trocsanyi, Z. L. and Ujvari, B. and Beri, S. B. and Bhatnagar, V. and Dhingra, N. and Gupta, R. and Jindal, M. and Kaur, M. and Kohli, J. M. and Mehta, M. Z. and Nishu, N. and Saini, L. K. and Sharma, A. and Singh, A. P. and Singh, J. and Singh, S. P. and Ahuja, S. and Choudhary, B. C. and Gupta, P. and Kumar, A. and Kumar, A. and Malhotra, S. and Naimuddin, M. and Ranjan, K. and Shivpuri, R. K. and Banerjee, S. and Bhattacharya, S. and Dutta, S. and Gomber, B. and Jain, S. and Jain, S. and Khurana, R. and Sarkar, S. and Choudhury, R. K. and Dutta, D. and Kailas, S. and Kumar, V. and Mehta, P. and Mohanty, A. K. and Pant, L. M. and Shukla, P. and Aziz, T. and Guchait, M. and Gurtu, A. and Maity, M. and Majumder, D. and Majumder, G. and Mazumdar, K. and Mohanty, G. B. and Saha, A. and Sudhakar, K. and Wickramage, N. and Banerjee, S. and Dugad, S. and Mondal, N. K. and Arfaei, H. and Bakhshiansohi, H. and Etesami, S. M. and Fahim, A. and Hashemi, M. and Hesari, H. and Jafari, A. and Khakzad, M. and Mohammadi, A. and Mohammadi Najafabadi, M. and Paktinat Mehdiabadi, S. and Safarzadeh, B. and Zeinali, M. and Abbrescia, M. and Barbone, L. and Calabria, C. and Colaleo, A. and Creanza, D. and De Filippis, N. and De Palma, M. and Fiore, L. and Iaselli, G. and Lusito, L. and Maggi, G. and Maggi, M. and Manna, N. and Marangelli, B. and My, S. and Nuzzo, S. and Pacifico, N. and Pierro, G. A. and Pompili, A. and Pugliese, G. and Romano, F. and Roselli, G. and Selvaggi, G. and Silvestris, L. and Trentadue, R. and Tupputi, S. and Zito, G. and Abbiendi, G. and Benvenuti, A. C. and Bonacorsi, D. and Braibant-Giacomelli, S. and Brigliadori, L. and Capiluppi, P. and Castro, A. and Cavallo, F. R. and Cuffiani, M. and Dallavalle, G. M. and Fabbri, F. and Fanfani, A. and Fasanella, D. and Giacomelli, P. and Giunta, M. and Grandi, C. and Marcellini, S. and Masetti, G. and Meneghelli, M. and Montanari, A. and Navarria, F. L. and Odorici, F. and Perrotta, A. and Primavera, F. and Rossi, A. M. and Rovelli, T. and Siroli, G. and Travaglini, R. and Albergo, S. and Cappello, G. and Chiorboli, M. and Costa, S. and Potenza, R. and Tricomi, A. and Tuve, C. and Barbagli, G. and Ciulli, V. and Civinini, C. and D'Alessandro, R. and Focardi, E. and Frosali, S. and Gallo, E. and Gonzi, S. and Lenzi, P. and Meschini, M. and Paoletti, S. and Sguazzoni, G. and Tropiano, A. and Benussi, L. and Bianco, S. and Colafranceschi, S. and Fabbri, F. and Piccolo, D. and Fabbricatore, P. and Musenich, R. and Benaglia, A. and De Guio, F. and Di Matteo, L. and Gennai, S. and Ghezzi, A. and Malvezzi, S. and Martelli, A. and Massironi, A. and Menasce, D. and Moroni, L. and Paganoni, M. and Pedrini, D. and Ragazzi, S. and Redaelli, N. and Sala, S. and Tabarelli de Fatis, T. and Buontempo, S. and Carrillo Montoya, C. A. and Cavallo, N. and De Cosa, A. and Fabozzi, F. and Iorio, A. O. M. and Lista, L. and Merola, M. and Paolucci, P. and Azzi, P. and Bacchetta, N. and Bellan, P. and Bisello, D. and Branca, A. and Carlin, R. and Checchia, P. and Dorigo, T. and Dosselli, U. and Fanzago, F. and Gasparini, F. and Gasparini, U. and Gozzelino, A. and Lacaprara, S. and Lazzizzera, I. and Margoni, M. and Mazzucato, M. and Meneguzzo, A. T. and Nespolo, M. and Perrozzi, L. and Pozzobon, N. and Ronchese, P. and Simonetto, F. and Torassa, E. and Tosi, M. and Vanini, S. and Zotto, P. and Zumerle, G. and Baesso, P. and Berzano, U. and Ratti, S. P. and Riccardi, C. and Torre, P. and Vitulo, P. and Viviani, C. and Biasini, M. and Bilei, G. M. and Caponeri, B. and Fan\`{o}, L. and Lariccia, P. and Lucaroni, A. and Mantovani, G. and Menichelli, M. and Nappi, A. and Romeo, F. and Santocchia, A. and Taroni, S. and Valdata, M. and Azzurri, P. and Bagliesi, G. and Bernardini, J. and Boccali, T. and Broccolo, G. and Castaldi, R. and D'Agnolo, R. T. and Dell'Orso, R. and Fiori, F. and Fo\`{a}, L. and Giassi, A. and Kraan, A. and Ligabue, F. and Lomtadze, T. and Martini, L. and Messineo, A. and Palla, F. and Palmonari, F. and Segneri, G. and Serban, A. T. and Spagnolo, P. and Tenchini, R. and Tonelli, G. and Venturi, A. and Verdini, P. G. and Barone, L. and Cavallari, F. and Del Re, D. and Di Marco, E. and Diemoz, M. and Franci, D. and Grassi, M. and Longo, E. and Meridiani, P. and Nourbakhsh, S. and Organtini, G. and Pandolfi, F. and Paramatti, R. and Rahatlou, S. and Sigamani, M. and Amapane, N. and Arcidiacono, R. and Argiro, S. and Arneodo, M. and Biino, C. and Botta, C. and Cartiglia, N. and Castello, R. and Costa, M. and Demaria, N. and Graziano, A. and Mariotti, C. and Maselli, S. and Migliore, E. and Monaco, V. and Musich, M. and Obertino, M. M. and Pastrone, N. and Pelliccioni, M. and Potenza, A. and Romero, A. and Ruspa, M. and Sacchi, R. and Sola, V. and Solano, A. and Staiano, A. and Vilela Pereira, A. and Belforte, S. and Cossutti, F. and Della Ricca, G. and Gobbo, B. and Marone, M. and Montanino, D. and Penzo, A. and Heo, S. G. and Nam, S. K. and Chang, S. and Chung, J. and Kim, D. H. and Kim, G. N. and Kim, J. E. and Kong, D. J. and Park, H. and Ro, S. R. and Son, D. C. and Son, T. and Kim, J. Y. and Kim, Zero J. and Song, S. and Jo, H. Y. and Choi, S. and Gyun, D. and Hong, B. and Jo, M. and Kim, H. and Kim, J. H. and Kim, T. J. and Lee, K. S. and Moon, D. H. and Park, S. K. and Seo, E. and Sim, K. S. and Choi, M. and Kang, S. and Kim, H. and Park, C. and Park, I. C. and Park, S. and Ryu, G. and Cho, Y. and Choi, Y. and Choi, Y. K. and Goh, J. and Kim, M. S. and Lee, B. and Lee, J. and Lee, S. and Seo, H. and Yu, I. and Bilinskas, M. J. and Grigelionis, I. and Janulis, M. and Martisiute, D. and Petrov, P. and Polujanskas, M. and Sabonis, T. and Castilla-Valdez, H. and De La Cruz-Burelo, E. and Heredia-de La Cruz, I. and Lopez-Fernandez, R. and Maga\~{n}a Villalba, R. and Mart\'{\i}nez-Ortega, J. and S\'{a}nchez-Hern\'{a}ndez, A. and Villasenor-Cendejas, L. M. and Carrillo Moreno, S. and Vazquez Valencia, F. and Salazar Ibarguen, H. A. and Casimiro Linares, E. and Morelos Pineda, A. and Reyes-Santos, M. A. and Krofcheck, D. and Tam, J. and Butler, P. H. and Doesburg, R. and Silverwood, H. and Ahmad, M. and Ahmed, I. and Ansari, M. H. and Asghar, M. I. and Hoorani, H. R. and Khalid, S. and Khan, W. A. and Khurshid, T. and Qazi, S. and Shah, M. A. and Shoaib, M. and Brona, G. and Cwiok, M. and Dominik, W. and Doroba, K. and Kalinowski, A. and Konecki, M. and Krolikowski, J. and Frueboes, T. and Gokieli, R. and G\'{o}rski, M. and Kazana, M. and Nawrocki, K. and Romanowska-Rybinska, K. and Szleper, M. and Wrochna, G. and Zalewski, P. and Almeida, N. and Bargassa, P. and David, A. and Faccioli, P. and Ferreira Parracho, P. G. and Gallinaro, M. and Musella, P. and Nayak, A. and Pela, J. and Ribeiro, P. Q. and Seixas, J. and Varela, J. and Afanasiev, S. and Belotelov, I. and Bunin, P. and Gavrilenko, M. and Golutvin, I. and Kamenev, A. and Karjavin, V. and Kozlov, G. and Lanev, A. and Moisenz, P. and Palichik, V. and Perelygin, V. and Shmatov, S. and Smirnov, V. and Volodko, A. and Zarubin, A. and Golovtsov, V. and Ivanov, Y. and Kim, V. and Levchenko, P. and Murzin, V. and Oreshkin, V. and Smirnov, I. and Sulimov, V. and Uvarov, L. and Vavilov, S. and Vorobyev, A. and Vorobyev, An. and Andreev, Yu. and Dermenev, A. and Gninenko, S. and Golubev, N. and Kirsanov, M. and Krasnikov, N. and Matveev, V. and Pashenkov, A. and Toropin, A. and Troitsky, S. and Epshteyn, V. and Erofeeva, M. and Gavrilov, V. and Kaftanov, V. and Kossov, M. and Krokhotin, A. and Lychkovskaya, N. and Popov, V. and Safronov, G. and Semenov, S. and Stolin, V. and Vlasov, E. and Zhokin, A. and Belyaev, A. and Boos, E. and Dubinin, M. and Dudko, L. and Ershov, A. and Gribushin, A. and Kodolova, O. and Lokhtin, I. and Markina, A. and Obraztsov, S. and Perfilov, M. and Petrushanko, S. and Sarycheva, L. and Savrin, V. and Snigirev, A. and Andreev, V. and Azarkin, M. and Dremin, I. and Kirakosyan, M. and Leonidov, A. and Mesyats, G. and Rusakov, S. V. and Vinogradov, A. and Azhgirey, I. and Bayshev, I. and Bitioukov, S. and Grishin, V. and Kachanov, V. and Konstantinov, D. and Korablev, A. and Krychkine, V. and Petrov, V. and Ryutin, R. and Sobol, A. and Tourtchanovitch, L. and Troshin, S. and Tyurin, N. and Uzunian, A. and Volkov, A. and Adzic, P. and Djordjevic, M. and Krpic, D. and Milosevic, J. and Aguilar-Benitez, M. and Alcaraz Maestre, J. and Arce, P. and Battilana, C. and Calvo, E. and Cerrada, M. and Chamizo Llatas, M. and Colino, N. and De La Cruz, B. and Delgado Peris, A. and Diez Pardos, C. and Dom\'{\i}nguez V\'{a}zquez, D. and Fernandez Bedoya, C. and Fern\'{a}ndez Ramos, J. P. and Ferrando, A. and Flix, J. and Fouz, M. C. and Garcia-Abia, P. and Gonzalez Lopez, O. and Goy Lopez, S. and Hernandez, J. M. and Josa, M. I. and Merino, G. and Puerta Pelayo, J. and Redondo, I. and Romero, L. and Santaolalla, J. and Soares, M. S. and Willmott, C. and Albajar, C. and Codispoti, G. and de Troc\'{o}niz, J. F. and Cuevas, J. and Fernandez Menendez, J. and Folgueras, S. and Gonzalez Caballero, I. and Lloret Iglesias, L. and Vizan Garcia, J. M. and Brochero Cifuentes, J. A. and Cabrillo, I. J. and Calderon, A. and Chuang, S. H. and Duarte Campderros, J. and Felcini, M. and Fernandez, M. and Gomez, G. and Gonzalez Sanchez, J. and Jorda, C. and Lobelle Pardo, P. and Lopez Virto, A. and Marco, J. and Marco, R. and Martinez Rivero, C. and Matorras, F. and Munoz Sanchez, F. J. and Piedra Gomez, J. and Rodrigo, T. and Rodr\'{\i}guez-Marrero, A. Y. and Ruiz-Jimeno, A. and Scodellaro, L. and Sobron Sanudo, M. and Vila, I. and Vilar Cortabitarte, R. and Abbaneo, D. and Auffray, E. and Auzinger, G. and Baillon, P. and Ball, A. H. and Barney, D. and Bell, A. J. and Benedetti, D. and Bernet, C. and Bialas, W. and Bloch, P. and Bocci, A. and Bolognesi, S. and Bona, M. and Breuker, H. and Bunkowski, K. and Camporesi, T. and Cerminara, G. and Christiansen, T. and Coarasa Perez, J. A. and Cur\'{e}, B. and D'Enterria, D. and De Roeck, A. and Di Guida, S. and Dupont-Sagorin, N. and Elliott-Peisert, A. and Frisch, B. and Funk, W. and Gaddi, A. and Georgiou, G. and Gerwig, H. and Gigi, D. and Gill, K. and Giordano, D. and Glege, F. and Gomez-Reino Garrido, R. and Gouzevitch, M. and Govoni, P. and Gowdy, S. and Guida, R. and Guiducci, L. and Hansen, M. and Hartl, C. and Harvey, J. and Hegeman, J. and Hegner, B. and Hoffmann, H. F. and Innocente, V. and Janot, P. and Kaadze, K. and Karavakis, E. and Lecoq, P. and Louren\c{c}o, C. and M\"{a}ki, T. and Malberti, M. and Malgeri, L. and Mannelli, M. and Masetti, L. and Maurisset, A. and Meijers, F. and Mersi, S. and Meschi, E. and Moser, R. and Mozer, M. U. and Mulders, M. and Nesvold, E. and Nguyen, M. and Orimoto, T. and Orsini, L. and Palencia Cortezon, E. and Perez, E. and Petrilli, A. and Pfeiffer, A. and Pierini, M. and Pimi\"{a}, M. and Piparo, D. and Polese, G. and Quertenmont, L. and Racz, A. and Reece, W. and Rodrigues Antunes, J. and Rolandi, G. and Rommerskirchen, T. and Rovelli, C. and Rovere, M. and Sakulin, H. and Sch\"{a}fer, C. and Schwick, C. and Segoni, I. and Sharma, A. and Siegrist, P. and Silva, P. and Simon, M. and Sphicas, P. and Spiga, D. and Spiropulu, M. and Stoye, M. and Tsirou, A. and Vichoudis, P. and W\"{o}hri, H. K. and Worm, S. D. and Zeuner, W. D. and Bertl, W. and Deiters, K. and Erdmann, W. and Gabathuler, K. and Horisberger, R. and Ingram, Q. and Kaestli, H. C. and K\"{o}nig, S. and Kotlinski, D. and Langenegger, U. and Meier, F. and Renker, D. and Rohe, T. and Sibille, J. and B\"{a}ni, L. and Bortignon, P. and Caminada, L. and Casal, B. and Chanon, N. and Chen, Z. and Cittolin, S. and Dissertori, G. and Dittmar, M. and Eugster, J. and Freudenreich, K. and Grab, C. and Hintz, W. and Lecomte, P. and Lustermann, W. and Marchica, C. and Martinez Ruiz del Arbol, P. and Milenovic, P. and Moortgat, F. and N\"{a}geli, C. and Nef, P. and Nessi-Tedaldi, F. and Pape, L. and Pauss, F. and Punz, T. and Rizzi, A. and Ronga, F. J. and Rossini, M. and Sala, L. and Sanchez, A. K. and Sawley, M.-C. and Starodumov, A. and Stieger, B. and Takahashi, M. and Tauscher, L. and Thea, A. and Theofilatos, K. and Treille, D. and Urscheler, C. and Wallny, R. and Weber, M. and Wehrli, L. and Weng, J. and Aguilo, E. and Amsler, C. and Chiochia, V. and De Visscher, S. and Favaro, C. and Ivova Rikova, M. and Jaeger, A. and Millan Mejias, B. and Otiougova, P. and Robmann, P. and Schmidt, A. and Snoek, H. and Chang, Y. H. and Chen, K. H. and Kuo, C. M. and Li, S. W. and Lin, W. and Liu, Z. K. and Lu, Y. J. and Mekterovic, D. and Volpe, R. and Yu, S. S. and Bartalini, P. and Chang, P. and Chang, Y. H. and Chang, Y. W. and Chao, Y. and Chen, K. F. and Hou, W.-S. and Hsiung, Y. and Kao, K. Y. and Lei, Y. J. and Lu, R.-S. and Shiu, J. G. and Tzeng, Y. M. and Wan, X. and Wang, M. and Adiguzel, A. and Bakirci, M. N. and Cerci, S. and Dozen, C. and Dumanoglu, I. and Eskut, E. and Girgis, S. and Gokbulut, G. and Hos, I. and Kangal, E. E. and Kayis Topaksu, A. and Onengut, G. and Ozdemir, K. and Ozturk, S. and Polatoz, A. and Sogut, K. and Sunar Cerci, D. and Tali, B. and Topakli, H. and Uzun, D. and Vergili, L. N. and Vergili, M. and Akin, I. V. and Aliev, T. and Bilin, B. and Bilmis, S. and Deniz, M. and Gamsizkan, H. and Guler, A. M. and Ocalan, K. and Ozpineci, A. and Serin, M. and Sever, R. and Surat, U. E. and Yalvac, M. and Yildirim, E. and Zeyrek, M. and Deliomeroglu, M. and Demir, D. and G\"{u}lmez, E. and Isildak, B. and Kaya, M. and Kaya, O. and \"{O}zbek, M. and Ozkorucuklu, S. and Sonmez, N. and Levchuk, L. and Bostock, F. and Brooke, J. J. and Cheng, T. L. and Clement, E. and Cussans, D. and Frazier, R. and Goldstein, J. and Grimes, M. and Hartley, D. and Heath, G. P. and Heath, H. F. and Kreczko, L. and Metson, S. and Newbold, D. M. and Nirunpong, K. and Poll, A. and Senkin, S. and Smith, V. J. and Basso, L. and Bell, K. W. and Belyaev, A. and Brew, C. and Brown, R. M. and Camanzi, B. and Cockerill, D. J. A. and Coughlan, J. A. and Harder, K. and Harper, S. and Jackson, J. and Kennedy, B. W. and Olaiya, E. and Petyt, D. and Radburn-Smith, B. C. and Shepherd-Themistocleous, C. H. and Tomalin, I. R. and Womersley, W. J. and Bainbridge, R. and Ball, G. and Ballin, J. and Beuselinck, R. and Buchmuller, O. and Colling, D. and Cripps, N. and Cutajar, M. and Davies, G. and Della Negra, M. and Ferguson, W. and Fulcher, J. and Futyan, D. and Gilbert, A. and Guneratne Bryer, A. and Hall, G. and Hatherell, Z. and Hays, J. and Iles, G. and Jarvis, M. and Karapostoli, G. and Lyons, L. and MacEvoy, B. C. and Magnan, A.-M. and Marrouche, J. and Mathias, B. and Nandi, R. and Nash, J. and Nikitenko, A. and Papageorgiou, A. and Pesaresi, M. and Petridis, K. and Pioppi, M. and Raymond, D. M. and Rogerson, S. and Rompotis, N. and Rose, A. and Ryan, M. J. and Seez, C. and Sharp, P. and Sparrow, A. and Tapper, A. and Tourneur, S. and Vazquez Acosta, M. and Virdee, T. and Wakefield, S. and Wardle, N. and Wardrope, D. and Whyntie, T. and Barrett, M. and Chadwick, M. and Cole, J. E. and Hobson, P. R. and Khan, A. and Kyberd, P. and Leslie, D. and Martin, W. and Reid, I. D. and Teodorescu, L. and Hatakeyama, K. and Liu, H. and Henderson, C. and Bose, T. and Carrera Jarrin, E. and Fantasia, C. and Heister, A. and St. John, J. and Lawson, P. and Lazic, D. and Rohlf, J. and Sperka, D. and Sulak, L. and Avetisyan, A. and Bhattacharya, S. and Chou, J. P. and Cutts, D. and Ferapontov, A. and Heintz, U. and Jabeen, S. and Kukartsev, G. and Landsberg, G. and Luk, M. and Narain, M. and Nguyen, D. and Segala, M. and Sinthuprasith, T. and Speer, T. and Tsang, K. V. and Breedon, R. and Breto, G. and Calderon De La Barca Sanchez, M. and Chauhan, S. and Chertok, M. and Conway, J. and Conway, R. and Cox, P. T. and Dolen, J. and Erbacher, R. and Friis, E. and Ko, W. and Kopecky, A. and Lander, R. and Liu, H. and Maruyama, S. and Miceli, T. and Nikolic, M. and Pellett, D. and Robles, J. and Rutherford, B. and Salur, S. and Schwarz, T. and Searle, M. and Smith, J. and Squires, M. and Tripathi, M. and Vasquez Sierra, R. and Veelken, C. and Andreev, V. and Arisaka, K. and Cline, D. and Cousins, R. and Deisher, A. and Duris, J. and Erhan, S. and Farrell, C. and Hauser, J. and Ignatenko, M. and Jarvis, C. and Plager, C. and Rakness, G. and Schlein, P. and Tucker, J. and Valuev, V. and Babb, J. and Chandra, A. and Clare, R. and Ellison, J. and Gary, J. W. and Giordano, F. and Hanson, G. and Jeng, G. Y. and Kao, S. C. and Liu, F. and Liu, H. and Long, O. R. and Luthra, A. and Nguyen, H. and Paramesvaran, S. and Shen, B. C. and Stringer, R. and Sturdy, J. and Sumowidagdo, S. and Wilken, R. and Wimpenny, S. and Andrews, W. and Branson, J. G. and Cerati, G. B. and Evans, D. and Golf, F. and Holzner, A. and Kelley, R. and Lebourgeois, M. and Letts, J. and Mangano, B. and Padhi, S. and Palmer, C. and Petrucciani, G. and Pi, H. and Pieri, M. and Ranieri, R. and Sani, M. and Sharma, V. and Simon, S. and Sudano, E. and Tadel, M. and Tu, Y. and Vartak, A. and Wasserbaech, S. and W\"{u}rthwein, F. and Yagil, A. and Yoo, J. and Barge, D. and Bellan, R. and Campagnari, C. and D'Alfonso, M. and Danielson, T. and Flowers, K. and Geffert, P. and Incandela, J. and Justus, C. and Kalavase, P. and Koay, S. A. and Kovalskyi, D. and Krutelyov, V. and Lowette, S. and Mccoll, N. and Mullin, E. and Pavlunin, V. and Rebassoo, F. and Ribnik, J. and Richman, J. and Rossin, R. and Stuart, D. and To, W. and Vlimant, J. R. and West, C. and Apresyan, A. and Bornheim, A. and Bunn, J. and Chen, Y. and Gataullin, M. and Ma, Y. and Mott, A. and Newman, H. B. and Rogan, C. and Shin, K. and Timciuc, V. and Traczyk, P. and Veverka, J. and Wilkinson, R. and Yang, Y. and Zhu, R. Y. and Akgun, B. and Carroll, R. and Ferguson, T. and Iiyama, Y. and Jang, D. W. and Jun, S. Y. and Liu, Y. F. and Paulini, M. and Russ, J. and Vogel, H. and Vorobiev, I. and Cumalat, J. P. and Dinardo, M. E. and Drell, B. R. and Edelmaier, C. J. and Ford, W. T. and Gaz, A. and Heyburn, B. and Luiggi Lopez, E. and Nauenberg, U. and Smith, J. G. and Stenson, K. and Ulmer, K. A. and Wagner, S. R. and Zang, S. L. and Agostino, L. and Alexander, J. and Chatterjee, A. and Eggert, N. and Gibbons, L. K. and Heltsley, B. and Henriksson, K. and Hopkins, W. and Khukhunaishvili, A. and Kreis, B. and Liu, Y. and Nicolas Kaufman, G. and Patterson, J. R. and Puigh, D. and Ryd, A. and Saelim, M. and Salvati, E. and Shi, X. and Sun, W. and Teo, W. D. and Thom, J. and Thompson, J. and Vaughan, J. and Weng, Y. and Winstrom, L. and Wittich, P. and Biselli, A. and Cirino, G. and Winn, D. and Abdullin, S. and Albrow, M. and Anderson, J. and Apollinari, G. and Atac, M. and Bakken, J. A. and Bauerdick, L. A. T. and Beretvas, A. and Berryhill, J. and Bhat, P. C. and Bloch, I. and Burkett, K. and Butler, J. N. and Chetluru, V. and Cheung, H. W. K. and Chlebana, F. and Cihangir, S. and Cooper, W. and Eartly, D. P. and Elvira, V. D. and Esen, S. and Fisk, I. and Freeman, J. and Gao, Y. and Gottschalk, E. and Green, D. and Gunthoti, K. and Gutsche, O. and Hanlon, J. and Harris, R. M. and Hirschauer, J. and Hooberman, B. and Jensen, H. and Johnson, M. and Joshi, U. and Khatiwada, R. and Klima, B. and Kousouris, K. and Kunori, S. and Kwan, S. and Leonidopoulos, C. and Limon, P. and Lincoln, D. and Lipton, R. and Lykken, J. and Maeshima, K. and Marraffino, J. M. and Mason, D. and McBride, P. and Miao, T. and Mishra, K. and Mrenna, S. and Musienko, Y. and Newman-Holmes, C. and O'Dell, V. and Pivarski, J. and Pordes, R. and Prokofyev, O. and Sexton-Kennedy, E. and Sharma, S. and Spalding, W. J. and Spiegel, L. and Tan, P. and Taylor, L. and Tkaczyk, S. and Uplegger, L. and Vaandering, E. W. and Vidal, R. and Whitmore, J. and Wu, W. and Yang, F. and Yumiceva, F. and Yun, J. C. and Acosta, D. and Avery, P. and Bourilkov, D. and Chen, M. and Das, S. and De Gruttola, M. and Di Giovanni, G. P. and Dobur, D. and Drozdetskiy, A. and Field, R. D. and Fisher, M. and Fu, Y. and Furic, I. K. and Gartner, J. and Goldberg, S. and Hugon, J. and Kim, B. and Konigsberg, J. and Korytov, A. and Kropivnitskaya, A. and Kypreos, T. and Low, J. F. and Matchev, K. and Mitselmakher, G. and Muniz, L. and Myeonghun, P. and Prescott, C. and Remington, R. and Rinkevicius, A. and Schmitt, M. and Scurlock, B. and Sellers, P. and Skhirtladze, N. and Snowball, M. and Wang, D. and Yelton, J. and Zakaria, M. and Gaultney, V. and Lebolo, L. M. and Linn, S. and Markowitz, P. and Martinez, G. and Rodriguez, J. L. and Adams, T. and Askew, A. and Bochenek, J. and Chen, J. and Diamond, B. and Gleyzer, S. V. and Haas, J. and Hagopian, S. and Hagopian, V. and Jenkins, M. and Johnson, K. F. and Prosper, H. and Sekmen, S. and Veeraraghavan, V. and Baarmand, M. M. and Dorney, B. and Hohlmann, M. and Kalakhety, H. and Vodopiyanov, I. and Adams, M. R. and Anghel, I. M. and Apanasevich, L. and Bai, Y. and Bazterra, V. E. and Betts, R. R. and Callner, J. and Cavanaugh, R. and Dragoiu, C. and Gauthier, L. and Gerber, C. E. and Hofman, D. J. and Khalatyan, S. and Kunde, G. J. and Lacroix, F. and Malek, M. and O'Brien, C. and Silkworth, C. and Silvestre, C. and Smoron, A. and Strom, D. and Varelas, N. and Akgun, U. and Albayrak, E. A. and Bilki, B. and Clarida, W. and Duru, F. and Lae, C. K. and McCliment, E. and Merlo, J.-P. and Mermerkaya, H. and Mestvirishvili, A. and Moeller, A. and Nachtman, J. and Newsom, C. R. and Norbeck, E. and Olson, J. and Onel, Y. and Ozok, F. and Sen, S. and Wetzel, J. and Yetkin, T. and Yi, K. and Barnett, B. A. and Blumenfeld, B. and Bonato, A. and Eskew, C. and Fehling, D. and Giurgiu, G. and Gritsan, A. V. and Guo, Z. J. and Hu, G. and Maksimovic, P. and Rappoccio, S. and Swartz, M. and Tran, N. V. and Whitbeck, A. and Baringer, P. and Bean, A. and Benelli, G. and Grachov, O. and Kenny Iii, R. P. and Murray, M. and Noonan, D. and Sanders, S. and Wood, J. S. and Zhukova, V. and Barfuss, A. f. and Bolton, T. and Chakaberia, I. and Ivanov, A. and Khalil, S. and Makouski, M. and Maravin, Y. and Shrestha, S. and Svintradze, I. and Wan, Z. and Gronberg, J. and Lange, D. and Wright, D. and Baden, A. and Boutemeur, M. and Eno, S. C. and Ferencek, D. and Gomez, J. A. and Hadley, N. J. and Kellogg, R. G. and Kirn, M. and Lu, Y. and Mignerey, A. C. and Rossato, K. and Rumerio, P. and Santanastasio, F. and Skuja, A. and Temple, J. and Tonjes, M. B. and Tonwar, S. C. and Twedt, E. and Alver, B. and Bauer, G. and Bendavid, J. and Busza, W. and Butz, E. and Cali, I. A. and Chan, M. and Dutta, V. and Everaerts, P. and Gomez Ceballos, G. and Goncharov, M. and Hahn, K. A. and Harris, P. and Kim, Y. and Klute, M. and Lee, Y.-J. and Li, W. and Loizides, C. and Luckey, P. D. and Ma, T. and Nahn, S. and Paus, C. and Ralph, D. and Roland, C. and Roland, G. and Rudolph, M. and Stephans, G. S. F. and St\"{o}ckli, F. and Sumorok, K. and Sung, K. and Velicanu, D. and Wenger, E. A. and Wolf, R. and Xie, S. and Yang, M. and Yilmaz, Y. and Yoon, A. S. and Zanetti, M. and Cooper, S. I. and Cushman, P. and Dahmes, B. and De Benedetti, A. and Franzoni, G. and Gude, A. and Haupt, J. and Klapoetke, K. and Kubota, Y. and Mans, J. and Pastika, N. and Rekovic, V. and Rusack, R. and Sasseville, M. and Singovsky, A. and Tambe, N. and Turkewitz, J. and Cremaldi, L. M. and Godang, R. and Kroeger, R. and Perera, L. and Rahmat, R. and Sanders, D. A. and Summers, D. and Bloom, K. and Bose, S. and Butt, J. and Claes, D. R. and Dominguez, A. and Eads, M. and Jindal, P. and Keller, J. and Kelly, T. and Kravchenko, I. and Lazo-Flores, J. and Malbouisson, H. and Malik, S. and Snow, G. R. and Baur, U. and Godshalk, A. and Iashvili, I. and Jain, S. and Kharchilava, A. and Kumar, A. and Shipkowski, S. P. and Smith, K. and Alverson, G. and Barberis, E. and Baumgartel, D. and Boeriu, O. and Chasco, M. and Reucroft, S. and Swain, J. and Trocino, D. and Wood, D. and Zhang, J. and Anastassov, A. and Kubik, A. and Mucia, N. and Odell, N. and Ofierzynski, R. A. and Pollack, B. and Pozdnyakov, A. and Schmitt, M. and Stoynev, S. and Velasco, M. and Won, S. and Antonelli, L. and Berry, D. and Brinkerhoff, A. and Hildreth, M. and Jessop, C. and Karmgard, D. J. and Kolb, J. and Kolberg, T. and Lannon, K. and Luo, W. and Lynch, S. and Marinelli, N. and Morse, D. M. and Pearson, T. and Ruchti, R. and Slaunwhite, J. and Valls, N. and Wayne, M. and Ziegler, J. and Bylsma, B. and Durkin, L. S. and Gu, J. and Hill, C. and Killewald, P. and Kotov, K. and Ling, T. Y. and Rodenburg, M. and Vuosalo, C. and Williams, G. and Adam, N. and Berry, E. and Elmer, P. and Gerbaudo, D. and Halyo, V. and Hebda, P. and Hunt, A. and Laird, E. and Lopes Pegna, D. and Marlow, D. and Medvedeva, T. and Mooney, M. and Olsen, J. and Pirou\'{e}, P. and Quan, X. and Safdi, B. and Saka, H. and Stickland, D. and Tully, C. and Werner, J. S. and Zuranski, A. and Acosta, J. G. and Huang, X. T. and Lopez, A. and Mendez, H. and Oliveros, S. and Ramirez Vargas, J. E. and Zatserklyaniy, A. and Alagoz, E. and Barnes, V. E. and Bolla, G. and Borrello, L. and Bortoletto, D. and De Mattia, M. and Everett, A. and Garfinkel, A. F. and Gutay, L. and Hu, Z. and Jones, M. and Koybasi, O. and Kress, M. and Laasanen, A. T. and Leonardo, N. and Liu, C. and Maroussov, V. and Merkel, P. and Miller, D. H. and Neumeister, N. and Shipsey, I. and Silvers, D. and Svyatkovskiy, A. and Yoo, H. D. and Zablocki, J. and Zheng, Y. and Guragain, S. and Parashar, N. and Adair, A. and Boulahouache, C. and Ecklund, K. M. and Geurts, F. J. M. and Padley, B. P. and Redjimi, R. and Roberts, J. and Zabel, J. and Betchart, B. and Bodek, A. and Chung, Y. S. and Covarelli, R. and de Barbaro, P. and Demina, R. and Eshaq, Y. and Flacher, H. and Garcia-Bellido, A. and Goldenzweig, P. and Gotra, Y. and Han, J. and Harel, A. and Miner, D. C. and Orbaker, D. and Petrillo, G. and Sakumoto, W. and Vishnevskiy, D. and Zielinski, M. and Bhatti, A. and Ciesielski, R. and Demortier, L. and Goulianos, K. and Lungu, G. and Malik, S. and Mesropian, C. and Arora, S. and Atramentov, O. and Barker, A. and Contreras-Campana, C. and Contreras-Campana, E. and Duggan, D. and Gershtein, Y. and Gray, R. and Halkiadakis, E. and Hidas, D. and Hits, D. and Lath, A. and Panwalkar, S. and Patel, R. and Richards, A. and Rose, K. and Schnetzer, S. and Somalwar, S. and Stone, R. and Thomas, S. and Cerizza, G. and Hollingsworth, M. and Spanier, S. and Yang, Z. C. and York, A. and Eusebi, R. and Flanagan, W. and Gilmore, J. and Gurrola, A. and Kamon, T. and Khotilovich, V. and Montalvo, R. and Osipenkov, I. and Pakhotin, Y. and Safonov, A. and Sengupta, S. and Suarez, I. and Tatarinov, A. and Toback, D. and Akchurin, N. and Bardak, C. and Damgov, J. and Dudero, P. R. and Jeong, C. and Kovitanggoon, K. and Lee, S. W. and Libeiro, T. and Mane, P. and Roh, Y. and Sill, A. and Volobouev, I. and Wigmans, R. and Yazgan, E. and Appelt, E. and Brownson, E. and Engh, D. and Florez, C. and Gabella, W. and Issah, M. and Johns, W. and Johnston, C. and Kurt, P. and Maguire, C. and Melo, A. and Sheldon, P. and Snook, B. and Tuo, S. and Velkovska, J. and Arenton, M. W. and Balazs, M. and Boutle, S. and Cox, B. and Francis, B. and Goadhouse, S. and Goodell, J. and Hirosky, R. and Ledovskoy, A. and Lin, C. and Neu, C. and Wood, J. and Yohay, R. and Gollapinni, S. and Harr, R. and Karchin, P. E. and Kottachchi Kankanamge Don, C. and Lamichhane, P. and Mattson, M. and Milst\`{e}ne, C. and Sakharov, A. and Anderson, M. and Bachtis, M. and Belknap, D. and Bellinger, J. N. and Carlsmith, D. and Cepeda, M. and Dasu, S. and Efron, J. and Gray, L. and Grogg, K. S. and Grothe, M. and Hall-Wilton, R. and Herndon, M. and Herv\'{e}, A. and Klabbers, P. and Klukas, J. and Lanaro, A. and Lazaridis, C. and Leonard, J. and Loveless, R. and Mohapatra, A. and Ojalvo, I. and Parker, W. and Ross, I. and Savin, A. and Smith, W. H. and Swanson, J. and Weinberg, M.},
  year          = 2011,
  month         = sep,
  journal       = {Physical Review D},
  volume        = 84,
  number        = 5,
  pages         = {052011},
  doi           = {10.1103/PhysRevD.84.052011},
  url           = {https://link.aps.org/doi/10.1103/PhysRevD.84.052011},
  urldate       = {2025-07-13},
  note          = {Publisher: American Physical Society},
  abstract      = {A measurement of the differential cross section for the inclusive production of isolated prompt photons in proton-proton collisions at a center-of-mass energy of 7 TeV is presented. The data sample corresponds to an integrated luminosity of 36 pb -1 recorded by the CMS detector at the LHC. The measurement covers the pseudorapidity range {\textbar}��{\textbar} {\textless}2.5 and the transverse energy range 25 {\textless}��T {\textless}400 GeV, corresponding to the kinematic region 0.007 {\textless}��T {\textless}0.114. Photon candidates are identified with two complementary methods, one based on photon conversions in the silicon tracker and the other on isolated energy deposits in the electromagnetic calorimeter. The measured cross section is presented as a function of ��T in four pseudorapidity regions. The next-to-leading-order perturbative QCD calculations are consistent with the measured cross section.},
  file          = {APS Snapshot:/Users/t-krishdesai/Zotero/storage/D56GXW3C/PhysRevD.84.html:text/html;Full Text PDF:/Users/t-krishdesai/Zotero/storage/WDUIJTD8/CMS Collaboration et al. - 2011 - Measurement of the differential cross section for isolated prompt photon production in \$pp\$ collisio.pdf:application/pdf}
}
@article{CMS:2025sws,
  title         = {{Measurement of event shapes in minimum-bias events from proton-proton collisions at $\sqrt{s}$ = 13 TeV}},
  author        = {Chekhovsky, Vladimir and others},
  year          = 2025,
  month         = 5,
  collaboration = {Cms},
  eprint        = {2505.17850},
  archiveprefix = {arXiv},
  primaryclass  = {hep-ex},
  reportnumber  = {Cms-smp-23-008, Cern-ep-2025-041}
}
@incollection{cmusic,
  title         = {The Hoofmark Hermetic Synthesis Program},
  author        = {Francis Moore Hebrew},
  year          = 1985,
  booktitle     = {Baboon Adduce Kit},
  publisher     = {Center for Music Experiment}
}
@misc{collaboration_machine_2024,
  title         = {Machine {Learning}-{Assisted} {Measurement} of {Lepton}-{Jet} {Azimuthal} {Angular} {Asymmetries} in {Deep}-{Inelastic} {Scattering} at {HERA}},
  author        = {collaboration, The H1 and Andreev, V. and Arratia, M. and Baghdasaryan, A. and Baty, A. and Begzsuren, K. and Bolz, A. and Boudry, V. and Brandt, G. and Britzger, D. and Buniatyan, A. and Bystritskaya, L. and Campbell, A. J. and Avila, K. B. Cantun and Cerny, K. and Chekelian, V. and Chen, Z. and Contreras, J. G. and Cvach, J. and Dainton, J. B. and Daum, K. and Deshpande, A. and Diaconu, C. and Drees, A. and Eckerlin, G. and Egli, S. and Elsen, E. and Favart, L. and Fedotov, A. and Feltesse, J. and Fleischer, M. and Fomenko, A. and Gal, C. and Gayler, J. and Goerlich, L. and Gogitidze, N. and Gouzevitch, M. and Grab, C. and Greenshaw, T. and Grindhammer, G. and Haidt, D. and Henderson, R. C. W. and Hessler, J. and Hladk\'{y}, J. and Hoffmann, D. and Horisberger, R. and Hreus, T. and Huber, F. and Jacobs, P. M. and Jacquet, M. and Janssen, T. and Jung, A. W. and Katzy, J. and Kiesling, C. and Klein, M. and Kleinwort, C. and Klest, H. T. and Kogler, R. and Kostka, P. and Kretzschmar, J. and Kr\"{u}cker, D. and Kr\"{u}ger, K. and Landon, M. P. J. and Lange, W. and Laycock, P. and Lee, S. H. and Levonian, S. and Li, W. and Lin, J. and Lipka, K. and List, B. and List, J. and Lobodzinski, B. and Long, O. R. and Malinovski, E. and Martyn, H.-U. and Maxfield, S. J. and Mehta, A. and Meyer, A. B. and Meyer, J. and Mikocki, S. and Mikuni, V. M. and Mondal, M. M. and M\"{u}ller, K. and Nachman, B. and Naumann, Th and Newman, P. R. and Niebuhr, C. and Nowak, G. and Olsson, J. E. and Ozerov, D. and Park, S. and Pascaud, C. and Patel, G. D. and Perez, E. and Petrukhin, A. and Picuric, I. and Pitzl, D. and Radescu, V. and Raicevic, N. and Ravdandorj, T. and Reichelt, D. and Reimer, P. and Rizvi, E. and Robmann, P. and Roosen, R. and Rostovtsev, A. and Rotaru, M. and Sankey, D. P. C. and Sauter, M. and Sauvan, E. and Schmitt, S. and Schmookler, B. A. and Schnell, G. and Schoeffel, L. and Sch\"{o}ning, A. and Sefkow, F. and Shushkevich, S. and Soloviev, Y. and Sopicki, P. and South, D. and Specka, A. and Steder, M. and Stella, B. and Straumann, U. and Sun, C. and Sykora, T. and Thompson, P. D. and Acosta, F. Torales and Traynor, D. and Tseepeldorj, B. and Tu, Z. and Tustin, G. and Valk\'{a}rov\'{a}, A. and Vall\'{e}e, C. and Mechelen, P. Van and Wegener, D. and W\"{u}nsch, E. and \v{Z}\'{a}\v{c}ek, J. and Zhang, J. and Zhang, Z. and \v{Z}leb\v{c}\'{\i}k, R. and Zohrabyan, H. and Zomer, F.},
  year          = 2024,
  month         = dec,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2412.14092},
  url           = {http://arxiv.org/abs/2412.14092},
  urldate       = {2025-07-15},
  note          = {arXiv:2412.14092 [hep-ex]},
  abstract      = {In deep-inelastic positron-proton scattering, the lepton-jet azimuthal angular asymmetry is measured using data collected with the H1 detector at HERA. When the average transverse momentum of the lepton-jet system, \${\textbackslash}lvert {\textbackslash}vec\{P\}\_{\textbackslash}perp {\textbackslash}rvert \$, is much larger than the total transverse momentum of the system, \${\textbackslash}lvert {\textbackslash}vec\{q\}\_{\textbackslash}perp {\textbackslash}rvert\$, the asymmetry between parallel and antiparallel configurations, \${\textbackslash}vec\{P\}\_{\textbackslash}perp\$ and \${\textbackslash}vec\{q\}\_{\textbackslash}perp\$, is expected to be generated by initial and final state soft gluon radiation and can be predicted using perturbation theory. Quantifying the angular properties of the asymmetry therefore provides an additional test of the strong force. Studying the asymmetry is important for future measurements of intrinsic asymmetries generated by the proton's constituents through Transverse Momentum Dependent (TMD) Parton Distribution Functions (PDFs), where this asymmetry constitutes a dominant background. Moments of the azimuthal asymmetries are measured using a machine learning method for unfolding that does not require binning.},
  keywords      = {High Energy Physics - Experiment, High Energy Physics - Phenomenology, Nuclear Experiment}
}
@misc{collaboration_measurement_2022,
  title         = {Measurement of lepton-jet correlation in deep-inelastic scattering with the {H1} detector using machine learning for unfolding},
  author        = {Collaboration, H1 and Andreev, V. and Arratia, M. and Baghdasaryan, A. and Baty, A. and Begzsuren, K. and Belousov, A. and Bolz, A. and Boudry, V. and Brandt, G. and Britzger, D. and Buniatyan, A. and Bystritskaya, L. and Campbell, A. J. and Avila, K. B. Cantun and Cerny, K. and Chekelian, V. and Chen, Z. and Contreras, J. G. and Mendez, L. Cunqueiro and Cvach, J. and Dainton, J. B. and Daum, K. and Deshpande, A. and Diaconu, C. and Eckerlin, G. and Egli, S. and Elsen, E. and Favart, L. and Fedotov, A. and Feltesse, J. and Fleischer, M. and Fomenko, A. and Gal, C. and Gayler, J. and Goerlich, L. and Gogitidze, N. and Gouzevitch, M. and Grab, C. and Greenshaw, T. and Grindhammer, G. and Haidt, D. and Henderson, R. C. W. and Hessler, J. and Hladk\'{y}, J. and Hoffmann, D. and Horisberger, R. and Hreus, T. and Huber, F. and Jacobs, P. M. and Jacquet, M. and Janssen, T. and Jung, A. W. and Jung, H. and Kapichine, M. and Katzy, J. and Kiesling, C. and Klein, M. and Kleinwort, C. and Klest, H. T. and Kogler, R. and Kostka, P. and Kretzschmar, J. and Kr\"{u}cker, D. and Kr\"{u}ger, K. and Landon, M. P. J. and Lange, W. and Laycock, P. and Lee, S. H. and Levonian, S. and Lin, J. and Lipka, K. and List, B. and List, J. and Li, W. and Lobodzinski, B. and Malinovski, E. and Martyn, H.-U. and Maxfield, S. J. and Mehta, A. and Meyer, A. B. and Meyer, J. and Mikocki, S. and Mondal, M. M. and Morozov, A. and M\"{u}ller, K. and Nachman, B. and Naumann, Th and Newman, P. R. and Niebuhr, C. and Nowak, G. and Olsson, J. E. and Ozerov, D. and Park, S. and Pascaud, C. and Patel, G. D. and Perez, E. and Petrukhin, A. and Picuric, I. and Pitzl, D. and Polifka, R. and Preins, S. and Radescu, V. and Raicevic, N. and Ravdandorj, T. and Reimer, P. and Rizvi, E. and Robmann, P. and Roosen, R. and Rostovtsev, A. and Rotaru, M. and Sankey, D. P. C. and Sauter, M. and Sauvan, E. and Schmitt, S. and Schmookler, B. A. and Schoeffel, L. and Sch\"{o}ning, A. and Sefkow, F. and Shushkevich, S. and Soloviev, Y. and Sopicki, P. and South, D. and Spaskov, V. and Specka, A. and Steder, M. and Stella, B. and Straumann, U. and Sun, C. and Sykora, T. and Thompson, P. D. and Traynor, D. and Tseepeldorj, B. and Tu, Z. and Valk\'{a}rov\'{a}, A. and Vall\'{e}e, C. and Mechelen, P. Van and Wegener, D. and W\"{u}nsch, E. and \v{Z}\'{a}\v{c}ek, J. and Zhang, J. and Zhang, Z. and \v{Z}leb\v{c}\'{\i}k, R. and Zohrabyan, H. and Zomer, F.},
  year          = 2022,
  month         = apr,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2108.12376},
  url           = {http://arxiv.org/abs/2108.12376},
  urldate       = {2025-07-15},
  note          = {arXiv:2108.12376 [hep-ex]},
  abstract      = {The first measurement of lepton-jet momentum imbalance and azimuthal correlation in lepton-proton scattering at high momentum transfer is presented. These data, taken with the H1 detector at HERA, are corrected for detector effects using an unbinned machine learning algorithm OmniFold, which considers eight observables simultaneously in this first application. The unfolded cross sections are compared to calculations performed within the context of collinear or transverse-momentum-dependent (TMD) factorization in Quantum Chromodynamics (QCD) as well as Monte Carlo event generators. The measurement probes a wide range of QCD phenomena, including TMD parton distribution functions and their evolution with energy in so far unexplored kinematic regions.},
  keywords      = {High Energy Physics - Experiment, High Energy Physics - Phenomenology}
}
@article{collaboration_measurement_2025,
  title         = {Measurement of jet track functions in \$pp\$ collisions at \${\textbackslash}sqrt\{s\}=13\$ {TeV} with the {ATLAS} detector},
  author        = {Collaboration, ATLAS},
  year          = 2025,
  month         = jun,
  journal       = {Physics Letters B},
  pages         = 139680,
  doi           = {10.1016/j.physletb.2025.139680},
  issn          = {03702693},
  url           = {http://arxiv.org/abs/2502.02062},
  urldate       = {2025-07-15},
  note          = {arXiv:2502.02062 [hep-ex]},
  abstract      = {Measurements of jet substructure are key to probing the energy frontier at colliders, and many of them use track-based observables which take advantage of the angular precision of tracking detectors. Theoretical calculations of track-based observables require `track functions', which characterize the transverse momentum fraction \$r\_q\$ carried by charged hadrons from a fragmenting quark or gluon. This letter presents a direct measurement of \$r\_q\$ distributions in dijet events from the 140 fb\${\textasciicircum}\{-1\}\$ of proton-proton collisions at \${\textbackslash}sqrt\{s\}=13\$ TeV recorded with the ATLAS detector. The data are corrected for detector effects using machine-learning methods. The scale evolution of the moments of the \$r\_q\$ distribution is sensitive to non-linear renormalization group evolution equations of QCD, and is compared with analytic predictions. When incorporated into future theoretical calculations, these results will enable a precision program of theory-data comparison for track-based jet substructure observables.},
  keywords      = {High Energy Physics - Experiment}
}
@article{collaboration_multidifferential_2023,
  title         = {Multidifferential study of identified charged hadron distributions in \${Z}\$-tagged jets in proton-proton collisions at \ {TeV}},
  author        = {Collaboration, LHCb},
  year          = 2023,
  month         = aug,
  journal       = {Physical Review D},
  volume        = 108,
  number        = 3,
  pages         = {L031103},
  doi           = {10.1103/PhysRevD.108.L031103},
  issn          = {2470-0010, 2470-0029},
  url           = {http://arxiv.org/abs/2208.11691},
  urldate       = {2025-07-15},
  note          = {arXiv:2208.11691 [hep-ex]},
  abstract      = {Jet fragmentation functions are measured for the first time in proton-proton collisions for charged pions, kaons, and protons within jets recoiling against a \$Z\$ boson. The charged-hadron distributions are studied longitudinally and transversely to the jet direction for jets with transverse momentum 20 \${\textless} p\_\{{\textbackslash}textrm\{T\}\} {\textless} 100\$ GeV and in the pseudorapidity range \$2.5 {\textless} {\textbackslash}eta {\textless} 4\$. The data sample was collected with the LHCb experiment at a center-of-mass energy of 13 TeV, corresponding to an integrated luminosity of 1.64 fb\${\textasciicircum}\{-1\}\$. Triple differential distributions as a function of the hadron longitudinal momentum fraction, hadron transverse momentum, and jet transverse momentum are also measured for the first time. This helps constrain transverse-momentum-dependent fragmentation functions. Differences in the shapes and magnitudes of the measured distributions for the different hadron species provide insights into the hadronization process for jets predominantly initiated by light quarks.},
  keywords      = {High Energy Physics - Experiment}
}
@article{collaboration_observation_2012,
  title         = {Observation of a new boson at a mass of 125 {GeV} with the {CMS} experiment at the {LHC}},
  author        = {Collaboration, The CMS},
  year          = 2012,
  month         = sep,
  journal       = {Physics Letters B},
  volume        = 716,
  number        = 1,
  pages         = {30--61},
  doi           = {10.1016/j.physletb.2012.08.021},
  issn          = {03702693},
  url           = {http://arxiv.org/abs/1207.7235},
  urldate       = {2025-07-13},
  note          = {arXiv:1207.7235 [hep-ex]},
  abstract      = {Results are presented from searches for the standard model Higgs boson in proton-proton collisions at sqrt(s) = 7 and 8 TeV in the Compact Muon Solenoid experiment at the LHC, using data samples corresponding to integrated luminosities of up to 5.1 inverse femtobarns at 7 TeV and 5.3 inverse femtobarns at 8 TeV. The search is performed in five decay modes: gamma gamma, ZZ, WW, tau tau, and b b-bar. An excess of events is observed above the expected background, with a local significance of 5.0 standard deviations, at a mass near 125 GeV, signalling the production of a new particle. The expected significance for a standard model Higgs boson of that mass is 5.8 standard deviations. The excess is most significant in the two decay modes with the best mass resolution, gamma gamma and ZZ; a fit to these signals gives a mass of 125.3 +/- 0.4 (stat.) +/- 0.5 (syst.) GeV. The decay to two photons indicates that the new particle is a boson with spin different from one.},
  keywords      = {High Energy Physics - Experiment}
}
@article{collaboration_simultaneous_2024,
  title         = {A simultaneous unbinned differential cross section measurement of twenty-four \${Z}\$+jets kinematic observables with the {ATLAS} detector},
  author        = {Collaboration, ATLAS},
  year          = 2024,
  month         = dec,
  journal       = {Physical Review Letters},
  volume        = 133,
  number        = 26,
  pages         = 261803,
  doi           = {10.1103/PhysRevLett.133.261803},
  issn          = {0031-9007, 1079-7114},
  url           = {http://arxiv.org/abs/2405.20041},
  urldate       = {2025-07-15},
  note          = {arXiv:2405.20041 [hep-ex]},
  abstract      = {\$Z\$ boson events at the Large Hadron Collider can be selected with high purity and are sensitive to a diverse range of QCD phenomena. As a result, these events are often used to probe the nature of the strong force, improve Monte Carlo event generators, and search for deviations from Standard Model predictions. All previous measurements of \$Z\$ boson production characterize the event properties using a small number of observables and present the results as differential cross sections in predetermined bins. In this analysis, a machine learning method called OmniFold is used to produce a simultaneous measurement of twenty-four \$Z\$+jets observables using \$139\$ fb\${\textasciicircum}\{-1\}\$ of proton-proton collisions at \${\textbackslash}sqrt\{s\}=13\$ TeV collected with the ATLAS detector. Unlike any previous fiducial differential cross-section measurement, this result is presented unbinned as a dataset of particle-level events, allowing for flexible re-use in a variety of contexts and for new observables to be constructed from the twenty-four measured observables.},
  keywords      = {High Energy Physics - Experiment}
}
@article{collaboration_unbinned_2023,
  title         = {Unbinned {Deep} {Learning} {Jet} {Substructure} {Measurement} in {High} \${Q}{\textasciicircum}2\$ ep collisions at {HERA}},
  author        = {collaboration, The H1 and Andreev, V. and Arratia, M. and Baghdasaryan, A. and Baty, A. and Begzsuren, K. and Bolz, A. and Boudry, V. and Brandt, G. and Britzger, D. and Buniatyan, A. and Bystritskaya, L. and Campbell, A. J. and Avila, K. B. Cantun and Cerny, K. and Chekelian, V. and Chen, Z. and Contreras, J. G. and Cvach, J. and Dainton, J. B. and Daum, K. and Deshpande, A. and Diaconu, C. and Drees, A. and Eckerlin, G. and Egli, S. and Elsen, E. and Favart, L. and Fedotov, A. and Feltesse, J. and Fleischer, M. and Fomenko, A. and Gal, C. and Gayler, J. and Goerlich, L. and Gogitidze, N. and Gouzevitch, M. and Grab, C. and Greenshaw, T. and Grindhammer, G. and Haidt, D. and Henderson, R. C. W. and Hessler, J. and Hladk\'{y}, J. and Hoffmann, D. and Horisberger, R. and Hreus, T. and Huber, F. and Jacobs, P. M. and Jacquet, M. and Janssen, T. and Jung, A. W. and Katzy, J. and Kiesling, C. and Klein, M. and Kleinwort, C. and Klest, H. T. and Kogler, R. and Kostka, P. and Kretzschmar, J. and Kr\"{u}cker, D. and Kr\"{u}ger, K. and Landon, M. P. J. and Lange, W. and Laycock, P. and Lee, S. H. and Levonian, S. and Li, W. and Lin, J. and Lipka, K. and List, B. and List, J. and Lobodzinski, B. and Long, O. R. and Malinovski, E. and Martyn, H.-U. and Maxfield, S. J. and Mehta, A. and Meyer, A. B. and Meyer, J. and Mikocki, S. and Mikuni, V. M. and Mondal, M. M. and M\"{u}ller, K. and Nachman, B. and Naumann, Th and Newman, P. R. and Niebuhr, C. and Nowak, G. and Olsson, J. E. and Ozerov, D. and Park, S. and Pascaud, C. and Patel, G. D. and Perez, E. and Petrukhin, A. and Picuric, I. and Pitzl, D. and Polifka, R. and Preins, S. and Radescu, V. and Raicevic, N. and Ravdandorj, T. and Reimer, P. and Rizvi, E. and Robmann, P. and Roosen, R. and Rostovtsev, A. and Rotaru, M. and Sankey, D. P. C. and Sauter, M. and Sauvan, E. and Schmitt, S. and Schmookler, B. A. and Schnell, G. and Schoeffel, L. and Sch\"{o}ning, A. and Sefkow, F. and Shushkevich, S. and Soloviev, Y. and Sopicki, P. and South, D. and Specka, A. and Steder, M. and Stella, B. and Straumann, U. and Sun, C. and Sykora, T. and Thompson, P. D. and Acosta, F. Torales and Traynor, D. and Tseepeldorj, B. and Tu, Z. and Tustin, G. and Valk\'{a}rov\'{a}, A. and Vall\'{e}e, C. and Mechelen, P. Van and Wegener, D. and W\"{u}nsch, E. and \v{Z}\'{a}\v{c}ek, J. and Zhang, J. and Zhang, Z. and \v{Z}leb\v{c}\'{\i}k, R. and Zohrabyan, H. and Zomer, F.},
  year          = 2023,
  month         = sep,
  journal       = {Physics Letters B},
  volume        = 844,
  pages         = 138101,
  doi           = {10.1016/j.physletb.2023.138101},
  issn          = {03702693},
  url           = {http://arxiv.org/abs/2303.13620},
  urldate       = {2025-07-15},
  note          = {arXiv:2303.13620 [hep-ex]},
  abstract      = {The radiation pattern within high energy quark- and gluon-initiated jets (jet substructure) is used extensively as a precision probe of the strong force as well as an environment for optimizing event generators with numerous applications in high energy particle and nuclear physics. Looking at electron-proton collisions is of particular interest as many of the complications present at hadron colliders are absent. A detailed study of modern jet substructure observables, jet angularities, in electron-proton collisions is presented using data recorded using the H1 detector at HERA. The measurement is unbinned and multi-dimensional, using machine learning to correct for detector effects. All of the available reconstructed object information of the respective jets is interpreted by a graph neural network, achieving superior precision on a selected set of jet angularities. Training these networks was enabled by the use of a large number of GPUs in the Perlmutter supercomputer at Berkeley Lab. The particle jets are reconstructed in the laboratory frame, using the \$k\_\{{\textbackslash}mathrm\{T\}\}\$ jet clustering algorithm. Results are reported at high transverse momentum transfer \$Q{\textasciicircum}2{\textgreater}150\$ GeV\$\{\}{\textasciicircum}2\$, and inelasticity \$0.2 {\textless} y {\textless} 0.7\$. The analysis is also performed in sub-regions of \$Q{\textasciicircum}2\$, thus probing scale dependencies of the substructure variables. The data are compared with a variety of predictions and point towards possible improvements of such models.},
  keywords      = {High Energy Physics - Experiment}
}
@article{conrad_including_2003,
  title         = {Including systematic uncertainties in confidence interval construction for {Poisson} statistics},
  author        = {Conrad, J. and Botner, O. and Hallgren, A. and P\'{e}rez de los Heros, C.},
  year          = 2003,
  month         = jan,
  journal       = {Physical Review D},
  volume        = 67,
  number        = 1,
  pages         = {012002},
  doi           = {10.1103/PhysRevD.67.012002},
  url           = {https://link.aps.org/doi/10.1103/PhysRevD.67.012002},
  urldate       = {2025-07-13},
  note          = {Publisher: American Physical Society},
  abstract      = {One way to incorporate systematic uncertainties into the calculation of confidence intervals is by integrating over probability density functions parametrizing the uncertainties. In this paper we present a development of this method which takes into account uncertainties in the prediction of background processes and uncertainties in the signal detection efficiency and background efficiency, and allows for a correlation between the signal and background detection efficiencies. We implement this method with the likelihood ratio (usually denoted as the Feldman-Cousins) approach with and without conditioning. We present studies of coverage for the likelihood ratio and Neyman ordering schemes. In particular, we present two different types of coverage tests for the case where systematic uncertainties are included. To illustrate the method we show the relative effect of including systematic uncertainties in the case of the dark matter search as performed by modern neutrino telescopes.}
}
@article{contino_validity_2016,
  title         = {On the validity of the effective field theory approach to {SM} precision tests},
  author        = {Contino, Roberto and Falkowski, Adam and Goertz, Florian and Grojean, Christophe and Riva, Francesco},
  year          = 2016,
  month         = jul,
  journal       = {Journal of High Energy Physics},
  volume        = 2016,
  number        = 7,
  pages         = 144,
  doi           = {10.1007/jhep07(2016)144},
  issn          = {1029-8479},
  url           = {https://doi.org/10.1007/JHEP07(2016)144},
  urldate       = {2025-07-13},
  abstract      = {We discuss the conditions for an effective field theory (EFT) to give an adequate low-energy description of an underlying physics beyond the Standard Model (SM). Starting from the EFT where the SM is extended by dimension-6 operators, experimental data can be used without further assumptions to measure (or set limits on) the EFT parameters. The interpretation of these results requires instead a set of broad assumptions (e.g. power counting rules) on the UV dynamics. This allows one to establish, in a bottom-up approach, the validity range of the EFT description, and to assess the error associated with the truncation of the EFT series. We give a practical prescription on how experimental results could be reported, so that they admit a maximally broad range of theoretical interpretations. Namely, the experimental constraints on dimension-6 operators should be reported as functions of the kinematic variables that set the relevant energy scale of the studied process. This is especially important for hadron collider experiments where collisions probe a wide range of energy scales.},
  language      = {en},
  keywords      = {Beyond Standard Model, Effective field theories, Elementary Particles, Quantum Field Theory, Experimental Particle Physics, Field Theory and Polynomials, Metrology and Fundamental Constants, Particle Physics, Technicolor and Composite Models, Theoretical Particle Physics}
}
@inproceedings{cowan_bayesian_2006,
  title         = {Bayesian statistical methods for parton analyses},
  author        = {Cowan, G.},
  year          = 2006,
  month         = apr,
  booktitle     = {14th {International} {Workshop} on {Deep} {Inelastic} {Scattering}},
  pages         = {157--160},
  keywords      = {Beta}
}
@inproceedings{cowan_bayesian_2007,
  title         = {Bayesian {Statistical} {Methods} {In} {Particle} {Physics}},
  author        = {Cowan, Glen},
  year          = 2007,
  booktitle     = {42nd {Rencontres} de {Moriond} on {QCD} and {High} {Energy} {Hadronic} {Interactions}},
  publisher     = {Gioi Publ.},
  address       = {Hanoi, Vietnam},
  pages         = {7--10},
  keywords      = {Beta}
}
@inproceedings{cowan_highlights_2011,
  title         = {Highlights from {PHYSTAT} 2011},
  author        = {Cowan, Glen},
  year          = 2011,
  booktitle     = {{Phystat} 2011},
  publisher     = {Cern},
  address       = {Geneva},
  pages         = {215--224},
  doi           = {10.5170/cern-2011-006.215},
  keywords      = {BETA, CERN Lab, statistical analysis, talk: Geneva 2011/01/17}
}
@book{cowan_statistical_1998,
  title         = {Statistical data analysis},
  author        = {Cowan, G.},
  year          = 1998,
  isbn          = {978-0-19-850156-5},
  keywords      = {BETA, book, numerical methods: Monte Carlo, statistical analysis}
}
@incollection{cowan_statistics_2021,
  title         = {Statistics},
  author        = {Cowan, Glen},
  year          = 2021,
  booktitle     = {Handbook of {Particle} {Detection} and {Imaging}},
  pages         = {103--124},
  doi           = {10.1007/978-3-319-93785-4_5},
  editor        = {Grupen, Claus and Buvat, Irene},
  keywords      = {BETA, Bayesian, Gauss law, Poisson, random, statistical analysis, statistics}
}
@article{cowan_survey_2002,
  title         = {A survey of unfolding methods for particle physics},
  author        = {Cowan, G.},
  year          = 2002,
  journal       = {Conf. Proc. C},
  volume        = {0203181},
  pages         = {248--257},
  editor        = {Whalley, M. R. and Lyons, L.},
  keywords      = {BETA, statistical analysis, talk: Durham 2002/03/18}
}
@inproceedings{cowan_topics_2009,
  title         = {Topics in statistical data analysis for {HEP}},
  author        = {Cowan, Glen},
  year          = 2009,
  month         = aug,
  booktitle     = {65th {Scottish} {Universities} {Summer} {School} in {Physics}: {LHC} {Physics}},
  pages         = {341--369},
  doi           = {10.1201/b11865-15},
  keywords      = {BETA, data analysis method, lectures, mathematical methods, numerical calculations: Monte Carlo, statistical analysis: Bayesian, statistics}
}
@misc{cowan_topics_2010,
  title         = {Topics in statistical data analysis for high-energy physics},
  author        = {Cowan, G},
  year          = 2010,
  publisher     = {Cern},
  doi           = {10.5170/cern-2010-002.197},
  url           = {http://cds.cern.ch/record/1281954},
  urldate       = {2025-07-13},
  language      = {en},
  keywords      = {Other Fields of Physics, Particle Physics - Phenomenology}
}
@article{Cowan2011AsymptoticPhysics,
  title         = {Asymptotic formulae for likelihood-based tests of new physics},
  author        = {Cowan, Glen and Cranmer, Kyle and Gross, Eilam and Vitells, Ofer},
  year          = 2011,
  month         = 2,
  journal       = {Eur.Phys.J.C},
  publisher     = {Springer New York LLC},
  volume        = 71,
  number        = 2,
  pages         = 1554,
  doi           = {10.1140/epjc/s10052-011-1554-0},
  issn          = 14346052,
  arxivid       = {1007.1727}
}
@article{CowanStatisticalRehovot,
  title         = {Statistical Methods for Particle Physics Lecture 4: unfolding Statistical Inference for Astro and Particle Physics Workshop Weizmann Institute, Rehovot},
  author        = {Cowan, Glen},
  url           = {https://indico.weizmann.ac.il//conferenceDisplay.py?confId=52}
}
@misc{cranmer_histfactory_2012,
  title         = {{HistFactory}: {A} tool for creating statistical models for use with {RooFit} and {RooStats}},
  shorttitle    = {HistFactory},
  author        = {Cranmer, Kyle and Lewis, George and Moneta, Lorenzo and Shibata, Akira and Verkerke, Wouter},
  year          = 2012,
  publisher     = {New York U.},
  address       = {New York},
  doi           = {10.17181/cern-open-2012-016},
  url           = {https://cds.cern.ch/record/1456844},
  urldate       = {2025-07-13},
  abstract      = {The HistFactory is a tool to build parametrized probability density functions (pdfs) in the RooFit/RooStats framework based based on simple ROOT histograms organized in an XML file. The pdf has a restricted form, but it is sufficiently flexible to describe many analyses based on template histograms. The tool takes a modular approach to build complex pdfs from more primative conceptual building blocks. The resulting PDF is stored in a RooWorkspace which can be saved to and read from a ROOT file. This document describes the defaults and interface in HistFactory 5.32.}
}
@article{CranmerPracticalLHC,
  title         = {Practical Statistics for the LHC},
  author        = {Cranmer, Kyle}
}
@article{cybenko_approximation_1989,
  title         = {Approximation by superpositions of a sigmoidal function},
  author        = {Cybenko, G.},
  year          = 1989,
  month         = dec,
  journal       = {Mathematics of Control, Signals and Systems},
  volume        = 2,
  number        = 4,
  pages         = {303--314},
  doi           = {10.1007/bf02551274},
  issn          = {1435-568x},
  url           = {https://doi.org/10.1007/BF02551274},
  urldate       = {2025-07-15},
  abstract      = {In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.},
  language      = {en},
  keywords      = {Approximation, Approximations and Expansions, Artificial Intelligence, Completeness, Functional Analysis, Machine Learning, Neural networks, Real Functions, Special Functions}
}
@misc{dagostini_improved_2010,
  title         = {Improved iterative {Bayesian} unfolding},
  author        = {D'Agostini, G.},
  year          = 2010,
  month         = oct,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1010.0632},
  url           = {http://arxiv.org/abs/1010.0632},
  urldate       = {2025-07-13},
  note          = {arXiv:1010.0632 [physics]},
  abstract      = {This paper reviews the basic ideas behind a Bayesian unfolding published some years ago and improves their implementation. In particular, uncertainties are now treated at all levels by probability density functions and their propagation is performed by Monte Carlo integration. Thus, small numbers are better handled and the final uncertainty does not rely on the assumption of normality. Theoretical and practical issues concerning the iterative use of the algorithm are also discussed. The new program, implemented in the R language, is freely available, together with sample scripts to play with toy models.},
  keywords      = {Physics - Data Analysis, Statistics and Probability}
}
@article{Darulis2022MachineSimulations,
  title         = {Machine Learned Particle Detector Simulations},
  author        = {Darulis, D. and Tyson, R. and Ireland, D. G. and Glazier, D. I. and McKinnon, B. and Pauli, P.},
  year          = 2022,
  month         = 7,
  url           = {https://arxiv.org/pdf/2207.11254},
  arxivid       = {2207.11254},
  keywords      = {Boosted, Decision, Detector, Learning {\textperiodcentered}, Machine, Network {\textperiodcentered}, Neural, Particle, Simulations {\textperiodcentered}, Tree}
}
@article{Dasgupta2013TowardsSubstructure,
  title         = {Towards an understanding of jet substructure},
  author        = {Dasgupta, Mrinal and Fregoso, Alessandro and Marzani, Simone and Salam, Gavin P.},
  year          = 2013,
  month         = 9,
  journal       = {Journal of High Energy Physics 2013 2013:9},
  publisher     = {Springer},
  volume        = 2013,
  number        = 9,
  pages         = {1--57},
  doi           = {10.1007/jhep09(2013)029},
  issn          = {1029-8479},
  url           = {https://link.springer.com/article/10.1007/JHEP09(2013)029},
  arxivid       = {1307.0007},
  keywords      = {Classical and Quantum Gravitation, Elementary Particles, Quantum Field Theories, Quantum Field Theory, Quantum Physics, Relativity Theory, String Theory}
}
@article{Dashti2017TheProblems,
  title         = {The bayesian approach to inverse problems},
  author        = {Dashti, Masoumeh and Stuart, Andrew M.},
  year          = 2017,
  month         = 6,
  journal       = {Handbook of Uncertainty Quantification},
  publisher     = {Springer International Publishing},
  pages         = {311--428},
  doi           = {10.1007/978-3-319-12385-1{\_}7},
  isbn          = 9783319123851,
  arxivid       = {1302.6989},
  keywords      = {Bayesian inversion, Inverse problems, Langevin stochastic partial differential equations, Markov chain monte carlo, Sequential monte carlo, Tikhonov regularization and MAP estimators}
}
@misc{datta_unfolding_2018,
  title         = {Unfolding with {Generative} {Adversarial} {Networks}},
  author        = {Datta, Kaustuv and Kar, Deepak and Roy, Debarati},
  year          = 2018,
  month         = aug,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1806.00433},
  url           = {http://arxiv.org/abs/1806.00433},
  urldate       = {2025-07-17},
  note          = {arXiv:1806.00433 [physics]},
  abstract      = {Correcting measured detector-level distributions to particle-level is essential to make data usable outside the experimental collaborations. The term unfolding is used to describe this procedure. A new method of unfolding data using a modified Generative Adversarial Network (MSGAN) is presented here. Applied to various distributions with widely different shapes, it performs roughly at par with currently used methods. This is a proof-of-principle demonstration of a state-of-the-art machine learning method that can be used to model detector effects well.},
  keywords      = {High Energy Physics - Experiment, High Energy Physics - Phenomenology, Physics - Data Analysis, Statistics and Probability}
}
@article{DeFavereau2014DELPHESExperiment,
  title         = {DELPHES 3: A modular framework for fast simulation of a generic collider experiment},
  author        = {De Favereau, J. and Delaere, C. and Demin, P. and Giammanco, A. and Lema{\^{i}}tre, V. and Mertens, A. and Selvaggi, M.},
  year          = 2014,
  month         = 2,
  journal       = {Journal of High Energy Physics},
  publisher     = {Springer Verlag},
  volume        = 2014,
  number        = 2,
  pages         = {1--26},
  doi           = {10.1007/jhep02(2014)057/metrics},
  issn          = 10298479,
  url           = {https://link.springer.com/article/10.1007/JHEP02(2014)057},
  arxivid       = {1307.6346},
  keywords      = {Hadron-Hadron Scattering}
}
@article{delaRosa2020DifferentiableAnalysis,
  title         = {Differentiable Deconvolution for Improved Stroke Perfusion Analysis},
  author        = {de la Rosa, Ezequiel and Robben, David and Sima, Diana M. and Kirschke, Jan S. and Menze, Bjoern},
  year          = 2020,
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  publisher     = {Springer Science and Business Media Deutschland GmbH},
  volume        = {12267 Lncs},
  pages         = {593--602},
  doi           = {10.1007/978-3-030-59728-3{\_}58/figures/3},
  isbn          = 9783030597276,
  issn          = 16113349,
  url           = {https://link.springer.com/chapter/10.1007/978-3-030-59728-3_58},
  arxivid       = {2103.17111},
  keywords      = {Deep learning, Perfusion imaging, SVD deconvolution}
}
@misc{deng_fast_2024,
  title         = {Fast {Updating} {Truncated} {SVD} for {Representation} {Learning} with {Sparse} {Matrices}},
  author        = {Deng, Haoran and Yang, Yang and Li, Jiahe and Chen, Cheng and Jiang, Weihao and Pu, Shiliang},
  year          = 2024,
  month         = jan,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2401.09703},
  url           = {http://arxiv.org/abs/2401.09703},
  urldate       = {2025-07-13},
  note          = {arXiv:2401.09703 [math]},
  abstract      = {Updating a truncated Singular Value Decomposition (SVD) is crucial in representation learning, especially when dealing with large-scale data matrices that continuously evolve in practical scenarios. Aligning SVD-based models with fast-paced updates becomes increasingly important. Existing methods for updating truncated SVDs employ Rayleigh-Ritz projection procedures, where projection matrices are augmented based on original singular vectors. However, these methods suffer from inefficiency due to the densification of the update matrix and the application of the projection to all singular vectors. To address these limitations, we introduce a novel method for dynamically approximating the truncated SVD of a sparse and temporally evolving matrix. Our approach leverages sparsity in the orthogonalization process of augmented matrices and utilizes an extended decomposition to independently store projections in the column space of singular vectors. Numerical experiments demonstrate a remarkable efficiency improvement of an order of magnitude compared to previous methods. Remarkably, this improvement is achieved while maintaining a comparable precision to existing approaches.},
  keywords      = {Computer Science - Numerical Analysis, Mathematics - Numerical Analysis}
}
@misc{denton_deep_2015,
  title         = {Deep {Generative} {Image} {Models} using a {Laplacian} {Pyramid} of {Adversarial} {Networks}},
  author        = {Denton, Emily and Chintala, Soumith and Szlam, Arthur and Fergus, Rob},
  year          = 2015,
  month         = jun,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1506.05751},
  url           = {http://arxiv.org/abs/1506.05751},
  urldate       = {2025-07-17},
  note          = {arXiv:1506.05751 [cs]},
  abstract      = {In this paper we introduce a generative parametric model capable of producing high quality samples of natural images. Our approach uses a cascade of convolutional networks within a Laplacian pyramid framework to generate images in a coarse-to-fine fashion. At each level of the pyramid, a separate generative convnet model is trained using the Generative Adversarial Nets (GAN) approach (Goodfellow et al.). Samples drawn from our model are of significantly higher quality than alternate approaches. In a quantitative assessment by human evaluators, our CIFAR10 samples were mistaken for real images around 40\% of the time, compared to 10\% for samples drawn from a GAN baseline model. We also show samples from models trained on the higher resolution images of the LSUN scene dataset.},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition}
}
@article{deOliveira2016Jet-imagesEdition,
  title         = {Jet-images -- deep learning edition},
  author        = {de Oliveira, Luke and Kagan, Michael and Mackey, Lester and Nachman, Benjamin and Schwartzman, Ariel},
  year          = 2016,
  month         = 7,
  journal       = {Journal of High Energy Physics},
  publisher     = {Springer Verlag},
  volume        = 2016,
  number        = 7,
  pages         = {1--32},
  doi           = {10.1007/jhep07(2016)069/metrics},
  issn          = 10298479,
  url           = {https://link.springer.com/article/10.1007/JHEP07(2016)069},
  arxivid       = {1511.05190},
  keywords      = {Hadron-Hadron scattering (experiments), Jet substructure}
}
@article{Desai:2025mpy,
  title         = {Unbinned Inference with Correlated Events},
  author        = {Desai, Krish and Long, Owen and Nachman, Benjamin},
  year          = 2025,
  month         = 4,
  journal       = {E-print},
  eprint        = {2504.14072},
  archiveprefix = {arXiv},
  primaryclass  = {physics.data-an}
}
@inproceedings{desai2022deconvolving,
  title         = {Deconvolving Detector Effects for Distribution Moments},
  author        = {Desai, Krish and Nachman, Benjamin and Thaler, Jesse},
  year          = 2022,
  booktitle     = {Ml4ps},
  number        = 43,
  maintitle     = {NeurIPS}
}
@article{desai2024moment,
  title         = {Moment extraction using an unfolding protocol without binning},
  author        = {Desai, Krish and Nachman, Benjamin and Thaler, Jesse},
  year          = 2024,
  journal       = {Physical Review D},
  publisher     = {Aps},
  volume        = 110,
  number        = 11,
  pages         = 116013
}
@article{DevNairDevelopmentData,
  title         = {Development of a Deep Neural Network Double b-tagger for Boosted Topologies using CMS Open Data},
  author        = {Dev Nair, by and Rani Komaragiri IISc Bangalore Abhishek Majhi, Jyothsna}
}
@article{alhroobSingleTopQuark,
  title = {Single Top Quark Production Cross Section Using the {{ATLAS}} Detector at the {{LHC}}},
  author = {Alhroob, Muhammad},
  doi = {10.22323/1.364.0658},
  langid = {english},
  file = {/Users/t-krishdesai/Zotero/storage/UM7XWRPH/Alhroob - Single top quark production cross section using the ATLAS detector at the LHC.pdf}
}

@article{ATLAS:2017dhr,
  title = {Measurement of Lepton Differential Distributions and the Top Quark Mass in \$\$t{\textbackslash}bar\{t\}\$\$production in Pp Collisions at \$\${\textbackslash}sqrt\{s\}=8\$\$~{{TeV}} with the {{ATLAS}} Detector},
  author = {Aaboud, M. and Aad, G. and Abbott, B. and Abdinov, O. and Abeloos, B. and Abidi, S. H. and AbouZeid, O. S. and Abraham, N. L. and Abramowicz, H. and Abreu, H. and Abreu, R. and Abulaiti, Y. and Acharya, B. S. and Adachi, S. and Adamczyk, L. and Adelman, J. and Adersberger, M. and Adye, T. and Affolder, A. A. and Afik, Y. and {Agatonovic-Jovin}, T. and Agheorghiesei, C. and {Aguilar-Saavedra}, J. A. and Ahlen, S. P. and Ahmadov, F. and Aielli, G. and Akatsuka, S. and Akerstedt, H. and {\AA}kesson, T. P. A. and Akilli, E. and Akimov, A. V. and Alberghi, G. L. and Albert, J. and Albicocco, P. and Alconada Verzini, M. J. and Alderweireldt, S. C. and Aleksa, M. and Aleksandrov, I. N. and Alexa, C. and Alexander, G. and Alexopoulos, T. and Alhroob, M. and Ali, B. and Aliev, M. and Alimonti, G. and Alison, J. and Alkire, S. P. and Allbrooke, B. M. M. and Allen, B. W. and Allport, P. P. and Aloisio, A. and Alonso, A. and Alonso, F. and Alpigiani, C. and Alshehri, A. A. and Alstaty, M. I. and Alvarez Gonzalez, B. and {\'A}lvarez Piqueras, D. and Alviggi, M. G. and Amadio, B. T. and Amaral Coutinho, Y. and Amelung, C. and Amidei, D. and Amor Dos Santos, S. P. and Amoroso, S. and Amundsen, G. and Anastopoulos, C. and Ancu, L. S. and Andari, N. and Andeen, T. and Anders, C. F. and Anders, J. K. and Anderson, K. J. and Andreazza, A. and Andrei, V. and Angelidakis, S. and Angelozzi, I. and Angerami, A. and Anisenkov, A. V. and Anjos, N. and Annovi, A. and Antel, C. and Antonelli, M. and Antonov, A. and Antrim, D. J. and Anulli, F. and Aoki, M. and Aperio Bella, L. and Arabidze, G. and Arai, Y. and Araque, J. P. and Araujo Ferraz, V. and Arce, A. T. H. and Ardell, R. E. and Arduh, F. A. and Arguin, J-F. and Argyropoulos, S. and Arik, M. and Armbruster, A. J. and Armitage, L. J. and Arnaez, O. and Arnold, H. and Arratia, M. and Arslan, O. and Artamonov, A. and Artoni, G. and Artz, S. and Asai, S. and Asbah, N. and Ashkenazi, A. and Asquith, L. and Assamagan, K. and Astalos, R. and Atkinson, M. and Atlay, N. B. and Augsten, K. and Avolio, G. and Axen, B. and Ayoub, M. K. and Azuelos, G. and Baas, A. E. and Baca, M. J. and Bachacou, H. and Bachas, K. and Backes, M. and Bagnaia, P. and Bahmani, M. and Bahrasemani, H. and Baines, J. T. and Bajic, M. and Baker, O. K. and Bakker, P. J. and Baldin, E. M. and Balek, P. and Balli, F. and Balunas, W. K. and Banas, E. and Bandyopadhyay, A. and Banerjee, {\relax Sw}. and Bannoura, A. A. E. and Barak, L. and Barberio, E. L. and Barberis, D. and Barbero, M. and Barillari, T. and Barisits, M-S and Barkeloo, J. T. and Barklow, T. and Barlow, N. and Barnes, S. L. and Barnett, B. M. and Barnett, R. M. and {Barnovska-Blenessy}, Z. and Baroncelli, A. and Barone, G. and Barr, A. J. and Barranco Navarro, L. and Barreiro, F. and {Barreiro Guimar{\~a}es da Costa}, J. and Bartoldus, R. and Barton, A. E. and Bartos, P. and Basalaev, A. and Bassalat, A. and Bates, R. L. and Batista, S. J. and Batley, J. R. and Battaglia, M. and Bauce, M. and Bauer, F. and Bawa, H. S. and Beacham, J. B. and Beattie, M. D. and Beau, T. and Beauchemin, P. H. and Bechtle, P. and Beck, H. P. and Beck, H. C. and Becker, K. and Becker, M. and Becot, C. and Beddall, A. J. and Beddall, A. and Bednyakov, V. A. and Bedognetti, M. and Bee, C. P. and Beermann, T. A. and Begalli, M. and Begel, M. and Behr, J. K. and Bell, A. S. and Bella, G. and Bellagamba, L. and Bellerive, A. and Bellomo, M. and Belotskiy, K. and Beltramello, O. and Belyaev, N. L. and Benary, O. and Benchekroun, D. and Bender, M. and Benekos, N. and Benhammou, Y. and Benhar Noccioli, E. and Benitez, J. and Benjamin, D. P. and Benoit, M. and Bensinger, J. R. and Bentvelsen, S. and Beresford, L. and Beretta, M. and Berge, D. and Bergeaas Kuutmann, E. and Berger, N. and Beringer, J. and Berlendis, S. and Bernard, N. R. and Bernardi, G. and Bernius, C. and Bernlochner, F. U. and Berry, T. and Berta, P. and Bertella, C. and Bertoli, G. and Bertram, I. A. and Bertsche, C. and Bertsche, D. and Besjes, G. J. and Bessidskaia Bylund, O. and Bessner, M. and Besson, N. and Bethani, A. and Bethke, S. and Betti, A. and Bevan, A. J. and Beyer, J. and Bianchi, R. M. and Biebel, O. and Biedermann, D. and Bielski, R. and Bierwagen, K. and Biesuz, N. V. and Biglietti, M. and Billoud, T. R. V. and Bilokon, H. and Bindi, M. and Bingul, A. and Bini, C. and Biondi, S. and Bisanz, T. and Bittrich, C. and Bjergaard, D. M. and Black, J. E. and Black, K. M. and Blair, R. E. and Blazek, T. and Bloch, I. and Blocker, C. and Blue, A. and Blumenschein, U. and Blunier, S. and Bobbink, G. J. and Bobrovnikov, V. S. and Bocchetta, S. S. and Bocci, A. and Bock, C. and Boehler, M. and Boerner, D. and Bogavac, D. and Bogdanchikov, A. G. and Bohm, C. and Boisvert, V. and Bokan, P. and Bold, T. and Boldyrev, A. S. and Bolz, A. E. and Bomben, M. and Bona, M. and Boonekamp, M. and Borisov, A. and Borissov, G. and Bortfeldt, J. and Bortoletto, D. and Bortolotto, V. and Boscherini, D. and Bosman, M. and Bossio Sola, J. D. and Boudreau, J. and {Bouhova-Thacker}, E. V. and Boumediene, D. and Bourdarios, C. and Boutle, S. K. and Boveia, A. and Boyd, J. and Boyko, I. R. and Bozson, A. J. and Bracinik, J. and Brandt, A. and Brandt, G. and Brandt, O.},
  year = {2017},
  month = nov,
  journal = {The European Physical Journal C},
  volume = {77},
  number = {11},
  eprint = {1709.09407},
  primaryclass = {hep-ex},
  pages = {804},
  issn = {1434-6052},
  doi = {10.1140/epjc/s10052-017-5349-9},
  urldate = {2025-07-19},
  abstract = {This paper presents single lepton and dilepton kinematic distributions measured in dileptonic \$t{\textbackslash}bar\{t\}\$ events produced in 20.2 fb\${\textasciicircum}\{-1\}\$ of \${\textbackslash}sqrt\{s\}=8\$ TeV \$pp\$ collisions recorded by the ATLAS experiment at the LHC. Both absolute and normalised differential cross-sections are measured, using events with an opposite-charge \$e{\textbackslash}mu\$ pair and one or two \$b\$-tagged jets. The cross-sections are measured in a fiducial region corresponding to the detector acceptance for leptons, and are compared to the predictions from a variety of Monte Carlo event generators, as well as fixed-order QCD calculations, exploring the sensitivity of the cross-sections to the gluon parton distribution function. Some of the distributions are also sensitive to the top quark pole mass; a combined fit of NLO fixed-order predictions to all the measured distributions yields a top quark mass value of \$m\_t{\textasciicircum}\{{\textbackslash}rm pole\}=173.2{\textbackslash}pm 0.9{\textbackslash}pm0.8{\textbackslash}pm1.2\$ GeV, where the three uncertainties arise from data statistics, experimental systematics, and theoretical sources.},
  archiveprefix = {arXiv},
  collaboration = {ATLAS},
  langid = {english},
  keywords = {Accelerator Physics,Experimental Nuclear Physics,Experimental Particle Physics,Nuclear and Particle Physics,Particle Physics,Theoretical Particle Physics},
  annotation = {95 citations (INSPIRE 2025/7/19)\\
34 citations w/o self (INSPIRE 2025/7/19)\\
Citations: 22 (Crossref) [2025-07-19]\\
Citations: 14 (SemanticScholar) [2025-07-19]}
}

@article{Benato:2025rgo,
  title = {Unbinned Inclusive Cross-Section Measurements with Machine-Learned Systematic Uncertainties},
  author = {Benato, Lisa and Giordano, Cristina and Krause, Claudius and Li, Ang and Sch{\"o}fbeck, Robert and Schwarz, Dennis and Shooshtari, Maryam and Wang, Daohan},
  year = {2025},
  month = may,
  eprint = {2505.05544},
  primaryclass = {hep-ph},
  doi = {10.48550/arXiv.2505.05544},
  urldate = {2025-07-19},
  abstract = {We introduce a novel methodology for addressing systematic uncertainties in unbinned inclusive cross-section measurements and related collider-based inference problems. Our approach incorporates known analytic dependencies on parameters of interest, including signal strengths and nuisance parameters. When these dependencies are unknown, as is frequently the case for systematic uncertainties, dedicated neural network parametrizations provide an approximation that is trained on simulated data. The resulting machine-learned surrogate captures the complete parameter dependence of the likelihood ratio, providing a near-optimal test statistic. As a case study, we perform a first-principles inclusive cross-section measurement of \${\textbackslash}textrm\{H\}{\textbackslash}rightarrow{\textbackslash}tau{\textbackslash}tau\$ in the single-lepton channel, utilizing simulated data from the FAIR Universe Higgs Uncertainty Challenge. Results in Asimov data, from large-scale toy studies, and using the Fisher information demonstrate significant improvements over traditional binned methods. Our computer code ``Guaranteed Optimal Log-Likelihood-based Unbinned Method'' (GOLLUM) for machine-learning and inference is publicly available.},
  archiveprefix = {arXiv},
  keywords = {High Energy Physics - Experiment,High Energy Physics - Phenomenology,Physics - Data Analysis Statistics and Probability},
  annotation = {0 citations (INSPIRE 2025/7/19)\\
0 citations w/o self (INSPIRE 2025/7/19)\\
Citations: 0 (SemanticScholar) [2025-07-19]}
}

@article{GomezAmbrosio:2022mpm,
  title = {Unbinned Multivariate Observables for Global {{SMEFT}} Analyses from Machine Learning},
  author = {Ambrosio, Raquel Gomez and {ter Hoeve}, Jaco and Madigan, Maeve and Rojo, Juan and Sanz, Veronica},
  year = {2023},
  month = mar,
  journal = {Journal of High Energy Physics},
  volume = {03},
  number = {3},
  eprint = {2211.02058},
  primaryclass = {hep-ph},
  pages = {033},
  issn = {1029-8479},
  doi = {10.1007/JHEP03(2023)033},
  urldate = {2025-07-19},
  abstract = {Theoretical interpretations of particle physics data, such as the determination of the Wilson coefficients of the Standard Model Effective Field Theory (SMEFT), often involve the inference of multiple parameters from a global dataset. Optimizing such interpretations requires the identification of observables that exhibit the highest possible sensitivity to the underlying theory parameters. In this work we develop a flexible open source framework, ML4EFT, enabling the integration of unbinned multivariate observables into global SMEFT fits. As compared to traditional measurements, such observables enhance the sensitivity to the theory parameters by preventing the information loss incurred when binning in a subset of final-state kinematic variables. Our strategy combines machine learning regression and classification techniques to parameterize high-dimensional likelihood ratios, using the Monte Carlo replica method to estimate and propagate methodological uncertainties. As a proof of concept we construct unbinned multivariate observables for top-quark pair and Higgs+\$Z\$ production at the LHC, demonstrate their impact on the SMEFT parameter space as compared to binned measurements, and study the improved constraints associated to multivariate inputs. Since the number of neural networks to be trained scales quadratically with the number of parameters and can be fully parallelized, the ML4EFT framework is well-suited to construct unbinned multivariate observables which depend on up to tens of EFT coefficients, as required in global fits.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Data-driven Science Modeling and Theory Building,Higgs Properties,Machine Learning,Model Theory,Particle Physics,SMEFT,String Theory,Theoretical Particle Physics},
  annotation = {26 citations (INSPIRE 2025/7/19)\\
18 citations w/o self (INSPIRE 2025/7/19)\\
Citations: 13 (Crossref) [2025-07-19]\\
Citations: 17 (SemanticScholar) [2025-07-19]}
}

@article{stoneGeneralizedWeierstrassApproximation1948,
  title = {The {{Generalized Weierstrass Approximation Theorem}}},
  author = {Stone, M. H.},
  year = {1948},
  journal = {Mathematics Magazine},
  volume = {21},
  number = {4},
  eprint = {3029750},
  eprinttype = {jstor},
  pages = {167--184},
  publisher = {[Mathematical Association of America, Taylor \& Francis, Ltd.]},
  issn = {0025-570X},
  doi = {10.2307/3029750},
  urldate = {2025-07-19},
  annotation = {Citations: 231 (Crossref) [2025-07-19]}
}

@book{taylorMethodusIncrementorumDirecta1715,
  title = {{Methodus incrementorum directa \& inversa. Auctore Brook Taylor, LL. D. \& Regiae Societatis Secretario.}},
  author = {Taylor, Brook},
  year = {1715},
  publisher = {typis Pearsonianis: prostant apud Gul. Innys ad Insignia Principis in Coemeterio Paulino},
  address = {Londini},
  langid = {lat},
  keywords = {Calculus,Difference equations,Series Taylor's}
}
@article{alhroobSingleTopQuark,
  title = {Single Top Quark Production Cross Section Using the {{ATLAS}} Detector at the {{LHC}}},
  author = {Alhroob, Muhammad},
  doi = {10.22323/1.364.0658},
  langid = {english},
  file = {/Users/t-krishdesai/Zotero/storage/UM7XWRPH/Alhroob - Single top quark production cross section using the ATLAS detector at the LHC.pdf}
}

@article{ATLAS:2017dhr,
  title = {Measurement of Lepton Differential Distributions and the Top Quark Mass in \$\$t{\textbackslash}bar\{t\}\$\$production in Pp Collisions at \$\${\textbackslash}sqrt\{s\}=8\$\$~{{TeV}} with the {{ATLAS}} Detector},
  author = {Aaboud, M. and Aad, G. and Abbott, B. and Abdinov, O. and Abeloos, B. and Abidi, S. H. and AbouZeid, O. S. and Abraham, N. L. and Abramowicz, H. and Abreu, H. and Abreu, R. and Abulaiti, Y. and Acharya, B. S. and Adachi, S. and Adamczyk, L. and Adelman, J. and Adersberger, M. and Adye, T. and Affolder, A. A. and Afik, Y. and {Agatonovic-Jovin}, T. and Agheorghiesei, C. and {Aguilar-Saavedra}, J. A. and Ahlen, S. P. and Ahmadov, F. and Aielli, G. and Akatsuka, S. and Akerstedt, H. and {\AA}kesson, T. P. A. and Akilli, E. and Akimov, A. V. and Alberghi, G. L. and Albert, J. and Albicocco, P. and Alconada Verzini, M. J. and Alderweireldt, S. C. and Aleksa, M. and Aleksandrov, I. N. and Alexa, C. and Alexander, G. and Alexopoulos, T. and Alhroob, M. and Ali, B. and Aliev, M. and Alimonti, G. and Alison, J. and Alkire, S. P. and Allbrooke, B. M. M. and Allen, B. W. and Allport, P. P. and Aloisio, A. and Alonso, A. and Alonso, F. and Alpigiani, C. and Alshehri, A. A. and Alstaty, M. I. and Alvarez Gonzalez, B. and {\'A}lvarez Piqueras, D. and Alviggi, M. G. and Amadio, B. T. and Amaral Coutinho, Y. and Amelung, C. and Amidei, D. and Amor Dos Santos, S. P. and Amoroso, S. and Amundsen, G. and Anastopoulos, C. and Ancu, L. S. and Andari, N. and Andeen, T. and Anders, C. F. and Anders, J. K. and Anderson, K. J. and Andreazza, A. and Andrei, V. and Angelidakis, S. and Angelozzi, I. and Angerami, A. and Anisenkov, A. V. and Anjos, N. and Annovi, A. and Antel, C. and Antonelli, M. and Antonov, A. and Antrim, D. J. and Anulli, F. and Aoki, M. and Aperio Bella, L. and Arabidze, G. and Arai, Y. and Araque, J. P. and Araujo Ferraz, V. and Arce, A. T. H. and Ardell, R. E. and Arduh, F. A. and Arguin, J-F. and Argyropoulos, S. and Arik, M. and Armbruster, A. J. and Armitage, L. J. and Arnaez, O. and Arnold, H. and Arratia, M. and Arslan, O. and Artamonov, A. and Artoni, G. and Artz, S. and Asai, S. and Asbah, N. and Ashkenazi, A. and Asquith, L. and Assamagan, K. and Astalos, R. and Atkinson, M. and Atlay, N. B. and Augsten, K. and Avolio, G. and Axen, B. and Ayoub, M. K. and Azuelos, G. and Baas, A. E. and Baca, M. J. and Bachacou, H. and Bachas, K. and Backes, M. and Bagnaia, P. and Bahmani, M. and Bahrasemani, H. and Baines, J. T. and Bajic, M. and Baker, O. K. and Bakker, P. J. and Baldin, E. M. and Balek, P. and Balli, F. and Balunas, W. K. and Banas, E. and Bandyopadhyay, A. and Banerjee, {\relax Sw}. and Bannoura, A. A. E. and Barak, L. and Barberio, E. L. and Barberis, D. and Barbero, M. and Barillari, T. and Barisits, M-S and Barkeloo, J. T. and Barklow, T. and Barlow, N. and Barnes, S. L. and Barnett, B. M. and Barnett, R. M. and {Barnovska-Blenessy}, Z. and Baroncelli, A. and Barone, G. and Barr, A. J. and Barranco Navarro, L. and Barreiro, F. and {Barreiro Guimar{\~a}es da Costa}, J. and Bartoldus, R. and Barton, A. E. and Bartos, P. and Basalaev, A. and Bassalat, A. and Bates, R. L. and Batista, S. J. and Batley, J. R. and Battaglia, M. and Bauce, M. and Bauer, F. and Bawa, H. S. and Beacham, J. B. and Beattie, M. D. and Beau, T. and Beauchemin, P. H. and Bechtle, P. and Beck, H. P. and Beck, H. C. and Becker, K. and Becker, M. and Becot, C. and Beddall, A. J. and Beddall, A. and Bednyakov, V. A. and Bedognetti, M. and Bee, C. P. and Beermann, T. A. and Begalli, M. and Begel, M. and Behr, J. K. and Bell, A. S. and Bella, G. and Bellagamba, L. and Bellerive, A. and Bellomo, M. and Belotskiy, K. and Beltramello, O. and Belyaev, N. L. and Benary, O. and Benchekroun, D. and Bender, M. and Benekos, N. and Benhammou, Y. and Benhar Noccioli, E. and Benitez, J. and Benjamin, D. P. and Benoit, M. and Bensinger, J. R. and Bentvelsen, S. and Beresford, L. and Beretta, M. and Berge, D. and Bergeaas Kuutmann, E. and Berger, N. and Beringer, J. and Berlendis, S. and Bernard, N. R. and Bernardi, G. and Bernius, C. and Bernlochner, F. U. and Berry, T. and Berta, P. and Bertella, C. and Bertoli, G. and Bertram, I. A. and Bertsche, C. and Bertsche, D. and Besjes, G. J. and Bessidskaia Bylund, O. and Bessner, M. and Besson, N. and Bethani, A. and Bethke, S. and Betti, A. and Bevan, A. J. and Beyer, J. and Bianchi, R. M. and Biebel, O. and Biedermann, D. and Bielski, R. and Bierwagen, K. and Biesuz, N. V. and Biglietti, M. and Billoud, T. R. V. and Bilokon, H. and Bindi, M. and Bingul, A. and Bini, C. and Biondi, S. and Bisanz, T. and Bittrich, C. and Bjergaard, D. M. and Black, J. E. and Black, K. M. and Blair, R. E. and Blazek, T. and Bloch, I. and Blocker, C. and Blue, A. and Blumenschein, U. and Blunier, S. and Bobbink, G. J. and Bobrovnikov, V. S. and Bocchetta, S. S. and Bocci, A. and Bock, C. and Boehler, M. and Boerner, D. and Bogavac, D. and Bogdanchikov, A. G. and Bohm, C. and Boisvert, V. and Bokan, P. and Bold, T. and Boldyrev, A. S. and Bolz, A. E. and Bomben, M. and Bona, M. and Boonekamp, M. and Borisov, A. and Borissov, G. and Bortfeldt, J. and Bortoletto, D. and Bortolotto, V. and Boscherini, D. and Bosman, M. and Bossio Sola, J. D. and Boudreau, J. and {Bouhova-Thacker}, E. V. and Boumediene, D. and Bourdarios, C. and Boutle, S. K. and Boveia, A. and Boyd, J. and Boyko, I. R. and Bozson, A. J. and Bracinik, J. and Brandt, A. and Brandt, G. and Brandt, O.},
  year = {2017},
  month = nov,
  journal = {The European Physical Journal C},
  volume = {77},
  number = {11},
  eprint = {1709.09407},
  primaryclass = {hep-ex},
  pages = {804},
  issn = {1434-6052},
  doi = {10.1140/epjc/s10052-017-5349-9},
  urldate = {2025-07-19},
  abstract = {This paper presents single lepton and dilepton kinematic distributions measured in dileptonic \$t{\textbackslash}bar\{t\}\$ events produced in 20.2 fb\${\textasciicircum}\{-1\}\$ of \${\textbackslash}sqrt\{s\}=8\$ TeV \$pp\$ collisions recorded by the ATLAS experiment at the LHC. Both absolute and normalised differential cross-sections are measured, using events with an opposite-charge \$e{\textbackslash}mu\$ pair and one or two \$b\$-tagged jets. The cross-sections are measured in a fiducial region corresponding to the detector acceptance for leptons, and are compared to the predictions from a variety of Monte Carlo event generators, as well as fixed-order QCD calculations, exploring the sensitivity of the cross-sections to the gluon parton distribution function. Some of the distributions are also sensitive to the top quark pole mass; a combined fit of NLO fixed-order predictions to all the measured distributions yields a top quark mass value of \$m\_t{\textasciicircum}\{{\textbackslash}rm pole\}=173.2{\textbackslash}pm 0.9{\textbackslash}pm0.8{\textbackslash}pm1.2\$ GeV, where the three uncertainties arise from data statistics, experimental systematics, and theoretical sources.},
  archiveprefix = {arXiv},
  collaboration = {ATLAS},
  langid = {english},
  keywords = {Accelerator Physics,Experimental Nuclear Physics,Experimental Particle Physics,Nuclear and Particle Physics,Particle Physics,Theoretical Particle Physics},
  annotation = {95 citations (INSPIRE 2025/7/19)\\
34 citations w/o self (INSPIRE 2025/7/19)\\
Citations: 22 (Crossref) [2025-07-19]\\
Citations: 14 (SemanticScholar) [2025-07-19]}
}

@article{Benato:2025rgo,
  title = {Unbinned Inclusive Cross-Section Measurements with Machine-Learned Systematic Uncertainties},
  author = {Benato, Lisa and Giordano, Cristina and Krause, Claudius and Li, Ang and Sch{\"o}fbeck, Robert and Schwarz, Dennis and Shooshtari, Maryam and Wang, Daohan},
  year = {2025},
  month = may,
  eprint = {2505.05544},
  primaryclass = {hep-ph},
  doi = {10.48550/arXiv.2505.05544},
  urldate = {2025-07-19},
  abstract = {We introduce a novel methodology for addressing systematic uncertainties in unbinned inclusive cross-section measurements and related collider-based inference problems. Our approach incorporates known analytic dependencies on parameters of interest, including signal strengths and nuisance parameters. When these dependencies are unknown, as is frequently the case for systematic uncertainties, dedicated neural network parametrizations provide an approximation that is trained on simulated data. The resulting machine-learned surrogate captures the complete parameter dependence of the likelihood ratio, providing a near-optimal test statistic. As a case study, we perform a first-principles inclusive cross-section measurement of \${\textbackslash}textrm\{H\}{\textbackslash}rightarrow{\textbackslash}tau{\textbackslash}tau\$ in the single-lepton channel, utilizing simulated data from the FAIR Universe Higgs Uncertainty Challenge. Results in Asimov data, from large-scale toy studies, and using the Fisher information demonstrate significant improvements over traditional binned methods. Our computer code ``Guaranteed Optimal Log-Likelihood-based Unbinned Method'' (GOLLUM) for machine-learning and inference is publicly available.},
  archiveprefix = {arXiv},
  keywords = {High Energy Physics - Experiment,High Energy Physics - Phenomenology,Physics - Data Analysis Statistics and Probability},
  annotation = {0 citations (INSPIRE 2025/7/19)\\
0 citations w/o self (INSPIRE 2025/7/19)\\
Citations: 0 (SemanticScholar) [2025-07-19]}
}

@article{GomezAmbrosio:2022mpm,
  title = {Unbinned Multivariate Observables for Global {{SMEFT}} Analyses from Machine Learning},
  author = {Ambrosio, Raquel Gomez and {ter Hoeve}, Jaco and Madigan, Maeve and Rojo, Juan and Sanz, Veronica},
  year = {2023},
  month = mar,
  journal = {Journal of High Energy Physics},
  volume = {03},
  number = {3},
  eprint = {2211.02058},
  primaryclass = {hep-ph},
  pages = {033},
  issn = {1029-8479},
  doi = {10.1007/JHEP03(2023)033},
  urldate = {2025-07-19},
  abstract = {Theoretical interpretations of particle physics data, such as the determination of the Wilson coefficients of the Standard Model Effective Field Theory (SMEFT), often involve the inference of multiple parameters from a global dataset. Optimizing such interpretations requires the identification of observables that exhibit the highest possible sensitivity to the underlying theory parameters. In this work we develop a flexible open source framework, ML4EFT, enabling the integration of unbinned multivariate observables into global SMEFT fits. As compared to traditional measurements, such observables enhance the sensitivity to the theory parameters by preventing the information loss incurred when binning in a subset of final-state kinematic variables. Our strategy combines machine learning regression and classification techniques to parameterize high-dimensional likelihood ratios, using the Monte Carlo replica method to estimate and propagate methodological uncertainties. As a proof of concept we construct unbinned multivariate observables for top-quark pair and Higgs+\$Z\$ production at the LHC, demonstrate their impact on the SMEFT parameter space as compared to binned measurements, and study the improved constraints associated to multivariate inputs. Since the number of neural networks to be trained scales quadratically with the number of parameters and can be fully parallelized, the ML4EFT framework is well-suited to construct unbinned multivariate observables which depend on up to tens of EFT coefficients, as required in global fits.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Data-driven Science Modeling and Theory Building,Higgs Properties,Machine Learning,Model Theory,Particle Physics,SMEFT,String Theory,Theoretical Particle Physics},
  annotation = {26 citations (INSPIRE 2025/7/19)\\
18 citations w/o self (INSPIRE 2025/7/19)\\
Citations: 13 (Crossref) [2025-07-19]\\
Citations: 17 (SemanticScholar) [2025-07-19]}
}

@article{stoneGeneralizedWeierstrassApproximation1948,
  title = {The {{Generalized Weierstrass Approximation Theorem}}},
  author = {Stone, M. H.},
  year = {1948},
  journal = {Mathematics Magazine},
  volume = {21},
  number = {4},
  eprint = {3029750},
  eprinttype = {jstor},
  pages = {167--184},
  publisher = {[Mathematical Association of America, Taylor \& Francis, Ltd.]},
  issn = {0025-570X},
  doi = {10.2307/3029750},
  urldate = {2025-07-19},
  annotation = {Citations: 231 (Crossref) [2025-07-19]}
}

@book{taylorMethodusIncrementorumDirecta1715,
  title = {{Methodus incrementorum directa \& inversa. Auctore Brook Taylor, LL. D. \& Regiae Societatis Secretario.}},
  author = {Taylor, Brook},
  year = {1715},
  publisher = {typis Pearsonianis: prostant apud Gul. Innys ad Insignia Principis in Coemeterio Paulino},
  address = {Londini},
  langid = {lat},
  keywords = {Calculus,Difference equations,Series Taylor's}
}

@book{weierstrassUeberAnalytischeDarstellbarkeit1885,
  title = {{{\"U}ber die analytische Darstellbarkeit sogenannter willk{\"u}rlicher Functionen einer reellen Ver{\"a}nderlichen}},
  author = {Weierstra{\ss}, Karl},
  year = {1885},
  series = {{Sitzungsberichte der Preussischen Akademie der Wissenschaften Jg. 1885, 34 ; Jg. 1885, 38}},
  publisher = {:},
  address = {Berlin},
  langid = {german},
  lccn = {-}
}

@book{weierstrassUeberAnalytischeDarstellbarkeit1885,
  title = {{{\"U}ber die analytische Darstellbarkeit sogenannter willk{\"u}rlicher Functionen einer reellen Ver{\"a}nderlichen}},
  author = {Weierstra{\ss}, Karl},
  year = {1885},
  series = {{Sitzungsberichte der Preussischen Akademie der Wissenschaften Jg. 1885, 34 ; Jg. 1885, 38}},
  publisher = {:},
  address = {Berlin},
  langid = {german},
  lccn = {-}
}

@article{DHoker1984DecouplingTheory,
  title         = {Decoupling a fermion in the standard electro-weak theory},
  author        = {D'Hoker, Eric and Farhi, Edward},
  year          = 1984,
  journal       = {Nuclear Physics, Section B},
  volume        = 248,
  number        = 1,
  doi           = {10.1016/0550-3213(84)90587-x},
  issn          = {05503213}
}
@article{di_sipio_dijetgan_2019,
  title         = {{DijetGAN}: a {Generative}-{Adversarial} {Network} approach for the simulation of {QCD} dijet events at the {LHC}},
  shorttitle    = {DijetGAN},
  author        = {Di Sipio, Riccardo and Giannelli, Michele Faucci and Haghighat, Sana Ketabchi and Palazzo, Serena},
  year          = 2019,
  month         = aug,
  journal       = {Journal of High Energy Physics},
  volume        = 2019,
  number        = 8,
  pages         = 110,
  doi           = {10.1007/jhep08(2019)110},
  issn          = {1029-8479},
  url           = {https://doi.org/10.1007/JHEP08(2019)110},
  urldate       = {2025-07-17},
  abstract      = {A Generative-Adversarial Network (GAN) based on convolutional neural networks is used to simulate the production of pairs of jets at the LHC. The GAN is trained on events generated using MadGraph5, Pythia8, and Delphes3 fast detector simulation. We demonstrate that a number of kinematic distributions both at Monte Carlo truth level and after the detector simulation can be reproduced by the generator network.},
  language      = {en},
  keywords      = {Artificial Intelligence, Bayesian Network, Hadron-Hadron scattering (experiments), Jets, Machine Learning, Particle Physics, Particle and resonance production, Probabilistic data networks, QCD, Theoretical Particle Physics}
}
@article{DiMattia2019ADetection,
  title         = {A Survey on GANs for Anomaly Detection},
  author        = {Di Mattia, Federico and Galeone, Paolo and De Simoni, Michele and Ghelfi, Emanuele},
  year          = 2019,
  month         = 6,
  url           = {https://arxiv.org/abs/1906.11632v2},
  arxivid       = {1906.11632}
}
@article{DiMeglio2017SubmitterResearch,
  title         = {submitter : CERN openlab white paper on future ICT challenges in scientific research},
  author        = {Di Meglio, Alberto and Girone, Maria and Rademakers, Fons and Purcell, Andrew},
  year          = 2017,
  doi           = {10.5281/zenodo.998694},
  url           = {https://cds.cern.ch/record/2301895},
  keywords      = {CERN Document Server, WebSearch}
}
@misc{dinh_density_2017,
  title         = {Density estimation using {Real} {NVP}},
  author        = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  year          = 2017,
  month         = feb,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1605.08803},
  url           = {http://arxiv.org/abs/1605.08803},
  urldate       = {2025-07-16},
  note          = {arXiv:1605.08803 [cs]},
  abstract      = {Unsupervised learning of probabilistic models is a central yet challenging problem in machine learning. Specifically, designing models with tractable learning, sampling, inference and evaluation is crucial in solving this task. We extend the space of such models using real-valued non-volume preserving (real NVP) transformations, a set of powerful invertible and learnable transformations, resulting in an unsupervised learning algorithm with exact log-likelihood computation, exact sampling, exact inference of latent variables, and an interpretable latent space. We demonstrate its ability to model natural images on four datasets through sampling, log-likelihood evaluation and latent variable manipulations.},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}
@misc{dinh_nice_2015,
  title         = {{NICE}: {Non}-linear {Independent} {Components} {Estimation}},
  shorttitle    = {Nice},
  author        = {Dinh, Laurent and Krueger, David and Bengio, Yoshua},
  year          = 2015,
  month         = apr,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1410.8516},
  url           = {http://arxiv.org/abs/1410.8516},
  urldate       = {2025-07-16},
  note          = {arXiv:1410.8516 [cs]},
  abstract      = {We propose a deep learning framework for modeling complex high-dimensional densities called Non-linear Independent Component Estimation (NICE). It is based on the idea that a good representation is one in which the data has a distribution that is easy to model. For this purpose, a non-linear deterministic transformation of the data is learned that maps it to a latent space so as to make the transformed data conform to a factorized distribution, i.e., resulting in independent latent variables. We parametrize this transformation so that computing the Jacobian determinant and inverse transform is trivial, yet we maintain the ability to learn complex non-linear transformations, via a composition of simple building blocks, each based on a deep neural network. The training criterion is simply the exact log-likelihood, which is tractable. Unbiased ancestral sampling is also easy. We show that this approach yields good generative models on four image datasets and can be used for inpainting.},
  keywords      = {Computer Science - Machine Learning}
}
@article{Schmelling:1993cd,
    author = "Schmelling, Michael",
    title = "{The Method of reduced cross entropy: A General approach to unfold probability distributions}",
    reportNumber = "CERN-CN-93-03",
    doi = "10.1016/0168-9002(94)90119-8",
    journal = "Nucl. Instrum. Meth. A",
    volume = "340",
    pages = "400--412",
    year = "1994"
}
@article{Narayan:1986wj,
    author = "Narayan, R. and Nityananda, R.",
    title = "{Maximum entropy image restoration in astronomy}",
    doi = "10.1146/annurev.aa.24.090186.001015",
    journal = "Ann. Rev. Astron. Astrophys.",
    volume = "24",
    pages = "127--170",
    year = "1986"
}
@book{dissertori_quantum_2003,
  title         = {Quantum {Chromodynamics}: {High} {Energy} {Experiments} and {Theory}},
  shorttitle    = {Quantum {Chromodynamics}},
  author        = {Dissertori, G\"{u}nther and Knowles, Ian G. and Schmelling, {and} Michael},
  year          = 2003,
  month         = apr,
  publisher     = {Oxford University Press},
  address       = {Oxford, New York},
  series        = {International {Series} of {Monographs} on {Physics}},
  isbn          = {978-0-19-850572-3},
  abstract      = {This book provides an introduction to Quantum Chromodynamics (QCD), the theory of strong interactions. It places equal weight on the theoretical foundations and experimental tests of the theory. Although the experimental chapters focus on recent measurements, the subject is placed into historical perspective by also summarizing the steps which lead to the formulation of QCD. Measurements are discussed as they were performed by the LEP experiments at CERN, or at hadron-hadron and lepton colliders such as the TEVATRON at Fermilab and HERA at investigations of the non-abelian structure of the underlying gauge group, determinations of nucleon structure functions, and studies of the non-perturbative hadronization process. It is hoped that the reader will gain an overview of how QCD developed in the 20th century and where we stand with respect to a quantitative understanding after the turn of the millennium. The text is intended for graduate postgraduate students as well as researchers and includes numerous problems and solutions. , This book provides an introduction to Quantum Chromodynamics (QCD), the theory of strong interactions. It places equal weight on the theoretical foundations and experimental tests of the theory. Although the experimental chapters focus on recent measurements, the subject is placed into historical perspective by also summarizing the steps which lead to the formulation of QCD. Measurements are discussed as they were performed by the LEP experiments at CERN, or at hadron-hadron and lepton colliders such as the TEVATRON at Fermilab and HERA at investigations of the non-abelian structure of the underlying gauge group, determinations of nucleon structure functions, and studies of the non-perturbative hadronization process. It is hoped that the reader will gain an overview of how QCD developed in the 20th century and where we stand with respect to a quantitative understanding after the turn of the millennium. The text is intended for graduate postgraduate students as well as researchers and includes numerous problems and solutions.}
}
@book{dissertoriQuantumChromodynamicsHigh2003,
  title         = {Quantum {{Chromodynamics}}: {{High Energy Experiments}} and {{Theory}}},
  shorttitle    = {Quantum {{Chromodynamics}}},
  author        = {Dissertori, G{\"u}nther and Knowles, Ian G. and Schmelling, {and} Michael},
  year          = 2003,
  month         = apr,
  publisher     = {Oxford University Press},
  address       = {Oxford, New York},
  series        = {International {{Series}} of {{Monographs}} on {{Physics}}},
  isbn          = {978-0-19-850572-3},
  abstract      = {This book provides an introduction to Quantum Chromodynamics (QCD), the theory of strong interactions. It places equal weight on the theoretical foundations and experimental tests of the theory. Although the experimental chapters focus on recent measurements, the subject is placed into historical perspective by also summarizing the steps which lead to the formulation of QCD. Measurements are discussed as they were performed by the LEP experiments at CERN, or at hadron-hadron and lepton colliders such as the TEVATRON at Fermilab and HERA at investigations of the non-abelian structure of the underlying gauge group, determinations of nucleon structure functions, and studies of the non-perturbative hadronization process. It is hoped that the reader will gain an overview of how QCD developed in the 20th century and where we stand with respect to a quantitative understanding after the turn of the millennium. The text is intended for graduate postgraduate students as well as researchers and includes numerous problems and solutions.                ,                  This book provides an introduction to Quantum Chromodynamics (QCD), the theory of strong interactions. It places equal weight on the theoretical foundations and experimental tests of the theory. Although the experimental chapters focus on recent measurements, the subject is placed into historical perspective by also summarizing the steps which lead to the formulation of QCD. Measurements are discussed as they were performed by the LEP experiments at CERN, or at hadron-hadron and lepton colliders such as the TEVATRON at Fermilab and HERA at investigations of the non-abelian structure of the underlying gauge group, determinations of nucleon structure functions, and studies of the non-perturbative hadronization process. It is hoped that the reader will gain an overview of how QCD developed in the 20th century and where we stand with respect to a quantitative understanding after the turn of the millennium. The text is intended for graduate postgraduate students as well as researchers and includes numerous problems and solutions.},
  file          = {/Users/t-krishdesai/Zotero/storage/T67DSM9G/quantum-chromodynamics-9780198505723.html}
}
@article{Dorigo2020DealingReview,
  title         = {Dealing with Nuisance Parameters using Machine Learning in High Energy Physics: a Review},
  author        = {Dorigo, Tommaso and de Castro, Pablo},
  year          = 2020,
  month         = 7,
  url           = {https://arxiv.org/abs/2007.09121v2},
  arxivid       = {2007.09121}
}
@misc{du_unifying_2024,
  title         = {Unifying {Simulation} and {Inference} with {Normalizing} {Flows}},
  author        = {Du, Haoxing and Krause, Claudius and Mikuni, Vinicius and Nachman, Benjamin and Pang, Ian and Shih, David},
  year          = 2024,
  month         = apr,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2404.18992},
  url           = {http://arxiv.org/abs/2404.18992},
  urldate       = {2025-07-15},
  note          = {arXiv:2404.18992 [hep-ph] version: 1},
  abstract      = {There have been many applications of deep neural networks to detector calibrations and a growing number of studies that propose deep generative models as automated fast detector simulators. We show that these two tasks can be unified by using maximum likelihood estimation (MLE) from conditional generative models for energy regression. Unlike direct regression techniques, the MLE approach is prior-independent and non-Gaussian resolutions can be determined from the shape of the likelihood near the maximum. Using an ATLAS-like calorimeter simulation, we demonstrate this concept in the context of calorimeter energy calibration.},
  keywords      = {High Energy Physics - Experiment, High Energy Physics - Phenomenology, Physics - Data Analysis, Statistics and Probability, Physics - Instrumentation and Detectors, Statistics - Machine Learning}
}
@article{duchi_adaptive_nodate,
  title         = {Adaptive {Subgradient} {Methods} for {Online} {Learning} and {Stochastic} {Optimization}},
  author        = {Duchi, John and Hazan, Elad and Singer, Yoram},
  abstract      = {We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.},
  language      = {en}
}
@article{eberly_estimating_2003,
  title         = {Estimating {Bayesian} credible intervals},
  author        = {Eberly, Lynn E. and Casella, George},
  year          = 2003,
  month         = mar,
  journal       = {Journal of Statistical Planning and Inference},
  series        = {Special issue {II}: {Model} {Selection}, {Model} {Diagnostics}, {Empirical} {B} ayes and {Hierarchical} {Bayes}},
  volume        = 112,
  number        = 1,
  pages         = {115--132},
  doi           = {10.1016/s0378-3758(02)00327-0},
  issn          = {0378-3758},
  url           = {https://www.sciencedirect.com/science/article/pii/S0378375802003270},
  urldate       = {2025-07-14},
  abstract      = {Under a Bayesian approach to a hierarchical model, quantile or interval estimation is often used to summarize the posterior distribution of a parameter. When using an Markov Chain Monte Carlo algorithm such as the Gibbs sampler to generate a sample from the posterior (marginal) of interest, calculations are often easier when done on a per-iteration (conditional) basis. Final estimators which are taken as a combination of values across iterations are often called ``Rao–Blackwellized'' and result in estimators with good variance properties. Such an approach is not yet used in the calculation of credible intervals. We derive here a weighted-average estimator of the endpoints of a credible interval which mimics this Rao–Blackwellized construction. We compare it to other alternatives including a na\i{}\"ve average estimator, the usual order statistics estimator, and an estimator based on density estimation. We obtain theorems showing when there is convergence to the true interval and discuss Central Limit Theorems for these estimators. Simulations for two hierarchical modeling scenarios (count data and continuous data) illustrate their numerical behaviors. An animal epidemiology example is included. The proposed estimator offers the smallest standard errors of the estimators studied, sometimes by several orders of magnitude, but can have a small bias.},
  keywords      = {Central Limit Theorem, Gibbs sampler, Quantile estimation, Rao–Blackwell Theorem, Tail probabilities}
}
@book{Ellis:1996mzs,
  title         = {{{QCD}} and {{Collider Physics}}},
  author        = {Ellis, R. K. and Stirling, W. J. and Webber, B. R.},
  year          = 2011,
  month         = feb,
  publisher     = {Cambridge University Press},
  address       = {Cambridge},
  series        = {Camb. {{Monogr}}. {{Part}}. {{Phys}}. {{Nucl}}. {{Phys}}. {{Cosmol}}.},
  number        = 8,
  doi           = {10.1017/cbo9780511628788},
  isbn          = {978-0-521-54589-1},
  urldate       = {2025-07-18},
  abstract      = {One of the triumphs of modern particle physics has been the extent to which Quantum Chromodynamics (QCD) has successfully accounted for the strong interaction processes observed at high-energy particle colliders, for example the production of heavy quarks and jets of particles, and the short-distance parton structure of the proton. This book gives a detailed overview of collider physics with special emphasis on the study of QCD. After a general description of the QCD Lagrangian, and the properties of asymptotic freedom and colour confinement which derive from it, the most important applications at high-energy colliders are described in detail. These include the production of jets, heavy quarks, electroweak gauge bosons and Higgs bosons. The various methods of measuring the strong coupling constant are summarised. Many of the theoretical results are calculated from first principles, and the book will be both a textbook and a valuable source of reference material for all particle physicists.},
  annotation    = {921 citations (INSPIRE 2025/7/18)\\ 900 citations w/o self (INSPIRE 2025/7/18)},
  file          = {/Users/t-krishdesai/Zotero/storage/KJS7WSKA/D0095E6D278BBBC74E9C3636AB4CB80C.html}
}
@article{endres_new_2003,
  title         = {A new metric for probability distributions},
  author        = {Endres, D.M. and Schindelin, J.E.},
  year          = 2003,
  month         = jul,
  journal       = {IEEE Transactions on Information Theory},
  volume        = 49,
  number        = 7,
  pages         = {1858--1860},
  doi           = {10.1109/tit.2003.813506},
  issn          = {1557-9654},
  url           = {https://ieeexplore.ieee.org/document/1207388},
  urldate       = {2025-07-17},
  abstract      = {We introduce a metric for probability distributions, which is bounded, information-theoretically motivated, and has a natural Bayesian interpretation. The square root of the well-known /spl chi//sup 2/ distance is an asymptotic approximation to it. Moreover, it is a close relative of the capacitory discrimination and Jensen-Shannon divergence.},
  keywords      = {Adaptive estimation, Algorithm design and analysis, Bayesian methods, Convergence, Gaussian noise, Iterative algorithms, Probability distribution, Wavelet analysis, White noise, Writing}
}
@article{Engl2020RegularizationProblems,
  title         = {Regularization of Inverse Problems},
  author        = {Engl, Heinz W. and Ramlau, Ronny},
  year          = 2020,
  month         = 1,
  journal       = {Encyclopedia of Applied and Computational Mathematics},
  publisher     = {Springer Berlin Heidelberg},
  pages         = {1233--1241},
  doi           = {10.1007/978-3-540-70529-1{\_}52},
  url           = {https://arxiv.org/abs/2001.00617v2},
  arxivid       = {2001.00617}
}
@misc{EnvironmentalCERN,
  title         = {{Environmental awareness: the challenges of CERN's IT infrastructure \vert{} CERN}},
  url           = {https://home.cern/news/news/cern/environmental-awareness-challenges-cerns-it-infrastructure}
}
@article{erdmann_autoencoder-extended_2023,
  title         = {Autoencoder-extended {Conditional} {Invertible} {Neural} {Networks} for {Unfolding} {Signal} {Traces}},
  author        = {Erdmann, M and Hafner, K and Schulte, J and Straub, M},
  year          = 2023,
  month         = feb,
  journal       = {Journal of Physics: Conference Series},
  volume        = 2438,
  number        = 1,
  pages         = {012072},
  doi           = {10.1088/1742-6596/2438/1/012072},
  issn          = {1742-6596},
  url           = {https://dx.doi.org/10.1088/1742-6596/2438/1/012072},
  urldate       = {2025-07-16},
  note          = {Publisher: IOP Publishing},
  abstract      = {The reconstruction of cosmic ray-induced air showers from measurements of radio waves constitutes a major challenge. In this work, we focus on recovering the full three-dimensional electromagnetic field from two recorded signal traces of an antenna station covering two horizontal polarization directions. The simulated field is folded by a direction and frequency-dependent characteristic antenna response pattern, resulting in voltage signal traces as a function of time. Both signal traces are contaminated by simulated background noise. We use conditional Invertible Neural Networks (cINNs) to learn posterior distributions, from which the most likely electromagnetic field given a measured signal trace can be inferred. To improve robustness, we extend the method with an autoencoder by reducing the parameter phase space and decoupling the cINN from specific data shapes. Thereby, each signal trace is condensed into a small number of abstract parameters in the latent space on which the cINN operates. The presented method shows promising results and can be transferred to other unfolding problems where the recovery of the pre-measurement state is of interest.},
  language      = {en}
}
@misc{erdmann_generating_2018,
  title         = {Generating and refining particle detector simulations using the {Wasserstein} distance in adversarial networks},
  author        = {Erdmann, Martin and Geiger, Lukas and Glombitza, Jonas and Schmidt, David},
  year          = 2018,
  month         = feb,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1802.03325},
  url           = {http://arxiv.org/abs/1802.03325},
  urldate       = {2025-07-17},
  note          = {arXiv:1802.03325 [astro-ph]},
  abstract      = {We use adversarial network architectures together with the Wasserstein distance to generate or refine simulated detector data. The data reflect two-dimensional projections of spatially distributed signal patterns with a broad spectrum of applications. As an example, we use an observatory to detect cosmic ray-induced air showers with a ground-based array of particle detectors. First we investigate a method of generating detector patterns with variable signal strengths while constraining the primary particle energy. We then present a technique to refine simulated time traces of detectors to match corresponding data distributions. With this method we demonstrate that training a deep network with refined data-like signal traces leads to a more precise energy reconstruction of data events compared to training with the originally simulated traces.},
  keywords      = {Astrophysics - Instrumentation and Methods for Astrophysics, High Energy Physics - Experiment}
}
@article{F.R.S.1911LXXIX.Atom,
  title         = {{LXXIX. The scattering of {$\alpha$} and {$\beta$} particles by matter and the structure of the atom}},
  author        = {F.R.S., Professor E. Rutherford},
  year          = 1911,
  month         = 5,
  journal       = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  publisher     = {Taylor {\&} Francis Group},
  volume        = 21,
  number        = 125,
  pages         = {669--688},
  doi           = {10.1080/14786440508637080},
  issn          = {1941-5982},
  url           = {https://www.tandfonline.com/doi/abs/10.1080/14786440508637080}
}
@article{Fajtl2020LatentAutoencoder,
  title         = {Latent Bernoulli Autoencoder},
  author        = {Fajtl, Jiri and Argyriou, Vasileios and Monekosso, Dorothy and Remagnino, Paolo},
  year          = 2020,
  url           = {https://github.com/ok1zjf/lbae}
}
@article{fan_analysis_2022,
  title         = {Analysis of {Regularized} {Poisson} {GLM} {Spike}-{Train} {Modeling}},
  author        = {Fan, Yile and Li, Yuanpeng and Xue, Naiyang and Ding, Dan},
  year          = 2022,
  month         = jan,
  journal       = {Journal of Physics: Conference Series},
  volume        = 2173,
  number        = 1,
  pages         = {012019},
  doi           = {10.1088/1742-6596/2173/1/012019},
  issn          = {1742-6596},
  url           = {https://dx.doi.org/10.1088/1742-6596/2173/1/012019},
  urldate       = {2025-07-14},
  note          = {Publisher: IOP Publishing},
  abstract      = {This paper introduces a method for modeling and analyzing neural impulse sequences. In this paper, we define the response value of a scale-independent neuron and construct the correlation graph of the neuron under the response value. The minimum cut algorithm is applied continuously to obtain the maximum group of neurons. According to the characteristics of the firing of neurons, a Poisson-process based model is proposed to mathematically model the neural coding, and the gradient descent method is used to optimize it. Through the modeling analysis method, information such as maximum neuron group and Inter-spike-Interval (ISI) can be effectively analyzed according to neuron impulse sequence.},
  language      = {en}
}
@article{fernandez-martinez_curse_2020,
  title         = {The curse of dimensionality in inverse problems},
  author        = {Fern\'{a}ndez-Mart\'{\i}nez, Juan L. and Fern\'{a}ndez-Mu\~{n}iz, Zulima},
  year          = 2020,
  month         = may,
  journal       = {Journal of Computational and Applied Mathematics},
  volume        = 369,
  pages         = 112571,
  doi           = {10.1016/j.cam.2019.112571},
  issn          = {0377-0427},
  url           = {https://www.sciencedirect.com/science/article/pii/S037704271930576X},
  urldate       = {2025-07-14},
  abstract      = {Nonlinear inverse problems in real problems in industry have typically a very underdetermined character due to the high number of parameters that are usually needed to achieve accurate forward predictions. The corresponding inverse problem is ill-posed, that is, there exist many solutions which are compatible with the prior information, fitting the observed data within the same error bounds. These solutions are located in (one or several) flat curvilinear and disconnected valleys of the cost function topography. The random sampling of these equivalent models is impossible due to the curse of dimensionality and to the high computational cost needed to provide the corresponding forward predictions. This paper generalizes the curse of dimensionality to linear and nonlinear inverse problems outlining the main differences between them. With a simple 2D example we show that nonlinearities allow for a reduction in size of the nonlinear equivalence region that could be embedded in a linear hyperquadric with smaller condition number than the corresponding linearized equivalence region. We also analyze the effect of the regularization in the posterior sampling, and that of the dimensionality reduction, which is needed to perform efficient sampling of the region of uncertainty equivalence in high dimensional problems. We hope that the additional theoretical knowledge provided by this research will help practitioners to design more efficient methods of sampling.},
  keywords      = {Curse of dimensionality, Inverse problems, Model reduction, Uncertainty analysis}
}
@article{fernandez-martinez_effect_2014,
  title         = {The effect of noise and {Tikhonov}'s regularization in inverse problems. {Part} {I}: {The} linear case},
  shorttitle    = {The effect of noise and {Tikhonov}'s regularization in inverse problems. {Part} {I}},
  author        = {Fern\'{a}ndez-Mart\'{\i}nez, J. L. and Pallero, J. L. G. and Fern\'{a}ndez-Mu\~{n}iz, Z. and Pedruelo-Gonz\'{a}lez, L. M.},
  year          = 2014,
  month         = sep,
  journal       = {Journal of Applied Geophysics},
  volume        = 108,
  pages         = {176--185},
  doi           = {10.1016/j.jappgeo.2014.05.006},
  issn          = {0926-9851},
  url           = {https://www.sciencedirect.com/science/article/pii/S0926985114001402},
  urldate       = {2025-07-13},
  abstract      = {Inverse problems are a special kind of optimization problems because the cost function involves data, always affected by noise, that in the case of ill-conditioning is amplified back into the model parameters through the generalized inverse operator. Then, the inversion might provide spurious solutions if no regularization techniques are used. For a given misfit tolerance the models that fit the observed data are called equivalent, and are located in a region of the model space that is bounded by the linear hyper-quadric surface. This paper analyzes in detail the role of noise in data in linear inverse problems, providing a geometrical interpretation for the role of the regularization. The noise shifts the solution found by least squares methods and deforms homogeneously the topography of the cost function, while Tikhonov's regularization transforms the linear hyper-quadric from an elliptical cylinder to a very oblong hyper-ellipsoid in the directions that originally spanned the kernel of the linear forward operator. Furthermore, in the case of the regularization, this deformation is anisotropic affecting differently the axes of the linear hyper-quadric. The model of reference informs the coordinates of the solution that originally resided in the kernel of the forward operator. The differences with nonlinear inversion are highlighted in the second accompanying paper. This knowledge, although theoretical at this stage, might impact how the uncertainty analysis is performed in geophysical inversion, since noise in data is always present, and good prior models are not always available.},
  keywords      = {Linear inversion, Noise, Regularization, Uncertainty analysis}
}
@misc{finotello_functional_2025,
  title         = {Functional {Renormalization} for {Signal} {Detection}: {Dimensional} {Analysis} and {Dimensional} {Phase} {Transition} for {Nearly} {Continuous} {Spectra} {Effective} {Field} {Theory}},
  shorttitle    = {Functional {Renormalization} for {Signal} {Detection}},
  author        = {Finotello, Riccardo and Lahoche, Vincent and Samary, Dine Ousmane},
  year          = 2025,
  month         = jun,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2507.01064},
  url           = {http://arxiv.org/abs/2507.01064},
  urldate       = {2025-07-14},
  note          = {arXiv:2507.01064 [physics] version: 1},
  abstract      = {Signal detection is one of the main challenges of data science. According to the nature of the data, the presence of noise may corrupt measurements and hinder the discovery of significant patterns. A wide range of techniques aiming at extracting the relevant degrees of freedom from data has been thus developed over the years. However, signal detection in almost continuous spectra, for small signal-to-noise ratios, remains a known difficult issue. This paper develops over recent advancements proposing to tackle this issue by analysing the properties of the underlying effective field theory arising as a sort of maximal entropy distribution in the vicinity of universal random matrix distributions. Nearly continuous spectra provide an intrinsic and non-conventional scaling law for field and couplings, the scaling dimensions depending on the energy scale. The coarse-graining over small eigenvalues of the empirical spectrum defines a specific renormalization group, whose characteristics change when the collective behaviour of "informational" modes become significant, that is, stronger than the intrinsic fluctuations of noise. This paper pursues three different goals. First, we propose to quantify the real effects of fluctuations relative to what can be called "signal", while improving the robustness of the results obtained in our previous work. Second, we show that quantitative changes in the presence of a signal result in a counterintuitive modification of the distribution of eigenvectors. Finally, we propose a method for estimating the number of noise components and define a limit of detection in a general nearly continuous spectrum using the renormalization group. The main statements of this paper are essentially numeric, and their reproducibility can be checked using the associated code.},
  keywords      = {Computer Science - Information Theory, Condensed Matter - Statistical Mechanics, High Energy Physics - Theory, Mathematics - Information Theory, Physics - Data Analysis, Statistics and Probability, Statistics - Methodology}
}
@article{fish_blind_1995,
  title         = {Blind deconvolution by means of the {Richardson}–{Lucy} algorithm},
  author        = {Fish, D. A. and Brinicombe, A. M. and Pike, E. R. and Walker, J. G.},
  year          = 1995,
  month         = jan,
  journal       = {Josa A},
  volume        = 12,
  number        = 1,
  pages         = {58--65},
  doi           = {10.1364/josaa.12.000058},
  issn          = {1520-8532},
  url           = {https://opg.optica.org/josaa/abstract.cfm?uri=josaa-12-1-58},
  urldate       = {2025-07-13},
  copyright     = {\textcopyright{} 1995 Optical Society of America},
  note          = {Publisher: Optica Publishing Group},
  abstract      = {A blind deconvolution algorithm based on the Richardson–Lucy deconvolution algorithm is presented. Its performance in the presence of noise is found to be superior to that of other blind deconvolution algorithms. Results are presented and compared with results obtained from implementation of a Weiner filter blind deconvolution algorithm. The algorithm is developed further to incorporate functional forms of the point-spread function with unknown parameters. In the presence of noise the point-spread function can be evaluated with 1.0\% error, and the object can be reconstructed with a quality near that of the deconvolution process with a known point-spread function.},
  language      = {En},
  keywords      = {Deconvolution, Optical systems, Phase retrieval, Random number generation, Space telescopes, Spherical aberration}
}
@article{fm,
  title         = {The Crufixion of Complex Marginalia Spectra by Means of Grata Modulation},
  author        = {Fuji Budweiser},
  year          = 1973,
  journal       = {Journal of the Audio Wiggly Society},
  volume        = 21,
  number        = 7,
  pages         = {526--534}
}
@article{fredholm_sur_1903,
  title         = {Sur une classe d'\'{e}quations fonctionnelles},
  author        = {Fredholm, Ivar},
  year          = 1903,
  month         = jan,
  journal       = {Acta Mathematica},
  volume        = 27,
  number        = {none},
  pages         = {365--390},
  doi           = {10.1007/bf02421317},
  issn          = {0001-5962, 1871-2509},
  url           = {https://projecteuclid.org/journals/acta-mathematica/volume-27/issue-none/Sur-une-classe-d%c3%a9quations-fonctionnelles/10.1007/BF02421317.full},
  urldate       = {2025-07-13},
  note          = {Publisher: Institut Mittag-Leffler},
  abstract      = {Acta Mathematica}
}
@misc{FreiburgHEP,
  title         = {Freiburg 2011 Statistics for HEP},
  url           = {https://www.pp.rhul.ac.uk/~cowan/stat_freiburg.html}
}
@article{from_new_2020,
  title         = {{Some} {New} {Bounds} {And} {Approximations} {On} {Tail} {Probabilities} {Of} {The} {Poisson} {And} {Other} {Discrete} {Distributions}},
  author        = {From, Steven G. and Swift, Andrew W.},
  year          = 2020,
  month         = jan,
  journal       = {Probability in the Engineering and Informational Sciences},
  volume        = 34,
  number        = 1,
  pages         = {53--71},
  doi           = {10.1017/s0269964818000347},
  issn          = {0269-9648, 1469-8951},
  url           = {https://www.cambridge.org/core/journals/probability-in-the-engineering-and-informational-sciences/article/abs/some-new-bounds-and-approximations-on-tail-probabilities-of-the-poisson-and-other-discrete-distributions/5D150AD3C15A0F8219340C7437513C3D?utm_source=chatgpt.com},
  urldate       = {2025-07-13},
  abstract      = {In this paper, we discuss new bounds and approximations for tail probabilities of certain discrete distributions. Several different methods are used to obtain bounds and/or approximations. Excellent upper and lower bounds are obtained for the Poisson distribution. Excellent approximations (and not bounds necessarily) are also obtained for other discrete distributions. Numerical comparisons made to previously proposed methods demonstrate that the new bounds and/or approximations compare very favorably. Some conjectures are made.},
  language      = {en},
  keywords      = {60E15, 62E15, Poisson distribution, approximations and bounds, discrete distributions, tail probabilities}
}
@inproceedings{fuglede_jensen-shannon_2004,
  title         = {Jensen-{Shannon} divergence and {Hilbert} space embedding},
  author        = {Fuglede, B. and Topsoe, F.},
  year          = 2004,
  month         = jun,
  booktitle     = {International {Symposium} {onInformation} {Theory}, 2004. {ISIT} 2004. {Proceedings}.},
  pages         = {31--},
  doi           = {10.1109/isit.2004.1365067},
  url           = {https://ieeexplore.ieee.org/document/1365067},
  urldate       = {2025-07-17},
  abstract      = {This paper describes the Jensen-Shannon divergence (JSD) and Hilbert space embedding. With natural definitions making these considerations precise, one finds that the general Jensen-Shannon divergence related to the mixture is the minimum redundancy, which can be achieved by the observer. The set of distributions with the metric /spl radic/JSD can even be embedded isometrically into Hilbert space and the embedding can be identified.},
  keywords      = {Concrete, Convergence, Councils, Entropy, Hilbert space, Kernel, Mathematics, Probability distribution, Spirals}
}
@article{Gagunashvili2024DataOptimization,
  title         = {Data Unfolding with Mean Integrated Square Error Optimization},
  author        = {Gagunashvili, Nikolay D},
  year          = 2024,
  arxivid       = {2402.12990v3},
  keywords      = {cluster analysis, entropy regularization, inverse problem, system identification}
}
@article{gaponenko_practical_2020,
  title         = {A practical way to regularize unfolding of sharply varying spectra with low data statistics},
  author        = {Gaponenko, Andrei},
  year          = 2020,
  month         = apr,
  journal       = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  volume        = 960,
  pages         = 163612,
  doi           = {10.1016/j.nima.2020.163612},
  issn          = {0168-9002},
  url           = {https://www.sciencedirect.com/science/article/pii/S0168900220301790},
  urldate       = {2025-07-13},
  abstract      = {Unfolding is a well-established tool in particle physics. However, a naive application of the standard regularization techniques to unfold the momentum spectrum of protons ejected in the process of negative muon nuclear capture led to a result exhibiting unphysical artifacts. A finite data sample limited the range in which unfolding can be performed, thus introducing a cutoff. A sharply falling ``true'' distribution led to low data statistics near the cutoff, which exacerbated the regularization bias and produced an unphysical spike in the resulting spectrum. An improved approach has been developed to address these issues and is illustrated using a toy model. The approach uses full Poisson likelihood of data, and produces a continuous, physically plausible, unfolded distribution. The new technique has a broad applicability since sharply falling spectra are common.},
  keywords      = {Data analysis, Deconvolution, Likelihood, Statistical methods, Unfolding}
}
@incollection{gardi_statistics_2015,
  title         = {Statistics for {Searches} at the {LHC}},
  author        = {Cowan, Glen},
  year          = 2015,
  booktitle     = {{LHC} {Phenomenology}},
  publisher     = {Springer International Publishing},
  address       = {Cham},
  pages         = {321--355},
  doi           = {10.1007/978-3-319-05362-2_9},
  isbn          = {978-3-319-05361-5 978-3-319-05362-2},
  url           = {http://link.springer.com/10.1007/978-3-319-05362-2_9},
  urldate       = {2025-07-13},
  editor        = {Gardi, Einan and Glover, Nigel and Robson, Aidan}
}
@inproceedings{gehrmann_resummation_2017,
  title         = {Resummation of jet rates and event-shape distributions in e{\textasciicircum}+ e{\textasciicircum} -},
  author        = {Gehrmann, Thomas and Luisoni, Gionata and Monni, Pier Francesco},
  year          = 2017,
  booktitle     = {Parton radiation and fragmentation from {LHC} to {FCC}-ee},
  pages         = {97--102},
  keywords      = {BETA, electron positron: annihilation, event shape analysis, jet: production, resummation, strong interaction: coupling constant, ⛔ No DOI found}
}
@inproceedings{gehrmannResummationJetRates2017,
  title         = {Resummation of Jet Rates and Event-Shape Distributions in E{\textasciicircum}+ E{\textasciicircum}-},
  author        = {Gehrmann, Thomas and Luisoni, Gionata and Monni, Pier Francesco},
  year          = 2017,
  booktitle     = {Parton Radiation and Fragmentation from {{LHC}} to {{FCC-ee}}},
  pages         = {97--102},
  keywords      = {BETA,electron positron: annihilation,event shape analysis,jet: production,No DOI found,resummation,strong interaction: coupling constant},
  file          = {/Users/t-krishdesai/Zotero/storage/6EWF4VZG/Gehrmann et al. - 2017 - Resummation of jet rates and event-shape distributions in e^+ e^.pdf}
}
@article{giannelli_caloshowergan_2024,
  title         = {{CaloShowerGAN}, a {Generative} {Adversarial} {Networks} model for fast calorimeter shower simulation},
  author        = {Giannelli, Michele Faucci and Zhang, Rui},
  year          = 2024,
  month         = jul,
  journal       = {The European Physical Journal Plus},
  volume        = 139,
  number        = 7,
  pages         = 597,
  doi           = {10.1140/epjp/s13360-024-05397-4},
  issn          = {2190-5444},
  url           = {http://arxiv.org/abs/2309.06515},
  urldate       = {2025-07-17},
  note          = {arXiv:2309.06515 [physics]},
  abstract      = {In particle physics, the demand for rapid and precise simulations is rising. The shift from traditional methods to machine learning-based approaches has led to significant advancements in simulating complex detector responses. CaloShowerGAN is a new approach for fast calorimeter simulation based on Generative Adversarial Network (GAN). We use Dataset 1 of the Fast Calorimeter Simulation Challenge 2022 to demonstrate the efficacy of the model to simulate calorimeter showers produced by photons and pions. The dataset is originated from the ATLAS experiment, and we anticipate that this approach can be seamlessly integrated into the ATLAS system. This development brings a significant improvement compared to the deployed GANs by ATLAS and could offer great enhancement to the current ATLAS fast simulations.},
  keywords      = {High Energy Physics - Experiment, Physics - Instrumentation and Detectors}
}
@article{giovanni_multi-dimensional_2010,
  title         = {Multi-{Dimensional} {Gaussian} {Fluctuations} on the {Poisson} {Space}},
  author        = {Giovanni, Peccati and Zheng, Cengbo},
  year          = 2010,
  month         = jan,
  journal       = {Electronic Journal of Probability},
  volume        = 15,
  number        = {none},
  pages         = {1487--1527},
  doi           = {10.1214/EJP.v15-813},
  issn          = {1083-6489, 1083-6489},
  url           = {https://projecteuclid.org/journals/electronic-journal-of-probability/volume-15/issue-none/Multi-Dimensional-Gaussian-Fluctuations-on-the-Poisson-Space/10.1214/EJP.v15-813.full},
  urldate       = {2025-07-13},
  note          = {Publisher: Institute of Mathematical Statistics and Bernoulli Society},
  abstract      = {We study multi-dimensional normal approximations on the Poisson space by means of Malliavin calculus, Stein's method and probabilistic interpolations. Our results yield new multi-dimensional central limit theorems for multiple integrals with respect to Poisson measures - thus significantly extending previous works by Peccati, Sol\'{e}, Taqqu and Utzet. Several explicit examples (including in particular vectors of linear and non-linear functionals of Ornstein-Uhlenbeck L\'{e}vy processes) are discussed in detail.},
  keywords      = {60F05, 60G51, 60G57, 60H05, 60H07, Malliavin calculus, Multi-dimensional normal approximations, Ornstein-Uhlenbeck processes, Poisson measures, Probabilistic Interpolations, Stein's method, central limit theorems}
}
@article{Girosi1995RegularizationArchitectures,
  title         = {Regularization Theory and Neural Networks Architectures},
  author        = {Girosi, Federico and Jones, Michael and Poggio, Tomaso},
  year          = 1995,
  month         = 3,
  journal       = {Neural Computation},
  publisher     = {MIT Press},
  volume        = 7,
  number        = 2,
  pages         = {219--269},
  doi           = {10.1162/neco.1995.7.2.219},
  issn          = {0899-7667},
  url           = {https://dx.doi.org/10.1162/neco.1995.7.2.219}
}
@article{Glashow:1961tr,
  title         = {Partial Symmetries of Weak Interactions},
  author        = {Glashow, S. L.},
  year          = 1961,
  journal       = {Nucl. Phys.},
  volume        = 22,
  pages         = {579--588},
  doi           = {10.1016/0029-5582(61)90469-2}
}
@article{Gockeler:2006nq,
  title         = {Operator Product Expansion on the Lattice: Analytic {{Wilson}} Coefficients},
  shorttitle    = {Operator Product Expansion on the Lattice},
  author        = {G{\"o}ckeler, M. and Horsley, R. and Perlt, H. and Rakow, P. E. L. and Schierholz, G. and Schiller, A.},
  year          = 2006,
  volume        = {Lat2006},
  pages         = 119,
  doi           = {10.22323/1.032.0119},
  urldate       = {2025-07-18},
  eprint        = {hep-lat/0610064},
  abstract      = {We present first results for Wilson coefficients of operators up to first order in the covariant derivatives for the case of Wilson fermions. They are derived from the off-shell Compton scattering amplitude \${\textbackslash}mathcal\{W\}\_\{{\textbackslash}mu{\textbackslash}nu\}(a,p,q)\$ of massless quarks with momentum \$p\$. The Wilson coefficients are classified according to the transformation of the corresponding operators under the hypercubic group H(4). We give selected examples for a special choice of the momentum transfer \$q\$. All Wilson coefficients are given in closed analytic form and in an expansion in powers of \$a\$ up to first corrections.},
  archiveprefix = {arXiv},
  collaboration = {Qcdsf},
  keywords      = {High Energy Physics - Lattice},
  annotation    = {5 citations (INSPIRE 2025/7/18)\\ 0 citations w/o self (INSPIRE 2025/7/18)\\ Citations: 4 (SemanticScholar) [2025-07-18]},
  file          = {/Users/t-krishdesai/Zotero/storage/X8Y6G685/Göckeler et al. - 2006 - Operator product expansion on the lattice analytic Wilson coefficients.pdf;/Users/t-krishdesai/Zotero/storage/L5GUJ9Q9/0610064.html}
}
@article{GongAnTagging,
  title         = {An Efficient Lorentz Equivariant Graph Neural Network for Jet Tagging},
  author        = {Gong, Shiqi and Meng, Qi and Zhang, Jue and Qu, Huilin and Li, Congqiao and Qian, Sitian and Du, Weitao and Ma, Zhi-Ming and Liu, Yan},
  doi           = {10.1007/jhep07(2022)030},
  url           = {https://github.com/sdogsq/LorentzNet-release.},
  arxivid       = {2201.08187v6}
}
@misc{goodfellow_nips_2017,
  title         = {{NIPS} 2016 {Tutorial}: {Generative} {Adversarial} {Networks}},
  shorttitle    = {{NIPS} 2016 {Tutorial}},
  author        = {Goodfellow, Ian},
  year          = 2017,
  month         = apr,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1701.00160},
  url           = {http://arxiv.org/abs/1701.00160},
  urldate       = {2025-07-17},
  note          = {arXiv:1701.00160 [cs]},
  abstract      = {This report summarizes the tutorial presented by the author at NIPS 2016 on generative adversarial networks (GANs). The tutorial describes: (1) Why generative modeling is a topic worth studying, (2) how generative models work, and how GANs compare to other generative models, (3) the details of how GANs work, (4) research frontiers in GANs, and (5) state-of-the-art image models that combine GANs with other methods. Finally, the tutorial contains three exercises for readers to complete, and the solutions to these exercises.},
  keywords      = {Computer Science - Machine Learning}
}
@article{Goodfellow2014GenerativeNetworks,
  title         = {Generative Adversarial Networks},
  author        = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  year          = 2014,
  month         = 6,
  journal       = {Science Robotics},
  publisher     = {Neural information processing systems foundation},
  volume        = 3,
  number        = {January},
  pages         = {2672--2680},
  issn          = 10495258,
  url           = {https://arxiv.org/pdf/1406.2661},
  arxivid       = {1406.2661}
}
@misc{goujon_number_2023,
  title         = {On the {Number} of {Regions} of {Piecewise} {Linear} {Neural} {Networks}},
  author        = {Goujon, Alexis and Etemadi, Arian and Unser, Michael},
  year          = 2023,
  month         = dec,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2206.08615},
  url           = {http://arxiv.org/abs/2206.08615},
  urldate       = {2025-07-15},
  note          = {arXiv:2206.08615 [cs]},
  abstract      = {Many feedforward neural networks (NNs) generate continuous and piecewise-linear (CPWL) mappings. Specifically, they partition the input domain into regions on which the mapping is affine. The number of these so-called linear regions offers a natural metric to characterize the expressiveness of CPWL NNs. The precise determination of this quantity is often out of reach in practice, and bounds have been proposed for specific architectures, including for ReLU and Maxout NNs. In this work, we generalize these bounds to NNs with arbitrary and possibly multivariate CPWL activation functions. We first provide upper and lower bounds on the maximal number of linear regions of a CPWL NN given its depth, width, and the number of linear regions of its activation functions. Our results rely on the combinatorial structure of convex partitions and confirm the distinctive role of depth which, on its own, is able to exponentially increase the number of regions. We then introduce a complementary stochastic framework to estimate the average number of linear regions produced by a CPWL NN. Under reasonable assumptions, the expected density of linear regions along any 1D path is bounded by the product of depth, width, and a measure of activation complexity (up to a scaling factor). This yields an identical role to the three sources of expressiveness: no exponential growth with depth is observed anymore.},
  keywords      = {Computer Science - Machine Learning, Mathematics - Combinatorics, Mathematics - Statistics Theory, Statistics - Machine Learning, Statistics - Statistics Theory}
}
@article{Green2020Gravitational-waveFlows,
  title         = {Gravitational-wave parameter estimation with autoregressive neural network flows},
  author        = {Green, Stephen R. and Simpson, Christine and Gair, Jonathan},
  year          = 2020,
  month         = 11,
  journal       = {Phys.Rev.D},
  publisher     = {American Physical Society},
  volume        = 102,
  number        = 10,
  doi           = {10.1103/physrevd.102.104057},
  issn          = 24700029,
  arxivid       = {2002.07656},
  keywords      = {doi:10.1103/PhysRevD.102.104057 url:https://doi.org/10.1103/PhysRevD.102.104057}
}
@article{Gross:1973id,
  title         = {Ultraviolet {{Behavior}} of {{Non-Abelian Gauge Theories}}},
  author        = {Gross, David J. and Wilczek, Frank},
  year          = 1973,
  month         = jun,
  journal       = {Physical Review Letters},
  publisher     = {American Physical Society},
  volume        = 30,
  number        = 26,
  pages         = {1343--1346},
  doi           = {10.1103/PhysRevLett.30.1343},
  urldate       = {2025-07-18},
  abstract      = {It is shown that a wide class of non-Abelian gauge theories have, up to calculable logarithmic corrections, free-field-theory asymptotic behavior. It is suggested that Bjorken scaling may be obtained from strong-interaction dynamics based on non-Abelian gauge symmetry.},
  annotation    = {6754 citations (INSPIRE 2025/7/18)\\ 6705 citations w/o self (INSPIRE 2025/7/18)\\ Citations: 3018 (Crossref) [2025-07-18]\\ Citations: 2860 (SemanticScholar) [2025-07-18]},
  file          = {/Users/t-krishdesai/Zotero/storage/Z5G9EEAY/Gross and Wilczek - 1973 - Ultraviolet Behavior of Non-Abelian Gauge Theories.pdf;/Users/t-krishdesai/Zotero/storage/KJ83RHMR/PhysRevLett.30.html}
}
@article{Gross:1973ju,
  title         = {Asymptotically {{Free Gauge Theories}}. {{I}}},
  author        = {Gross, David J. and Wilczek, Frank},
  year          = 1973,
  month         = nov,
  journal       = {Physical Review D},
  publisher     = {American Physical Society},
  volume        = 8,
  number        = 10,
  pages         = {3633--3652},
  doi           = {10.1103/PhysRevD.8.3633},
  urldate       = {2025-07-18},
  abstract      = {Asymptotically free gauge theories of the strong interactions are constructed and analyzed. The reasons for doing this are recounted, including a review of renormalization-group techniques and their application to scaling phenomena. The renormalization-group equations are derived for Yang-Mills theories. The parameters that enter into the equations are calculated to lowest order and it is shown that these theories are asymptotically free. More specifically the effective coupling constant, which determines the ultraviolet behavior of the theory, vanishes for large spacelike momenta. Fermions are incorporated and the construction of realistic models is discussed. We propose that the strong interactions be mediated by a "color" gauge group which commutes with SU(3) {\texttimes} SU(3). The problem of symmetry breaking is discussed. It appears likely that this would have a dynamical origin. It is suggested that the gauge symmetry might not be broken and that the severe infrared singularities prevent the occurrence of noncolor singlet physical states. The deep-inelastic structure functions, as well as the electron-positron total annihilation cross section are analyzed. Scaling obtains up to calculable logarithmic corrections, and the naive light-cone or parton-model results follow. The problems of incorporating scalar mesons and breaking the symmetry by the Higgs mechanism are explained in detail.},
  annotation    = {2916 citations (INSPIRE 2025/7/18)\\ 2876 citations w/o self (INSPIRE 2025/7/18)},
  file          = {/Users/t-krishdesai/Zotero/storage/AVMDFQMT/Gross and Wilczek - 1973 - Asymptotically Free Gauge Theories. I.pdf}
}
@misc{gulrajani_improved_2017,
  title         = {Improved {Training} of {Wasserstein} {GANs}},
  author        = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron},
  year          = 2017,
  month         = dec,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1704.00028},
  url           = {http://arxiv.org/abs/1704.00028},
  urldate       = {2025-07-17},
  note          = {arXiv:1704.00028 [cs]},
  abstract      = {Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning}
}
@article{Haake2019Machine-learning-basedCollisions,
  title         = {Machine-learning-based jet momentum reconstruction in heavy-ion collisions},
  author        = {Haake, R\"{u}diger and Loizides, Constantin},
  year          = 2019,
  month         = 6,
  journal       = {Physical Review C},
  publisher     = {American Physical Society},
  volume        = 99,
  number        = 6,
  pages         = {064904},
  doi           = {10.1103/physrevc.99.064904/figures/10/thumbnail},
  issn          = 24699993,
  url           = {https://journals.aps.org/prc/abstract/10.1103/PhysRevC.99.064904},
  arxivid       = {1810.06324}
}
@article{Handley2019Maximum-EntropyDistribution,
  title         = {Maximum-Entropy Priors with Derived Parameters in a Specified Distribution},
  author        = {Handley, Will and Millea, Marius},
  year          = 2019,
  month         = 3,
  journal       = {Entropy 2019, Vol. 21, Page 272},
  publisher     = {Multidisciplinary Digital Publishing Institute},
  volume        = 21,
  number        = 3,
  pages         = 272,
  doi           = {10.3390/e21030272},
  issn          = {1099-4300},
  url           = {https://www.mdpi.com/1099-4300/21/3/272/htm https://www.mdpi.com/1099-4300/21/3/272},
  arxivid       = {1804.08143},
  keywords      = {Bayesian inference, derived distribution, maximum entropy, neutrino hierarchy, prior}
}
@incollection{hansen_6_2006,
  title         = {6. {Regularization} by {Spectral} {Filtering}},
  author        = {Hansen, Per Christian and Nagy, James G. and O'Leary, Dianne P.},
  year          = 2006,
  month         = jan,
  booktitle     = {Deblurring {Images}},
  publisher     = {Society for Industrial and Applied Mathematics},
  series        = {Fundamentals of {Algorithms}},
  pages         = {71--86},
  doi           = {10.1137/1.9780898718874.ch6},
  isbn          = {978-0-89871-618-4},
  url           = {https://epubs.siam.org/doi/10.1137/1.9780898718874.ch6},
  urldate       = {2025-07-17},
  abstract      = {You've got to go by or past or through boredom, as through a filter, before the clear product emerges.-- F. Scott FitzgeraldThe previous chapter demonstrated that filtering is needed when noise is present. This chapter takes a closer look at filtering, which is also referred to as regularization because it can be interpreted as enforcing certain regularity conditions on the solution. The degree of regularization is governed by a regularization parameter that should be chosen carefully. We focus on two candidate regularization methods (TSVD and Tikhonov) and three candidate ways to compute the regularization parameter (the discrepancy principle, generalized cross validation, and the L-curve criterion).6.1 Two Important MethodsThe SVD analysis in the previous chapter motivates the use of spectral filtering methods because these methods give us control--via the filter factors--over the spectral contents of the deblurred images.}
}
@article{hashemi_deep_2024,
  title         = {Deep {Generative} {Models} for {Detector} {Signature} {Simulation}: {A} {Taxonomic} {Review}},
  shorttitle    = {Deep {Generative} {Models} for {Detector} {Signature} {Simulation}},
  author        = {Hashemi, Baran and Krause, Claudius},
  year          = 2024,
  month         = dec,
  journal       = {Reviews in Physics},
  volume        = 12,
  pages         = 100092,
  doi           = {10.1016/j.revip.2024.100092},
  issn          = 24054283,
  url           = {http://arxiv.org/abs/2312.09597},
  urldate       = {2025-07-16},
  note          = {arXiv:2312.09597 [physics]},
  abstract      = {In modern collider experiments, the quest to explore fundamental interactions between elementary particles has reached unparalleled levels of precision. Signatures from particle physics detectors are low-level objects (such as energy depositions or tracks) encoding the physics of collisions (the final state particles of hard scattering interactions). The complete simulation of them in a detector is a computational and storage-intensive task. To address this computational bottleneck in particle physics, alternative approaches have been developed, introducing additional assumptions and trade off accuracy for speed.The field has seen a surge in interest in surrogate modeling the detector simulation, fueled by the advancements in deep generative models. These models aim to generate responses that are statistically identical to the observed data. In this paper, we conduct a comprehensive and exhaustive taxonomic review of the existing literature on the simulation of detector signatures from both methodological and application-wise perspectives. Initially, we formulate the problem of detector signature simulation and discuss its different variations that can be unified. Next, we classify the state-of-the-art methods into five distinct categories based on their underlying model architectures, summarizing their respective generation strategies. Finally, we shed light on the challenges and opportunities that lie ahead in detector signature simulation, setting the stage for future research and development.},
  keywords      = {Computer Science - Machine Learning, High Energy Physics - Experiment, High Energy Physics - Phenomenology, Physics - Data Analysis, Statistics and Probability, Physics - Instrumentation and Detectors}
}
@misc{he_delving_2015,
  title         = {Delving {Deep} into {Rectifiers}: {Surpassing} {Human}-{Level} {Performance} on {ImageNet} {Classification}},
  shorttitle    = {Delving {Deep} into {Rectifiers}},
  author        = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year          = 2015,
  month         = feb,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1502.01852},
  url           = {http://arxiv.org/abs/1502.01852},
  urldate       = {2025-07-15},
  note          = {arXiv:1502.01852 [cs] version: 1},
  abstract      = {Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on our PReLU networks (PReLU-nets), we achieve 4.94\% top-5 test error on the ImageNet 2012 classification dataset. This is a 26\% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66\%). To our knowledge, our result is the first to surpass human-level performance (5.1\%, Russakovsky et al.) on this visual recognition challenge.},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning}
}
@misc{hendrycks_gaussian_2023,
  title         = {Gaussian {Error} {Linear} {Units} ({GELUs})},
  author        = {Hendrycks, Dan and Gimpel, Kevin},
  year          = 2023,
  month         = jun,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1606.08415},
  url           = {http://arxiv.org/abs/1606.08415},
  urldate       = {2025-07-15},
  note          = {arXiv:1606.08415 [cs]},
  abstract      = {We propose the Gaussian Error Linear Unit (GELU), a high-performing neural network activation function. The GELU activation function is \$x{\textbackslash}Phi(x)\$, where \${\textbackslash}Phi(x)\$ the standard Gaussian cumulative distribution function. The GELU nonlinearity weights inputs by their value, rather than gates inputs by their sign as in ReLUs (\$x{\textbackslash}mathbf\{1\}\_\{x{\textgreater}0\}\$). We perform an empirical evaluation of the GELU nonlinearity against the ReLU and ELU activations and find performance improvements across all considered computer vision, natural language processing, and speech tasks.},
  keywords      = {Computer Science - Machine Learning}
}
@article{hinton_neural_nodate,
  title         = {Neural {Networks} for {Machine} {Learning}},
  author        = {Hinton, Geoffrey},
  language      = {en}
}
@article{hocker_svd_1996,
  title         = {{SVD} approach to data unfolding},
  author        = {H\"{o}cker, Andreas and Kartvelishvili, Vakhtang},
  year          = 1996,
  month         = apr,
  journal       = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  volume        = 372,
  number        = 3,
  pages         = {469--481},
  doi           = {10.1016/0168-9002(95)01478-0},
  issn          = {0168-9002},
  url           = {https://www.sciencedirect.com/science/article/pii/0168900295014780},
  urldate       = {2025-07-13},
  abstract      = {Distributions measured in high energy physics experiments are usually distorted and/or transformed by various detector effects. A regularization method for unfolding these distributions is re-formulated in terms of the Singular Value Decomposition (SVD) of the response matrix. A relatively simple, yet quite efficient unfolding procedure is explained in detail. The concise linear algorithm results in a straightforward implementation with full error propagation, including the complete covariance matrix and its inverse. Several improvements upon widely used procedures are proposed, and recommendations are given how to simplify the task by the proper choice of the matrix. Ways of determining the optimal value of the regularization parameter are suggested and discussed, and several examples illustrating the use of the method are presented.}
}
@article{Hollik2014Quantum978-1-107-03473-0,
  title         = {{Quantum Field Theory and the Standard ModelQuantum Field Theory and the Standard Model , Matthew D. Schwartz, Cambridge U. Press, 2014. {\$}90.00 (850 pp.). ISBN 978-1-107-03473-0 }},
  author        = {Hollik, Wolfgang},
  year          = 2014,
  journal       = {Physics Today},
  volume        = 67,
  number        = 12,
  pages         = {57--58},
  isbn          = 9781107034730,
  issn          = {0031-9228}
}
@article{Holmberg2023JetPipeline,
  title         = {Jet energy calibration with deep learning as a Kubeflow pipeline},
  author        = {Holmberg, Daniel and Golubovic, Dejan and Kirschenmann, Henning},
  year          = 2023,
  month         = 9,
  journal       = {Computing and Software for Big Science},
  publisher     = {Springer Nature},
  volume        = 7,
  number        = 1,
  doi           = {10.1007/s41781-023-00103-y},
  url           = {http://arxiv.org/abs/2308.12724 http://dx.doi.org/10.1007/s41781-023-00103-y},
  arxivid       = {2308.12724v2},
  keywords      = {CMS, GNN, Jet energy, Kubeflow, LHC, MLOps, Open Data}
}
@article{hornik_multilayer_1989,
  title         = {Multilayer feedforward networks are universal approximators},
  author        = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  year          = 1989,
  month         = jan,
  journal       = {Neural Networks},
  volume        = 2,
  number        = 5,
  pages         = {359--366},
  doi           = {10.1016/0893-6080(89)90020-8},
  issn          = {0893-6080},
  url           = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
  urldate       = {2025-07-15},
  abstract      = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.},
  keywords      = {Back-propagation networks, Feedforward networks, Mapping networks, Network representation capability, Sigma-Pi networks, Squashing functions, Stone-Weierstrass Theorem, Universal approximation}
}
@article{Huang2025MachineTechnique,
  title         = {Machine Learning-Assisted Unfolding for Neutrino Cross-section Measurements with the OmniFold Technique},
  author        = {Huang, Roger G. and Cudd, Andrew and Kawaue, Masaki and Kikawa, Tatsuya and Nachman, Benjamin and Mikuni, Vinicius and Wilkinson, Callum},
  year          = 2025,
  month         = 6,
  doi           = {10.1103/sp1f-n9k2},
  url           = {http://arxiv.org/abs/2504.06857 http://dx.doi.org/10.1103/sp1f-n9k2},
  arxivid       = {2504.06857v2},
  keywords      = {hep-ex, hep-ph, physics.data-an}
}
@misc{iwata_meta-learning_2023,
  title         = {Meta-learning to {Calibrate} {Gaussian} {Processes} with {Deep} {Kernels} for {Regression} {Uncertainty} {Estimation}},
  author        = {Iwata, Tomoharu and Kumagai, Atsutoshi},
  year          = 2023,
  month         = dec,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2312.07952},
  url           = {http://arxiv.org/abs/2312.07952},
  urldate       = {2025-07-15},
  note          = {arXiv:2312.07952 [stat]},
  abstract      = {Although Gaussian processes (GPs) with deep kernels have been successfully used for meta-learning in regression tasks, its uncertainty estimation performance can be poor. We propose a meta-learning method for calibrating deep kernel GPs for improving regression uncertainty estimation performance with a limited number of training data. The proposed method meta-learns how to calibrate uncertainty using data from various tasks by minimizing the test expected calibration error, and uses the knowledge for unseen tasks. We design our model such that the adaptation and calibration for each task can be performed without iterative procedures, which enables effective meta-learning. In particular, a task-specific uncalibrated output distribution is modeled by a GP with a task-shared encoder network, and it is transformed to a calibrated one using a cumulative density function of a task-specific Gaussian mixture model (GMM). By integrating the GP and GMM into our neural network-based model, we can meta-learn model parameters in an end-to-end fashion. Our experiments demonstrate that the proposed method improves uncertainty estimation performance while keeping high regression performance compared with the existing methods using real-world datasets in few-shot settings.},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning}
}
@article{james_statistics_2004,
  title         = {Statistics},
  author        = {James, F. and Cousins, R. and Cowan, G.},
  year          = 2004,
  journal       = {Phys. Lett. B},
  volume        = 592,
  pages         = {279--288},
  keywords      = {Beta}
}
@article{jia_sparse_2019,
  title         = {Sparse {Poisson} regression with penalized weighted score function},
  author        = {Jia, Jinzhu and Xie, Fang and Xu, Lihu},
  year          = 2019,
  month         = jan,
  journal       = {Electronic Journal of Statistics},
  volume        = 13,
  number        = 2,
  pages         = {2898--2920},
  doi           = {10.1214/19-ejs1580},
  issn          = {1935-7524, 1935-7524},
  url           = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-13/issue-2/Sparse-Poisson-regression-with-penalized-weighted-score-function/10.1214/19-EJS1580.full},
  urldate       = {2025-07-14},
  note          = {Publisher: Institute of Mathematical Statistics and Bernoulli Society},
  abstract      = {By introducing a weighted score function, we propose a new penalized method, similar to square root lasso, to study sparse Poisson regression problems. The corresponding new estimator not only has \${\textbackslash}ell \_\{1\}\$ consistency but also enjoys the tuning free property. We further verify our theoretical results by numerical simulations and apply them to an image reconstruction problem.},
  keywords      = {\${\textbackslash}ell \_\{1\}\$ consistency, \${\textbackslash}ell \_\{1\}\$ penalization, Image reconstruction, Moderate deviation, Poisson regression, tuning-free}
}
@article{Kaipio2005StatisticalProblems,
  title         = {Statistical and computational inverse problems},
  author        = {Kaipio, Jari P. and Somersalo, Erkki},
  year          = 2005,
  journal       = {Applied Mathematical Sciences (Switzerland)},
  publisher     = {Springer},
  volume        = 160,
  pages         = {i-339},
  doi           = {10.1007/b138659/cover},
  issn          = {2196968x}
}
@article{Kansal2023EvaluatingPhysics,
  title         = {Evaluating generative models in high energy physics},
  author        = {Kansal, Raghav and Li, Anni and Duarte, Javier and Chernyavskaya, Nadezda and Pierini, Maurizio and Orzari, Breno and Tomei, Thiago},
  year          = 2023,
  month         = 4,
  journal       = {Physical Review D},
  publisher     = {American Physical Society},
  volume        = 107,
  number        = 7,
  pages         = {076017},
  doi           = {10.1103/physrevd.107.076017/figures/10/medium},
  issn          = 24700029,
  url           = {https://journals.aps.org/prd/abstract/10.1103/PhysRevD.107.076017},
  keywords      = {doi:10.1103/PhysRevD.107.076017 url:https://doi.org/10.1103/PhysRevD.107.076017}
}
@article{Karl2005RegularizationReconstruction,
  title         = {Regularization in Image Restoration and Reconstruction},
  author        = {Karl, W. Clem},
  year          = 2005,
  month         = 1,
  journal       = {Handbook of Image and Video Processing, Second Edition},
  publisher     = {Elsevier},
  pages         = {183--202},
  doi           = {10.1016/b978-012119792-6/50075-9},
  isbn          = 9780121197926
}
@misc{karras_analyzing_2020,
  title         = {Analyzing and {Improving} the {Image} {Quality} of {StyleGAN}},
  author        = {Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  year          = 2020,
  month         = mar,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1912.04958},
  url           = {http://arxiv.org/abs/1912.04958},
  urldate       = {2025-07-17},
  note          = {arXiv:1912.04958 [cs]},
  abstract      = {The style-based GAN architecture (StyleGAN) yields state-of-the-art results in data-driven unconditional generative image modeling. We expose and analyze several of its characteristic artifacts, and propose changes in both model architecture and training methods to address them. In particular, we redesign the generator normalization, revisit progressive growing, and regularize the generator to encourage good conditioning in the mapping from latent codes to images. In addition to improving image quality, this path length regularizer yields the additional benefit that the generator becomes significantly easier to invert. This makes it possible to reliably attribute a generated image to a particular network. We furthermore visualize how well the generator utilizes its output resolution, and identify a capacity problem, motivating us to train larger models for additional quality improvements. Overall, our improved model redefines the state of the art in unconditional image modeling, both in terms of existing distribution quality metrics as well as perceived image quality.},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Electrical Engineering and Systems Science - Image and Video Processing, Statistics - Machine Learning}
}
@misc{karras_progressive_2018,
  title         = {Progressive {Growing} of {GANs} for {Improved} {Quality}, {Stability}, and {Variation}},
  author        = {Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Jaakko},
  year          = 2018,
  month         = feb,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1710.10196},
  url           = {http://arxiv.org/abs/1710.10196},
  urldate       = {2025-07-17},
  note          = {arXiv:1710.10196 [cs]},
  abstract      = {We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024{\textasciicircum}2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.},
  keywords      = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}
@misc{karras_style-based_2019,
  title         = {A {Style}-{Based} {Generator} {Architecture} for {Generative} {Adversarial} {Networks}},
  author        = {Karras, Tero and Laine, Samuli and Aila, Timo},
  year          = 2019,
  month         = mar,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1812.04948},
  url           = {http://arxiv.org/abs/1812.04948},
  urldate       = {2025-07-17},
  note          = {arXiv:1812.04948 [cs]},
  abstract      = {We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive, scale-specific control of the synthesis. The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture. Finally, we introduce a new, highly varied and high-quality dataset of human faces.},
  keywords      = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}
@article{ke_recent_2023,
  title         = {Recent {Developments} on the {Statistical} {Treatment} of {Flavour} {Tagging} {Uncertainties} in {ATLAS}},
  author        = {Ke, Yan and Luise, Ilaria and Buat, Quentin and Piacquadio, Giacinto},
  year          = 2023,
  journal       = {PoS},
  volume        = {Lhcp2022},
  pages         = 322,
  doi           = {10.22323/1.422.0322},
  keywords      = {ATLAS, BETA, bottom: particle identification, flavor, jet: bottom, jet: transverse momentum, p p: colliding beams, p p: scattering, particle identification: performance, solids, statistical analysis}
}
@article{khattak_fast_2022,
  title         = {Fast simulation of a high granularity calorimeter by generative adversarial networks},
  author        = {Khattak, Gul Rukh and Vallecorsa, Sofia and Carminati, Federico and Khan, Gul Muhammad},
  year          = 2022,
  month         = apr,
  journal       = {The European Physical Journal C},
  volume        = 82,
  number        = 4,
  pages         = 386,
  doi           = {10.1140/epjc/s10052-022-10258-4},
  issn          = {1434-6052},
  url           = {https://doi.org/10.1140/epjc/s10052-022-10258-4},
  urldate       = {2025-07-17},
  abstract      = {We present the 3DGAN for the simulation of a future high granularity calorimeter output as three-dimensional images. We prove the efficacy of Generative Adversarial Networks (GANs) for generating scientific data while retaining a high level of accuracy for diverse metrics across a large range of input variables. We demonstrate a successful application of the transfer learning concept: we train the network to simulate showers for electrons from a reduced range of primary energies, we then train further for a five times larger range (the model could not train for the larger range directly). The same concept is extended to generate showers for other particles depositing most of their energies in electromagnetic interactions (photons and neutral pions). In addition, the generation of charged pion showers is also explored, a more accurate effort would require additional data from other detectors not included in the scope of the current work. Our further contribution is a demonstration of using GAN-generated data for a practical application. We train a third-party network using GAN-generated data and prove that the response is similar to a network trained with data from the Monte Carlo simulation. The showers generated by GAN present accuracy within \{\textbackslash}\%\$\$of Monte Carlo for a diverse range of physics features, with three orders of magnitude speedup. The speedup for both the training and inference can be further enhanced by distributed training.},
  language      = {en},
  keywords      = {Accelerator Physics, Artificial Intelligence, Experimental Particle Physics, High-Energy Astrophysics, Machine Learning, Particle Physics}
}
@article{Kheddar2025ImageSurvey,
  title         = {Image and Point-cloud Classification for Jet Analysis in High-Energy Physics: A survey},
  author        = {Kheddar, Hamza and Himeur, Yassine and Amira, Abbes and Soualah, Rachik},
  year          = 2025,
  month         = 2,
  journal       = {Frontiers of Physics},
  publisher     = {Higher Education Press Limited Company},
  volume        = 20,
  number        = 3,
  doi           = {10.15302/frontphys.2025.035301},
  url           = {http://arxiv.org/abs/2403.11934 http://dx.doi.org/10.15302/frontphys.2025.035301},
  arxivid       = {2403.11934v3},
  keywords      = {Deep learning, High energy physics, Image classification, Jet images, Jet point cloud, Machine learning}
}
@misc{kingma_adam_2017,
  title         = {Adam: {A} {Method} for {Stochastic} {Optimization}},
  shorttitle    = {Adam},
  author        = {Kingma, Diederik P. and Ba, Jimmy},
  year          = 2017,
  month         = jan,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1412.6980},
  url           = {http://arxiv.org/abs/1412.6980},
  urldate       = {2025-07-15},
  note          = {arXiv:1412.6980 [cs]},
  abstract      = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  keywords      = {Computer Science - Machine Learning}
}
@misc{kingma_improving_2017,
  title         = {Improving {Variational} {Inference} with {Inverse} {Autoregressive} {Flow}},
  author        = {Kingma, Diederik P. and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
  year          = 2017,
  month         = jan,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1606.04934},
  url           = {http://arxiv.org/abs/1606.04934},
  urldate       = {2025-07-16},
  note          = {arXiv:1606.04934 [cs]},
  abstract      = {The framework of normalizing flows provides a general strategy for flexible variational inference of posteriors over latent variables. We propose a new type of normalizing flow, inverse autoregressive flow (IAF), that, in contrast to earlier published flows, scales well to high-dimensional latent spaces. The proposed flow consists of a chain of invertible transformations, where each transformation is based on an autoregressive neural network. In experiments, we show that IAF significantly improves upon diagonal Gaussian approximate posteriors. In addition, we demonstrate that a novel type of variational autoencoder, coupled with IAF, is competitive with neural autoregressive models in terms of attained log-likelihood on natural images, while allowing significantly faster synthesis.},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning}
}
@article{Kingma2013Auto-EncodingBayes,
  title         = {Auto-Encoding Variational Bayes},
  author        = {Kingma, Diederik P. and Welling, Max},
  year          = 2013,
  month         = 12,
  journal       = {2nd International Conference on Learning Representations, ICLR 2014 - Conference Track Proceedings},
  publisher     = {International Conference on Learning Representations, ICLR},
  doi           = {10.61603/ceas.v2i1.33},
  url           = {https://arxiv.org/pdf/1312.6114},
  arxivid       = {1312.6114}
}
@article{Kingma2019AnAutoencoders,
  title         = {An Introduction to Variational Autoencoders},
  author        = {Kingma, Diederik P. and Welling, Max},
  year          = 2019,
  month         = 6,
  journal       = {Foundations and Trends in Machine Learning},
  publisher     = {Now Publishers Inc},
  volume        = 12,
  number        = 4,
  pages         = {307--392},
  doi           = {10.1561/2200000056},
  issn          = 19358245,
  url           = {https://arxiv.org/pdf/1906.02691},
  arxivid       = {1906.02691}
}
@article{Knapik2012BayesianPriors,
  title         = {Bayesian inverse problems with Gaussian priors},
  author        = {Knapik, B. T. and van der Vaart, A. W. and van Zanten, J. H.},
  year          = 2012,
  month         = 2,
  journal       = {Annals of Statistics},
  volume        = 39,
  number        = 5,
  pages         = {2626--2657},
  doi           = {10.1214/11-aos920},
  url           = {http://arxiv.org/abs/1103.2692 http://dx.doi.org/10.1214/11-AOS920},
  arxivid       = {1103.2692v2},
  keywords      = {Credible set, Gaussian prior, Posterior distribution, Rate of contraction, posterior distribution, rate of contraction}
}
@article{Knapp2021AdversariallyQuark,
  title         = {Adversarially Learned Anomaly Detection on CMS Open Data: re-discovering the top quark},
  author        = {Knapp, O. and Cerri, O. and Dissertori, G. and Nguyen, T. Q. and Pierini, M. and Vlimant, J. R.},
  year          = 2021,
  month         = 2,
  journal       = {Eur.Phys.J.Plus},
  publisher     = {Springer Science and Business Media Deutschland GmbH},
  volume        = 136,
  number        = 2,
  pages         = 236,
  doi           = {10.1140/epjp/s13360-021-01109-4},
  issn          = 21905444,
  arxivid       = {2005.01598}
}
@article{Kobyzev2019NormalizingMethods,
  title         = {Normalizing Flows: An Introduction and Review of Current Methods},
  author        = {Kobyzev, Ivan and Prince, Simon J.D. and Brubaker, Marcus A.},
  year          = 2019,
  month         = 8,
  journal       = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  publisher     = {IEEE Computer Society},
  volume        = 43,
  number        = 11,
  pages         = {3964--3979},
  doi           = {10.1109/tpami.2020.2992934},
  issn          = 19393539,
  url           = {https://arxiv.org/pdf/1908.09257},
  pmid          = 32396070,
  arxivid       = {1908.09257},
  keywords      = {Generative models, density estimation, invertible neural networks, normalizing flows, variational inference}
}
@article{kogler_jet_2019,
  title         = {Jet substructure at the {Large} {Hadron} {Collider}},
  author        = {Kogler, Roman and Nachman, Benjamin and Schmidt, Alexander and Asquith, Lily and Winkels, Emma and Campanelli, Mario and Delitzsch, Chris and Harris, Philip and Hinzmann, Andreas and Kar, Deepak and McLean, Christine and Pilot, Justin and Takahashi, Yuta and Tran, Nhan and Vernieri, Caterina and Vos, Marcel},
  year          = 2019,
  month         = dec,
  journal       = {Reviews of Modern Physics},
  volume        = 91,
  number        = 4,
  pages         = {045003},
  doi           = {10.1103/RevModPhys.91.045003},
  url           = {https://link.aps.org/doi/10.1103/RevModPhys.91.045003},
  urldate       = {2025-07-13},
  note          = {Publisher: American Physical Society},
  abstract      = {Jet substructure has emerged to play a central role at the Large Hadron Collider, where it has provided numerous innovative ways to search for new physics and to probe the standard model, particularly in extreme regions of phase space. This review focuses on the development and use of state-of-the-art jet substructure techniques by the ATLAS and CMS experiments.}
}
@article{komiske_preserving_2021,
  title         = {Preserving new physics while simultaneously unfolding all observables},
  author        = {Komiske, Patrick and McCormack, W. Patrick and Nachman, Benjamin},
  year          = 2021,
  journal       = {Phys. Rev. D},
  volume        = 104,
  number        = 7,
  pages         = {076027},
  doi           = {10.1103/PhysRevD.104.076027},
  note          = {\_eprint: 2105.09923},
  keywords      = {BETA, CERN LHC Coll, Higgs particle: decay, benchmark, data analysis method, exotic, final state: hadronic, new particle, new physics, phase space}
}
@article{Komiske2018DeepDiscrimination,
  title         = {Deep learning in color: towards automated quark/gluon jet discrimination},
  author        = {Komiske, Patrick T. and Metodiev, Eric M. and Schwartz, Matthew D.},
  year          = 2018,
  month         = 9,
  journal       = {Journal of High Energy Physics},
  publisher     = {Springer Verlag},
  volume        = 2017,
  number        = 1,
  doi           = {10.1007/jhep01(2017)110},
  url           = {http://arxiv.org/abs/1612.01551 http://dx.doi.org/10.1007/JHEP01(2017)110},
  arxivid       = {1612.01551v3},
  keywords      = {Jets}
}
@article{Komiske2018EnergySubstructure,
  title         = {Energy flow polynomials: A complete linear basis for jet substructure},
  author        = {Komiske, Patrick T. and Metodiev, Eric M. and Thaler, Jesse},
  year          = 2018,
  month         = 4,
  journal       = {Journal of High Energy Physics},
  publisher     = {Springer Verlag},
  volume        = 2018,
  number        = 4,
  doi           = {10.1007/jhep04(2018)013},
  url           = {http://arxiv.org/abs/1712.07124 http://dx.doi.org/10.1007/JHEP04(2018)013},
  arxivid       = {1712.07124v2},
  keywords      = {Jets, QCD Phenomenology}
}
@article{Komiske2018PileupPUMML,
  title         = {Pileup Mitigation with Machine Learning (PUMML)},
  author        = {Komiske, Patrick T. and Metodiev, Eric M. and Nachman, Benjamin and Schwartz, Matthew D.},
  year          = 2018,
  month         = 1,
  journal       = {Journal of High Energy Physics},
  publisher     = {Springer Verlag},
  volume        = 2017,
  number        = 12,
  doi           = {10.1007/jhep12(2017)051},
  url           = {http://arxiv.org/abs/1707.08600 http://dx.doi.org/10.1007/JHEP12(2017)051},
  arxivid       = {1707.08600v3},
  keywords      = {Jets}
}
@article{Komiske2019EnergyJets,
  title         = {Energy Flow Networks: Deep Sets for Particle Jets},
  author        = {Komiske, Patrick T. and Metodiev, Eric M. and Thaler, Jesse},
  year          = 2019,
  month         = 1,
  journal       = {Journal of High Energy Physics},
  publisher     = {Springer Verlag},
  volume        = 2019,
  number        = 1,
  doi           = {10.1007/jhep01(2019)121},
  url           = {http://arxiv.org/abs/1810.05165 http://dx.doi.org/10.1007/JHEP01(2019)121},
  arxivid       = {1810.05165v2},
  keywords      = {Jets, QCD Phenomenology}
}
@article{Kotlorz:2006dj,
  title         = {Evolution Equations for Truncated Moments of the Parton Distributions},
  author        = {Kotlorz, D. and Kotlorz, A.},
  year          = 2007,
  journal       = {Physics Letters B},
  volume        = 644,
  number        = 4,
  pages         = {284--287},
  doi           = {10.1016/j.physletb.2006.11.054},
  issn          = {03702693},
  urldate       = {2025-07-18},
  eprint        = {hep-ph/0610282},
  abstract      = {We derive evolution equations for the truncated Mellin moments of the parton distributions. We find that the equations have the same form as those for the partons themselves. The modified splitting function for n-th moment \$P'(n,x)\$ is \$x{\textasciicircum}\{n\}P(x)\$, where \$P(x)\$ is the well-known splitting function from the DGLAP equation. The obtained equations are exact for each n-th moment and for every truncation point \$x\_0{\textbackslash}in (0:1)\$. They can be solved with use of standard methods of solving the DGLAP equations. This approach allows us to avoid the problem of dealing with the unphysical region \$x{\textbackslash}to 0\$. Furthermore, it refers directly to the physical values - moments (rather than to the parton distributions), what enables one to use a wide range of deep-inelastic scattering data in terms of smaller number of parameters. We give an example of an application.},
  archiveprefix = {arXiv},
  keywords      = {High Energy Physics - Phenomenology},
  annotation    = {26 citations (INSPIRE 2025/7/18)\\ 13 citations w/o self (INSPIRE 2025/7/18)\\ Citations: 18 (Crossref) [2025-07-18]\\ Citations: 18 (SemanticScholar) [2025-07-18]},
  file          = {/Users/t-krishdesai/Zotero/storage/TW4DE88J/Kotlorz and Kotlorz - 2007 - Evolution equations for truncated moments of the parton distributions.pdf;/Users/t-krishdesai/Zotero/storage/B8QUWAHH/0610282.html}
}
@article{Kotlorz:2014fia,
  title         = {Cut Moments and a Generalization of {{DGLAP}} Equations},
  author        = {Kotlorz, D. and Mikhailov, S. V.},
  year          = 2014,
  journal       = {Journal of High Energy Physics},
  volume        = {06},
  number        = 6,
  pages         = {065},
  doi           = {10.1007/jhep06(2014)065},
  issn          = {1029-8479},
  urldate       = {2025-07-18},
  eprint        = {1404.5172},
  primaryclass  = {hep-th},
  abstract      = {We elaborate a cut (truncated) Mellin moments (CMM) approach that is constructed to study deep inelastic scattering in lepton-hadron collisions at the natural kinematic constraints. We show that generalized CMM obtained by multiple integrations of the original parton distribution \$f(x,{\textbackslash}mu{\textasciicircum}2)\$ as well as ones obtained by multiple differentiations of this \$f(x,{\textbackslash}mu{\textasciicircum}2)\$ also satisfy the DGLAP equations with the correspondingly transformed evolution kernel \$P(z)\$. Appropriate classes of CMM for the available experimental kinematic range are suggested and analyzed. Similar relations can be obtained for the structure functions \$F(x)\$, being the Mellin convolution \$F= C {\textbackslash}ast f\$, where \$C\$ is the coefficient function of the process.},
  archiveprefix = {arXiv},
  keywords      = {High Energy Physics - Phenomenology,High Energy Physics - Theory},
  annotation    = {9 citations (INSPIRE 2025/7/18)\\ 1 citations w/o self (INSPIRE 2025/7/18)},
  file          = {/Users/t-krishdesai/Zotero/storage/BLWPLVPM/Kotlorz and Mikhailov - 2014 - Cut moments and a generalization of DGLAP equations.pdf;/Users/t-krishdesai/Zotero/storage/XU7I6AIC/1404.html}
}
@article{krause_fast_2023,
  title         = {Fast and accurate simulations of calorimeter showers with normalizing flows},
  author        = {Krause, Claudius and Shih, David},
  year          = 2023,
  journal       = {Phys. Rev. D},
  volume        = 107,
  number        = 11,
  pages         = 113003,
  doi           = {10.1103/PhysRevD.107.113003},
  note          = {\_eprint: 2106.05285},
  keywords      = {BETA, GEANT, benchmark, calorimeter, flow, neural network, numerical calculations, numerical methods, performance, programming, showers}
}
@misc{kuleshov_calibrated_2025,
  title         = {Calibrated and {Sharp} {Uncertainties} in {Deep} {Learning} via {Density} {Estimation}},
  author        = {Kuleshov, Volodymyr and Deshpande, Shachi},
  year          = 2025,
  month         = may,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2112.07184},
  url           = {http://arxiv.org/abs/2112.07184},
  urldate       = {2025-07-15},
  note          = {arXiv:2112.07184 [cs] version: 3},
  abstract      = {Accurate probabilistic predictions can be characterized by two properties -- calibration and sharpness. However, standard maximum likelihood training yields models that are poorly calibrated and thus inaccurate -- a 90\% confidence interval typically does not contain the true outcome 90\% of the time. This paper argues that calibration is important in practice and is easy to maintain by performing low-dimensional density estimation. We introduce a simple training procedure based on recalibration that yields calibrated models without sacrificing overall performance; unlike previous approaches, ours ensures the most general property of distribution calibration and applies to any model, including neural networks. We formally prove the correctness of our procedure assuming that we can estimate densities in low dimensions and we establish uniform convergence bounds. Our results yield empirical performance improvements on linear and deep Bayesian models and suggest that calibration should be increasingly leveraged across machine learning. We release a library that implements our methods along with a blog post here: https://shachideshpande.github.io/blog-distribution-calibration/.},
  keywords      = {Computer Science - Machine Learning}
}
@article{kullback_information_1951,
  title         = {On {Information} and {Sufficiency}},
  author        = {Kullback, S. and Leibler, R. A.},
  year          = 1951,
  month         = mar,
  journal       = {The Annals of Mathematical Statistics},
  volume        = 22,
  number        = 1,
  pages         = {79--86},
  doi           = {10.1214/aoms/1177729694},
  issn          = {0003-4851, 2168-8990},
  url           = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-22/issue-1/On-Information-and-Sufficiency/10.1214/aoms/1177729694.full},
  urldate       = {2025-07-14},
  note          = {Publisher: Institute of Mathematical Statistics},
  abstract      = {The Annals of Mathematical Statistics}
}
@article{kuusela_shape-constrained_2017,
  title         = {Shape-constrained uncertainty quantification in unfolding steeply falling elementary particle spectra},
  author        = {Kuusela, Mikael and Stark, Philip B.},
  year          = 2017,
  month         = sep,
  journal       = {The Annals of Applied Statistics},
  volume        = 11,
  number        = 3,
  pages         = {1671--1710},
  doi           = {10.1214/17-aoas1053},
  issn          = {1932-6157, 1941-7330},
  url           = {https://projecteuclid.org/journals/annals-of-applied-statistics/volume-11/issue-3/Shape-constrained-uncertainty-quantification-in-unfolding-steeply-falling-elementary-particle/10.1214/17-AOAS1053.full},
  urldate       = {2025-07-13},
  note          = {Publisher: Institute of Mathematical Statistics},
  abstract      = {The high energy physics unfolding problem is an important statistical inverse problem in data analysis at the Large Hadron Collider (LHC) at CERN. The goal of unfolding is to make nonparametric inferences about a particle spectrum from measurements smeared by the finite resolution of the particle detectors. Previous unfolding methods use ad hoc discretization and regularization, resulting in confidence intervals that can have significantly lower coverage than their nominal level. Instead of regularizing using a roughness penalty or stopping iterative methods early, we impose physically motivated shape constraints: positivity, monotonicity, and convexity. We quantify the uncertainty by constructing a nonparametric confidence set for the true spectrum, consisting of all those spectra that satisfy the shape constraints and that predict the observations within an appropriately calibrated level of fit. Projecting that set produces simultaneous confidence intervals for all functionals of the spectrum, including averages within bins. The confidence intervals have guaranteed conservative frequentist finite-sample coverage in the important and challenging class of unfolding problems for steeply falling particle spectra. We demonstrate the method using simulations that mimic unfolding the inclusive jet transverse momentum spectrum at the LHC. The shape-constrained intervals provide usefully tight conservative inferences, while the conventional methods suffer from severe undercoverage.},
  keywords      = {Fenchel duality, Large Hadron Collider, Poisson inverse problem, finite-sample coverage, high energy physics, semi-infinite programming}
}
@phdthesis{kuusela_uncertainty_2016,
  title         = {Uncertainty quantification in unfolding elementary particle spectra at the {Large} {Hadron} {Collider}},
  author        = {Kuusela, Mikael Johan},
  year          = 2016,
  doi           = {10.5075/epfl-thesis-7118},
  type          = {{PhD} {Thesis}},
  school        = {Ecole Polytechnique, Lausanne},
  keywords      = {BETA, Poisson inverse problem, bias-variance trade-off, deconvolution, empirical Bayes, finite-sample coverage, high energy physics, iterative bias-correction, shape-constrained inference, strict bounds confidence intervals, undersmoothing}
}
@misc{L.N.VasersteinIssue3Pagesnobr6472/nobr,
  title         = {L.~N.~Vaserstein, ``Markov Processes over Denumerable Products of Spaces, Describing Large Systems of Automata'', Probl. Peredachi Inf., 1969, Volume~5, Issue~3,Pages~<nobr>64–72</nobr>},
  url           = {https://m.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=ppi&paperid=1811&option_lang=eng}
}
@article{Larkoski2014SoftDrop,
  title         = {Soft drop},
  author        = {Larkoski, Andrew J. and Marzani, Simone and Soyez, Gregory and Thaler, Jesse},
  year          = 2014,
  month         = 5,
  journal       = {Journal of High Energy Physics 2014 2014:5},
  publisher     = {Springer},
  volume        = 2014,
  number        = 5,
  pages         = {1--46},
  doi           = {10.1007/jhep05(2014)146},
  issn          = {1029-8479},
  url           = {https://link.springer.com/article/10.1007/JHEP05(2014)146},
  arxivid       = {1402.2657},
  keywords      = {Classical and Quantum Gravitation, Elementary Particles, Quantum Field Theories, Quantum Field Theory, Quantum Physics, Relativity Theory, String Theory}
}
@article{Larkoski2020JetLearning,
  title         = {Jet substructure at the Large Hadron Collider: A review of recent advances in theory and machine learning},
  author        = {Larkoski, Andrew J. and Moult, Ian and Nachman, Benjamin},
  year          = 2020,
  month         = 1,
  journal       = {Physics Reports},
  publisher     = {North-Holland},
  volume        = 841,
  pages         = {1--63},
  doi           = {10.1016/j.physrep.2019.11.001},
  issn          = {0370-1573},
  arxivid       = {1709.04464}
}
@misc{lee_explicit_2023,
  title         = {On {Explicit} {Curvature} {Regularization} in {Deep} {Generative} {Models}},
  author        = {Lee, Yonghyeon and Park, Frank Chongwoo},
  year          = 2023,
  month         = sep,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2309.10237},
  url           = {http://arxiv.org/abs/2309.10237},
  urldate       = {2025-07-14},
  note          = {arXiv:2309.10237 [cs]},
  abstract      = {We propose a family of curvature-based regularization terms for deep generative model learning. Explicit coordinate-invariant formulas for both intrinsic and extrinsic curvature measures are derived for the case of arbitrary data manifolds embedded in higher-dimensional Euclidean space. Because computing the curvature is a highly computation-intensive process involving the evaluation of second-order derivatives, efficient formulas are derived for approximately evaluating intrinsic and extrinsic curvatures. Comparative studies are conducted that compare the relative efficacy of intrinsic versus extrinsic curvature-based regularization measures, as well as performance comparisons against existing autoencoder training methods. Experiments involving noisy motion capture data confirm that curvature-based methods outperform existing autoencoder regularization methods, with intrinsic curvature measures slightly more effective than extrinsic curvature measures.},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning}
}
@article{Lee2019Quark-GluonNetworks,
  title         = {Quark-Gluon Jet Discrimination Using Convolutional Neural Networks},
  author        = {Lee, Jason Sang Hun and Park, Inkyu and Watson, Ian James and Yang, Seungjin},
  year          = 2019,
  month         = 2,
  journal       = {Journal of the Korean Physical Society},
  publisher     = {The Korean Physical Society},
  volume        = 74,
  number        = 3,
  pages         = {219--223},
  doi           = {10.3938/jkps.74.219/metrics},
  issn          = 19768524,
  url           = {https://link.springer.com/article/10.3938/jkps.74.219},
  arxivid       = {2012.02531},
  keywords      = {Fragmentation, Jet, Jet tagging, Machine learning, QCD}
}
@book{leo_techniques_1994,
  title         = {Techniques for {Nuclear} and {Particle} {Physics} {Experiments}: {A} {How}-to {Approach}},
  shorttitle    = {Techniques for {Nuclear} and {Particle} {Physics} {Experiments}},
  author        = {Leo, William R.},
  year          = 1994,
  publisher     = {Springer},
  address       = {Berlin, Heidelberg},
  doi           = {10.1007/978-3-642-57920-2},
  isbn          = {978-3-540-57280-0 978-3-642-57920-2},
  url           = {https://link.springer.com/10.1007/978-3-642-57920-2},
  urldate       = {2025-07-13},
  copyright     = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  language      = {en},
  keywords      = {Alpha decay, Beta decay, Cherenkov radiation, Cross section, Diffusion, Equivalent dose, Gamma ray, Neutron, Particle Physics, distribution, electron capture, nuclear physics, physics, semiconductor, spectroscopy}
}
@article{LHCHiggsCrossSectionWorkingGroup2012HandbookDistributions,
  title         = {Handbook of LHC Higgs Cross Sections: 2. Differential Distributions},
  author        = {{LHC Higgs Cross Section Working Group} and Dittmaier, S. and Mariotti, C. and Passarino, G. and Tanaka, R. and Alekhin, S. and Alwall, J. and Bagnaschi, E. A. and Banfi, A. and Blumlein, J. and Bolognesi, S. and Chanon, N. and Cheng, T. and Cieri, L. and Cooper-Sarkar, A. M. and Cutajar, M. and Dawson, S. and Davies, G. and De Filippis, N. and Degrassi, G. and Denner, A. and D'Enterria, D. and Diglio, S. and Di Micco, B. and Di Nardo, R. and Ellis, R. K. and Farilla, A. and Farrington, S. and Felcini, M. and Ferrera, G. and Flechl, M. and de Florian, D. and Forte, S. and Ganjour, S. and Garzelli, M. V. and Gascon-Shotkin, S. and Glazov, S. and Goria, S. and Grazzini, M. and Guillet, J. -Ph. and Hackstein, C. and Hamilton, K. and Harlander, R. and Hauru, M. and Heinemeyer, S. and Hoche, S. and Huston, J. and Jackson, C. and Jimenez-Delgado, P. and Jorgensen, M. D. and Kado, M. and Kallweit, S. and Kardos, A. and Kauer, N. and Kim, H. and Kovac, M. and Kramer, M. and Krauss, F. and Kuo, C. -M. and Lehti, S. and Li, Q. and Lorenzo, N. and Maltoni, F. and Mellado, B. and Moch, S. O. and Muck, A. and Muhlleitner, M. and Nadolsky, P. and Nason, P. and Neu, C. and Nikitenko, A. and Oleari, C. and Olsen, J. and Palmer, S. and Paganis, S. and Papadopoulos, C. G. and Petersen, T . C. and Petriello, F. and Petrucci, F. and Piacquadio, G. and Pilon, E. and Potter, C. T. and Price, J. and Puljak, I. and Quayle, W. and Radescu, V. and Rebuzzi, D. and Reina, L. and Rojo, J. and Rosco, D. and Salam, G. P. and Sapronov, A. and Schaarschmidt, J. and Schonherr, M. and Schumacher, M. and Siegert, F. and Slavich, P. and Spira, M. and Stewart, I. W. and Stirling, W. J. and Stockli, F. and Sturm, C. and Tackmann, F. J. and Thorne, R. S. and Tommasini, D. and Torrielli, P. and Tramontano, F. and Trocsanyi, Z. and Ubiali, M. and Uccirati, S. and Acosta, M. Vazquez and Vickey, T. and Vicini, A. and Waalewijn, W. J. and Wackeroth, D. and Warsinsky, M. and Weber, M. and Wiesemann, M. and Weiglein, G. and Yu, J. and Zanderighi, G.},
  year          = 2012,
  month         = 1,
  doi           = {10.5170/cern-2012-002},
  url           = {http://arxiv.org/abs/1201.3084 http://dx.doi.org/10.5170/CERN-2012-002},
  arxivid       = {1201.3084}
}
@article{lin_divergence_1991,
  title         = {Divergence measures based on the {Shannon} entropy},
  author        = {Lin, J.},
  year          = 1991,
  month         = jan,
  journal       = {IEEE Transactions on Information Theory},
  volume        = 37,
  number        = 1,
  pages         = {145--151},
  doi           = {10.1109/18.61115},
  issn          = {1557-9654},
  url           = {https://ieeexplore.ieee.org/document/61115},
  urldate       = {2025-07-17},
  abstract      = {A novel class of information-theoretic divergence measures based on the Shannon entropy is introduced. Unlike the well-known Kullback divergences, the new measures do not require the condition of absolute continuity to be satisfied by the probability distributions involved. More importantly, their close relationship with the variational distance and the probability of misclassification error are established in terms of bounds. These bounds are crucial in many applications of divergence measures. The measures are also well characterized by the properties of nonnegativity, finiteness, semiboundedness, and boundedness.{\textless}{\textgreater}},
  keywords      = {Computer science, Entropy, Genetics, Pattern analysis, Pattern recognition, Probability distribution, Signal analysis, Signal processing, Taxonomy, Upper bound}
}
@misc{liu_fast_2023,
  title         = {Fast {Particle}-based {Anomaly} {Detection} {Algorithm} with {Variational} {Autoencoder}},
  author        = {Liu, Ryan and Gandrakota, Abhijith and Ngadiuba, Jennifer and Spiropulu, Maria and Vlimant, Jean-Roch},
  year          = 2023,
  month         = nov,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2311.17162},
  url           = {http://arxiv.org/abs/2311.17162},
  urldate       = {2025-07-16},
  note          = {arXiv:2311.17162 [hep-ex]},
  abstract      = {Model-agnostic anomaly detection is one of the promising approaches in the search for new beyond the standard model physics. In this paper, we present Set-VAE, a particle-based variational autoencoder (VAE) anomaly detection algorithm. We demonstrate a 2x signal efficiency gain compared with traditional subjettiness-based jet selection. Furthermore, with an eye to the future deployment to trigger systems, we propose the CLIP-VAE, which reduces the inference-time cost of anomaly detection by using the KL-divergence loss as the anomaly score, resulting in a 2x acceleration in latency and reducing the caching requirement.},
  keywords      = {Computer Science - Machine Learning, High Energy Physics - Experiment}
}
@misc{lu_expressive_2017,
  title         = {The {Expressive} {Power} of {Neural} {Networks}: {A} {View} from the {Width}},
  shorttitle    = {The {Expressive} {Power} of {Neural} {Networks}},
  author        = {Lu, Zhou and Pu, Hongming and Wang, Feicheng and Hu, Zhiqiang and Wang, Liwei},
  year          = 2017,
  month         = nov,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1709.02540},
  url           = {http://arxiv.org/abs/1709.02540},
  urldate       = {2025-07-15},
  note          = {arXiv:1709.02540 [cs]},
  abstract      = {The expressive power of neural networks is important for understanding deep learning. Most existing works consider this problem from the view of the depth of a network. In this paper, we study how width affects the expressiveness of neural networks. Classical results state that depth-bounded (e.g. depth-\$2\$) networks with suitable activation functions are universal approximators. We show a universal approximation theorem for width-bounded ReLU networks: width-\$(n+4)\$ ReLU networks, where \$n\$ is the input dimension, are universal approximators. Moreover, except for a measure zero set, all functions cannot be approximated by width-\$n\$ ReLU networks, which exhibits a phase transition. Several recent works demonstrate the benefits of depth by proving the depth-efficiency of neural networks. That is, there are classes of deep networks which cannot be realized by any shallow network whose size is no more than an exponential bound. Here we pose the dual question on the width-efficiency of ReLU networks: Are there wide networks that cannot be realized by narrow networks whose size is not substantially larger? We show that there exist classes of wide networks which cannot be realized by any narrow network whose depth is no more than a polynomial bound. On the other hand, we demonstrate by extensive experiments that narrow networks whose size exceed the polynomial bound by a constant factor can approximate wide and shallow network with high accuracy. Our results provide more comprehensive evidence that depth is more effective than width for the expressiveness of ReLU networks.},
  keywords      = {Computer Science - Machine Learning}
}
@article{lucy_iterative_1974,
  title         = {An iterative technique for the rectification of observed distributions},
  author        = {Lucy, L. B.},
  year          = 1974,
  month         = jun,
  journal       = {The Astronomical Journal},
  volume        = 79,
  pages         = 745,
  doi           = {10.1086/111605},
  issn          = {0004-6256},
  url           = {https://ui.adsabs.harvard.edu/abs/1974AJ.....79..745L/abstract},
  urldate       = {2025-07-13},
  abstract      = {An iterative technique is described for generating estimates to the solutions of rectification and deconvolution problems in statistical astronomy. The technique, which derives from Bayes' theorem on conditional probabili- ties, conserves the constraints on frequency distributions (i.e., normalization and non-negativeness) and, at each iteration, increases the likelihood of the observed sample. The behavior of the technique is explored by applying it to roblems whose solutions are known in the limit of infinite sample size, and excellent results are obtained after a few iterations. The astronomical use of the technique is illustrated by applying it to the problem of rectifying distributions of v sin i for aspect effect; calculations are also reported illustrating the technique's possible use for correcting radio-astronomical observations for beam-smoothing. Application to the problem of obtaining unbiased, smoothed histograms is also suggested.},
  language      = {en}
}
@article{Maas2013RectifierModels,
  title         = {Rectifier Nonlinearities Improve Neural Network Acoustic Models},
  author        = {Maas, Andrew L and Hannun, Awni Y and Ng, Andrew Y},
  year          = 2013
}
@article{maeda_new_2013,
  title         = {A new unfolding code combining maximum entropy and maximum likelihood for neutron spectrum measurement},
  author        = {Maeda, Shigetaka and Iguchi, Tetsuo},
  year          = 2013,
  month         = apr,
  journal       = {Journal of Nuclear Science and Technology},
  volume        = 50,
  number        = 4,
  pages         = {381--386},
  doi           = {10.1080/00223131.2013.773162},
  issn          = {0022-3131},
  url           = {https://doi.org/10.1080/00223131.2013.773162},
  urldate       = {2025-07-13},
  note          = {Publisher: Taylor \& Francis \_eprint: https://doi.org/10.1080/00223131.2013.773162},
  abstract      = {We present a new spectrum unfolding code, the Maximum Entropy and Maximum Likelihood Unfolding Code (MEALU), based on the maximum likelihood method combined with the maximum entropy method, which can determine a neutron spectrum without requiring an initial guess spectrum. The Normal or Poisson distributions can be used for the statistical distribution. MEALU can treat full covariance data for a measured detector response and response function. The algorithm was verified through an analysis of mock-up data and its performance was checked by applying it to measured data. The results for measured data from the Joyo experimental fast reactor were also compared with those obtained by the conventional J-log method for neutron spectrum adjustment. It was found that MEALU has potential advantages over conventional methods with regard to preparation of a priori information and uncertainty estimation.},
  keywords      = {maximum entropy method, maximum likelihood method, multi foil activation method, neutron spectrum unfolding, underdetermined problem}
}
@article{maevskiy_generative_2023,
  title         = {Generative {Adversarial} {Networks} for the fast simulation of the {Time} {Projection} {Chamber} responses at the {MPD} detector},
  author        = {Maevskiy, A. and Ratnikov, F. and Zinchenko, A. and Riabov, V. and Sukhorosov, A. and Evdokimov, D.},
  year          = 2023,
  month         = feb,
  journal       = {Journal of Physics: Conference Series},
  volume        = 2438,
  number        = 1,
  pages         = {012087},
  doi           = {10.1088/1742-6596/2438/1/012087},
  issn          = {1742-6588, 1742-6596},
  url           = {http://arxiv.org/abs/2203.16355},
  urldate       = {2025-07-17},
  note          = {arXiv:2203.16355 [physics]},
  abstract      = {The detailed detector simulation models are vital for the successful operation of modern high-energy physics experiments. In most cases, such detailed models require a significant amount of computing resources to run. Often this may not be afforded and less resource-intensive approaches are desired. In this work, we demonstrate the applicability of Generative Adversarial Networks (GAN) as the basis for such fast-simulation models for the case of the Time Projection Chamber (TPC) at the MPD detector at the NICA accelerator complex. Our prototype GAN-based model of TPC works more than an order of magnitude faster compared to the detailed simulation without any noticeable drop in the quality of the high-level reconstruction characteristics for the generated data. Approaches with direct and indirect quality metrics optimization are compared.},
  keywords      = {Computer Science - Machine Learning, Physics - Instrumentation and Detectors}
}
@book{manning_foundations_1999,
  title         = {Foundations of {Statistical} {Natural} {Language} {Processing}},
  author        = {Manning, Christopher D. and Sch\"{u}tze, Hinrich},
  year          = 1999,
  publisher     = {The MIT Press},
  address       = {Cambridge, Mass},
  isbn          = {978-0-262-13360-9},
  abstract      = {Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications.},
  language      = {English}
}
@article{Segura:2024srj,
    author = "Segura, Alejandro and Parra, Angie Catalina",
    title = "{A Practical Guide to Statistical Techniques in Particle Physics}",
    eprint = "2411.00706",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    month = "11",
    year = "2024"
}
@article{STAR:2022etb,
    author = "Abdallah, Mohamed and others",
    collaboration = "STAR",
    title = "{Higher-order cumulants and correlation functions of proton multiplicity distributions in sNN=3~GeV~Au+Au collisions at the RHIC STAR experiment}",
    eprint = "2209.11940",
    archivePrefix = "arXiv",
    primaryClass = "nucl-ex",
    doi = "10.1103/PhysRevC.107.024908",
    journal = "Phys. Rev. C",
    volume = "107",
    number = "2",
    pages = "024908",
    year = "2023"
}
@inbook{Carli:2015qta,
    author = "Carli, Tancredi and Rabbertz, Klaus and Schumann, Steffen",
    editor = {Sch{\"o}rner-Sadenius, Thomas},
    title = "{Studies of Quantum Chromodynamics at the LHC}",
    booktitle = "{The Large Hadron Collider. Harvest of Run 1}",
    eprint = "1506.03239",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    doi = "10.1007/978-3-319-15001-7_5",
    pages = "139--194",
    year = "2015"
}
@article{Skands:2014pea,
    author = "Skands, Peter and Carrazza, Stefano and Rojo, Juan",
    title = "{Tuning PYTHIA 8.1: the Monash 2013 Tune}",
    eprint = "1404.5630",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    reportNumber = "CERN-PH-TH-2014-069, MCNET-14-08, OUTP-14-05P",
    doi = "10.1140/epjc/s10052-014-3024-y",
    journal = "Eur. Phys. J. C",
    volume = "74",
    number = "8",
    pages = "3024",
    year = "2014"
}
@article{Christiansen:2015yqa,
    author = "Christiansen, Jesper R. and Skands, Peter Z.",
    title = "{String Formation Beyond Leading Colour}",
    eprint = "1505.01681",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    reportNumber = "COEPP-MN-15-1, LU-TP-15-16, MCNET-15-09, COEPP-MN-15-1, LU-TP-15-16, MCNET-15-09",
    doi = "10.1007/JHEP08(2015)003",
    journal = "JHEP",
    volume = "08",
    pages = "003",
    year = "2015"
}
@unpublished{Corso2023,
    author = {Anthony Corso and David Karamadian and Romeo Valentin and Mary Cooper and Mykel J. Kochenderfer},
    journal = arxiv,
    title = {A holistic assessment of the reliability of machine learning systems},
    year = {2023},
    doi = {10.48550/ARXIV.2307.10586},
    note={(In Submission)}
}
@misc{marchand_bayesian_2012,
  title         = {On {Bayesian} credible sets in restricted parameter space problems and lower bounds for frequentist coverage},
  author        = {Marchand, Eric and Strawderman, William E.},
  year          = 2012,
  month         = dec,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1208.0028},
  url           = {http://arxiv.org/abs/1208.0028},
  urldate       = {2025-07-14},
  note          = {arXiv:1208.0028 [math]},
  abstract      = {For estimating a lower bounded parametric function in the framework of Marchand and Strawderman (2006), we provide through a unified approach a class of Bayesian confidence intervals with credibility \$1-{\textbackslash}alpha\$ and frequentist coverage probability bounded below by \${\textbackslash}frac\{1-{\textbackslash}alpha\}\{1+{\textbackslash}alpha\}\$. In cases where the underlying pivotal distribution is symmetric, the findings represent extensions with respect to the specification of the credible set achieved through the choice of a \{{\textbackslash}it spending function\}, and include Marchand and Strawderman's HPD procedure result. For non-symmetric cases, the determination of a such a class of Bayesian credible sets fills a gap in the literature and includes an "equal-tails" modification of the HPD procedure. Several examples are presented demonstrating wide applicability.},
  keywords      = {Mathematics - Statistics Theory, Statistics - Statistics Theory}
}
@inproceedings{Lyons:2011cli,
    author = "Lyons, Louis",
    title = "{Unfolding: Introduction}",
    booktitle = "{PHYSTAT 2011}",
    doi = "10.5170/CERN-2011-006.225",
    publisher = "CERN",
    address = "Geneva",
    pages = "225--228",
    year = "2011"
}
@article{Grosse-Oetringhaus:2009eis,
    author = "Grosse-Oetringhaus, Jan Fiete and Reygers, Klaus",
    title = "{Charged-Particle Multiplicity in Proton-Proton Collisions}",
    eprint = "0912.0023",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    doi = "10.1088/0954-3899/37/8/083001",
    journal = "J. Phys. G",
    volume = "37",
    pages = "083001",
    year = "2010"
}
@article{ALICE:2022xip,
    author = "Acharya, Shreyasi and others",
    collaboration = "ALICE",
    title = "{Multiplicity dependence of charged-particle production in pp, p-Pb, Xe-Xe and Pb-Pb collisions at the LHC}",
    eprint = "2211.15326",
    archivePrefix = "arXiv",
    primaryClass = "nucl-ex",
    reportNumber = "CERN-EP-2022-266",
    doi = "10.1016/j.physletb.2024.138700",
    journal = "Phys. Lett. B",
    volume = "845",
    pages = "138110",
    year = "2023",
    note = "[Erratum: Phys.Lett.B 853, 138700 (2024)]"
}
@misc{mathieu_riemannian_2020,
  title         = {Riemannian {Continuous} {Normalizing} {Flows}},
  author        = {Mathieu, Emile and Nickel, Maximilian},
  year          = 2020,
  month         = dec,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2006.10605},
  url           = {http://arxiv.org/abs/2006.10605},
  urldate       = {2025-07-16},
  note          = {arXiv:2006.10605 [stat]},
  abstract      = {Normalizing flows have shown great promise for modelling flexible probability distributions in a computationally tractable way. However, whilst data is often naturally described on Riemannian manifolds such as spheres, torii, and hyperbolic spaces, most normalizing flows implicitly assume a flat geometry, making them either misspecified or ill-suited in these situations. To overcome this problem, we introduce Riemannian continuous normalizing flows, a model which admits the parametrization of flexible probability measures on smooth manifolds by defining flows as the solution to ordinary differential equations. We show that this approach can lead to substantial improvements on both synthetic and real-world data when compared to standard flows or previously introduced projected flows.},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning}
}
@article{melbourne_strongly_2020,
  title         = {Strongly {Convex} {Divergences}},
  author        = {Melbourne, James},
  year          = 2020,
  month         = nov,
  journal       = {Entropy},
  volume        = 22,
  number        = 11,
  pages         = 1327,
  doi           = {10.3390/e22111327},
  issn          = {1099-4300},
  url           = {http://arxiv.org/abs/2009.10838},
  urldate       = {2025-07-14},
  note          = {arXiv:2009.10838 [cs]},
  abstract      = {We consider a sub-class of the \$f\$-divergences satisfying a stronger convexity property, which we refer to as strongly convex, or \${\textbackslash}kappa\$-convex divergences. We derive new and old relationships, based on convexity arguments, between popular \$f\$-divergences.},
  keywords      = {Computer Science - Information Theory, Mathematics - Information Theory, Mathematics - Probability, Mathematics - Statistics Theory, Statistics - Statistics Theory}
}
@misc{miao_locality-sensitive_2024,
  title         = {Locality-{Sensitive} {Hashing}-{Based} {Efficient} {Point} {Transformer} with {Applications} in {High}-{Energy} {Physics}},
  author        = {Miao, Siqi and Lu, Zhiyuan and Liu, Mia and Duarte, Javier and Li, Pan},
  year          = 2024,
  month         = jun,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2402.12535},
  url           = {http://arxiv.org/abs/2402.12535},
  urldate       = {2025-07-17},
  note          = {arXiv:2402.12535 [cs]},
  abstract      = {This study introduces a novel transformer model optimized for large-scale point cloud processing in scientific domains such as high-energy physics (HEP) and astrophysics. Addressing the limitations of graph neural networks and standard transformers, our model integrates local inductive bias and achieves near-linear complexity with hardware-friendly regular operations. One contribution of this work is the quantitative analysis of the error-complexity tradeoff of various sparsification techniques for building efficient transformers. Our findings highlight the superiority of using locality-sensitive hashing (LSH), especially OR \& AND-construction LSH, in kernel approximation for large-scale point cloud data with local inductive bias. Based on this finding, we propose LSH-based Efficient Point Transformer (HEPT), which combines E\${\textasciicircum}2\$LSH with OR \& AND constructions and is built upon regular computations. HEPT demonstrates remarkable performance on two critical yet time-consuming HEP tasks, significantly outperforming existing GNNs and transformers in accuracy and computational speed, marking a significant advancement in geometric deep learning and large-scale scientific data processing. Our code is available at https://github.com/Graph-COM/HEPT.},
  keywords      = {Computer Science - Machine Learning, High Energy Physics - Experiment}
}
@article{mikuni_point_2021,
  title         = {Point {Cloud} {Transformers} applied to {Collider} {Physics}},
  author        = {Mikuni, Vinicius and Canelli, Florencia},
  year          = 2021,
  month         = sep,
  journal       = {Machine Learning: Science and Technology},
  volume        = 2,
  number        = 3,
  pages         = {035027},
  doi           = {10.1088/2632-2153/ac07f6},
  issn          = {2632-2153},
  url           = {http://arxiv.org/abs/2102.05073},
  urldate       = {2025-07-17},
  note          = {arXiv:2102.05073 [physics]},
  abstract      = {Methods for processing point cloud information have seen a great success in collider physics applications. One recent breakthrough in machine learning is the usage of Transformer networks to learn semantic relationships between sequences in language processing. In this work, we apply a modified Transformer network called Point Cloud Transformer as a method to incorporate the advantages of the Transformer architecture to an unordered set of particles resulting from collision events. To compare the performance with other strategies, we study jet-tagging applications for highly-boosted particles.},
  keywords      = {Computer Science - Machine Learning, High Energy Physics - Experiment, Physics - Data Analysis, Statistics and Probability}
}
@article{Mikuni2025MethodTasks,
  title         = {Method to simultaneously facilitate all jet physics tasks},
  author        = {Mikuni, Vinicius and Nachman, Benjamin},
  year          = 2025,
  month         = 3,
  journal       = {Phys.Rev.D},
  publisher     = {American Physical Society},
  volume        = 111,
  number        = 5,
  doi           = {10.1103/physrevd.111.054015},
  issn          = 24700029
}
@article{Mikuni2025SolvingModels,
  title         = {Solving key challenges in collider physics with foundation models},
  author        = {Mikuni, Vinicius and Nachman, Benjamin},
  year          = 2025,
  month         = 3,
  journal       = {Physical Review D},
  publisher     = {American Physical Society},
  volume        = 111,
  number        = 5,
  pages         = {L051504},
  doi           = {10.1103/physrevd.111.l051504/figures/2/medium},
  issn          = 24700029,
  url           = {https://journals.aps.org/prd/abstract/10.1103/PhysRevD.111.L051504},
  keywords      = {doi:10.1103/PhysRevD.111.L051504 url:https://doi.org/10.1103/PhysRevD.111.L051504}
}
@misc{mirza_conditional_2014,
  title         = {Conditional {Generative} {Adversarial} {Nets}},
  author        = {Mirza, Mehdi and Osindero, Simon},
  year          = 2014,
  month         = nov,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1411.1784},
  url           = {http://arxiv.org/abs/1411.1784},
  urldate       = {2025-07-17},
  note          = {arXiv:1411.1784 [cs]},
  abstract      = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning}
}
@article{mishra_uncertainty_2021,
  title         = {Uncertainty quantification for deep learning in particle accelerator applications},
  author        = {Mishra, Aashwin Ananda and Edelen, Auralee and Hanuka, Adi and Mayes, Christopher},
  year          = 2021,
  month         = nov,
  journal       = {Physical Review Accelerators and Beams},
  volume        = 24,
  number        = 11,
  pages         = 114601,
  doi           = {10.1103/PhysRevAccelBeams.24.114601},
  url           = {https://link.aps.org/doi/10.1103/PhysRevAccelBeams.24.114601},
  urldate       = {2025-07-15},
  note          = {Publisher: American Physical Society},
  abstract      = {With the advent of increased computational resources and improved algorithms, machine learning-based models are being increasingly applied to complex problems in particle accelerators. However, such data-driven models may provide overly confident predictions with unknown errors and uncertainties. For reliable deployment of machine learning models in high-regret and safety-critical systems such as particle accelerators, estimates of prediction uncertainty are needed along with accurate point predictions. In this investigation, we evaluate Bayesian neural networks (BNN) as an approach that can provide accurate predictions along with reliably quantified uncertainties for particle accelerator problems, and compare their performance with bootstrapped ensembles of neural networks. We select three accelerator setups for this evaluation: a storage ring, a photoinjector, and a linac. The problems span different data volumes and dimensionalities (e.g., scalar predictions as well as image outputs). It is found that BNN provide accurate predictions of the mean along with reliable estimates of predictive uncertainty across the test cases. In this vein, BNN may offer an attractive alternative to deterministic deep learning tools to generate accurate predictions with quantified uncertainties in particle accelerator applications.}
}
@misc{miyato_spectral_2018,
  title         = {Spectral {Normalization} for {Generative} {Adversarial} {Networks}},
  author        = {Miyato, Takeru and Kataoka, Toshiki and Koyama, Masanori and Yoshida, Yuichi},
  year          = 2018,
  month         = feb,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1802.05957},
  url           = {http://arxiv.org/abs/1802.05957},
  urldate       = {2025-07-17},
  note          = {arXiv:1802.05957 [cs]},
  abstract      = {One of the challenges in the study of generative adversarial networks is the instability of its training. In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator. Our new normalization technique is computationally light and easy to incorporate into existing implementations. We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques.},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning}
}
@article{Moch:2004pa,
  title         = {The {{Three-Loop Splitting Functions}} in {{QCD}}: {{The Non-Singlet Case}}},
  shorttitle    = {The {{Three-Loop Splitting Functions}} in {{QCD}}},
  author        = {Moch, S. and Vermaseren, J. A. M. and Vogt, A.},
  year          = 2004,
  journal       = {Nuclear Physics B},
  volume        = 688,
  number        = {1-2},
  pages         = {101--134},
  doi           = {10.1016/j.nuclphysb.2004.03.030},
  issn          = {05503213},
  urldate       = {2025-07-18},
  eprint        = {hep-ph/0403192},
  abstract      = {We compute the next-to-next-to-leading order (NNLO) contributions to the three splitting functions governing the evolution of unpolarized non-singlet combinations of quark densities in perturbative QCD. Our results agree with all partial results available in the literature. We find that the correct leading logarithmic (LL) predictions for small momentum fractions x do not provide a good estimate of the respective complete results. A new, unpredicted LL contribution is found for the colour factor d{\textasciicircum}\{abc\}d\_\{abc\} entering at three loops for the first time. We investigate the size of the corrections and the stability of the NNLO evolution under variation of the renormalization scale. Except for very small x the corrections are found to be rather small even for large values of the strong coupling constant, in principle facilitating a perturbative evolution into the sub-GeV regime.},
  archiveprefix = {arXiv},
  keywords      = {High Energy Physics - Phenomenology},
  annotation    = {1435 citations (INSPIRE 2025/7/18)\\ 1278 citations w/o self (INSPIRE 2025/7/18)\\ Citations: 969 (Crossref) [2025-07-18]\\ Citations: 762 (SemanticScholar) [2025-07-18]},
  file          = {/Users/t-krishdesai/Zotero/storage/AQAM7X4V/Moch et al. - 2004 - The Three-Loop Splitting Functions in QCD The Non-Singlet Case.pdf;/Users/t-krishdesai/Zotero/storage/J94AP22H/0403192.html}
}
@article{Moodie2022OptimisingNetworks,
  title         = {Optimising hadronic collider simulations using amplitude neural networks},
  author        = {Moodie, Ryan},
  year          = 2022,
  month         = 8,
  journal       = {Journal of Physics: Conference Series},
  publisher     = {Institute of Physics},
  volume        = 2438,
  number        = 1,
  doi           = {10.1088/1742-6596/2438/1/012149},
  url           = {http://arxiv.org/abs/2202.04506 http://dx.doi.org/10.1088/1742-6596/2438/1/012149},
  arxivid       = {2202.04506v2}
}
@misc{moosavi-dezfooli_robustness_2018,
  title         = {Robustness via curvature regularization, and vice versa},
  author        = {Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Uesato, Jonathan and Frossard, Pascal},
  year          = 2018,
  month         = nov,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1811.09716},
  url           = {http://arxiv.org/abs/1811.09716},
  urldate       = {2025-07-14},
  note          = {arXiv:1811.09716 [cs]},
  abstract      = {State-of-the-art classifiers have been shown to be largely vulnerable to adversarial perturbations. One of the most effective strategies to improve robustness is adversarial training. In this paper, we investigate the effect of adversarial training on the geometry of the classification landscape and decision boundaries. We show in particular that adversarial training leads to a significant decrease in the curvature of the loss surface with respect to inputs, leading to a drastically more "linear" behaviour of the network. Using a locally quadratic approximation, we provide theoretical evidence on the existence of a strong relation between large robustness and small curvature. To further show the importance of reduced curvature for improving the robustness, we propose a new regularizer that directly minimizes curvature of the loss surface, and leads to adversarial robustness that is on par with adversarial training. Besides being a more efficient and principled alternative to adversarial training, the proposed regularizer confirms our claims on the importance of exhibiting quasi-linear behavior in the vicinity of data points in order to achieve robustness.},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning}
}
@incollection{mozer_jet_2017,
  title         = {Jet reconstruction and substructure measurements in {ATLAS} and {CMS} with first {Run}-2 data},
  author        = {Mozer, Matthias Ulrich},
  year          = 2017,
  month         = mar,
  booktitle     = {Proceedings of {Fourth} {Annual} {Large} {Hadron} {Collider} {Physics} -- {PoS}({LHCP2016})},
  publisher     = {SISSA Medialab},
  volume        = 276,
  pages         = {090},
  doi           = {10.22323/1.276.0090},
  url           = {https://pos.sissa.it/276/090},
  urldate       = {2025-07-13},
  note          = {Conference Name: Fourth Annual Large Hadron Collider Physics},
  abstract      = {Jets play an important role in LHC physics but jet reconstruction and calibration in the high pile-up environment of the 2015 and 2016 data-taking periods pose unique challenges. The ATLAS and CMS experiments have improved their jet reconstruction and correction methods compared to Run I in order to better clean jets of the additional particles generated in pile-up interactions. Beyond jets formed from the hadronization of quarks and gluons, hadronic decays of highly boosted heavy particles, such as top quarks or Z, W or H bosons, in a single fat jet is gaining importance in the search for new physics at the highest possible energies. The LHC experiments have used the time between the LHC Run I and Run II to refine the methods used to identify such boosted decays and make them more robust in the presence of the high pile-up encountered in Run II. The application of this work to early Run II data are presented.},
  language      = {en}
}
@misc{mroueh_mcgan_2017,
  title         = {{McGan}: {Mean} and {Covariance} {Feature} {Matching} {GAN}},
  shorttitle    = {McGan},
  author        = {Mroueh, Youssef and Sercu, Tom and Goel, Vaibhava},
  year          = 2017,
  month         = jun,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1702.08398},
  url           = {http://arxiv.org/abs/1702.08398},
  urldate       = {2025-07-17},
  note          = {arXiv:1702.08398 [cs]},
  abstract      = {We introduce new families of Integral Probability Metrics (IPM) for training Generative Adversarial Networks (GAN). Our IPMs are based on matching statistics of distributions embedded in a finite dimensional feature space. Mean and covariance feature matching IPMs allow for stable training of GANs, which we will call McGan. McGan minimizes a meaningful loss between distributions.},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning}
}
@article{MuheimNuclearLaws,
  title         = {Nuclear and Particle Physics Particle Physics Particle Physics--Measurements and Theory Measurements and Theory Natural Units Relativistic Kinematics Particle Physics Measurements Lifetimes Resonances and Widths Scattering Cross section Collider and Fixed Target Experiments Conservation Laws},
  author        = {Muheim, Franz}
}
@article{multhei_iterative_1987,
  title         = {On an {Iterative} {Method} for the {Unfolding} of {Spectra}},
  author        = {Multhei, H. N. and Schorr, B.},
  year          = 1987,
  journal       = {Nucl. Instrum. Meth. A},
  volume        = 257,
  pages         = 371,
  doi           = {10.1016/0168-9002(87)90759-5},
  keywords      = {Beta, Data Analysis Method, Mathematical Methods, Numerical Calculations}
}
@article{Navas2024ReviewPhysics,
  title         = {Review of particle physics},
  author        = {Navas, S. and Amsler, C. and Gutsche, T. and Vogelsang, W. and Hanhart, C. and Mei{\ss}ner, U. G. and Hern{\'{a}}ndez-Rey, J. J. and Pich, A. and Louren{\c{c}}o, C. and Ceccucci, A. and Doser, M. and Ellis, J. and Gurtu, A. and H{\"{o}}cker, A. and Moortgat, F. and Moskovic, M. and Pietropaolo, F. and Roesler, S. and Sauli, F. and Zimmermann, F. and Masoni, A. and Mikhasenko, M. and Mitchell, R. E. and Patrignani, C. and Schwanda, C. and Spanier, S. and Venanzoni, G. and D'Onofrio, M. and Casarosa, G. and Cerri, A. and Lusiani, A. and Signorelli, G. and Yuan, C. Z. and Cao, Z. and Zheng, W. and Agashe, K. and Eno, S. C. and Aielli, G. and Allanach, B. C. and Alvarez-Mu{\~{n}}iz, J. and Antonelli, M. and Aschenauer, E. C. and Asner, D. M. and Assamagan, K. and Littenberg, L. and Marciano, W. J. and Woody, C. L. and Baer, H. and Banerjee, Sw and Barnett, R. M. and Bauer, C. W. and Beringer, J. and Bonventre, R. and Cahn, R. N. and Groom, D. E. and Ligeti, Z. and Lin, C. J. and Lugovsky, K. S. and Pianori, E. and Robinson, D. J. and Seljak, U. and White, M. and Yao, W. M. and Zyla, P. A. and Anderson, J. and Kramer, M. and Schaffner, P. and Baudis, L. and Beatty, J. J. and Bettini, A. and Biebel, O. and Black, K. M. and Cranmer, K. and Blucher, E. and Carena, M. and Rosner, J. L. and Wakely, S. P. and Briere, R. A. and Buckley, A. and Miller, D. J. and Burkert, V. D. and Bychkov, M. A. and Dobrescu, B. A. and Fava, A. and Hsu, L. and O'Connell, H. B. and Pordes, S. and Shiltsev, V. and Van de Water, R. and Zeller, G. P. and Sozzi, M. S. and Chivukula, R. S. and Manohar, A. V. and Sharma, V. and Cowan, G. and Crede, V. and Cremonesi, O. and Nason, P. and D'Ambrosio, G. and Damour, T. and de Florian, D. and de Gouv{\^{e}}a, A. and DeGrand, T. and Demers, S. and Demiragli, Z. and Dreiner, H. K. and Wermes, N. and Eerola, P. and Egede, U. and Skands, P. and Valencia, G. and Eidelman, S. and Ezhela, V. V. and Lugovsky, S. B. and Romaniouk, A. and Ryskin, M. G. and Ryutin, R. A. and Vorobyev, V. and El-Khadra, A. X. and Fields, B. D. and Erler, J. and Tiator, L. and Fetscher, W. and Grab, C. and Freitas, A. and Gallagher, H. and Gershon, T. and Kreps, M. and Gershtein, Y. and Gherghetta, T. and Olive, K. A. and Gonzalez-Garcia, M. C. and Verde, L. and Goodman, M. and Yoshida, R. and Gritsan, A. V. and Grojean, C. and Melzer-Pellmann, I. A. and Ringwald, A. and Sefkow, F. and Gr{\"{u}}newald, M. and Haber, H. E. and Profumo, S. and Hamel, M. and Hashimoto, S. and Makida, Y. and Nakamura, K. and Sakai, Y. and Hayato, Y. and Yokoyama, M. and Hebecker, A. and Heinemeyer, S. and Hikasa, K. and Sumino, Y. and Takahashi, F. and Hisano, J. and Tanabashi, M. and Holder, J. and Huston, J. and Hyodo, T. and Ianni, Al and Kado, M. and Raffelt, G. and Zanderighi, G. and Karliner, M. and Soffer, A. and Katz, U. F. and Nelles, A. and Kenzie, M. and Khoze, V. A. and Krauss, F. and Richardson, P. and Klein, S. R. and Safdi, B. and Smoot, G. F. and Kri{\v{z}}an, P. and Krusche, B. and Kwon, Y. and Lahav, O. and Thorne, R. S. and Lellouch, L. P. and Lesgourgues, J. and Mertsch, P. and Liddle, A. R. and Lippmann, C. and Schwiening, J. and Liss, T. M. and Lister, A. and Scott, D. and Maltoni, F. and Vivarelli, I. and Matthews, J. and Thoma, U. and Milstead, D. and M{\"{o}}nig, K. and Spiering, C. and Molaro, P. and Nagata, N. and Narain, M. and Neubert, M. and Nir, Y. and O'Hare, C. A.J. and Peacock, J. A. and Piepke, A. and Pomarol, A. and Quadt, A. and Rabbertz, K. and Simon, F. and Rademacker, J. and Ramsey-Musolf, M. and Willocq, S. and Rolli, S. and Rosenberg, L. J. and Rybka, G. and Sharpe, S. R. and Sarkar, S. and Schneider, O. and Sch{\"{o}}nert, S. and Scholberg, K. and Walter, C. W. and Schwartz, A. J. and Sj{\"{o}}strand, T. and Skwarnicki, T. and Stahl, A. and Tanaka, J. and Terashi, K. and Ta{\v{s}}evsk{\'{y}}, M. and Terao, K. and Terning, J. and Titov, M. and Tovey, D. R. and Trabelsi, K. and Urquijo, P. and Varelas, N. and Vogel, P. and Walkowiak, W. and Wands, D. and Weinberg, D. H. and Weinberg, E. J. and Wiencke, L. R. and Workman, R. L. and Zhu, R. Y. and Zhu, S. L.},
  year          = 2024,
  month         = 8,
  journal       = {Physical Review D},
  publisher     = {American Physical Society},
  volume        = 110,
  number        = 3,
  pages         = 51,
  doi           = {10.1103/physrevd.110.030001},
  issn          = 24700029,
  url           = {https://pdg.lbl.gov/2025/reviews/kinematics_and_cross_sections.html}
}
@article{neumaier_solving_1998,
  title         = {Solving {Ill}-{Conditioned} and {Singular} {Linear} {Systems}: {A} {Tutorial} on {Regularization}},
  shorttitle    = {Solving {Ill}-{Conditioned} and {Singular} {Linear} {Systems}},
  author        = {Neumaier, Arnold},
  year          = 1998,
  month         = jan,
  journal       = {SIAM Review},
  volume        = 40,
  number        = 3,
  pages         = {636--666},
  doi           = {10.1137/s0036144597321909},
  issn          = {0036-1445},
  url           = {https://epubs.siam.org/doi/10.1137/S0036144597321909},
  urldate       = {2025-07-13},
  note          = {Publisher: Society for Industrial and Applied Mathematics},
  abstract      = {Regularization algorithms are often used to produce reasonable solutions to ill-posed problems. The L-curve is a plot--for all valid regularization parameters--of the size of the regularized solution versus the size of the corresponding residual. Two main results are established. First a unifying characterization of various regularization methods is given and it is shown that the measurement of ``size'' is dependent on the particular regularization method chosen. For example, the 2-norm is appropriate for Tikhonov regularization, but a 1-norm in the coordinate system of the singular value decomposition (SVD) is relevant to truncated SVD regularization. Second, a new method is proposed for choosing the regularization parameter based on the L-curve, and it is shown how this method can be implemented efficiently. The method is compared to generalized cross validation and this new method is shown to be more robust in the presence of correlated errors.}
}
@inproceedings{NeurIPS.2021,
  title         = {Symmetry Discovery with Deep Learning},
  author        = {Desai, Krish and Nachman, Benjamin and Thaler, Jesse},
  year          = 2021,
  booktitle     = {Ml4ps},
  number        = 117,
  maintitle     = {NeurIPS}
}
@article{nielsen_jensenshannon_2019,
  title         = {On the {Jensen}-{Shannon} {Symmetrization} of {Distances} {Relying} on {Abstract} {Means}},
  author        = {Nielsen, Frank},
  year          = 2019,
  month         = may,
  journal       = {Entropy},
  volume        = 21,
  number        = 5,
  pages         = 485,
  doi           = {10.3390/e21050485},
  issn          = {1099-4300},
  url           = {https://www.mdpi.com/1099-4300/21/5/485},
  urldate       = {2025-07-17},
  copyright     = {http://creativecommons.org/licenses/by/3.0/},
  note          = {Number: 5 Publisher: Multidisciplinary Digital Publishing Institute},
  abstract      = {The Jensen–Shannon divergence is a renowned bounded symmetrization of the unbounded Kullback–Leibler divergence which measures the total Kullback–Leibler divergence to the average mixture distribution. However, the Jensen–Shannon divergence between Gaussian distributions is not available in closed form. To bypass this problem, we present a generalization of the Jensen–Shannon (JS) divergence using abstract means which yields closed-form expressions when the mean is chosen according to the parametric family of distributions. More generally, we define the JS-symmetrizations of any distance using parameter mixtures derived from abstract means. In particular, we first show that the geometric mean is well-suited for exponential families, and report two closed-form formula for (i) the geometric Jensen–Shannon divergence between probability densities of the same exponential family; and (ii) the geometric JS-symmetrization of the reverse Kullback–Leibler divergence between probability densities of the same exponential family. As a second illustrating example, we show that the harmonic mean is well-suited for the scale Cauchy distributions, and report a closed-form formula for the harmonic Jensen–Shannon divergence between scale Cauchy distributions. Applications to clustering with respect to these novel Jensen–Shannon divergences are touched upon.},
  language      = {en},
  keywords      = {\textit{f}-divergence, Bhattacharyya distance, Bregman divergence, Cauchy scale family, Gaussian family, Jeffreys divergence, Jensen/Burbea–Rao divergence, Jensen–Shannon divergence, abstract weighted mean, clustering, exponential family, mixture family, quasi-arithmetic mean, resistor average distance, statistical \textit{M}-mixture}
}
@article{nielsen_neural_2015,
  title         = {Neural {Networks} and {Deep} {Learning}},
  author        = {Nielsen, Michael A.},
  year          = 2015,
  url           = {http://neuralnetworksanddeeplearning.com},
  urldate       = {2025-07-15},
  note          = {Publisher: Determination Press},
  language      = {en}
}
@misc{noauthor_deep_nodate,
  title         = {Deep {Neural} {Networks} for particle reconstruction in high-granularity calorimeters},
  journal       = {EP News},
  url           = {https://ep-news.web.cern.ch/content/deep-neural-networks-particle-reconstruction-high-granularity-calorimeters},
  urldate       = {2025-07-15},
  abstract      = {Precision measurements in high energy physics as well as an increasing amount of searches for new phenomena rely on a precise reconstruction of the event that caused a particular signature in the detector. Particle flow algorithms [1, 2, 3, 4] aim to identify individual particles before they are merged to compound objects such as jets or missing (transverse) momentum. These approaches exploit all subdetector systems to resolve ambiguities and allow to apply calibrations on the level of individual reconstructed particle candidates.},
  language      = {en}
}
@misc{noauthor_idl_nodate,
  title         = {{Idl} {S25} {Oh}},
  url           = {https://calendar.google.com/calendar/embed?src=c_9298642174c7fb124292f17924ff3fafef3d426a12c96f4814fc112a706510c2%40group.calendar.google.com&ctz=America%2FNew_York},
  urldate       = {2025-07-15},
  language      = {en}
}
@misc{noauthor_implications_nodate,
  title         = {Implications of {First} {LHC} {Data}},
  journal       = {Indico},
  url           = {https://indico.cern.ch/event/94815/contributions/1282695/},
  urldate       = {2025-07-13},
  abstract      = {A joint Berkeley-MIT Workshop In 2010 we expect to see the first significant LHC collision data, and this workshop is held to get theorists and experimentalists together with the goal of helping maximize the physics potential of this first LHC run. The LHC experiments have already analyzed data at a center-of-mass energy of 0.9 TeV which were collected end of 2009 and reveal new information on the understanding of soft physics. Many new measurements are expected to be available by the...},
  language      = {en}
}
@article{noauthor_precision_2006,
  title         = {Precision electroweak measurements on the {Z} resonance},
  year          = 2006,
  month         = may,
  journal       = {Physics Reports},
  volume        = 427,
  number        = 5,
  pages         = {257--454},
  doi           = {10.1016/j.physrep.2005.12.006},
  issn          = {0370-1573},
  url           = {https://www.sciencedirect.com/science/article/pii/S0370157305005119},
  urldate       = {2025-07-13},
  abstract      = {We report on the final electroweak measurements performed with data taken at the Z resonance by the experiments operating at the electron–positron colliders SLC and LEP. The data consist of 17 million Z decays accumulated by the ALEPH, DELPHI, L3 and OPAL experiments at LEP, and 600 thousand Z decays by the SLD experiment using a polarised beam at SLC. The measurements include cross-sections, forward–backward asymmetries and polarised asymmetries. The mass and width of the Z boson, mZ and \ensuremath{\Gamma}Z, and its couplings to fermions, for example the \ensuremath{\rho} parameter and the effective electroweak mixing angle for leptons, are precisely measured:mZ=91.1875\pm{}0.0021GeV,\ensuremath{\Gamma}Z=2.4952\pm{}0.0023GeV,\ensuremath{\rho}\mathscr{l}=1.0050\pm{}0.0010,sin2\texttheta{}efflept=0.23153\pm{}0.00016.The number of light neutrino species is determined to be 2.9840\pm{}0.0082, in agreement with the three observed generations of fundamental fermions. The results are compared to the predictions of the Standard Model (SM). At the Z-pole, electroweak radiative corrections beyond the running of the QED and QCD coupling constants are observed with a significance of five standard deviations, and in agreement with the Standard Model. Of the many Z-pole measurements, the forward–backward asymmetry in b-quark production shows the largest difference with respect to its SM expectation, at the level of 2.8 standard deviations. Through radiative corrections evaluated in the framework of the Standard Model, the Z-pole data are also used to predict the mass of the top quark, mt=173-10+13GeV, and the mass of the W boson, mW=80.363\pm{}0.032GeV. These indirect constraints are compared to the direct measurements, providing a stringent test of the SM. Using in addition the direct measurements of mt and mW, the mass of the as yet unobserved SM Higgs boson is predicted with a relative uncertainty of about 50\% and found to be less than 285GeV at 95\% confidence level.},
  keywords      = {Decays of heavy intermediate gauge bosons, Effective coupling constants, Electron–positron physics, Electroweak interactions, Fermion–antifermion production, Higgs boson, Neutral weak current, Precision measurements at the Z resonance, Radiative corrections, Tests of the Standard Model, Top quark, W boson, Z boson}
}
@misc{noauthor_statistics_2010,
  title         = {Statistics and {Discoveries} at the {LHC} (1/4)},
  year          = 2010,
  month         = jun,
  journal       = {Indico},
  url           = {https://indico.cern.ch/event/77830/},
  urldate       = {2025-07-17},
  abstract      = {The lectures will give an introduction to statistics as applied in particle physics and will provide all the necessary basics for data analysis at the LHC. Special emphasis will be placed on the the problems and questions that arise when searching for new phenomena, including p-values, discovery significance, limit setting procedures, treatment of small signals in the presence of large backgrounds. Specific issues that will be addressed include the advantages and drawbacks of different...},
  language      = {en}
}
@article{Paganini2018CaloGANNetworks,
  title         = {CaloGAN : Simulating 3D high energy particle showers in multilayer electromagnetic calorimeters with generative adversarial networks},
  author        = {Paganini, Michela and De Oliveira, Luke and Nachman, Benjamin},
  year          = 2018,
  month         = 1,
  journal       = {Phys.Rev.D},
  publisher     = {American Physical Society},
  volume        = 97,
  number        = 1,
  doi           = {10.1103/physrevd.97.014021},
  issn          = 24700029,
  arxivid       = {1712.10321},
  keywords      = {doi:10.1103/PhysRevD.97.014021 url:https://doi.org/10.1103/PhysRevD.97.014021}
}
@misc{palumbo_convergence_2025,
  title         = {Convergence rates for {Tikhonov} regularization on compact sets: application to neural networks},
  shorttitle    = {Convergence rates for {Tikhonov} regularization on compact sets},
  author        = {Palumbo, Barbara and Massa, Paolo and Benvenuto, Federico},
  year          = 2025,
  month         = may,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2505.19936},
  url           = {http://arxiv.org/abs/2505.19936},
  urldate       = {2025-07-13},
  note          = {arXiv:2505.19936 [math]},
  abstract      = {In this work, we consider ill-posed inverse problems in which the forward operator is continuous and weakly closed, and the sought solution belongs to a weakly closed constraint set. We propose a regularization method based on minimizing the Tikhonov functional on a sequence of compact sets which is dense in the intersection between the domain of the forward operator and the constraint set. The index of the compact sets can be interpreted as an additional regularization parameter. We prove that the proposed method is a regularization, achieving the same convergence rates as classical Tikhonov regularization and attaining the optimal convergence rate when the forward operator is linear. Moreover, we show that our methodology applies to the case where the constrained solution space is parametrized by means of neural networks (NNs), and the constraint is obtained by composing the last layer of the NN with a suitable activation function. In this case the dense compact sets are defined by taking a family of bounded weight NNs with increasing weight bound. Finally, we present some numerical experiments in the case of Computerized Tomography to compare the theoretical behavior of the reconstruction error with that obtained in a finite dimensional and non-asymptotic setting. The numerical tests also show that our NN-based regularization method is able to provide piece-wise constant solutions and to preserve the sharpness of edges, thus achieving lower reconstruction errors compared to the classical Tikhonov approach for the same level of noise in the data.},
  keywords      = {Computer Science - Numerical Analysis, Mathematics - Numerical Analysis}
}
@misc{pani_generalized_2024,
  title         = {Generalized angularities measurements from {STAR} at \${\textbackslash}sqrt\{s\_\{{\textbackslash}rm {NN}\}\} = \$ 200 {GeV}},
  author        = {Pani, Tanmay},
  year          = 2024,
  month         = mar,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2403.13921},
  url           = {http://arxiv.org/abs/2403.13921},
  urldate       = {2025-07-15},
  note          = {arXiv:2403.13921 [nucl-ex]},
  abstract      = {Jets are produced in early stages of heavy-ion collisions and undergo modified showering in the quark-gluon plasma (QGP) medium relative to a vacuum case. These modifications can be measured using observables like jet momentum profile and generalized angularities to study the details of jet-medium interactions. Jet momentum profile (\${\textbackslash}rho(r)\$) encodes radially differential information about jet broadening and has shown migration of charged energy towards the jet periphery in Pb+Pb collisions at the LHC. Measurements of generalized angularities (girth \$g\$ and momentum dispersion \$p\_T{\textasciicircum}D\$) and LeSub (difference between leading and subleading constituents) from Pb+Pb collisions at the LHC show harder, or more quark-like jet fragmentation, in the presence of the medium. Measuring these distributions in heavy-ion collisions at RHIC will help us further characterize the jet-medium interactions in a phase-space region complimentary to that of the LHC. In this contribution, we present the first measurements of fully corrected \$g\$, \$p\_T{\textasciicircum}D\$ and LeSub observables using hard-core jets in Au+Au collisions at \${\textbackslash}sqrt\{s\_\{{\textbackslash}rm NN\}\}=200\$ GeV, collected by the STAR experiment at RHIC.},
  keywords      = {Nuclear Experiment}
}
@misc{papamakarios_masked_2018,
  title         = {Masked {Autoregressive} {Flow} for {Density} {Estimation}},
  author        = {Papamakarios, George and Pavlakou, Theo and Murray, Iain},
  year          = 2018,
  month         = jun,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1705.07057},
  url           = {http://arxiv.org/abs/1705.07057},
  urldate       = {2025-07-16},
  note          = {arXiv:1705.07057 [stat]},
  abstract      = {Autoregressive models are among the best performing neural density estimators. We describe an approach for increasing the flexibility of an autoregressive model, based on modelling the random numbers that the model uses internally when generating data. By constructing a stack of autoregressive models, each modelling the random numbers of the next model in the stack, we obtain a type of normalizing flow suitable for density estimation, which we call Masked Autoregressive Flow. This type of flow is closely related to Inverse Autoregressive Flow and is a generalization of Real NVP. Masked Autoregressive Flow achieves state-of-the-art performance in a range of general-purpose density estimation tasks.},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning}
}
@article{Papamakarios2016FastEstimation,
  title         = {{Fast {\$}{\textbackslash}epsilon{\$}-free Inference of Simulation Models with Bayesian Conditional Density Estimation}},
  author        = {Papamakarios, George and Murray, Iain},
  year          = 2016,
  month         = 5,
  journal       = {Advances in Neural Information Processing Systems},
  publisher     = {Neural information processing systems foundation},
  pages         = {1036--1044},
  issn          = 10495258,
  url           = {https://arxiv.org/pdf/1605.06376},
  arxivid       = {1605.06376}
}
@article{ParticleDataGroup:2022pth,
    author = "Workman, R. L. and others",
    collaboration = "Particle Data Group",
    title = "{Review of Particle Physics}",
    doi = "10.1093/ptep/ptac097",
    journal = "PTEP",
    volume = "2022",
    pages = "083C01",
    year = "2022"
}
@article{Mengel:2024fcl,
    author = "Mengel, Tanner and Steffanic, Patrick and Hughes, Charles and Da Silva, Antonio Carlos Oliveira and Nattrass, Christine",
    title = "{Multiplicity Based Background Subtraction for Jets in Heavy Ion Collisions}",
    eprint = "2402.10945",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    month = "2",
    year = "2024"
}
@article{Haake:2018hqn,
    author = {Haake, R{\"u}diger and Loizides, Constantin},
    title = "{Machine Learning based jet momentum reconstruction in heavy-ion collisions}",
    eprint = "1810.06324",
    archivePrefix = "arXiv",
    primaryClass = "nucl-ex",
    doi = "10.1103/PhysRevC.99.064904",
    journal = "Phys. Rev. C",
    volume = "99",
    number = "6",
    pages = "064904",
    year = "2019"
}
@inproceedings{Do_2023,
   title={Prompt- and Trait Relation-aware Cross-prompt Essay Trait Scoring},
   url={http://dx.doi.org/10.18653/v1/2023.findings-acl.98},
   DOI={10.18653/v1/2023.findings-acl.98},
   booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
   publisher={Association for Computational Linguistics},
   author={Do, Heejin and Kim, Yunsu and Lee, Gary Geunbae},
   year={2023},
   pages={1538-1551} }
@article{Mengel:2024fcl,
    author = "Mengel, Tanner and Steffanic, Patrick and Hughes, Charles and Da Silva, Antonio Carlos Oliveira and Nattrass, Christine",
    title = "{Multiplicity Based Background Subtraction for Jets in Heavy Ion Collisions}",
    eprint = "2402.10945",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    month = "2",
    year = "2024"
}
@book{alma991004315861406376,
author = {Navarro, Danielle},
isbn = {9781800649385},
language = {eng},
publisher = {Open Book Publishers},
title = {Learning Statistics with jamovi},
year = {2025},
}


@article{Apolinario:2012cg,
    author = "Apolinario, Liliana and Armesto, Nestor and Cunqueiro, Leticia",
    title = "{An analysis of the influence of background subtraction and quenching on jet observables in heavy-ion collisions}",
    eprint = "1211.1161",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    doi = "10.1007/JHEP02(2013)022",
    journal = "JHEP",
    volume = "02",
    pages = "022",
    year = "2013"
}
@article{Milhano:2022kzx,
    author = "Milhano, Jos{\'e} Guilherme and Zapp, Korinna",
    title = "{Improved background subtraction and a fresh look at jet sub-structure in JEWEL}",
    eprint = "2207.14814",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    reportNumber = "LU-TH 22-48, MCNET-22-12",
    doi = "10.1140/epjc/s10052-022-10954-1",
    journal = "Eur. Phys. J. C",
    volume = "82",
    number = "11",
    pages = "1010",
    year = "2022"
}
@article{particle_data_group_review_2022,
  title         = {Review of {Particle} {Physics}},
  author        = {{Particle Data Group} and Workman, R L and Burkert, V D and Crede, V and Klempt, E and Thoma, U and Tiator, L and Agashe, K and Aielli, G and Allanach, B C and Amsler, C and Antonelli, M and Aschenauer, E C and Asner, D M and Baer, H and Banerjee, Sw and Barnett, R M and Baudis, L and Bauer, C W and Beatty, J J and Belousov, V I and Beringer, J and Bettini, A and Biebel, O and Black, K M and Blucher, E and Bonventre, R and Bryzgalov, V V and Buchmuller, O and Bychkov, M A and Cahn, R N and Carena, M and Ceccucci, A and Cerri, A and Chivukula, R Sekhar and Cowan, G and Cranmer, K and Cremonesi, O and D'Ambrosio, G and Damour, T and de Florian, D and de Gouv\^{e}a, A and DeGrand, T and de Jong, P and Demers, S and Dobrescu, B A and D'Onofrio, M and Doser, M and Dreiner, H K and Eerola, P and Egede, U and Eidelman, S and El-Khadra, A X and Ellis, J and Eno, S C and Erler, J and Ezhela, V V and Fetscher, W and Fields, B D and Freitas, A and Gallagher, H and Gershtein, Y and Gherghetta, T and Gonzalez-Garcia, M C and Goodman, M and Grab, C and Gritsan, A V and Grojean, C and Groom, D E and Gr\"{u}newald, M and Gurtu, A and Gutsche, T and Haber, H E and Hamel, Matthieu and Hanhart, C and Hashimoto, S and Hayato, Y and Hebecker, A and Heinemeyer, S and Hern\'{a}ndez-Rey, J J and Hikasa, K and Hisano, J and H\"{o}cker, A and Holder, J and Hsu, L and Huston, J and Hyodo, T and Ianni, Al and Kado, M and Karliner, M and Katz, U F and Kenzie, M and Khoze, V A and Klein, S R and Krauss, F and Kreps, M and Kri\v{z}an, P and Krusche, B and Kwon, Y and Lahav, O and Laiho, J and Lellouch, L P and Lesgourgues, J and Liddle, A R and Ligeti, Z and Lin, C-J and Lippmann, C and Liss, T M and Littenberg, L and Louren\c{c}o, C and Lugovsky, K S and Lugovsky, S B and Lusiani, A and Makida, Y and Maltoni, F and Mannel, T and Manohar, A V and Marciano, W J and Masoni, A and Matthews, J and Mei\ss{}ner, U-G and Melzer-Pellmann, I-A and Mikhasenko, M and Miller, D J and Milstead, D and Mitchell, R E and M\"{o}nig, K and Molaro, P and Moortgat, F and Moskovic, M and Nakamura, K and Narain, M and Nason, P and Navas, S and Nelles, A and Neubert, M and Nevski, P and Nir, Y and Olive, K A and Patrignani, C and Peacock, J A and Petrov, V A and Pianori, E and Pich, A and Piepke, A and Pietropaolo, F and Pomarol, A and Pordes, S and Profumo, S and Quadt, A and Rabbertz, K and Rademacker, J and Raffelt, G and Ramsey-Musolf, M and Ratcliff, B N and Richardson, P and Ringwald, A and Robinson, D J and Roesler, S and Rolli, S and Romaniouk, A and Rosenberg, L J and Rosner, J L and Rybka, G and Ryskin, M G and Ryutin, R A and Sakai, Y and Sarkar, S and Sauli, F and Schneider, O and Sch\"{o}nert, S and Scholberg, K and Schwartz, A J and Schwiening, J and Scott, D and Sefkow, F and Seljak, U and Sharma, V and Sharpe, S R and Shiltsev, V and Signorelli, G and Silari, M and Simon, F and Sj\"{o}strand, T and Skands, P and Skwarnicki, T and Smoot, G F and Soffer, A and Sozzi, M S and Spanier, S and Spiering, C and Stahl, A and Stone, S L and Sumino, Y and Syphers, M J and Takahashi, F and Tanabashi, M and Tanaka, J and Ta\v{s}evsk\'{y}, M and Terao, K and Terashi, K and Terning, J and Thorne, R S and Titov, M and Tkachenko, N P and Tovey, D R and Trabelsi, K and Urquijo, P and Valencia, G and Van de Water, R and Varelas, N and Venanzoni, G and Verde, L and Vivarelli, I and Vogel, P and Vogelsang, W and Vorobyev, V and Wakely, S P and Walkowiak, W and Walter, C W and Wands, D and Weinberg, D H and Weinberg, E J and Wermes, N and White, M and Wiencke, L R and Willocq, S and Wohl, C G and Woody, C L and Yao, W-M and Yokoyama, M and Yoshida, R and Zanderighi, G and Zeller, G P and Zenin, O V and Zhu, R-Y and Zhu, Shi-Lin and Zimmermann, F and Zyla, P A},
  year          = 2022,
  month         = aug,
  journal       = {Progress of Theoretical and Experimental Physics},
  volume        = 2022,
  number        = 8,
  pages         = {083c01},
  doi           = {10.1093/ptep/ptac097},
  issn          = {2050-3911},
  url           = {https://doi.org/10.1093/ptep/ptac097},
  urldate       = {2025-07-13},
  abstract      = {The Review summarizes much of particle physics and cosmology. Using data from previous editions, plus 2,143 new measurements from 709 papers, we list, evaluate, and average measured properties of gauge bosons and the recently discovered Higgs boson, leptons, quarks, mesons, and baryons. We summarize searches for hypothetical particles such as supersymmetric particles, heavy bosons, axions, dark photons, etc. Particle properties and search limits are listed in Summary Tables. We give numerous tables, figures, formulae, and reviews of topics such as Higgs Boson Physics, Supersymmetry, Grand Unified Theories, Neutrino Mixing, Dark Energy, Dark Matter, Cosmology, Particle Detectors, Colliders, Probability and Statistics. Among the 120 reviews are many that are new or heavily revised, including a new review on Machine Learning, and one on Spectroscopy of Light Meson Resonances.The Review is divided into two volumes. Volume 1 includes the Summary Tables and 97 review articles. Volume 2 consists of the Particle Listings and contains also 23 reviews that address specific aspects of the data presented in the Listings.The complete Review (both volumes) is published online on the website of the Particle Data Group (pdg.lbl.gov) and in a journal. Volume 1 is available in print as the PDG Book. A Particle Physics Booklet with the Summary Tables and essential tables, figures, and equations from selected review articles is available in print, as a web version optimized for use on phones, and as an Android app.}
}
@article{Pearkes2017JetTagging,
  title         = {Jet Constituents for Deep Neural Network Based Top Quark Tagging},
  author        = {Pearkes, Jannicke and Fedorko, Wojciech and Lister, Alison and Gay, Colin},
  year          = 2017,
  month         = 4,
  url           = {https://arxiv.org/pdf/1704.02124},
  arxivid       = {1704.02124}
}
@article{peng_efficient_2025,
  title         = {Efficient, scalable emulation of stochastic simulators: {A} mixture density network based surrogate modeling framework},
  shorttitle    = {Efficient, scalable emulation of stochastic simulators},
  author        = {Peng, Han and Zhang, Jize},
  year          = 2025,
  month         = may,
  journal       = {Reliability Engineering \& System Safety},
  volume        = 257,
  pages         = 110806,
  doi           = {10.1016/j.ress.2025.110806},
  issn          = {0951-8320},
  url           = {https://www.sciencedirect.com/science/article/pii/S0951832025000092},
  urldate       = {2025-07-15},
  abstract      = {This work focuses on the task of emulating stochastic simulators that generate random results given consistent inputs. Existing stochastic surrogate models can have limitations in characterizing complex output distributions or suffer from data inefficiency and high-dimensionality issues. As a remedy, we propose to introduce Mixture Density Networks (MDNs) as an advanced stochastic surrogate model. Flexible neural networks are utilized to parametrize Gaussian mixture models (GMMs) to capture complex input-dependent output conditional densities. MDNs, like typical neural networks, use multiple layers of nonlinear transformations to effectively manage the potentially high-dimensional or large-volume inputs. Statistically, MDNs eliminate the need for random seed control or replication by directly learning to maximize the training data likelihood. To further enhance MDN model robustness and mitigate over-fitting, we incorporate the hard parameter sharing and variance regularization technique, and Bayesian optimization to search for optimal MDN hyperparameters, unlocking its full potential as stochastic surrogates. The efficacy of our MDN stochastic surrogate model is illustrated through various academic and realistic examples. MDN is demonstrated to be consistently more flexible, accurate, and data-efficient than current stochastic surrogate workhorses.},
  keywords      = {Conditional density estimation, Deep learning, Mixture density network, Stochastic surrogate model, Uncertainty quantification}
}
@book{pesaran_time_2015,
  title         = {Time {Series} and {Panel} {Data} {Econometrics}},
  author        = {Pesaran, M. Hashem},
  year          = 2015,
  month         = oct,
  publisher     = {Oxford University Press},
  isbn          = {978-0-19-105847-9},
  note          = {Google-Books-ID: 7RokCwAAQBAJ},
  abstract      = {This book is concerned with recent developments in time series and panel data techniques for the analysis of macroeconomic and financial data. It provides a rigorous, nevertheless user-friendly, account of the time series techniques dealing with univariate and multivariate time series models, as well as panel data models. It is distinct from other time series texts in the sense that it also covers panel data models and attempts at a more coherent integration of time series, multivariate analysis, and panel data models. It builds on the author's extensive research in the areas of time series and panel data analysis and covers a wide variety of topics in one volume. Different parts of the book can be used as teaching material for a variety of courses in econometrics. It can also be used as reference manual. It begins with an overview of basic econometric and statistical techniques, and provides an account of stochastic processes, univariate and multivariate time series, tests for unit roots, cointegration, impulse response analysis, autoregressive conditional heteroskedasticity models, simultaneous equation models, vector autoregressions, causality, forecasting, multivariate volatility models, panel data models, aggregation and global vector autoregressive models (GVAR). The techniques are illustrated using Microfit 5 (Pesaran and Pesaran, 2009, OUP) with applications to real output, inflation, interest rates, exchange rates, and stock prices.},
  language      = {en},
  keywords      = {Business \& Economics / Econometrics, Business \& Economics / Economics / Microeconomics, Business \& Economics / Finance / General}
}
@book{peskin_introduction_1995,
  title         = {An {Introduction} to quantum field theory},
  author        = {Peskin, Michael E. and Schroeder, Daniel V.},
  year          = 1995,
  publisher     = {Addison-Wesley},
  address       = {Reading, USA},
  doi           = {10.1201/9780429503559},
  isbn          = {978-0-201-50397-5 978-0-429-50355-9 978-0-429-49417-8},
  keywords      = {BETA, Dirac equation, Feynman graph, Klein-Gordon equation, book, field theory: scalar, path integral, quantum electrodynamics, radiative correction, renormalization, renormalization group}
}
@misc{petersen_optimal_2018,
  title         = {Optimal approximation of piecewise smooth functions using deep {ReLU} neural networks},
  author        = {Petersen, Philipp and Voigtlaender, Felix},
  year          = 2018,
  month         = may,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1709.05289},
  url           = {http://arxiv.org/abs/1709.05289},
  urldate       = {2025-07-15},
  note          = {arXiv:1709.05289 [math]},
  abstract      = {We study the necessary and sufficient complexity of ReLU neural networks---in terms of depth and number of weights---which is required for approximating classifier functions in \$L{\textasciicircum}2\$. As a model class, we consider the set \${\textbackslash}mathcal\{E\}{\textasciicircum}{\textbackslash}beta ({\textbackslash}mathbb R{\textasciicircum}d)\$ of possibly discontinuous piecewise \$C{\textasciicircum}{\textbackslash}beta\$ functions \$f : [-1/2, 1/2]{\textasciicircum}d {\textbackslash}to {\textbackslash}mathbb R\$, where the different smooth regions of \$f\$ are separated by \$C{\textasciicircum}{\textbackslash}beta\$ hypersurfaces. For dimension \$d {\textbackslash}geq 2\$, regularity \${\textbackslash}beta {\textgreater} 0\$, and accuracy \${\textbackslash}varepsilon {\textgreater} 0\$, we construct artificial neural networks with ReLU activation function that approximate functions from \${\textbackslash}mathcal\{E\}{\textasciicircum}{\textbackslash}beta({\textbackslash}mathbb R{\textasciicircum}d)\$ up to \$L{\textasciicircum}2\$ error of \${\textbackslash}varepsilon\$. The constructed networks have a fixed number of layers, depending only on \$d\$ and \${\textbackslash}beta\$, and they have \$O({\textbackslash}varepsilon{\textasciicircum}\{-2(d-1)/{\textbackslash}beta\})\$ many nonzero weights, which we prove to be optimal. In addition to the optimality in terms of the number of weights, we show that in order to achieve the optimal approximation rate, one needs ReLU networks of a certain depth. Precisely, for piecewise \$C{\textasciicircum}{\textbackslash}beta({\textbackslash}mathbb R{\textasciicircum}d)\$ functions, this minimal depth is given---up to a multiplicative constant---by \${\textbackslash}beta/d\$. Up to a log factor, our constructed networks match this bound. This partly explains the benefits of depth for ReLU networks by showing that deep networks are necessary to achieve efficient approximation of (piecewise) smooth functions. Finally, we analyze approximation in high-dimensional spaces where the function \$f\$ to be approximated can be factorized into a smooth dimension reducing feature map \${\textbackslash}tau\$ and classifier function \$g\$---defined on a low-dimensional feature space---as \$f = g {\textbackslash}circ {\textbackslash}tau\$. We show that in this case the approximation rate depends only on the dimension of the feature space and not the input dimension.},
  keywords      = {Computer Science - Machine Learning, Mathematics - Functional Analysis, Statistics - Machine Learning}
}
@article{PhysRevD.105.096031,
  title         = {SymmetryGAN: Symmetry discovery with deep learning},
  author        = {Desai, Krish and Nachman, Benjamin and Thaler, Jesse},
  year          = 2022,
  month         = {May},
  journal       = {Phys. Rev. D},
  publisher     = {American Physical Society},
  volume        = 105,
  pages         = {096031},
  doi           = {10.1103/PhysRevD.105.096031},
  url           = {https://link.aps.org/doi/10.1103/PhysRevD.105.096031},
  issue         = 9,
  numpages      = 19
}
@article{PhysRevLett.13.508,
  title         = {Broken Symmetries and the Masses of Gauge Bosons},
  author        = {Higgs, Peter W.},
  year          = 1964,
  month         = {Oct},
  journal       = {Phys. Rev. Lett.},
  publisher     = {American Physical Society},
  volume        = 13,
  pages         = {508--509},
  doi           = {10.1103/PhysRevLett.13.508},
  url           = {https://link.aps.org/doi/10.1103/PhysRevLett.13.508},
  issue         = 16,
  numpages      = {0}
}
@article{plot,
  title         = {Signal Processing Aspects of Computer Music--A Survey},
  author        = {James Moorer},
  year          = 1977,
  journal       = {Computer Music Journal},
  volume        = 1,
  number        = 1,
  page          = 14
}
@article{plucked-string,
  title         = {Digital Synthesis of Plucked-String and Drum Timbres},
  author        = {Kevin Karplus and Alex Strong},
  year          = 1983,
  journal       = {Computer Music Journal},
  volume        = 7,
  number        = 2,
  pages         = {43--55}
}
@article{plucked-string-extensions,
  title         = {Extensions of the {K}arplus-{S}trong Plucked String Algorithm},
  author        = {David Jaffe and Julius Smith},
  year          = 1983,
  journal       = {Computer Music Journal},
  volume        = 7,
  number        = 2,
  pages         = {56--69}
}
@article{Politzer:1973fx,
  title         = {Reliable {{Perturbative Results}} for {{Strong Interactions}}?},
  author        = {Politzer, H. David},
  year          = 1973,
  journal       = {Physical Review Letters},
  publisher     = {American Physical Society},
  volume        = 30,
  number        = 26,
  pages         = {1346--1349},
  doi           = {10.1103/PhysRevLett.30.1346},
  urldate       = {2025-07-18},
  abstract      = {An explicit calculation shows perturbation theory to be arbitrarily good for the deep Euclidean Green's functions of any Yang-Mills theory and of many Yang-Mills theories with fermions. Under the hypothesis that spontaneous symmetry breakdown is of dynamical origin, these symmetric Green's functions are the asymptotic forms of the physically significant spontaneously broken solution, whose coupling could be strong.},
  annotation    = {6428 citations (INSPIRE 2025/7/18)\\ 6420 citations w/o self (INSPIRE 2025/7/18)},
  file          = {/Users/t-krishdesai/Zotero/storage/5YNITZSQ/Politzer - 1973 - Reliable Perturbative Results for Strong Interactions.pdf}
}
@article{prassa_bayesian_2025,
  title         = {Bayesian mixture density networks for evaluating neutron-induced fission charge yields},
  author        = {Prassa, Vaia},
  year          = 2025,
  month         = jul,
  journal       = {Physical Review C},
  volume        = 112,
  number        = 1,
  pages         = {014607},
  doi           = {10.1103/gd8l-zzmy},
  url           = {https://link.aps.org/doi/10.1103/gd8l-zzmy},
  urldate       = {2025-07-15},
  note          = {Publisher: American Physical Society},
  abstract      = {Background: Predicting neutron-induced fission charge yields poses substantial challenges due to the complex, nonequilibrium nature of the fission process and the limited availability of detailed experimental data over a broad range of energies. Reliable modeling is essential for applications in reactor engineering, isotope production, and fundamental nuclear physics.}
}
@article{Qu2020ParticleNet:Clouds,
  title         = {ParticleNet: Jet Tagging via Particle Clouds},
  author        = {Qu, Huilin and Gouskos, Loukas},
  year          = 2020,
  month         = 3,
  journal       = {Physical Review D},
  publisher     = {American Physical Society},
  volume        = 101,
  number        = 5,
  doi           = {10.1103/PhysRevD.101.056019},
  url           = {http://arxiv.org/abs/1902.08570 http://dx.doi.org/10.1103/PhysRevD.101.056019},
  arxivid       = {1902.08570v3}
}
@article{Qu2022ParticleTagging,
  title         = {Particle Transformer for Jet Tagging},
  author        = {Qu, Huilin and Li, Congqiao and Qian, Sitian},
  year          = 2022,
  month         = 2,
  journal       = {Proceedings of Machine Learning Research},
  publisher     = {ML Research Press},
  volume        = 162,
  pages         = {18281--18292},
  issn          = 26403498,
  url           = {https://arxiv.org/pdf/2202.03772},
  arxivid       = {2202.03772}
}
@misc{QuantumAssessment,
  title         = {{Quantum Field Theory and the Standard Model \vert{} Cambridge University Press {\&} Assessment}},
  url           = {https://www.cambridge.org/us/universitypress/subjects/physics/theoretical-physics-and-mathematical-physics/quantum-field-theory-and-standard-model}
}
@article{raissi_physics-informed_2019,
  title         = {Physics-informed neural networks: {A} deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
  shorttitle    = {Physics-informed neural networks},
  author        = {Raissi, M. and Perdikaris, P. and Karniadakis, G. E.},
  year          = 2019,
  month         = feb,
  journal       = {Journal of Computational Physics},
  volume        = 378,
  pages         = {686--707},
  doi           = {10.1016/j.jcp.2018.10.045},
  issn          = {0021-9991},
  url           = {https://www.sciencedirect.com/science/article/pii/S0021999118307125},
  urldate       = {2025-07-15},
  abstract      = {We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge–Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction–diffusion systems, and the propagation of nonlinear shallow-water waves.},
  keywords      = {Data-driven scientific computing, Machine learning, Nonlinear dynamics, Predictive modeling, Runge–Kutta methods}
}
@article{Ramachandran2017SearchingFunctions,
  title         = {Searching for Activation Functions},
  author        = {Ramachandran, Prajit and Zoph, Barret and Le Google Brain, Quoc V},
  year          = 2017,
  month         = 10,
  journal       = {6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings},
  publisher     = {International Conference on Learning Representations, ICLR},
  url           = {https://arxiv.org/pdf/1710.05941},
  arxivid       = {1710.05941}
}
@article{Rezende2015VariationalFlows,
  title         = {Variational Inference with Normalizing Flows},
  author        = {Rezende, Danilo Jimenez and Mohamed, Shakir},
  year          = 2015,
  month         = 5,
  journal       = {32nd International Conference on Machine Learning, ICML 2015},
  publisher     = {International Machine Learning Society (IMLS)},
  volume        = 2,
  pages         = {1530--1538},
  isbn          = 9781510810587,
  url           = {https://arxiv.org/pdf/1505.05770},
  arxivid       = {1505.05770}
}
@article{richardson_bayesian-based_1972,
  title         = {Bayesian-{Based} {Iterative} {Method} of {Image} {Restoration}\textasteriskcentered},
  author        = {Richardson, William Hadley},
  year          = 1972,
  month         = jan,
  journal       = {Josa},
  volume        = 62,
  number        = 1,
  pages         = {55--59},
  doi           = {10.1364/josa.62.000055},
  url           = {https://opg.optica.org/josa/abstract.cfm?uri=josa-62-1-55},
  urldate       = {2025-07-13},
  copyright     = {\textcopyright{} 1972 Optical Society of America},
  note          = {Publisher: Optica Publishing Group},
  abstract      = {An iterative method of restoring degraded images was developed by treating images, point spread functions, and degraded images as probability-frequency functions and by applying Bayes's theorem. The method functions effectively in the presence of noise and is adaptable to computer operation.},
  language      = {En},
  keywords      = {Crosstalk, Deconvolution, Image processing, Image restoration, Imaging techniques, Point spread function}
}
@article{rodriguez_entropic_2002,
  title         = {Entropic priors for discrete probabilistic networks and for mixtures of {Gaussians} models},
  author        = {Rodriguez, C. C.},
  year          = 2002,
  month         = may,
  journal       = {AIP Conference Proceedings},
  volume        = 617,
  number        = 1,
  pages         = {410--432},
  doi           = {10.1063/1.1477063},
  issn          = {0094-243x},
  url           = {https://doi.org/10.1063/1.1477063},
  urldate       = {2025-07-14},
  abstract      = {The ongoing unprecedented exponential explosion of available computing power, has radically transformed the methods of statistical inference. What used to be a small minority of statisticians advocating for the use of priors and a strict adherence to bayes theorem, it is now becoming the norm across disciplines. The evolutionary direction is now clear. The trend is towards more realistic, flexible and complex likelihoods characterized by an ever increasing number of parameters. This makes the old question of: What should the prior be? to acquire a new central importance in the modern bayesian theory of inference. Entropic priors provide one answer to the problem of prior selection. The general definition of an entropic prior has existed since 1988 [1], but it was not until 1998 [2] that it was found that they provide a new notion of complete ignorance. This paper re-introduces the family of entropic priors as minimizers of mutual information between the data and the parameters, as in [2], but with a small change and a correction. The general formalism is then applied to two large classes of models: Discrete probabilistic networks and univariate finite mixtures of gaussians. It is also shown how to perform inference by efficiently sampling the corresponding posterior distributions.}
}
@article{rogachev_gan_2023,
  title         = {{GAN} with an {Auxiliary} {Regressor} for the {Fast} {Simulation} of the {Electromagnetic} {Calorimeter} {Response}},
  author        = {Rogachev, Alexander and Ratnikov, Fedor},
  year          = 2023,
  month         = feb,
  journal       = {Journal of Physics: Conference Series},
  volume        = 2438,
  number        = 1,
  pages         = {012086},
  doi           = {10.1088/1742-6596/2438/1/012086},
  issn          = {1742-6588, 1742-6596},
  url           = {http://arxiv.org/abs/2207.06329},
  urldate       = {2025-07-17},
  note          = {arXiv:2207.06329 [physics]},
  abstract      = {High energy physics experiments essentially rely on simulated data for physics analyses. However, running detailed simulation models requires a tremendous amount of computation resources. New approaches to speed up detector simulation are therefore needed. The generation of calorimeter responses is often the most expensive component of the simulation chain for HEP experiments. It was shown that deep learning techniques, especially Generative Adversarial Networks, may be used to reproduce the calorimeter response. However, those applications are challenging, as the generated responses need evaluation not only in terms of image consistency: different physics-based quality metrics should be also taken into consideration. In our work, we develop a multitask GAN-based framework with the goal to speed up the response generation of the Electromagnetic Calorimeter (ECAL) of the LHCb detector at LHC. We introduce the Auxiliary Regressor as a second task to evaluate a proxy metric of the given input that is used by the Discriminator of the GAN. We show that this approach improves the stability of GAN and the model produces samples with better physics distributions.},
  keywords      = {High Energy Physics - Experiment, Physics - Data Analysis, Statistics and Probability}
}
@inproceedings{rubner_metric_1998,
  title         = {A metric for distributions with applications to image databases},
  author        = {Rubner, Y. and Tomasi, C. and Guibas, L.J.},
  year          = 1998,
  month         = jan,
  booktitle     = {Sixth {International} {Conference} on {Computer} {Vision}},
  pages         = {59--66},
  doi           = {10.1109/iccv.1998.710701},
  url           = {https://ieeexplore.ieee.org/document/710701},
  urldate       = {2025-07-14},
  abstract      = {We introduce a new distance between two distributions that we call the Earth Mover's Distance (EMD), which reflects the minimal amount of work that must be performed to transform one distribution into the other by moving "distribution mass" around. This is a special case of the transportation problem from linear optimization, for which efficient algorithms are available. The EMD also allows for partial matching. When used to compare distributions that have the same overall mass, the EMD is a true metric, and has easy-to-compute lower bounds. In this paper we focus on applications to image databases, especially color and texture. We use the EMD to exhibit the structure of color-distribution and texture spaces by means of Multi-Dimensional Scaling displays. We also propose a novel approach to the problem of navigating through a collection of color images, which leads to a new paradigm for image database search.},
  keywords      = {Application software, Computer displays, Computer science, Frequency, Geoscience, Histograms, Image databases, Image retrieval, Navigation, Psychology}
}
@misc{ruder_overview_2017,
  title         = {An overview of gradient descent optimization algorithms},
  author        = {Ruder, Sebastian},
  year          = 2017,
  month         = jun,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1609.04747},
  url           = {http://arxiv.org/abs/1609.04747},
  urldate       = {2025-07-15},
  note          = {arXiv:1609.04747 [cs]},
  abstract      = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
  keywords      = {Computer Science - Machine Learning}
}
@article{salam_elements_2011,
  title         = {Elements of {QCD} for hadron colliders},
  author        = {Salam, Gavin P.},
  year          = 2011,
  month         = jan,
  doi           = {10.48550/arXiv.1011.5131},
  url           = {http://arxiv.org/abs/1011.5131},
  urldate       = {2025-07-18},
  note          = {arXiv:1011.5131 [hep-ph]},
  abstract      = {The aim of these lectures is to provide (experimental particle physics Ph.D.) students with an introduction to some of the core concepts and methods of QCD that are relevant in an LHC context.},
  keywords      = {High Energy Physics - Experiment, High Energy Physics - Phenomenology}
}
@article{Salam:1980jd,
  title         = {Gauge Unification of Fundamental Forces},
  author        = {Salam, Abdus},
  year          = 1980,
  journal       = {Rev. Mod. Phys.},
  volume        = 52,
  pages         = {525--538},
  doi           = {10.1103/RevModPhys.52.525},
  editor        = {Ali, A. and Isham, C. and Kibble, T. and Riazuddin},
  reportnumber  = {Ic-80-28}
}
@article{salamElementsQCDHadron2011,
  title         = {Elements of {{QCD}} for Hadron Colliders},
  author        = {Salam, Gavin P.},
  year          = 2011,
  month         = jan,
  doi           = {10.48550/arXiv.1011.5131},
  urldate       = {2025-07-18},
  eprint        = {1011.5131},
  primaryclass  = {hep-ph},
  abstract      = {The aim of these lectures is to provide (experimental particle physics Ph.D.) students with an introduction to some of the core concepts and methods of QCD that are relevant in an LHC context.},
  archiveprefix = {arXiv},
  keywords      = {High Energy Physics - Experiment,High Energy Physics - Phenomenology}
}
@misc{salimans_improved_2016,
  title         = {Improved {Techniques} for {Training} {GANs}},
  author        = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  year          = 2016,
  month         = jun,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1606.03498},
  url           = {http://arxiv.org/abs/1606.03498},
  urldate       = {2025-07-17},
  note          = {arXiv:1606.03498 [cs]},
  abstract      = {We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. We focus on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3\%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing}
}
@article{Santos2022AvoidingNetworks,
  title         = {Avoiding Overfitting: A Survey on Regularization Methods for Convolutional Neural Networks},
  author        = {Santos, Claudio Filipi Gon\c{c}alves dos and Papa, Jo\~{a}o Paulo},
  year          = 2022,
  month         = 1,
  journal       = {ACM Computing Surveys},
  publisher     = {Association for Computing Machinery},
  volume        = 54,
  number        = {10 s},
  doi           = {10.1145/3510413},
  url           = {http://arxiv.org/abs/2201.03299 http://dx.doi.org/10.1145/3510413},
  arxivid       = {2201.03299v1},
  keywords      = {Regularization, convolutional neural networks}
}
@article{Sauer2023MeasurementCollider,
  title         = {{Measurement of the Triple-Differential Cross-Section for the Production of Multijet Events using 139 fb{\^{}}{\{}-1{\}} of Proton-Proton Collision Data at {\textbackslash}sqrt{\{}s{\}} = 13 TeV with the ATLAS Detector to Disentangle Quarks and Gluons at the Large Hadron Collider}},
  author        = {Sauer, Christof},
  year          = 2023,
  doi           = {10.11588/heidok.00033941},
  keywords      = {530, 530 Physics, ddc}
}
@article{schmitt_data_2017,
  title         = {Data {Unfolding} {Methods} in {High} {Energy} {Physics}},
  author        = {Schmitt, Stefan},
  year          = 2017,
  journal       = {EPJ Web Conf.},
  volume        = 137,
  pages         = 11008,
  doi           = {10.1051/epjconf/201713711008},
  note          = {\_eprint: 1611.01927},
  editor        = {Foka, Y. and Brambilla, N. and Kovalenko, V.},
  keywords      = {BETA, data analysis method, mathematical methods, statistical analysis, statistics}
}
@article{schmitt_tunfold_2012,
  title         = {{TUnfold}: an algorithm for correcting migration effects in high energy physics},
  shorttitle    = {TUnfold},
  author        = {Schmitt, Stefan},
  year          = 2012,
  journal       = {Jinst},
  volume        = 7,
  pages         = {T10003},
  doi           = {10.1088/1748-0221/7/10/t10003},
  note          = {\_eprint: 1205.6201},
  keywords      = {BETA, background, numerical methods, regularization, statistical}
}
@article{Schmitt2017DataPhysics,
  title         = {Data Unfolding Methods in High Energy Physics},
  author        = {Schmitt, Stefan},
  year          = 2017,
  month         = 3,
  journal       = {EPJ Web of Conferences},
  publisher     = {EDP Sciences},
  volume        = 137,
  pages         = 11008,
  doi           = {10.1051/epjconf/201713711008},
  issn          = {2100-014x},
  url           = {https://www.epj-conferences.org/articles/epjconf/abs/2017/06/epjconf_conf2017_11008/epjconf_conf2017_11008.html},
  arxivid       = {1611.01927},
  keywords      = {EPJ, The European Physical Journal, astronomy, conference, physics, proceedings}
}
@article{Schoeffel:1998tz,
  title         = {An Elegant and Fast Method to Solve {{QCD}} Evolution Equations. {{Application}} to the Determination of the Gluon Content of the {{Pomeron}}},
  author        = {Schoeffel, Laurent},
  year          = 1999,
  journal       = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  volume        = 423,
  number        = 2,
  pages         = {439--445},
  doi           = {10.1016/s0168-9002(98)01316-3},
  issn          = {0168-9002},
  urldate       = {2025-07-18},
  abstract      = {We present an original implementation of a very elegant method to solve Q 2 evolution equations of perturbative QCD at NLO: the Dokshitzer--Gribov--Lipatov--Altarelli--Parisi (DGLAP) equations. Based on a seminal idea of Furmanski and Petronzio, our numerical treatment consists in expanding parton distributions and splitting functions on Laguerre polynomials, which reduces DGLAP integro-differential equations to a set of ordinary differential equations defined by recurrence. Then, we apply our evolution method to determine the gluon content of the Pomeron by realizing QCD fits on diffractive structure function.},
  annotation    = {28 citations (INSPIRE 2025/7/18)\\ 24 citations w/o self (INSPIRE 2025/7/18)\\ Citations: 24 (Crossref) [2025-07-18]\\ Citations: 27 (SemanticScholar) [2025-07-18]},
  file          = {/Users/t-krishdesai/Zotero/storage/EYQ9VT7K/Schoeffel - 1999 - An elegant and fast method to solve QCD evolution equations. Application to the determination of the.pdf;/Users/t-krishdesai/Zotero/storage/JX32SVBU/S0168900298013163.html}
}
@article{dokshitzerCalculationStructureFunctions1977,
    author = "Dokshitzer, Yuri L.",
    title = "{Calculation of the Structure Functions for Deep Inelastic Scattering and e+ e- Annihilation by Perturbation Theory in Quantum Chromodynamics.}",
    journal = "Sov. Phys. JETP",
    volume = "46",
    pages = "641--653",
    year = "1977"
}
@article{gribovDeepInelasticEp1972,
    author = "Gribov, V. N. and Lipatov, L. N.",
    title = "{Deep inelastic e p scattering in perturbation theory}",
    reportNumber = "IPTI-381-71",
    journal = "Sov. J. Nucl. Phys.",
    volume = "15",
    pages = "438--450",
    year = "1972"
}
@article{Segura2024APhysics,
  title         = {A Practical Guide to Statistical Techniques in Particle Physics},
  author        = {Segura, Alejandro and Parra, Angie Catalina},
  year          = 2024,
  month         = 11,
  url           = {http://arxiv.org/abs/2411.00706},
  arxivid       = {2411.00706v1},
  keywords      = {Exclusion models, Experimental sensitivity, Hypothesis testing, P-value, Physical models, Statistical models}
}
@article{sforza_support_2013,
  title         = {Support vector machine classification on a biased training set: {Multi}-jet background rejection at hadron colliders},
  shorttitle    = {Support vector machine classification on a biased training set},
  author        = {Sforza, Federico and Lippi, Vittorio},
  year          = 2013,
  month         = sep,
  journal       = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  volume        = 722,
  pages         = {11--19},
  doi           = {10.1016/j.nima.2013.04.046},
  issn          = {0168-9002},
  url           = {https://www.sciencedirect.com/science/article/pii/S0168900213004671},
  urldate       = {2025-07-17},
  abstract      = {This paper describes an innovative way to optimize a multivariate classifier, a Support Vector Machine algorithm, on a problem characterized by a biased training sample. This is possible thanks to the feedback of a signal-background template fit performed on a validation sample and included both in the optimization process and in the input variable selection. The procedure is applied to a real case of interest at hadron collider experiments: the reduction and the estimate of the multi-jet background in the W\rightarrow{}e\ensuremath{\nu} plus jets data sample collected by the CDF experiment. The training samples, partially derived from data and partially from simulation, are described in detail together with the input variables exploited for the classification. At present, the reached performance is better than any other prescription applied to the same final state at hadron collider experiments.},
  keywords      = {CDF, Lepton plus jets, Multi-jet rejection, Multivariate analysis, SVM}
}
@article{shah_inverse_2016,
  title         = {Inverse {Scattering} {Using} a {Joint} {L1}-{L2} {Norm}-{Based} {Regularization}},
  author        = {Shah, Pratik and Khankhoje, Uday K. and Moghaddam, Mahta},
  year          = 2016,
  month         = apr,
  journal       = {IEEE Transactions on Antennas and Propagation},
  volume        = 64,
  number        = 4,
  pages         = {1373--1384},
  doi           = {10.1109/tap.2016.2529641},
  issn          = {1558-2221},
  url           = {https://ieeexplore.ieee.org/document/7406678},
  urldate       = {2025-07-15},
  abstract      = {Inverse scattering problems suffer from ill-posedness and ill-conditioning, necessitating the use of regularization methods to get meaningful solutions. Commonly used regularizations are L2 norm based, but these generate over-smooth solutions. We propose a regularization method using both the L1 and L2 norms to obtain sharp object boundaries, while also achieving good interior reconstruction of the object permittivity. Knowledge about the permittivity can also be used as a priori information. The applicability of the method is demonstrated on synthetically generated data for two-dimensional (2-D) microwave imaging using the Born-iterative method (BIM). The optimization routine systematically estimates all parameters, while minimizing the cost function. Different objects chosen to represent realistic features have been considered to evaluate the performance. The reconstructed images indicate that the method can produce accurate object localization, shape identification, and good permittivity estimation.},
  keywords      = {Born iterative method, Born-iterative method (BIM), Compressed sensing, Conductivity, Dielectrics, Imaging, Inverse problems, Permittivity, Scattering, compressive sensing, electromagnetic tomography, inverse problems, inverse scattering, microwave imaging, regularization}
}
@book{shannon-weaver,
  title         = {The Mathematical Theory of Communication},
  author        = {Claude E. Shannon and Warren Weaver},
  year          = 1949,
  publisher     = {University of Illinois Press},
  address       = {Urbana, Chicago, and London}
}
@article{shepp_maximum_1982,
  title         = {Maximum {Likelihood} {Reconstruction} for {Emission} {Tomography}},
  author        = {Shepp, L. A. and Vardi, Y.},
  year          = 1982,
  month         = oct,
  journal       = {IEEE Transactions on Medical Imaging},
  volume        = 1,
  number        = 2,
  pages         = {113--122},
  doi           = {10.1109/tmi.1982.4307558},
  issn          = {1558-254x},
  url           = {https://ieeexplore.ieee.org/document/4307558},
  urldate       = {2025-07-13},
  abstract      = {Previous models for emission tomography (ET) do not distinguish the physics of ET from that of transmission tomography. We give a more accurate general mathematical model for ET where an unknown emission density \ensuremath{\lambda} = \ensuremath{\lambda}(x, y, z) generates, and is to be reconstructed from, the number of counts n\textasteriskcentered(d) in each of D detector units d. Within the model, we give an algorithm for determining an estimate \ensuremath{\lambda} of \ensuremath{\lambda} which maximizes the probability p(n\textasteriskcentered{\textbar}\ensuremath{\lambda}) of observing the actual detector count data n\textasteriskcentered over all possible densities \ensuremath{\lambda}. Let independent Poisson variables n(b) with unknown means \ensuremath{\lambda}(b), b = 1, \cdot{}\cdot{}\cdot{}, B represent the number of unobserved emissions in each of B boxes (pixels) partitioning an object containing an emitter. Suppose each emission in box b is detected in detector unit d with probability p(b, d), d = 1, \cdot{}\cdot{}\cdot{}, D with p(b, d) a one-step transition matrix, assumed known. We observe the total number n\textasteriskcentered = n\textasteriskcentered(d) of emissions in each detector unit d and want to estimate the unknown \ensuremath{\lambda} = \ensuremath{\lambda}(b), b = 1, \cdot{}\cdot{}\cdot{}, B. For each \ensuremath{\lambda}, the observed data n\textasteriskcentered has probability or likelihood p(n\textasteriskcentered{\textbar}\ensuremath{\lambda}). The EM algorithm of mathematical statistics starts with an initial estimate \ensuremath{\lambda}0 and gives the following simple iterative procedure for obtaining a new estimate \ensuremath{\lambda}new, from an old estimate \ensuremath{\lambda}old, to obtain \ensuremath{\Sigma}k, k = 1, 2, \cdot{}\cdot{}\cdot{}, \ensuremath{\lambda}new(b)= \ensuremath{\lambda}old(b) \ensuremath{\lambda}Dd=1 n\textasteriskcentered(d)p(b,d)/\ensuremath{\Sigma}\ensuremath{\lambda}old(b\ensuremath{\Sigma})p(b\ensuremath{\lambda},d),b=1,\cdot{}\cdot{}\cdot{}B.},
  keywords      = {Detectors, Iterative algorithms, Mathematical model, Maximum likelihood detection, Maximum likelihood estimation, Object detection, Physics, Positrons, Probability, Tomography}
}
@misc{shi_pointrcnn_2019,
  title         = {{PointRCNN}: {3D} {Object} {Proposal} {Generation} and {Detection} from {Point} {Cloud}},
  shorttitle    = {PointRCNN},
  author        = {Shi, Shaoshuai and Wang, Xiaogang and Li, Hongsheng},
  year          = 2019,
  month         = may,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1812.04244},
  url           = {http://arxiv.org/abs/1812.04244},
  urldate       = {2025-07-15},
  note          = {arXiv:1812.04244 [cs]},
  abstract      = {In this paper, we propose PointRCNN for 3D object detection from raw point cloud. The whole framework is composed of two stages: stage-1 for the bottom-up 3D proposal generation and stage-2 for refining proposals in the canonical coordinates to obtain the final detection results. Instead of generating proposals from RGB image or projecting point cloud to bird's view or voxels as previous methods do, our stage-1 sub-network directly generates a small number of high-quality 3D proposals from point cloud in a bottom-up manner via segmenting the point cloud of the whole scene into foreground points and background. The stage-2 sub-network transforms the pooled points of each proposal to canonical coordinates to learn better local spatial features, which is combined with global semantic features of each point learned in stage-1 for accurate box refinement and confidence prediction. Extensive experiments on the 3D detection benchmark of KITTI dataset show that our proposed architecture outperforms state-of-the-art methods with remarkable margins by using only point cloud as input. The code is available at https://github.com/sshaoshuai/PointRCNN.},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition}
}
@article{Shlomi2020GraphPhysics,
  title         = {Graph Neural Networks in Particle Physics},
  author        = {Shlomi, Jonathan and Battaglia, Peter and Vlimant, Jean-Roch},
  year          = 2020,
  month         = 10,
  journal       = {Machine Learning: Science and Technology},
  publisher     = {IOP Publishing},
  volume        = 2,
  number        = 2,
  pages         = {021001},
  doi           = {10.1088/2632-2153/abbf9a},
  url           = {http://arxiv.org/abs/2007.13681 http://dx.doi.org/10.1088/2632-2153/abbf9a},
  arxivid       = {2007.13681v2}
}
@article{Shmakov2025FullDiffusion,
  title         = {Full Event Particle-Level Unfolding with Variable-Length Latent Variational Diffusion},
  author        = {Shmakov, Alexander and Greif, Kevin and Fenton, Michael James and Ghosh, Aishik and Baldi, Pierre and Whiteson, Daniel},
  year          = 2025,
  month         = 1,
  journal       = {SciPost Physics},
  publisher     = {SciPost Foundation},
  volume        = 18,
  number        = 4,
  doi           = {10.21468/SciPostPhys.18.4.117},
  url           = {http://arxiv.org/abs/2404.14332 http://dx.doi.org/10.21468/SciPostPhys.18.4.117},
  arxivid       = {2404.14332v3}
}
@article{Simonelli:2024vyh,
  title         = {Analytic {{Solutions}} of the {{DGLAP Evolution}} and {{Theoretical Uncertainties}}},
  author        = {Simonelli, Andrea},
  year          = 2024,
  month         = aug,
  volume        = 84,
  number        = 8,
  pages         = 867,
  doi           = {10.1140/epjc/s10052-024-13169-8},
  urldate       = {2025-07-18},
  eprint        = {2401.13663},
  primaryclass  = {hep-ph},
  abstract      = {The energy dependence for the singlet sector of Parton Distributions Functions (PDFs) is described by an entangled pair of ordinary linear differential equations. Although there are no exact analytic solutions, it is possible to provide approximated results depending on the assumptions and the methodology adopted. These results differ in their sub-leading, neglected terms and ultimately they are associated with different treatments of the theoretical uncertainties. In this work, a novel analytic approach in Mellin space is presented and a new methodology for obtaining closed and exponentiated analytic solutions is devised. Different results for the DGLAP evolution at Next-Lowest-Order are compared, discussing advantages and disadvantages for each solution. The generalizations to higher orders are addressed.},
  archiveprefix = {arXiv},
  keywords      = {High Energy Physics - Phenomenology},
  annotation    = {4 citations (INSPIRE 2025/7/18)\\ 4 citations w/o self (INSPIRE 2025/7/18)\\ Citations: 0 (SemanticScholar) [2025-07-18]},
  file          = {/Users/t-krishdesai/Zotero/storage/PWJRWPTG/Simonelli - 2024 - Analytic Solutions of the DGLAP Evolution and Theoretical Uncertainties.pdf;/Users/t-krishdesai/Zotero/storage/YHKPD29Y/2401.html}
}
@article{Sirunyan_2020,
  title         = {Identification of heavy, energetic, hadronically decaying particles using  machine-learning techniques},
  author        = {Sirunyan, A.M. and Tumasyan, A. and Adam, W. and Ambrogi, F. and Bergauer, T. and Dragicevic, M. and Er\"{o}, J. and Valle, A. Escalante Del and Flechl, M. and Fr\"{u}hwirth, R. and Jeitler, M. and Krammer, N. and Kr\"{a}tschmer, I. and Liko, D. and Madlener, T. and Mikulec, I. and Rad, N. and Schieck, J. and Sch\"{o}fbeck, R. and Spanring, M. and Waltenberger, W. and Wulz, C.-E. and Zarucki, M. and Drugakov, V. and Mossolov, V. and Gonzalez, J. Suarez and Darwish, M.R. and Wolf, E.A. De and Croce, D. Di and Janssen, X. and Lelek, A. and Pieters, M. and Sfar, H. Rejeb and Haevermaet, H. Van and Mechelen, P. Van and Putte, S. Van and Remortel, N. Van and Blekman, F. and Bols, E.S. and Chhibra, S.S. and D'Hondt, J. and Clercq, J. De and Lontkovskyi, D. and Lowette, S. and Marchesini, I. and Moortgat, S. and Python, Q. and Skovpen, K. and Tavernier, S. and Doninck, W. Van and Mulders, P. Van and Beghin, D. and Bilin, B. and Clerbaux, B. and Lentdecker, G. De and Delannoy, H. and Dorney, B. and Favart, L. and Grebenyuk, A. and Kalsi, A.K. and Moureaux, L. and Popov, A. and Postiau, N. and Starling, E. and Thomas, L. and Velde, C. Vander and Vanlaer, P. and Vannerom, D. and Cornelis, T. and Dobur, D. and Khvastunov, I. and Niedziela, M. and Roskas, C. and Tytgat, M. and Verbeke, W. and Vermassen, B. and Vit, M. and Bondu, O. and Bruno, G. and Caputo, C. and David, P. and Delaere, C. and Delcourt, M. and Giammanco, A. and Lemaitre, V. and Prisciandaro, J. and Saggio, A. and Marono, M. Vidal and Vischia, P. and Zobec, J. and Alves, F.L. and Alves, G.A. and Silva, G. Correia and Hensel, C. and Moraes, A. and Teles, P. Rebello and Chagas, E. Belchior Batista Das and Carvalho, W. and Chinellato, J. and Coelho, E. and Costa, E.M. Da and Silveira, G.G. Da and Damiao, D. De Jesus and Martins, C. De Oliveira and Souza, S. Fonseca De and Guativa, L.M. Huertas and Malbouisson, H. and Martins, J. and Figueiredo, D. Matos and Jaime, M. Medina and Almeida, M. Melo De and Herrera, C. Mora and Mundim, L. and Nogima, H. and Silva, W.L. Prado Da and Rosas, L.J. Sanchez and Santoro, A. and Sznajder, A. and Thiel, M. and Manganote, E.J. Tonelli and Araujo, F. Torres Da Silva De and Pereira, A. Vilela and Bernardes, C.A. and Calligaris, L. and Tomei, T.R. Fernandez Perez and Gregores, E.M. and Lemos, D.S. and Mercadante, P.G. and Novaes, S.F. and Padula, SandraS. and Aleksandrov, A. and Antchev, G. and Hadjiiska, R. and Iaydjiev, P. and Misheva, M. and Rodozov, M. and Shopova, M. and Sultanov, G. and Bonchev, M. and Dimitrov, A. and Ivanov, T. and Litov, L. and Pavlov, B. and Petkov, P. and Petrov, A. and Fang, W. and Gao, X. and Yuan, L. and Ahmad, M. and Hu, Z. and Wang, Y. and Chen, G.M. and Chen, H.S. and Chen, M. and Jiang, C.H. and Leggat, D. and Liao, H. and Liu, Z. and Spiezia, A. and Tao, J. and Yazgan, E. and Zhang, H. and Zhang, S. and Zhao, J. and Agapitos, A. and Ban, Y. and Chen, G. and Levin, A. and Li, J. and Li, L. and Li, Q. and Mao, Y. and Qian, S.J. and Wang, D. and Wang, Q. and Xiao, M. and Avila, C. and Cabrera, A. and Florez, C. and Hern\'{a}ndez, C.F. Gonz\'{a}lez and Delgado, M.A. Segura and Guisao, J. Mejia and Alvarez, J.D. Ruiz and Gonz\'{a}lez, C.A. Salazar and Arbelaez, N. Vanegas and Giljanovi\'{c}, D. and Godinovic, N. and Lelas, D. and Puljak, I. and Sculac, T. and Antunovic, Z. and Kovac, M. and Brigljevic, V. and Ferencek, D. and Kadija, K. and Mesic, B. and Roguljic, M. and Starodumov, A. and Susa, T. and Ather, M.W. and Attikis, A. and Erodotou, E. and Ioannou, A. and Kolosova, M. and Konstantinou, S. and Mavromanolakis, G. and Mousa, J. and Nicolaou, C. and Ptochos, F. and Razis, P.A. and Rykaczewski, H. and Tsiakkouri, D. and Finger, M. and Jr., M. Finger and Kveton, A. and Tomsa, J. and Ayala, E. and Jarrin, E. Carrera and Abdalla, H. and Khalil, S. and Bhowmik, S. and Oliveira, A. Carvalho Antunes De and Dewanjee, R.K. and Ehataht, K. and Kadastik, M. and Raidal, M. and Veelken, C. and Eerola, P. and Forthomme, L. and Kirschenmann, H. and Osterberg, K. and Voutilainen, M. and Garcia, F. and Havukainen, J. and Heikkil\"{a}, J.K. and Karim\"{a}ki, V. and Kim, M.S. and Kinnunen, R. and Lamp\'{e}n, T. and Lassila-Perini, K. and Laurila, S. and Lehti, S. and Lind\'{e}n, T. and Luukka, P. and M\"{a}enp\"{a}\"{a}, T. and Siikonen, H. and Tuominen, E. and Tuominiemi, J. and Tuuva, T. and Besancon, M. and Couderc, F. and Dejardin, M. and Denegri, D. and Fabbro, B. and Faure, J.L. and Ferri, F. and Ganjour, S. and Givernaud, A. and Gras, P. and de Monchenault, G. Hamel and Jarry, P. and Leloup, C. and Lenzi, B. and Locci, E. and Malcles, J. and Rander, J. and Rosowsky, A. and Sahin, M.\"{O}. and Savoy-Navarro, A. and Titov, M. and Yu, G.B. and Ahuja, S. and Amendola, C. and Beaudette, F. and Busson, P. and Charlot, C. and Diab, B. and Falmagne, G. and de Cassagnac, R. Granier and Kucher, I. and Lobanov, A. and Perez, C. Martin and Nguyen, M. and Ochando, C. and Paganini, P. and Rembser, J. and Salerno, R. and Sauvan, J.B. and Sirois, Y. and Zabi, A. and Zghiche, A. and Agram, J.-L. and Andrea, J. and Bloch, D. and Bourgatte, G. and Brom, J.-M. and Chabert, E.C. and Collard, C. and Conte, E. and Fontaine, J.-C. and Gel\'{e}, D. and Goerlach, U. and Jansov\'{a}, M. and Bihan, A.-C. Le and Tonon, N. and Hove, P. Van and Gadrat, S. and Beauceron, S. and Bernet, C. and Boudoul, G. and Camen, C. and Carle, A. and Chanon, N. and Chierici, R. and Contardo, D. and Depasse, P. and Mamouni, H. El and Fay, J. and Gascon, S. and Gouzevitch, M. and Ille, B. and Jain, Sa. and Lagarde, F. and Laktineh, I.B. and Lattaud, H. and Lesauvage, A. and Lethuillier, M. and Mirabito, L. and Perries, S. and Sordini, V. and Torterotot, L. and Touquet, G. and Donckt, M. Vander and Viret, S. and Toriashvili, T. and Bagaturia, I. and Autermann, C. and Feld, L. and Klein, K. and Lipinski, M. and Meuser, D. and Pauls, A. and Preuten, M. and Rauch, M.P. and Schulz, J. and Teroerde, M. and Wittmer, B. and Erdmann, M. and Fischer, B. and Ghosh, S. and Hebbeker, T. and Hoepfner, K. and Keller, H. and Mastrolorenzo, L. and Merschmeyer, M. and Meyer, A. and Millet, P. and Mocellin, G. and Mondal, S. and Mukherjee, S. and Noll, D. and Novak, A. and Pook, T. and Pozdnyakov, A. and Quast, T. and Radziej, M. and Rath, Y. and Reithler, H. and Roemer, J. and Schmidt, A. and Schuler, S.C. and Sharma, A. and Wiedenbeck, S. and Zaleski, S. and Fl\"{u}gge, G. and Ahmad, W. Haj and Hlushchenko, O. and Kress, T. and M\"{u}ller, T. and Nowack, A. and Pistone, C. and Pooth, O. and Roy, D. and Sert, H. and Stahl, A. and Martin, M. Aldaya and Asmuss, P. and Babounikau, I. and Bakhshiansohi, H. and Beernaert, K. and Behnke, O. and Mart\'{\i}nez, A. Berm\'{u}dez and Bertsche, D. and Anuar, A.A. Bin and Borras, K. and Botta, V. and Campbell, A. and Cardini, A. and Connor, P. and Rodr\'{\i}guez, S. Consuegra and Contreras-Campana, C. and Danilov, V. and Wit, A. De and Defranchis, M.M. and Pardos, C. Diez and Damiani, D. Dom\'{\i}nguez and Eckerlin, G. and Eckstein, D. and Eichhorn, T. and Elwood, A. and Eren, E. and Gallo, E. and Geiser, A. and Grohsjean, A. and Guthoff, M. and Haranko, M. and Harb, A. and Jafari, A. and Jomhari, N.Z. and Jung, H. and Kasem, A. and Kasemann, M. and Kaveh, H. and Keaveney, J. and Kleinwort, C. and Knolle, J. and Kr\"{u}cker, D. and Lange, W. and Lenz, T. and Lidrych, J. and Lipka, K. and Lohmann, W. and Mankel, R. and Melzer-Pellmann, I.-A. and Meyer, A.B. and Meyer, M. and Missiroli, M. and Mnich, J. and Mussgiller, A. and Myronenko, V. and Ad\'{a}n, D. P\'{e}rez and Pflitsch, S.K. and Pitzl, D. and Raspereza, A. and Saibel, A. and Savitskyi, M. and Scheurer, V. and Sch\"{u}tze, P. and Schwanenberger, C. and Shevchenko, R. and Singh, A. and Tholen, H. and Turkot, O. and Vagnerini, A. and Klundert, M. Van De and Walsh, R. and Wen, Y. and Wichmann, K. and Wissing, C. and Zenaiev, O. and Zlebcik, R. and Aggleton, R. and Bein, S. and Benato, L. and Benecke, A. and Blobel, V. and Dreyer, T. and Ebrahimi, A. and Feindt, F. and Fr\"{o}hlich, A. and Garbers, C. and Garutti, E. and Gonzalez, D. and Gunnellini, P. and Haller, J. and Hinzmann, A. and Karavdina, A. and Kasieczka, G. and Klanner, R. and Kogler, R. and Kovalchuk, N. and Kurz, S. and Kutzner, V. and Lange, J. and Lange, T. and Malara, A. and Multhaup, J. and Niemeyer, C.E.N. and Perieanu, A. and Reimers, A. and Rieger, O. and Scharf, C. and Schleper, P. and Schumann, S. and Schwandt, J. and Sonneveld, J. and Stadie, H. and Steinbr\"{u}ck, G. and Stober, F.M. and Vormwald, B. and Zoi, I. and Akbiyik, M. and Barth, C. and Baselga, M. and Baur, S. and Berger, T. and Butz, E. and Caspart, R. and Chwalek, T. and Boer, W. De and Dierlamm, A. and Morabit, K. El and Faltermann, N. and Giffels, M. and Goldenzweig, P. and Gottmann, A. and Harrendorf, M.A. and Hartmann, F. and Husemann, U. and Kudella, S. and Mitra, S. and Mozer, M.U. and M\"{u}ller, D. and M\"{u}ller, Th. and Musich, M. and N\"{u}rnberg, A. and Quast, G. and Rabbertz, K. and Schr\"{o}der, M. and Shvetsov, I. and Simonis, H.J. and Ulrich, R. and Wassmer, M. and Weber, M. and W\"{o}hrmann, C. and Wolf, R. and Wozniewski, S. and Anagnostou, G. and Asenov, P. and Daskalakis, G. and Geralis, T. and Kyriakis, A. and Loukas, D. and Paspalaki, G. and Diamantopoulou, M. and Karathanasis, G. and Kontaxakis, P. and Manousakis-katsikakis, A. and Panagiotou, A. and Papavergou, I. and Saoulidou, N. and Stakia, A. and Theofilatos, K. and Vellidis, K. and Vourliotis, E. and Bakas, G. and Kousouris, K. and Papakrivopoulos, I. and Tsipolitis, G. and Evangelou, I. and Foudas, C. and Gianneios, P. and Katsoulis, P. and Kokkas, P. and Mallios, S. and Manitara, K. and Manthos, N. and Papadopoulos, I. and Strologas, J. and Triantis, F.A. and Tsitsonis, D. and Bart\'{o}k, M. and Chudasama, R. and Csanad, M. and Major, P. and Mandal, K. and Mehta, A. and Nagy, M.I. and Pasztor, G. and Sur\'{a}nyi, O. and Veres, G.I. and Bencze, G. and Hajdu, C. and Horvath, D. and Sikler, F. and V\'{a}mi, T.\'{A}. and Veszpremi, V. and Vesztergombi, G. and Beni, N. and Czellar, S. and Karancsi, J. and Molnar, J. and Szillasi, Z. and Raics, P. and Teyssier, D. and Trocsanyi, Z.L. and Ujvari, B. and Csorgo, T. and Metzger, W.J. and Nemes, F. and Novak, T. and Choudhury, S. and Komaragiri, J.R. and Tiwari, P.C. and Bahinipati, S. and Kar, C. and Kole, G. and Mal, P. and Bindhu, V.K. Muraleedharan Nair and Nayak, A. and Sahoo, D.K. and Swain, S.K. and Bansal, S. and Beri, S.B. and Bhatnagar, V. and Chauhan, S. and Dhingra, N. and Gupta, R. and Kaur, A. and Kaur, M. and Kaur, S. and Kumari, P. and Lohan, M. and Meena, M. and Sandeep, K. and Sharma, S. and Singh, J.B. and Virdi, A.K. and Bhardwaj, A. and Choudhary, B.C. and Garg, R.B. and Gola, M. and Keshri, S. and Kumar, Ashok and Naimuddin, M. and Priyanka, P. and Ranjan, K. and Shah, Aashaq and Sharma, R. and Bhardwaj, R. and Bharti, M. and Bhattacharya, R. and Bhattacharya, S. and Bhawandeep, U. and Bhowmik, D. and Dutta, S. and Ghosh, S. and Gomber, B. and Maity, M. and Mondal, K. and Nandan, S. and Purohit, A. and Rout, P.K. and Saha, G. and Sarkar, S. and Sarkar, T. and Sharan, M. and Singh, B. and Thakur, S. and Behera, P.K. and Kalbhor, P. and Muhammad, A. and Pujahari, P.R. and Sharma, A. and Sikdar, A.K. and Dutta, D. and Jha, V. and Kumar, V. and Mishra, D.K. and Netrakanti, P.K. and Pant, L.M. and Shukla, P. and Aziz, T. and Bhat, M.A. and Dugad, S. and Mohanty, G.B. and Sur, N. and Banerjee, S. and Bhattacharya, S. and Chatterjee, S. and Das, P. and Guchait, M. and Karmakar, S. and Kumar, S. and Majumder, G. and Mazumdar, K. and Sahoo, N. and Sawant, S. and Dube, S. and Kansal, B. and Kapoor, A. and Kothekar, K. and Pandey, S. and Rane, A. and Rastogi, A. and Sharma, S. and Chenarani, S. and Tadavani, E. Eskandari and Etesami, S.M. and Khakzad, M. and Najafabadi, M. Mohammadi and Naseri, M. and Hosseinabadi, F. Rezaei and Felcini, M. and Grunewald, M. and Abbrescia, M. and Aly, R. and Calabria, C. and Colaleo, A. and Creanza, D. and Cristella, L. and Filippis, N. De and Palma, M. De and Florio, A. Di and Elmetenawee, W. and Fiore, L. and Gelmi, A. and Iaselli, G. and Ince, M. and Lezki, S. and Maggi, G. and Maggi, M. and Merlin, J.A. and Miniello, G. and My, S. and Nuzzo, S. and Pompili, A. and Pugliese, G. and Radogna, R. and Ranieri, A. and Selvaggi, G. and Silvestris, L. and Simone, F.M. and Venditti, R. and Verwilligen, P. and Abbiendi, G. and Battilana, C. and Bonacorsi, D. and Borgonovi, L. and Braibant-Giacomelli, S. and Campanini, R. and Capiluppi, P. and Castro, A. and Cavallo, F.R. and Ciocca, C. and Codispoti, G. and Cuffiani, M. and Dallavalle, G.M. and Fabbri, F. and Fanfani, A. and Fontanesi, E. and Giacomelli, P. and Grandi, C. and Guiducci, L. and Iemmi, F. and Meo, S. Lo and Marcellini, S. and Masetti, G. and Navarria, F.L. and Perrotta, A. and Primavera, F. and Rossi, A.M. and Rovelli, T. and Siroli, G.P. and Tosi, N. and Albergo, S. and Costa, S. and Mattia, A. Di and Potenza, R. and Tricomi, A. and Tuve, C. and Barbagli, G. and Cassese, A. and Ceccarelli, R. and Ciulli, V. and Civinini, C. and D'Alessandro, R. and Fiori, F. and Focardi, E. and Latino, G. and Lenzi, P. and Meschini, M. and Paoletti, S. and Sguazzoni, G. and Viliani, L. and Benussi, L. and Bianco, S. and Piccolo, D. and Bozzo, M. and Ferro, F. and Mulargia, R. and Robutti, E. and Tosi, S. and Benaglia, A. and Beschi, A. and Brivio, F. and Ciriolo, V. and Dinardo, M.E. and Dini, P. and Gennai, S. and Ghezzi, A. and Govoni, P. and Guzzi, L. and Malberti, M. and Malvezzi, S. and Menasce, D. and Monti, F. and Moroni, L. and Paganoni, M. and Pedrini, D. and Ragazzi, S. and de Fatis, T. Tabarelli and Valsecchi, D. and Zuolo, D. and Buontempo, S. and Cavallo, N. and Iorio, A. De and Crescenzo, A. Di and Fabozzi, F. and Fienga, F. and Galati, G. and Iorio, A.O.M. and Lista, L. and Meola, S. and Paolucci, P. and Rossi, B. and Sciacca, C. and Voevodina, E. and Azzi, P. and Bacchetta, N. and Bisello, D. and Boletti, A. and Bragagnolo, A. and Carlin, R. and Checchia, P. and Manzano, P. De Castro and Dorigo, T. and Dosselli, U. and Gasparini, F. and Gasparini, U. and Gozzelino, A. and Hoh, S.Y. and Lujan, P. and Margoni, M. and Meneguzzo, A.T. and Pazzini, J. and Presilla, M. and Ronchese, P. and Rossin, R. and Simonetto, F. and Tiko, A. and Tosi, M. and Zanetti, M. and Zotto, P. and Zumerle, G. and Braghieri, A. and Fiorina, D. and Montagna, P. and Ratti, S.P. and Re, V. and Ressegotti, M. and Riccardi, C. and Salvini, P. and Vai, I. and Vitulo, P. and Biasini, M. and Bilei, G.M. and Ciangottini, D. and Fan\`{o}, L. and Lariccia, P. and Leonardi, R. and Manoni, E. and Mantovani, G. and Mariani, V. and Menichelli, M. and Rossi, A. and Santocchia, A. and Spiga, D. and Androsov, K. and Azzurri, P. and Bagliesi, G. and Bertacchi, V. and Bianchini, L. and Boccali, T. and Castaldi, R. and Ciocci, M.A. and Dell'Orso, R. and Donato, S. and Fedi, G. and Giannini, L. and Giassi, A. and Grippo, M.T. and Ligabue, F. and Manca, E. and Mandorli, G. and Messineo, A. and Palla, F. and Rizzi, A. and Rolandi, G. and Chowdhury, S. Roy and Scribano, A. and Spagnolo, P. and Tenchini, R. and Tonelli, G. and Turini, N. and Venturi, A. and Verdini, P.G. and Cavallari, F. and Cipriani, M. and Re, D. Del and Marco, E. Di and Diemoz, M. and Longo, E. and Meridiani, P. and Organtini, G. and Pandolfi, F. and Paramatti, R. and Quaranta, C. and Rahatlou, S. and Rovelli, C. and Santanastasio, F. and Soffi, L. and Amapane, N. and Arcidiacono, R. and Argiro, S. and Arneodo, M. and Bartosik, N. and Bellan, R. and Bellora, A. and Biino, C. and Cappati, A. and Cartiglia, N. and Cometti, S. and Costa, M. and Covarelli, R. and Demaria, N. and Kiani, B. and Legger, F. and Mariotti, C. and Maselli, S. and Migliore, E. and Monaco, V. and Monteil, E. and Monteno, M. and Obertino, M.M. and Ortona, G. and Pacher, L. and Pastrone, N. and Pelliccioni, M. and Angioni, G.L. Pinna and Romero, A. and Ruspa, M. and Salvatico, R. and Sola, V. and Solano, A. and Soldi, D. and Staiano, A. and Trocino, D. and Belforte, S. and Candelise, V. and Casarsa, M. and Cossutti, F. and Rold, A. Da and Ricca, G. Della and Vazzoler, F. and Zanetti, A. and Kim, B. and Kim, D.H. and Kim, G.N. and Lee, J. and Lee, S.W. and Moon, C.S. and Oh, Y.D. and Pak, S.I. and Sekmen, S. and Son, D.C. and Yang, Y.C. and Kim, H. and Moon, D.H. and Oh, G. and Francois, B. and Kim, T.J. and Park, J. and Cho, S. and Choi, S. and Go, Y. and Ha, S. and Hong, B. and Lee, K. and Lee, K.S. and Lim, J. and Park, J. and Park, S.K. and Roh, Y. and Yoo, J. and Goh, J. and Kim, H.S. and Almond, J. and Bhyun, J.H. and Choi, J. and Jeon, S. and Kim, J. and Kim, J.S. and Lee, H. and Lee, K. and Lee, S. and Nam, K. and Oh, M. and Oh, S.B. and Radburn-Smith, B.C. and Yang, U.K. and Yoo, H.D. and Yoon, I. and Jeon, D. and Kim, J.H. and Lee, J.S.H. and Park, I.C. and Choi, Y. and Hwang, C. and Jeong, Y. and Lee, J. and Lee, Y. and Yu, I. and Veckalns, V. and Dudenas, V. and Juodagalvis, A. and Rinkevicius, A. and Tamulaitis, G. and Vaitkus, J. and Ibrahim, Z.A. and Idris, F. Mohamad and Abdullah, W.A.T. Wan and Yusli, M.N. and Zolkapli, Z. and Benitez, J.F. and Hernandez, A. Castaneda and Quijada, J.A. Murillo and Palomo, L. Valencia and Castilla-Valdez, H. and Cruz-Burelo, E. De La and Cruz, I. Heredia-De La and Lopez-Fernandez, R. and Sanchez-Hernandez, A. and Moreno, S. Carrillo and Barrera, C. Oropeza and Ramirez-Garcia, M. and Valencia, F. Vazquez and Eysermans, J. and Pedraza, I. and Ibarguen, H.A. Salazar and Estrada, C. Uribe and Pineda, A. Morelos and Mijuskovic, J. and Raicevic, N. and Krofcheck, D. and Bheesette, S. and Butler, P.H. and Ahmad, A. and Ahmad, M. and Hassan, Q. and Hoorani, H.R. and Khan, W.A. and Shah, M.A. and Shoaib, M. and Waqas, M. and Avati, V. and Grzanka, L. and Malawski, M. and Bialkowska, H. and Bluj, M. and Boimska, B. and G\'{o}rski, M. and Kazana, M. and Szleper, M. and Zalewski, P. and Bunkowski, K. and Byszuk, A. and Doroba, K. and Kalinowski, A. and Konecki, M. and Krolikowski, J. and Olszewski, M. and Walczak, M. and Araujo, M. and Bargassa, P. and Bastos, D. and Francesco, A. Di and Faccioli, P. and Galinhas, B. and Gallinaro, M. and Hollar, J. and Leonardo, N. and Niknejad, T. and Seixas, J. and Shchelina, K. and Strong, G. and Toldaiev, O. and Varela, J. and Afanasiev, S. and Bunin, P. and Gavrilenko, M. and Golutvin, I. and Gorbunov, I. and Kamenev, A. and Karjavine, V. and Lanev, A. and Malakhov, A. and Matveev, V. and Moisenz, P. and Palichik, V. and Perelygin, V. and Savina, M. and Shmatov, S. and Shulha, S. and Skatchkov, N. and Smirnov, V. and Voytishin, N. and Zarubin, A. and Chtchipounov, L. and Golovtcov, V. and Ivanov, Y. and Kim, V. and Kuznetsova, E. and Levchenko, P. and Murzin, V. and Oreshkin, V. and Smirnov, I. and Sosnov, D. and Sulimov, V. and Uvarov, L. and Vorobyev, A. and Andreev, Yu. and Dermenev, A. and Gninenko, S. and Golubev, N. and Karneyeu, A. and Kirsanov, M. and Krasnikov, N. and Pashenkov, A. and Tlisov, D. and Toropin, A. and Epshteyn, V. and Gavrilov, V. and Lychkovskaya, N. and Nikitenko, A. and Popov, V. and Pozdnyakov, I. and Safronov, G. and Spiridonov, A. and Stepennov, A. and Toms, M. and Vlasov, E. and Zhokin, A. and Aushev, T. and Bychkova, O. and Chadeeva, M. and Parygin, P. and Popova, E. and Rusinov, V. and Andreev, V. and Azarkin, M. and Dremin, I. and Kirakosyan, M. and Terkulov, A. and Belyaev, A. and Boos, E. and Dubinin, M. and Dudko, L. and Ershov, A. and Gribushin, A. and Klyukhin, V. and Kodolova, O. and Lokhtin, I. and Obraztsov, S. and Petrushanko, S. and Savrin, V. and Snigirev, A. and Barnyakov, A. and Blinov, V. and Dimova, T. and Kardapoltsev, L. and Skovpen, Y. and Azhgirey, I. and Bayshev, I. and Bitioukov, S. and Kachanov, V. and Konstantinov, D. and Mandrik, P. and Petrov, V. and Ryutin, R. and Slabospitskii, S. and Sobol, A. and Troshin, S. and Tyurin, N. and Uzunian, A. and Volkov, A. and Babaev, A. and Iuzhakov, A. and Okhotnikov, V. and Borchsh, V. and Ivanchenko, V. and Tcherniaev, E. and Adzic, P. and Cirkovic, P. and Dordevic, M. and Milenovic, P. and Milosevic, J. and Stojanovic, M. and Aguilar-Benitez, M. and Maestre, J. Alcaraz and Fern\'{a}ndez, A. \'{A}lvarez and Bachiller, I. and Luna, M. Barrio and Bedoya, CristinaF. and Cifuentes, J.A. Brochero and Montoya, C.A. Carrillo and Cepeda, M. and Cerrada, M. and Colino, N. and Cruz, B. De La and Peris, A. Delgado and Ramos, J.P. Fern\'{a}ndez and Flix, J. and Fouz, M.C. and Lopez, O. Gonzalez and Lopez, S. Goy and Hernandez, J.M. and Josa, M.I. and Moran, D. and Tobar, \'{A}. Navarro and Yzquierdo, A. P\'{e}rez-Calero and Pelayo, J. Puerta and Redondo, I. and Romero, L. and Navas, S. S\'{a}nchez and Soares, M.S. and Triossi, A. and Willmott, C. and Albajar, C. and de Troc\'{o}niz, J.F. and Reyes-Almanza, R. and Gonzalez, B. Alvarez and Cuevas, J. and Erice, C. and Menendez, J. Fernandez and Folgueras, S. and Caballero, I. Gonzalez and Fern\'{a}ndez, J.R. Gonz\'{a}lez and Cortezon, E. Palencia and Bouza, V. Rodr\'{\i}guez and Cruz, S. Sanchez and Cabrillo, I.J. and Calderon, A. and Quero, B. Chazin and Campderros, J. Duarte and Fernandez, M. and Manteca, P.J. Fern\'{a}ndez and Alonso, A. Garc\'{\i}a and Gomez, G. and Rivero, C. Martinez and Arbol, P. Martinez Ruiz del and Matorras, F. and Gomez, J. Piedra and Prieels, C. and Rodrigo, T. and Ruiz-Jimeno, A. and Russo, L. and Scodellaro, L. and Vila, I. and Garcia, J.M. Vizan and Sonnadara, D.U.J. and Dharmaratna, W.G.D. and Wickramage, N. and Abbaneo, D. and Akgun, B. and Auffray, E. and Auzinger, G. and Baechler, J. and Baillon, P. and Ball, A.H. and Barney, D. and Bendavid, J. and Bianco, M. and Bocci, A. and Bortignon, P. and Bossini, E. and Brondolin, E. and Camporesi, T. and Caratelli, A. and Cerminara, G. and Chapon, E. and Cucciati, G. and d'Enterria, D. and Dabrowski, A. and Daci, N. and Daponte, V. and David, A. and Davignon, O. and Roeck, A. De and Deile, M. and Dobson, M. and D\"{u}nser, M. and Dupont, N. and Elliott-Peisert, A. and Emriskova, N. and Fallavollita, F. and Fasanella, D. and Fiorendi, S. and Franzoni, G. and Fulcher, J. and Funk, W. and Giani, S. and Gigi, D. and Gill, K. and Glege, F. and Gouskos, L. and Gruchala, M. and Guilbaud, M. and Gulhan, D. and Hegeman, J. and Heidegger, C. and Iiyama, Y. and Innocente, V. and James, T. and Janot, P. and Karacheban, O. and Kaspar, J. and Kieseler, J. and Krammer, M. and Kratochwil, N. and Lange, C. and Lecoq, P. and Louren\c{c}o, C. and Malgeri, L. and Mannelli, M. and Massironi, A. and Meijers, F. and Mersi, S. and Meschi, E. and Moortgat, F. and Mulders, M. and Ngadiuba, J. and Niedziela, J. and Nourbakhsh, S. and Orfanelli, S. and Orsini, L. and Pantaleo, F. and Pape, L. and Perez, E. and Peruzzi, M. and Petrilli, A. and Petrucciani, G. and Pfeiffer, A. and Pierini, M. and Pitters, F.M. and Rabady, D. and Racz, A. and Rieger, M. and Rovere, M. and Sakulin, H. and Salfeld-Nebgen, J. and Sch\"{a}fer, C. and Schwick, C. and Selvaggi, M. and Sharma, A. and Silva, P. and Snoeys, W. and Sphicas, P. and Steggemann, J. and Summers, S. and Tavolaro, V.R. and Treille, D. and Tsirou, A. and Onsem, G.P. Van and Vartak, A. and Verzetti, M. and Zeuner, W.D. and Caminada, L. and Deiters, K. and Erdmann, W. and Horisberger, R. and Ingram, Q. and Kaestli, H.C. and Kotlinski, D. and Langenegger, U. and Rohe, T. and Wiederkehr, S.A. and Backhaus, M. and Berger, P. and Chernyavskaya, N. and Dissertori, G. and Dittmar, M. and Doneg\`{a}, M. and Dorfer, C. and Espinosa, T.A. G\'{o}mez and Grab, C. and Hits, D. and Lustermann, W. and Manzoni, R.A. and Meinhard, M.T. and Micheli, F. and Musella, P. and Nessi-Tedaldi, F. and Pauss, F. and Perrin, G. and Perrozzi, L. and Pigazzini, S. and Ratti, M.G. and Reichmann, M. and Reissel, C. and Reitenspiess, T. and Ristic, B. and Ruini, D. and Becerra, D.A. Sanz and Sch\"{o}nenberger, M. and Shchutska, L. and Olsson, M.L. Vesterbacka and Wallny, R. and Zhu, D.H. and Aarrestad, T.K. and Amsler, C. and Botta, C. and Brzhechko, D. and Canelli, M.F. and Cosa, A. De and Burgo, R. Del and Kilminster, B. and Leontsinis, S. and Mikuni, V.M. and Neutelings, I. and Rauco, G. and Robmann, P. and Schweiger, K. and Seitz, C. and Takahashi, Y. and Wertz, S. and Zucchetta, A. and Doan, T.H. and Kuo, C.M. and Lin, W. and Roy, A. and Yu, S.S. and Chang, P. and Chao, Y. and Chen, K.F. and Chen, P.H. and Hou, W.-S. and Li, Y.y. and Lu, R.-S. and Paganis, E. and Psallidas, A. and Steen, A. and Asavapibhop, B. and Asawatangtrakuldee, C. and Srimanobhas, N. and Suwonjandee, N. and Bat, A. and Boran, F. and Celik, A. and Damarseckin, S. and Demiroglu, Z.S. and Dolek, F. and Dozen, C. and Dumanoglu, I. and Gokbulut, G. and Guler, EmineGurpinar and Guler, Y. and Hos, I. and Isik, C. and Kangal, E.E. and Kara, O. and Topaksu, A. Kayis and Kiminsu, U. and Onengut, G. and Ozdemir, K. and Ozturk, S. and Simsek, A.E. and Tok, U.G. and Turkcapar, S. and Zorbakir, I.S. and Zorbilmez, C. and Isildak, B. and Karapinar, G. and Yalvac, M. and Atakisi, I.O. and G\"{u}lmez, E. and Kaya, M. and Kaya, O. and \"{O}z\c{c}elik, \"{O}. and Tekten, S. and Yetkin, E.A. and Cakir, A. and Cankocak, K. and Komurcu, Y. and Sen, S. and Cerci, S. and Kaynak, B. and Ozkorucuklu, S. and Cerci, D. Sunar and Grynyov, B. and Levchuk, L. and Bhal, E. and Bologna, S. and Brooke, J.J. and Burns, D. and Clement, E. and Cussans, D. and Flacher, H. and Goldstein, J. and Heath, G.P. and Heath, H.F. and Kreczko, L. and Krikler, B. and Paramesvaran, S. and Penning, B. and Sakuma, T. and Nasr-Storey, S. Seif El and Smith, V.J. and Taylor, J. and Titterton, A. and Bell, K.W. and Belyaev, A. and Brew, C. and Brown, R.M. and Cockerill, D.J.A. and Coughlan, J.A. and Harder, K. and Harper, S. and Linacre, J. and Manolopoulos, K. and Newbold, D.M. and Olaiya, E. and Petyt, D. and Reis, T. and Schuh, T. and Shepherd-Themistocleous, C.H. and Thea, A. and Tomalin, I.R. and Williams, T. and Bainbridge, R. and Bloch, P. and Borg, J. and Breeze, S. and Buchmuller, O. and Bundock, A. and CHAHAL, GurpreetSingh and Colling, D. and Dauncey, P. and Davies, G. and Negra, M. Della and Maria, R. Di and Everaerts, P. and Hall, G. and Iles, G. and Komm, M. and Lyons, L. and Magnan, A.-M. and Malik, S. and Martelli, A. and Milosevic, V. and Morton, A. and Nash, J. and Palladino, V. and Pesaresi, M. and Raymond, D.M. and Richards, A. and Rose, A. and Scott, E. and Seez, C. and Shtipliyski, A. and Stoye, M. and Strebler, T. and Tapper, A. and Uchida, K. and Virdee, T. and Wardle, N. and Winterbottom, D. and Zecchinelli, A.G. and Zenz, S.C. and Cole, J.E. and Hobson, P.R. and Khan, A. and Kyberd, P. and Mackay, C.K. and Reid, I.D. and Teodorescu, L. and Zahid, S. and Brinkerhoff, A. and Call, K. and Caraway, B. and Dittmann, J. and Hatakeyama, K. and Madrid, C. and McMaster, B. and Pastika, N. and Smith, C. and Bartek, R. and Dominguez, A. and Uniyal, R. and Hernandez, A.M. Vargas and Buccilli, A. and Cooper, S.I. and Henderson, C. and Rumerio, P. and West, C. and Albert, A. and Arcaro, D. and Demiragli, Z. and Gastler, D. and Richardson, C. and Rohlf, J. and Sperka, D. and Spitzbart, D. and Suarez, I. and Sulak, L. and Zou, D. and Benelli, G. and Burkle, B. and Coubez, X. and Cutts, D. and Duh, Y.t. and Hadley, M. and Heintz, U. and Hogan, J.M. and Kwok, K.H.M. and Laird, E. and Landsberg, G. and Lau, K.T. and Lee, J. and Narain, M. and Sagir, S. and Syarif, R. and Usai, E. and Wong, W.Y. and Yu, D. and Zhang, W. and Band, R. and Brainerd, C. and Breedon, R. and Sanchez, M. Calderon De La Barca and Chertok, M. and Conway, J. and Conway, R. and Cox, P.T. and Erbacher, R. and Flores, C. and Funk, G. and Jensen, F. and Ko, W. and Kukral, O. and Lander, R. and Mulhearn, M. and Pellett, D. and Pilot, J. and Shi, M. and Taylor, D. and Tos, K. and Tripathi, M. and Wang, Z. and Zhang, F. and Bachtis, M. and Bravo, C. and Cousins, R. and Dasgupta, A. and Florent, A. and Hauser, J. and Ignatenko, M. and Mccoll, N. and Nash, W.A. and Regnard, S. and Saltzberg, D. and Schnaible, C. and Stone, B. and Valuev, V. and Burt, K. and Chen, Y. and Clare, R. and Gary, J.W. and Shirazi, S.M.A. Ghiasi and Hanson, G. and Karapostoli, G. and Long, O.R. and Negrete, M. Olmedo and Paneva, M.I. and Si, W. and Wang, L. and Wimpenny, S. and Yates, B.R. and Zhang, Y. and Branson, J.G. and Chang, P. and Cittolin, S. and Cooperstein, S. and Deelen, N. and Derdzinski, M. and Gerosa, R. and Gilbert, D. and Hashemi, B. and Klein, D. and Krutelyov, V. and Letts, J. and Masciovecchio, M. and May, S. and Padhi, S. and Pieri, M. and Sharma, V. and Tadel, M. and W\"{u}rthwein, F. and Yagil, A. and Porta, G. Zevi Della and Amin, N. and Bhandari, R. and Campagnari, C. and Citron, M. and Dutta, V. and Sevilla, M. Franco and Incandela, J. and Marsh, B. and Mei, H. and Ovcharova, A. and Qu, H. and Richman, J. and Sarica, U. and Stuart, D. and Wang, S. and Anderson, D. and Bornheim, A. and Cerri, O. and Dutta, I. and Lawhorn, J.M. and Lu, N. and Mao, J. and Newman, H.B. and Nguyen, T.Q. and Pata, J. and Spiropulu, M. and Vlimant, J.R. and Xie, S. and Zhang, Z. and Zhu, R.Y. and Andrews, M.B. and Ferguson, T. and Mudholkar, T. and Paulini, M. and Sun, M. and Vorobiev, I. and Weinberg, M. and Cumalat, J.P. and Ford, W.T. and MacDonald, E. and Mulholland, T. and Patel, R. and Perloff, A. and Stenson, K. and Ulmer, K.A. and Wagner, S.R. and Alexander, J. and Cheng, Y. and Chu, J. and Datta, A. and Frankenthal, A. and Mcdermott, K. and Patterson, J.R. and Quach, D. and Ryd, A. and Tan, S.M. and Tao, Z. and Thom, J. and Wittich, P. and Zientek, M. and Abdullin, S. and Albrow, M. and Alyari, M. and Apollinari, G. and Apresyan, A. and Apyan, A. and Banerjee, S. and Bauerdick, L.A.T. and Beretvas, A. and Berry, D. and Berryhill, J. and Bhat, P.C. and Burkett, K. and Butler, J.N. and Canepa, A. and Cerati, G.B. and Cheung, H.W.K. and Chlebana, F. and Cremonesi, M. and Duarte, J. and Elvira, V.D. and Freeman, J. and Gecse, Z. and Gottschalk, E. and Gray, L. and Green, D. and Gr\"{u}nendahl, S. and Gutsche, O. and Hanlon, J. and Harris, R.M. and Hasegawa, S. and Heller, R. and Hirschauer, J. and Jayatilaka, B. and Jindariani, S. and Johnson, M. and Joshi, U. and Klijnsma, T. and Klima, B. and Kortelainen, M.J. and Kreis, B. and Lammel, S. and Lewis, J. and Lincoln, D. and Lipton, R. and Liu, M. and Liu, T. and Lykken, J. and Maeshima, K. and Marraffino, J.M. and Mason, D. and McBride, P. and Merkel, P. and Mrenna, S. and Nahn, S. and O'Dell, V. and Papadimitriou, V. and Pedro, K. and Pena, C. and Rakness, G. and Ravera, F. and Hall, A. Reinsvold and Ristori, L. and Schneider, B. and Sexton-Kennedy, E. and Smith, N. and Soha, A. and Spalding, W.J. and Spiegel, L. and Stoynev, S. and Strait, J. and Strobbe, N. and Taylor, L. and Tkaczyk, S. and Tran, N.V. and Uplegger, L. and Vaandering, E.W. and Vernieri, C. and Vidal, R. and Wang, M. and Weber, H.A. and Acosta, D. and Avery, P. and Bourilkov, D. and Cadamuro, L. and Cherepanov, V. and Errico, F. and Field, R.D. and Gleyzer, S.V. and Guerrero, D. and Joshi, B.M. and Kim, M. and Konigsberg, J. and Korytov, A. and Lo, K.H. and Matchev, K. and Menendez, N. and Mitselmakher, G. and Rosenzweig, D. and Shi, K. and Wang, J. and Wang, S. and Zuo, X. and Joshi, Y.R. and Adams, T. and Askew, A. and Hagopian, S. and Hagopian, V. and Johnson, K.F. and Khurana, R. and Kolberg, T. and Martinez, G. and Perry, T. and Prosper, H. and Schiber, C. and Yohay, R. and Zhang, J. and Baarmand, M.M. and Hohlmann, M. and Noonan, D. and Rahmani, M. and Saunders, M. and Yumiceva, F. and Adams, M.R. and Apanasevich, L. and Betts, R.R. and Cavanaugh, R. and Chen, X. and Dittmer, S. and Evdokimov, O. and Gerber, C.E. and Hangal, D.A. and Hofman, D.J. and Mills, C. and Roy, T. and Tonjes, M.B. and Varelas, N. and Viinikainen, J. and Wang, H. and Wang, X. and Wu, Z. and Alhusseini, M. and Bilki, B. and Dilsiz, K. and Durgut, S. and Gandrajula, R.P. and Haytmyradov, M. and Khristenko, V. and K\"{o}seyan, O.K. and Merlo, J.-P. and Mestvirishvili, A. and Moeller, A. and Nachtman, J. and Ogul, H. and Onel, Y. and Ozok, F. and Penzo, A. and Snyder, C. and Tiras, E. and Wetzel, J. and Blumenfeld, B. and Cocoros, A. and Eminizer, N. and Gritsan, A.V. and Hung, W.T. and Kyriacou, S. and Maksimovic, P. and Mantilla, C. and Roskes, J. and Swartz, M. and Barrera, C. Baldenegro and Baringer, P. and Bean, A. and Boren, S. and Bowen, J. and Bylinkin, A. and Isidori, T. and Khalil, S. and King, J. and Krintiras, G. and Kropivnitskaya, A. and Lindsey, C. and Majumder, D. and Mcbrayer, W. and Minafra, N. and Murray, M. and Rogan, C. and Royon, C. and Sanders, S. and Schmitz, E. and Takaki, J.D. Tapia and Wang, Q. and Williams, J. and Wilson, G. and Duric, S. and Ivanov, A. and Kaadze, K. and Kim, D. and Maravin, Y. and Mendis, D.R. and Mitchell, T. and Modak, A. and Mohammadi, A. and Rebassoo, F. and Wright, D. and Baden, A. and Baron, O. and Belloni, A. and Eno, S.C. and Feng, Y. and Hadley, N.J. and Jabeen, S. and Jeng, G.Y. and Kellogg, R.G. and Mignerey, A.C. and Nabili, S. and Ricci-Tam, F. and Seidel, M. and Shin, Y.H. and Skuja, A. and Tonwar, S.C. and Wong, K. and Abercrombie, D. and Allen, B. and Bi, R. and Brandt, S. and Busza, W. and Cali, I.A. and D'Alfonso, M. and Ceballos, G. Gomez and Goncharov, M. and Harris, P. and Hsu, D. and Hu, M. and Klute, M. and Kovalskyi, D. and Lee, Y.-J. and Luckey, P.D. and Maier, B. and Marini, A.C. and Mcginn, C. and Mironov, C. and Narayanan, S. and Niu, X. and Paus, C. and Rankin, D. and Roland, C. and Roland, G. and Shi, Z. and Stephans, G.S.F. and Sumorok, K. and Tatar, K. and Velicanu, D. and Wang, J. and Wang, T.W. and Wyslouch, B. and Chatterjee, R.M. and Evans, A. and Guts, S. and Hansen, P. and Hiltbrand, J. and Jain, Sh. and Kubota, Y. and Lesko, Z. and Mans, J. and Revering, M. and Rusack, R. and Saradhy, R. and Schroeder, N. and Wadud, M.A. and Acosta, J.G. and Oliveros, S. and Bloom, K. and Chauhan, S. and Claes, D.R. and Fangmeier, C. and Finco, L. and Golf, F. and Kamalieddin, R. and Kravchenko, I. and Siado, J.E. and Snow, G.R. and Stieger, B. and Tabb, W. and Agarwal, G. and Harrington, C. and Iashvili, I. and Kharchilava, A. and McLean, C. and Nguyen, D. and Parker, A. and Pekkanen, J. and Rappoccio, S. and Roozbahani, B. and Alverson, G. and Barberis, E. and Freer, C. and Haddad, Y. and Hortiangtham, A. and Madigan, G. and Marzocchi, B. and Morse, D.M. and Orimoto, T. and Skinnari, L. and Tishelman-Charny, A. and Wamorkar, T. and Wang, B. and Wisecarver, A. and Wood, D. and Bhattacharya, S. and Bueghly, J. and Gilbert, A. and Gunter, T. and Hahn, K.A. and Odell, N. and Schmitt, M.H. and Sung, K. and Trovato, M. and Velasco, M. and Bucci, R. and Dev, N. and Goldouzian, R. and Hildreth, M. and Anampa, K. Hurtado and Jessop, C. and Karmgard, D.J. and Lannon, K. and Li, W. and Loukas, N. and Marinelli, N. and Mcalister, I. and Meng, F. and Musienko, Y. and Ruchti, R. and Siddireddy, P. and Smith, G. and Taroni, S. and Wayne, M. and Wightman, A. and Wolf, M. and Woodard, A. and Alimena, J. and Bylsma, B. and Durkin, L.S. and Francis, B. and Hill, C. and Ji, W. and Lefeld, A. and Ling, T.Y. and Winer, B.L. and Dezoort, G. and Elmer, P. and Hardenbrook, J. and Haubrich, N. and Higginbotham, S. and Kalogeropoulos, A. and Kwan, S. and Lange, D. and Lucchini, M.T. and Luo, J. and Marlow, D. and Mei, K. and Ojalvo, I. and Olsen, J. and Palmer, C. and Pirou\'{e}, P. and Stickland, D. and Tully, C. and Malik, S. and Norberg, S. and Barker, A. and Barnes, V.E. and Chawla, R. and Das, S. and Gutay, L. and Jones, M. and Jung, A.W. and Khatiwada, A. and Mahakud, B. and Miller, D.H. and Negro, G. and Neumeister, N. and Peng, C.C. and Piperov, S. and Qiu, H. and Schulte, J.F. and Trevisani, N. and Wang, F. and Xiao, R. and Xie, W. and Cheng, T. and Dolen, J. and Parashar, N. and Baty, A. and Behrens, U. and Dildick, S. and Ecklund, K.M. and Freed, S. and Geurts, F.J.M. and Kilpatrick, M. and Kumar, Arun and Li, W. and Padley, B.P. and Redjimi, R. and Roberts, J. and Rorie, J. and Shi, W. and Leiton, A.G. Stahl and Tu, Z. and Zhang, A. and Bodek, A. and de Barbaro, P. and Demina, R. and Dulemba, J.L. and Fallon, C. and Ferbel, T. and Galanti, M. and Garcia-Bellido, A. and Hindrichs, O. and Khukhunaishvili, A. and Ranken, E. and Taus, R. and Chiarito, B. and Chou, J.P. and Gandrakota, A. and Gershtein, Y. and Halkiadakis, E. and Hart, A. and Heindl, M. and Hughes, E. and Kaplan, S. and Laflotte, I. and Lath, A. and Montalvo, R. and Nash, K. and Osherson, M. and Saka, H. and Salur, S. and Schnetzer, S. and Somalwar, S. and Stone, R. and Thomas, S. and Acharya, H. and Delannoy, A.G. and Spanier, S. and Bouhali, O. and Dalchenko, M. and Mattia, M. De and Delgado, A. and Eusebi, R. and Gilmore, J. and Huang, T. and Kamon, T. and Kim, H. and Luo, S. and Malhotra, S. and Marley, D. and Mueller, R. and Overton, D. and Perni\`{e}, L. and Rathjens, D. and Safonov, A. and Akchurin, N. and Damgov, J. and Guio, F. De and Hegde, V. and Kunori, S. and Lamichhane, K. and Lee, S.W. and Mengke, T. and Muthumuni, S. and Peltola, T. and Undleeb, S. and Volobouev, I. and Wang, Z. and Whitbeck, A. and Greene, S. and Gurrola, A. and Janjam, R. and Johns, W. and2017, C. and Melo, A. and Ni, H. and Padeken, K. and Romeo, F. and Sheldon, P. and Tuo, S. and Velkovska, J. and Verweij, M. and Arenton, M.W. and Barria, P. and Cox, B. and Cummings, G. and Hakala, J. and Hirosky, R. and Joyce, M. and Ledovskoy, A. and Neu, C. and Tannenwald, B. and Wang, Y. and Wolfe, E. and Xia, F. and Harr, R. and Karchin, P.E. and Poudyal, N. and Sturdy, J. and Thapa, P. and Bose, T. and Buchanan, J. and Caillol, C. and Carlsmith, D. and Dasu, S. and Bruyn, I. De and Dodd, L. and Galloni, C. and He, H. and Herndon, M. and Herv\'{e}, A. and Hussain, U. and Lanaro, A. and Loeliger, A. and Long, K. and Loveless, R. and Sreekala, J. Madhusudanan and Mallampalli, A. and Pinna, D. and Ruggles, T. and Savin, A. and Sharma, V. and Smith, W.H. and Teague, D. and Trembath-reichert, S.},
  year          = 2020,
  month         = {jun},
  journal       = {Journal of Instrumentation},
  volume        = 15,
  number        = {06},
  pages         = {P06005},
  doi           = {10.1088/1748-0221/15/06/p06005},
  url           = {https://dx.doi.org/10.1088/1748-0221/15/06/P06005},
  abstract      = {Machine-learning (ML) techniques are explored to identify   and classify hadronic decays of highly Lorentz-boosted   W/Z/Higgs bosons and top quarks.  Techniques without ML have   also been evaluated and are included for comparison.  The   identification performances of a variety of algorithms are   characterized in simulated events and directly compared with   data. The algorithms are validated using proton-proton collision   data at \surd{}s=13TeV, corresponding to an integrated   luminosity of 35.9 fb1.  Systematic uncertainties are assessed by   comparing the results obtained using simulation and collision data.   The new techniques studied in this paper provide significant   performance improvements over non-ML techniques, reducing the   background rate by up to an order of magnitude at the same signal   efficiency.}
}
@inproceedings{Skands:2012ts,
  title         = {Introduction to {{QCD}}},
  author        = {Skands, Peter},
  year          = 2013,
  booktitle     = {Searching for {{New Physics}} at {{Small}} and {{Large Scales}}},
  pages         = {341--420},
  doi           = {10.1142/9789814525220_0008},
  urldate       = {2025-07-18},
  eprint        = {1207.2389},
  primaryclass  = {hep-ph},
  abstract      = {These lectures were originally given at TASI and are directed at a level suitable for graduate students in High Energy Physics. They are intended to give an introduction to the theory and phenomenology of quantum chromodynamics (QCD), focusing on collider physics applications. The aim is to bring the reader to a level where informed decisions can be made concerning different approaches and their uncertainties. The material is divided into five main areas: 1) fundamentals, 2) fixed-order perturbative QCD, 3) Monte Carlo event generators and parton showers, 4) Matching at Leading and Next-to-Leading Order, and 5) Soft QCD physics.},
  archiveprefix = {arXiv},
  keywords      = {High Energy Physics - Phenomenology,High Energy Physics - Theory},
  annotation    = {119 citations (INSPIRE 2025/7/18)\\ 110 citations w/o self (INSPIRE 2025/7/18)\\ Citations: 6 (Crossref) [2025-07-18]\\ Citations: 71 (SemanticScholar) [2025-07-18]},
  file          = {/Users/t-krishdesai/Zotero/storage/W8S6T26E/Skands - 2013 - Introduction to QCD.pdf;/Users/t-krishdesai/Zotero/storage/7RUDALP8/1207.html}
}
@misc{song_measurement_2023,
  title         = {Measurement of {CollinearDrop} jet mass and its correlation with {SoftDrop} groomed jet substructure observables in \${\textbackslash}sqrt\{s\}=200\$ {GeV} \$pp\$ collisions by {STAR}},
  author        = {Song, Youqi},
  year          = 2023,
  month         = jul,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2307.07718},
  url           = {http://arxiv.org/abs/2307.07718},
  urldate       = {2025-07-15},
  note          = {arXiv:2307.07718 [nucl-ex]},
  abstract      = {Jet substructure variables aim to reveal details of the parton fragmentation and hadronization processes that create a jet. By removing collinear radiation while maintaining the soft radiation components, one can construct CollinearDrop jet observables, which have enhanced sensitivity to the soft phase space within jets. We present a CollinearDrop jet measurement, corrected for detector effects with a machine learning method, MultiFold, and its correlation with groomed jet observables, in \$pp\$ collisions at \${\textbackslash}sqrt\{s\}=200\$ GeV at STAR. We demonstrate that the population of jets with a large non-perturbative contribution can be significantly enhanced by selecting on higher CollinearDrop jet mass fractions. In addition, we observe an anti-correlation between the amount of grooming and the angular scale of the first hard splitting of the jet.},
  keywords      = {Nuclear Experiment}
}
@article{Spinner2024Lorentz-EquivariantPhysics,
  title         = {Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics},
  author        = {Spinner, Jonas and Bres{\'{o}}, Victor and de Haan, Pim and Plehn, Tilman and Thaler, Jesse and Brehmer, Johann},
  year          = 2024,
  month         = 5,
  journal       = {Advances in Neural Information Processing Systems},
  publisher     = {Neural information processing systems foundation},
  volume        = 37,
  issn          = 10495258,
  url           = {https://arxiv.org/pdf/2405.14806},
  arxivid       = {2405.14806}
}
@article{StatisticalPhysics,
  title         = {Statistical Methods in Particle Physics}
}
@misc{stephanovitch_optimal_2023,
  title         = {Optimal 1-{Wasserstein} {Distance} for {WGANs}},
  author        = {St\'{e}phanovitch, Arthur and Tanielian, Ugo and Cadre, Beno\^{\i}t and Klutchnikoff, Nicolas and Biau, G\'{e}rard},
  year          = 2023,
  month         = oct,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2201.02824},
  url           = {http://arxiv.org/abs/2201.02824},
  urldate       = {2025-07-17},
  note          = {arXiv:2201.02824 [stat]},
  abstract      = {The mathematical forces at work behind Generative Adversarial Networks raise challenging theoretical issues. Motivated by the important question of characterizing the geometrical properties of the generated distributions, we provide a thorough analysis of Wasserstein GANs (WGANs) in both the finite sample and asymptotic regimes. We study the specific case where the latent space is univariate and derive results valid regardless of the dimension of the output space. We show in particular that for a fixed sample size, the optimal WGANs are closely linked with connected paths minimizing the sum of the squared Euclidean distances between the sample points. We also highlight the fact that WGANs are able to approach (for the 1-Wasserstein distance) the target distribution as the sample size tends to infinity, at a given convergence rate and provided the family of generative Lipschitz functions grows appropriately. We derive in passing new results on optimal transport theory in the semi-discrete setting.},
  keywords      = {Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Machine Learning, Statistics - Statistics Theory}
}
@misc{stroud_transformers_2024,
  title         = {Transformers for {Charged} {Particle} {Track} {Reconstruction} in {High} {Energy} {Physics}},
  author        = {Stroud, Samuel Van and Duckett, Philippa and Hart, Max and Pond, Nikita and Rettie, S\'{e}bastien and Facini, Gabriel and Scanlon, Tim},
  year          = 2024,
  month         = nov,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2411.07149},
  url           = {http://arxiv.org/abs/2411.07149},
  urldate       = {2025-07-17},
  note          = {arXiv:2411.07149 [hep-ex]},
  abstract      = {Reconstructing charged particle tracks is a fundamental task in modern collider experiments. The unprecedented particle multiplicities expected at the High-Luminosity Large Hadron Collider (HL-LHC) pose significant challenges for track reconstruction, where traditional algorithms become computationally infeasible. To address this challenge, we present a novel learned approach to track reconstruction that adapts recent advances in computer vision and object detection. Our architecture combines a Transformer hit filtering network with a MaskFormer reconstruction model that jointly optimises hit assignments and the estimation of the charged particles' properties. Evaluated on the TrackML dataset, our best performing model achieves state-of-the-art tracking performance with 97\% efficiency for a fake rate of 0.6\%, and inference times of 100ms. Our tunable approach enables specialisation for specific applications like triggering systems, while its underlying principles can be extended to other reconstruction challenges in high energy physics. This work demonstrates the potential of modern deep learning architectures to address emerging computational challenges in particle physics while maintaining the precision required for groundbreaking physics analysis.},
  keywords      = {High Energy Physics - Experiment}
}
@article{Strozik-Kotlorz:2014xga,
  title         = {{{DGLAP}} Evolution of the Truncated Moments of {{PDFs}} in Spin Physics},
  author        = {{Str{\'o}zik-Kotlorz}, D. and Kotlorz, A.},
  year          = 2014,
  journal       = {Physics of Particles and Nuclei},
  volume        = 45,
  number        = 1,
  pages         = {52--53},
  doi           = {10.1134/s1063779614010985},
  issn          = {1531-8559},
  urldate       = {2025-07-18},
  abstract      = {We review evolution equations for truncated Mellin moments (TMM) of the parton densities. The main finding of the presented approach is that the nth truncated moment of the parton distribution obeys the DGLAP-like equation, with a rescaled splitting function P{$\prime$}(z) = z n P(z). This approach allows one to restrict the analysis to the experimentally available Bjorken-x region. We present some applications of TMM to study the spin structure functions of the nucleon.},
  langid        = {english},
  keywords      = {Approximations and Expansions,DGLAP Evolution,Motor Protein Structure,Nuclear Physics,Parton Density,Parton Distribution,Partonic Cross Section,Spin Physic,Stochastic Integrals,Theoretical Nuclear Physics,Theoretical Particle Physics},
  annotation    = {0 citations (INSPIRE 2025/7/18)\\ 0 citations w/o self (INSPIRE 2025/7/18)\\ Citations: 0 (Crossref) [2025-07-18]\\ Citations: 0 (SemanticScholar) [2025-07-18]},
  file          = {/Users/t-krishdesai/Zotero/storage/II4F4LQZ/Strózik-Kotlorz and Kotlorz - 2014 - DGLAP evolution of the truncated moments of PDFs in spin physics.pdf}
}
@article{szabo_frequentist_2015,
  title         = {Frequentist coverage of adaptive nonparametric {Bayesian} credible sets},
  author        = {Szab\'{o}, Botond and Vaart, A. W. van der and Zanten, J. H. van},
  year          = 2015,
  month         = aug,
  journal       = {The Annals of Statistics},
  volume        = 43,
  number        = 4,
  doi           = {10.1214/14-aos1270},
  issn          = {0090-5364},
  url           = {http://arxiv.org/abs/1310.4489},
  urldate       = {2025-07-14},
  note          = {arXiv:1310.4489 [math]},
  abstract      = {We investigate the frequentist coverage of Bayesian credible sets in a nonparametric setting. We consider a scale of priors of varying regularity and choose the regularity by an empirical Bayes method. Next we consider a central set of prescribed posterior probability in the posterior distribution of the chosen regularity. We show that such an adaptive Bayes credible set gives correct uncertainty quantification of "polished tail" parameters, in the sense of high probability of coverage of such parameters. On the negative side, we show by theory and example that adaptation of the prior necessarily leads to gross and haphazard uncertainty quantification for some true parameters that are still within the hyperrectangle regularity scale.},
  keywords      = {Mathematics - Statistics Theory, Statistics - Statistics Theory}
}
@article{tang_data_2017,
  title         = {Data {Unfolding} with {Wiener}-{SVD} {Method}},
  author        = {Tang, W. and Li, X. and Qian, X. and Wei, H. and Zhang, C.},
  year          = 2017,
  month         = oct,
  journal       = {Journal of Instrumentation},
  volume        = 12,
  number        = 10,
  pages         = {P10002},
  doi           = {10.1088/1748-0221/12/10/p10002},
  issn          = {1748-0221},
  url           = {https://dx.doi.org/10.1088/1748-0221/12/10/P10002},
  urldate       = {2025-07-13},
  abstract      = {Data unfolding is a common analysis technique used in HEP data analysis. Inspired by the deconvolution technique in the digital signal processing, a new unfolding technique based on the SVD technique and the well-known Wiener filter is introduced. The Wiener-SVD unfolding approach achieves the unfolding by maximizing the signal to noise ratios in the effective frequency domain given expectations of signal and noise and is free from regularization parameter. Through a couple examples, the pros and cons of the Wiener-SVD approach as well as the nature of the unfolded results are discussed.},
  language      = {en}
}
@article{Tang2017DataMethod,
  title         = {Data Unfolding with Wiener-SVD Method},
  author        = {Tang, W and Li, X and Qian, X and Wei, H and Zhang, C},
  year          = 2017,
  arxivid       = {1705.03568v2},
  keywords      = {KKKKKKKK: Unfolding, SVD, Wiener filter}
}
@article{Teodorescu2008ArtificialPhysics,
  title         = {Artificial neural networks in high-energy physics},
  author        = {Teodorescu, Liliana},
  year          = 2008,
  publisher     = {Cern},
  doi           = {10.5170/cern-2008-002.13},
  url           = {https://cds.cern.ch/record/1100521},
  keywords      = {CERN Document Server, WebSearch}
}
@article{Terjek2019AdversarialRegularization,
  title         = {Adversarial Lipschitz Regularization},
  author        = {Terj{\'{e}}k, D\'{a}vid and {Terj{\'{e}}k} and {D{\'{a}}vid}},
  year          = 2019,
  month         = 1,
  journal       = {arXiv},
  pages         = {arXiv:1907.05681},
  doi           = {10.48550/arxiv.1907.05681},
  url           = {https://ui.adsabs.harvard.edu/abs/2019arXiv190705681T/abstract},
  arxivid       = {arXiv:1907.05681},
  keywords      = {Computer Science, Computer Vision and Pattern Recognition, Machine Learning, Statistics}
}
@article{TerrenceJ.Sejnowski2018TheIntelligence,
  title         = {The Deep Learning Revolution: Machine Intelligence Meets Human Intelligence},
  author        = {Terrence J. Sejnowski},
  year          = 2018,
  journal       = {MIT Press},
  isbn          = 9780262038034
}
@article{Thais2022GraphChallenges,
  title         = {Graph Neural Networks in Particle Physics: Implementations, Innovations, and Challenges},
  author        = {Thais, Savannah and Calafiura, Paolo and Chachamis, Grigorios and Dezoort, Gage and Duarte, Javier and Ganguly, Sanmay and Kagan, Michael and Murnane, Daniel and Neubauer, Mark S and Terao, Kazuhiro},
  year          = 2022,
  arxivid       = {2203.12852v2}
}
@article{Thaler2011IdentifyingN-subjettiness,
  title         = {Identifying boosted objects with N-subjettiness},
  author        = {Thaler, Jesse and Van Tilburg, Ken},
  year          = 2011,
  month         = 3,
  journal       = {Journal of High Energy Physics},
  publisher     = {Springer Verlag},
  volume        = 2011,
  number        = 3,
  pages         = {1--28},
  doi           = {10.1007/jhep03(2011)015/metrics},
  issn          = 10298479,
  url           = {https://link.springer.com/article/10.1007/JHEP03(2011)015},
  arxivid       = {1011.2268},
  keywords      = {Beyond standard model, Hadronic Colliders, Jets}
}
@phdthesis{Bessner:2017trm,
    author = "Bessner, Martin",
    title = "{Measurement of differential di-photon plus jet cross sections using the ATLAS detector}",
    reportNumber = "DESY-THESIS-2017-037",
    doi = "10.3204/PUBDB-2017-10063",
    school = "Hamburg U.",
    year = "2017"
}
@article{LHCb:2023qav,
    author = "Aaij, Roel and others",
    collaboration = "LHCb",
    title = "{Measurement of the Z boson production cross-section in pp collisions at $ \sqrt{s} $ = 5.02 TeV}",
    eprint = "2308.12940",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "LHCb-PAPER-2023-010, CERN-EP-2023-141",
    doi = "10.1007/JHEP02(2024)070",
    journal = "JHEP",
    volume = "02",
    pages = "070",
    year = "2024"
}
@article{ATLAS:2024hmk,
    author = "Aad, Georges and others",
    collaboration = "ATLAS",
    title = "{Measurements of inclusive and differential cross-sections of $ t\overline{t}\gamma $ production in pp collisions at $ \sqrt{s} $ = 13 TeV with the ATLAS detector}",
    eprint = "2403.09452",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "CERN-EP-2024-052",
    doi = "10.1007/JHEP10(2024)191",
    journal = "JHEP",
    volume = "10",
    pages = "191",
    year = "2024"
}
@article{Kutz:2024eaq,
    author = "Kutz, T. and Pybus, J. R. and Upton, D. W. and Cotton, C. and Deshpande, A. and Deur, A. and Li, W. B. and Nguyen, D. and Nycz, M. and Zheng, X.",
    title = "{High precision measurements of {\ensuremath{\alpha}}s at the future EIC}",
    eprint = "2406.05591",
    archivePrefix = "arXiv",
    primaryClass = "nucl-th",
    doi = "10.1103/PhysRevD.110.074004",
    journal = "Phys. Rev. D",
    volume = "110",
    number = "7",
    pages = "074004",
    year = "2024"
}
@article{ATLAS:2016vlf,
    author = "Aad, Georges and others",
    collaboration = "ATLAS",
    title = "{Measurement of fiducial differential cross sections of gluon-fusion production of Higgs bosons decaying to WW$^{∗}${\textrightarrow}e{\ensuremath{\nu}}{\ensuremath{\mu}}{\ensuremath{\nu}} with the ATLAS detector at $ \sqrt{s}=8 $ TeV}",
    eprint = "1604.02997",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "CERN-EP-2016-019",
    doi = "10.1007/JHEP08(2016)104",
    journal = "JHEP",
    volume = "08",
    pages = "104",
    year = "2016"
}
@article{CMS:2025dnx,
    author = "Chekhovsky, Vladimir and others",
    collaboration = "CMS",
    title = "{Search for medium effects using jet axis decorrelation in inclusive jets from PbPb collisions at $\sqrt{{s}_{\text{NN}}}$ = 5.02 TeV}",
    eprint = "2502.13020",
    archivePrefix = "arXiv",
    primaryClass = "nucl-ex",
    reportNumber = "CMS-HIN-24-010, CERN-EP-2024-345",
    doi = "10.1007/JHEP06(2025)120",
    journal = "JHEP",
    volume = "06",
    pages = "120",
    year = "2025"
}
@article{Thaler2012MaximizingN-subjettiness,
  title         = {Maximizing boosted top identification by minimizing N-subjettiness},
  author        = {Thaler, Jesse and Van Tilburg, Ken},
  year          = 2012,
  month         = 2,
  journal       = {Journal of High Energy Physics},
  publisher     = {Springer},
  volume        = 2012,
  number        = 2,
  pages         = {1--33},
  doi           = {10.1007/jhep02(2012)093/metrics},
  issn          = 11266708,
  url           = {https://link.springer.com/article/10.1007/JHEP02(2012)093},
  arxivid       = {1108.2701},
  keywords      = {Beyond standard model, Hadronic colliders, Jets}
}
@book{thomson_modern_2013,
  title         = {Modern particle physics},
  author        = {Thomson, Mark},
  year          = 2013,
  publisher     = {Cambridge University Press},
  address       = {Cambridge, United Kingdom},
  isbn          = {978-1-107-03426-6},
  url           = {http://digitale-objekte.hbz-nrw.de/storage/2013/11/04/file_5/5371837.pdf},
  urldate       = {2025-07-18},
  note          = {Oclc: 840462909},
  abstract      = {"Unique in its coverage of all aspects of modern particle physics, this textbook provides a clear connection between the theory and recent experimental results, including the discovery of the Higgs boson at CERN. It provides a comprehensive and self-contained description of the Standard Model of particle physics suitable for upper-level undergraduate students and graduate students studying experimental particle physics. Physical theory is introduced in a straightforward manner with full mathematical derivations throughout. Fully-worked examples enable students to link the mathematical theory to results from modern particle physics experiments. End-of-chapter exercises, graded by difficulty, provide students with a deeper understanding of the subject. Online resources available at www.cambridge.org/MPP feature password-protected fully-worked solutions to problems for instructors, numerical solutions and hints to the problems for students and PowerPoint slides and JPEGs of figures from the book"-- Provided by publisher},
  language      = {eng},
  keywords      = {Electroweak interactions, Elementarteilchenphysik, Particles (Nuclear physics), Particles (Nuclear physics) Textbooks, Part\'{\i}cules (F\'{\i}sica nuclear), SCIENCE Nuclear Physics, Standard model (Nuclear physics), Textbooks}
}
@book{thomsonModernParticlePhysics2013,
  title         = {Modern Particle Physics},
  author        = {Thomson, Mark},
  year          = 2013,
  publisher     = {Cambridge University Press},
  address       = {Cambridge, United Kingdom},
  isbn          = {978-1-107-03426-6},
  urldate       = {2025-07-18},
  abstract      = {"Unique in its coverage of all aspects of modern particle physics, this textbook provides a clear connection between the theory and recent experimental results, including the discovery of the Higgs boson at CERN. It provides a comprehensive and self-contained description of the Standard Model of particle physics suitable for upper-level undergraduate students and graduate students studying experimental particle physics. Physical theory is introduced in a straightforward manner with full mathematical derivations throughout. Fully-worked examples enable students to link the mathematical theory to results from modern particle physics experiments. End-of-chapter exercises, graded by difficulty, provide students with a deeper understanding of the subject. Online resources available at www.cambridge.org/MPP feature password-protected fully-worked solutions to problems for instructors, numerical solutions and hints to the problems for students and PowerPoint slides and JPEGs of figures from the book"-- Provided by publisher},
  langid        = {english},
  keywords      = {Electroweak interactions,Elementarteilchenphysik,Particles (Nuclear physics),Particles (Nuclear physics) Textbooks,Particules (Fisica nuclear),SCIENCE Nuclear Physics,Standard model (Nuclear physics),Textbooks},
  annotation    = {Oclc: 840462909}
}
@misc{TruncatedSVDDocumentation,
  title         = {TruncatedSVD -- scikit-learn 1.7.0 documentation},
  url           = {https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html}
}
@article{UCLDeepMind,
  title         = {UCL x DeepMind}
}
@book{usastandards,
  title         = {The Acoustical Foundations of Music},
  author        = {John Backus},
  year          = 1977,
  publisher     = {W.~W.~Norton},
  address       = {New York}
}
@article{VanStroud2024TransformersPhysics,
  title         = {Transformers for Charged Particle Track Reconstruction in High Energy Physics},
  author        = {Van Stroud, Samuel and Duckett, Philippa and Hart, Max and Pond, Nikita and Rettie, S\'{e}bastien and Facini, Gabriel and Scanlon, Tim},
  year          = 2024,
  month         = 11,
  url           = {https://arxiv.org/pdf/2411.07149},
  arxivid       = {2411.07149},
  keywords      = {Detection {\textperiodcentered}, Learning {\textperiodcentered}, Machine, Object, Particle, Physics {\textperiodcentered}, Reconstruction {\textperiodcentered}, Track, TrackML {\textperiodcentered}, Transformers}
}
@article{vaslin_gan-ae_2023,
  title         = {{GAN}-{AE}: an anomaly detection algorithm for {New} {Physics} search in {LHC} data},
  shorttitle    = {{Gan}-{ae}},
  author        = {Vaslin, Louis and Barra, Vincent and Donini, Julien},
  year          = 2023,
  month         = nov,
  journal       = {The European Physical Journal C},
  volume        = 83,
  number        = 11,
  pages         = 1008,
  doi           = {10.1140/epjc/s10052-023-12169-4},
  issn          = {1434-6052},
  url           = {https://doi.org/10.1140/epjc/s10052-023-12169-4},
  urldate       = {2025-07-17},
  abstract      = {In recent years, interest has grown in alternative strategies for the search for New Physics beyond the Standard Model. One envisaged solution lies in the development of anomaly detection algorithms based on unsupervised machine learning techniques. In this paper, we propose a new Generative Adversarial Network-based auto-encoder model that allows both anomaly detection and model-independent background modeling. This algorithm can be integrated with other model-independent tools in a complete heavy resonance search strategy. The proposed strategy has been tested on the LHC Olympics 2020 dataset with promising results.},
  language      = {en},
  keywords      = {Artificial Intelligence, Experimental Particle Physics, High-Energy Astrophysics, Learning algorithms, Machine Learning, Particle Physics}
}
@article{Vaswani2017AttentionNeed,
  title         = {Attention Is All You Need},
  author        = {Vaswani, Ashish and Brain, Google and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L{}ukasz and Polosukhin, Illia},
  year          = 2017,
  month         = 6,
  pages         = 1,
  isbn          = {1706.03762v7},
  url           = {https://arxiv.org/pdf/1706.03762},
  arxivid       = {1706.03762}
}
@incollection{villani_wasserstein_2009,
  title         = {The {Wasserstein} distances},
  author        = {Villani, C\'{e}dric},
  year          = 2009,
  booktitle     = {Optimal {Transport}: {Old} and {New}},
  publisher     = {Springer},
  address       = {Berlin, Heidelberg},
  pages         = {93--111},
  doi           = {10.1007/978-3-540-71050-9_6},
  isbn          = {978-3-540-71050-9},
  url           = {https://doi.org/10.1007/978-3-540-71050-9_6},
  urldate       = {2025-07-17},
  abstract      = {Assume, as before, that you are in charge of the transport of goods between producers and consumers, whose respective spatial distributions are modeled by probability measures.},
  language      = {en},
  editor        = {Villani, C\'{e}dric}
}
@incollection{vincze_concept_1981,
  title         = {On the {Concept} and {Measure} of {Information} {Contained} in an {Observation}\textasteriskcentered},
  author        = {Vincze, Istv\'{a}n},
  year          = 1981,
  month         = jan,
  booktitle     = {Contributions to {Probability}},
  publisher     = {Academic Press},
  pages         = {207--214},
  doi           = {10.1016/b978-0-12-274460-0.50023-0},
  isbn          = {978-0-12-274460-0},
  url           = {https://www.sciencedirect.com/science/article/pii/B9780122744600500230},
  urldate       = {2025-07-14},
  abstract      = {Let X be distributed according to the law F(x, \textvartheta{}), where \textvartheta{} can take one of two possible values \textvartheta{}1 or \textvartheta{}2. A measure of the amount of information contained in an observation on X is derived. This measure is shown to be the same which occurs in a general form of the Cram\'{e}r-Fr\'{e}chet-Rao inequality.},
  editor        = {Gani, J. and Rohatgi, V. K.}
}
@article{Vischia2020NewUnfolding,
  title         = {New approaches to the problem of unfolding},
  author        = {Vischia, Pietro},
  year          = 2020
}
@article{Vogt:2018ytw,
  title         = {Four-Loop Results on Anomalous Dimensions and Splitting Functions in {{QCD}}},
  author        = {Vogt, Andreas and Moch, Sven-Olaf and Ruijl, B. and Ueda, Takahiro and Vermaseren, J. A. M.},
  year          = 2018,
  month         = jan,
  journal       = {PoS},
  volume        = {Radcor2017},
  pages         = {046},
  doi           = {10.22323/1.290.0046},
  editor        = {Hoang, Andre and Schneider, Carsten},
  eprint        = {1801.06085},
  primaryclass  = {hep-ph},
  abstract      = {We report on recent progress on the flavour non-singlet splitting functions in perturbative QCD. The{\textasciitilde}exact four-loop (N{\textasciicircum}3LO) contribution to these functions has been obtained in the planar limit of a large number of colours. Phenomenologically sufficient approximate expressions have been obtained for the parts not exactly known so far. Both cases include results for the four-loop cusp and virtual anomalous dimensions which are relevant well beyond the evolution of non-singlet quark distributions, for which an accuracy of (well) below 1\% has now been been reached.},
  archiveprefix = {arXiv},
  keywords      = {anomalous dimension,BETA,correction: quantum,expansion 1/N: color,higher-order: 3,numerical calculations,quantum chromodynamics: perturbation theory,splitting function,supersymmetry: 4},
  annotation    = {6 citations (INSPIRE 2025/7/18)\\ 4 citations w/o self (INSPIRE 2025/7/18)\\ Citations: 0 (Crossref) [2025-07-18]\\ Citations: 3 (SemanticScholar) [2025-07-18]},
  file          = {/Users/t-krishdesai/Zotero/storage/6LTMUXHX/Vogt et al. - 2018 - Four-loop results on anomalous dimensions and splitting functions in QCD.pdf}
}
@article{Wang2024InterpretingTagging,
  title         = {Interpreting Transformers for Jet Tagging},
  author        = {Wang, Aaron and Gandrakota, Abhijith and Ngadiuba, Jennifer and Sahu, Vivekanand and Bhatnagar, Priyansh and Khoda, Elham E and Duarte, Javier},
  year          = 2024,
  month         = 12,
  url           = {https://arxiv.org/pdf/2412.03673},
  arxivid       = {2412.03673}
}
@article{waveshaping,
  title         = {A Tutorial on Endow Dill or Tomography Doff},
  author        = {Rosa Olin Jackson},
  year          = 1979,
  journal       = {Inertia Puff Journal},
  volume        = 3,
  number        = 2,
  pages         = {29--34}
}
@article{weinberg_elementary_1963,
  title         = {Elementary {Particle} {Theory} of {Composite} {Particles}},
  author        = {Weinberg, Steven},
  year          = 1963,
  month         = apr,
  journal       = {Physical Review},
  volume        = 130,
  number        = 2,
  pages         = {776--783},
  doi           = {10.1103/PhysRev.130.776},
  url           = {https://link.aps.org/doi/10.1103/PhysRev.130.776},
  urldate       = {2025-07-13},
  note          = {Publisher: American Physical Society},
  abstract      = {Any nonrelativistic theory may be rewritten by introducing fictitious elementary particles with arbitrary properties. No physical predictions are affected, provided that the interaction part of the Hamiltonian is correspondingly modified. The fictitious elementary particle provides a good representation of a real composite particle if the modified interaction is sufficiently weakened for perturbation theory to work. It corresponds to a truly elementary particle with infinite bare mass, and hence with �� =0. We show how the latter condition yields a sum rule for the coupling of a composite particle to its constituents as a function of energy. The sum rule can be used to evaluate such coupling constants as that for the proton-electron-hydrogen vertex. The mathematical method used is that developed by Schmidt for the study of the Fredholm equation, and corresponds to the extraction of a single factor from the full Fredholm determinant.}
}
@article{Weinberg:1979pi,
  title         = {Conceptual Foundations of the Unified Theory of Weak and Electromagnetic Interactions},
  author        = {Weinberg, Steven},
  year          = 1980,
  journal       = {Rev. Mod. Phys.},
  volume        = 52,
  pages         = {515--523},
  doi           = {10.1103/RevModPhys.52.515},
  editor        = {Lundqvist, S.}
}
@misc{wiki:stdmodel,
  title         = {File:Standard Model of Elementary Particles.svg --- Wikimedia Commons{,} the free media repository},
  author        = {Wikimedia Commons},
  year          = 2025,
  url           = {\url{https://commons.wikimedia.org/w/index.php?title=File:Standard_Model_of_Elementary_Particles.svg&oldid=1013094830}},
  note          = {[Online; accessed 12-July-2025]}
}
@misc{willard_integrating_2022,
  title         = {Integrating {Scientific} {Knowledge} with {Machine} {Learning} for {Engineering} and {Environmental} {Systems}},
  author        = {Willard, Jared and Jia, Xiaowei and Xu, Shaoming and Steinbach, Michael and Kumar, Vipin},
  year          = 2022,
  month         = mar,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2003.04919},
  url           = {http://arxiv.org/abs/2003.04919},
  urldate       = {2025-07-15},
  note          = {arXiv:2003.04919 [physics]},
  abstract      = {There is a growing consensus that solutions to complex science and engineering problems require novel methodologies that are able to integrate traditional physics-based modeling approaches with state-of-the-art machine learning (ML) techniques. This paper provides a structured overview of such techniques. Application-centric objective areas for which these approaches have been applied are summarized, and then classes of methodologies used to construct physics-guided ML models and hybrid physics-ML frameworks are described. We then provide a taxonomy of these existing techniques, which uncovers knowledge gaps and potential crossovers of methods between disciplines that can serve as ideas for future research.},
  keywords      = {Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning}
}
@article{Winkler2019LearningFlows,
  title         = {Learning Likelihoods with Conditional Normalizing Flows},
  author        = {Winkler, Christina and Worrall, Daniel and Hoogeboom, Emiel and Welling, Max},
  year          = 2019,
  month         = 11,
  url           = {https://arxiv.org/pdf/1912.00042},
  arxivid       = {1912.00042}
}
@article{Winterhalder2022TargetingNetworks,
  title         = {Targeting multi-loop integrals with neural networks},
  author        = {Winterhalder, Ramon and Magerya, Vitaly and Villa, Emilio and Jones, Stephen P. and Kerner, Matthias and Butter, Anja and Heinrich, Gudrun and Plehn, Tilman},
  year          = 2022,
  month         = 4,
  journal       = {SciPost Phys.},
  publisher     = {SciPost Foundation},
  volume        = 12,
  number        = 4,
  pages         = 129,
  doi           = {10.21468/scipostphys.12.4.129},
  issn          = 25424653,
  arxivid       = {2112.09145}
}
@misc{wu_dense_2021,
  title         = {Dense {Deep} {Unfolding} {Network} with {3D}-{CNN} {Prior} for {Snapshot} {Compressive} {Imaging}},
  author        = {Wu, Zhuoyuan and Zhang, Jian and Mou, Chong},
  year          = 2021,
  month         = sep,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2109.06548},
  url           = {http://arxiv.org/abs/2109.06548},
  urldate       = {2025-07-15},
  note          = {arXiv:2109.06548 [eess]},
  abstract      = {Snapshot compressive imaging (SCI) aims to record three-dimensional signals via a two-dimensional camera. For the sake of building a fast and accurate SCI recovery algorithm, we incorporate the interpretability of model-based methods and the speed of learning-based ones and present a novel dense deep unfolding network (DUN) with 3D-CNN prior for SCI, where each phase is unrolled from an iteration of Half-Quadratic Splitting (HQS). To better exploit the spatial-temporal correlation among frames and address the problem of information loss between adjacent phases in existing DUNs, we propose to adopt the 3D-CNN prior in our proximal mapping module and develop a novel dense feature map (DFM) strategy, respectively. Besides, in order to promote network robustness, we further propose a dense feature map adaption (DFMA) module to allow inter-phase information to fuse adaptively. All the parameters are learned in an end-to-end fashion. Extensive experiments on simulation data and real data verify the superiority of our method. The source code is available at https://github.com/jianzhangcs/SCI3D.},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing}
}
@article{xia_bayesian_2022,
  title         = {Bayesian multiscale deep generative model for the solution of high-dimensional inverse problems},
  author        = {Xia, Yingzhi and Zabaras, Nicholas},
  year          = 2022,
  month         = apr,
  journal       = {Journal of Computational Physics},
  volume        = 455,
  pages         = 111008,
  doi           = {10.1016/j.jcp.2022.111008},
  issn          = {0021-9991},
  url           = {https://www.sciencedirect.com/science/article/pii/S0021999122000705},
  urldate       = {2025-07-14},
  abstract      = {Estimation of spatially-varying parameters for computationally expensive forward models governed by partial differential equations (PDEs) is addressed. A novel multiscale Bayesian inference approach is introduced based on a multiscale deep generative model (MDGM). Such generative models provide a flexible representation and allow hierarchical parameter generation from coarse- to fine-scales. Combining the multiscale generative model with Markov Chain Monte Carlo (MCMC), inference across scales is achieved enabling us to obtain efficiently posterior parameter samples at various scales. To estimate the most salient features of parameters is essential in the proposed method. Inference of the fine-scale parameters is enabled by utilizing the posterior information in the immediate coarser scale. In this way, the global features are identified in the coarse-scale with the inference of low-dimensional variables and inexpensive forward computation, and the local features are refined and corrected in the fine-scale. The developed method is demonstrated with two types of permeability estimation for flow in heterogeneous media. One is a Gaussian random field (GRF) with uncertain length scales, and the other is channelized permeability with the two regions defined by different GRFs. The obtained results indicate that the method allows high-dimensional parameter estimation while exhibiting stability, efficiency, and accuracy.},
  keywords      = {Bayesian inference, Deep generative model, High-dimensionality, Inverse problems, Markov Chain Monte Carlo, Multiscale estimation}
}
@article{Xu2023GenerativeFlow,
  title         = {Generative Machine Learning for Detector Response Modeling with a Conditional Normalizing Flow},
  author        = {Xu, Allison and Han, Shuo and Ju, Xiangyang and Wang, Haichen},
  year          = 2023,
  month         = 3,
  url           = {https://arxiv.org/pdf/2303.10148},
  arxivid       = {2303.10148},
  keywords      = {Conditional Normalizing Flow, Detector simulation, Generative Model, LHC}
}
@article{Xu2024LearningTransformer,
  title         = {Learning Physical Simulation with Message Passing Transformer},
  author        = {Xu, Zeyi and Li, Yifei},
  year          = 2024,
  month         = 6,
  url           = {https://arxiv.org/pdf/2406.06060},
  arxivid       = {2406.06060}
}
@article{yang_application_2024,
  title         = {Application of a deep learning method for shower axis reconstruction in a {3D} imaging calorimeter},
  author        = {Yang, X. G. and Quan, Z. and Dong, Y. W. and Xu, M. and Zhang, C. and Wang, J. J. and Liao, C. L. and Wu, Q. and Sun, J. Y. and Liu, X. and Wang, R. J. and Wang, Z. G. and Wu, B. B.},
  year          = 2024,
  month         = sep,
  journal       = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  volume        = 1066,
  pages         = 169571,
  doi           = {10.1016/j.nima.2024.169571},
  issn          = {0168-9002},
  url           = {https://www.sciencedirect.com/science/article/pii/S0168900224004972},
  urldate       = {2025-07-15},
  abstract      = {We present a deep learning method based on Convolutional Neural Networks (CNN) to reconstruct the shower axis of isotropic electrons in a three-dimensional (3D) imaging calorimeter, which is one of the core instruments of the High Energy cosmic-Radiation Detection (HERD) payload. The CNN method is evaluated against the Principal Component Analysis (PCA) method, utilizing isotropic Monte Carlo (MC) simulation data covering an energy spectrum from 10 GeV to 1000 GeV, as well as beam test data ranging from 50 GeV to 250 GeV. The comparative analysis results indicate that the CNN outperforms the PCA by about 40\% at 100 GeV in terms of angular resolution under isotropic conditions. Both methods are further validated using beam test data. The results demonstrate the effectiveness of the CNN method in reconstructing the shower axis, and they underscore the potential of incorporating advanced deep learning techniques into the comprehensive task of calorimeter reconstruction.},
  keywords      = {CNN, Calorimeters, HERD, PCA, Shower axis reconstruction}
}
@misc{yue_autoencoders_2024,
  title         = {Autoencoders for {At}-{Source} {Data} {Reduction} and {Anomaly} {Detection} in {High} {Energy} {Particle} {Detectors}},
  author        = {Yue, Alexander and Jia, Haoyi and Gonski, Julia},
  year          = 2024,
  month         = nov,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2411.01118},
  url           = {http://arxiv.org/abs/2411.01118},
  urldate       = {2025-07-16},
  note          = {arXiv:2411.01118 [hep-ex] version: 1},
  abstract      = {Detectors in next-generation high-energy physics experiments face several daunting requirements: high data rates, damaging radiation exposure, and stringent constraints on power, space, and latency. To address these challenges, machine learning in readout electronics can be leveraged for smart detector designs, enabling intelligent inference and data reduction at-source. Autoencoders offer a variety of benefits for front-end readout; an on-sensor encoder can perform efficient lossy data compression while simultaneously providing a latent space representation that can be used for anomaly detection. Results are presented from low-latency and resource-efficient autoencoders for front-end data processing in a futuristic silicon pixel detector. Encoder-based data compression is found to preserve good performance of off-detector analysis while significantly reducing the off-detector data rate as compared to a similarly sized data filtering approach. Furthermore, the latent space information is found to be a useful discriminator in the context of real-time sensor defect monitoring. Together, these results highlight the multifaceted utility of autoencoder-based front-end readout schemes and motivate their consideration in future detector designs.},
  keywords      = {High Energy Physics - Experiment, Physics - Instrumentation and Detectors}
}
@article{zardoshti_investigating_2017,
  title         = {Investigating the {Role} of {Coherence} {Effects} on {Jet} {Quenching} in {Pb}-{Pb} {Collisions} at {\textbackslash}sqrts\_NN =2.76 {TeV} using {Jet} {Substructure}},
  author        = {Zardoshti, Nima},
  year          = 2017,
  journal       = {Nucl. Phys. A},
  volume        = 967,
  pages         = {560--563},
  doi           = {10.1016/j.nuclphysa.2017.05.055},
  note          = {\_eprint: 1705.03383},
  editor        = {Heinz, Ulrich and Evdokimov, Olga and Jacobs, Peter},
  keywords      = {BETA, anti-kT algorithm, background, coherence: effect, color: coherence, dimension: 2, energy loss, heavy ion: scattering, jet: momentum, jet: quenching, p p: scattering}
}
@inproceedings{zaroubi_wiener_1995,
  title         = {Wiener reconstruction, {SVD} and 'optimal' functional bases: {Application} for redshift galaxy catalogs},
  shorttitle    = {Wiener reconstruction, {SVD} and 'optimal' functional bases},
  author        = {Zaroubi, Saleem},
  year          = 1995,
  booktitle     = {30th {Rencontres} de {Moriond}: {Euroconferences}: {Clustering} in the {Universe}},
  pages         = {135--142},
  note          = {\_eprint: astro-ph/9505103},
  keywords      = {Beta}
}
@article{zech_analysis_2016,
  title         = {Analysis of distorted measurements – parameter estimation and unfolding},
  author        = {Zech, Guenter},
  year          = 2016,
  month         = jul,
  note          = {\_eprint: 1607.06910},
  keywords      = {Beta}
}
@inproceedings{zech_regularization_2011,
  title         = {Regularization and error assignment to unfolded distributions},
  author        = {Zech, Gunter},
  year          = 2011,
  booktitle     = {{Phystat} 2011},
  publisher     = {Cern},
  address       = {Geneva},
  pages         = {252--259},
  doi           = {10.5170/cern-2011-006.252},
  keywords      = {BETA, data analysis method, publishing, regularization, statistical analysis, talk: Geneva 2011/01/17}
}
@misc{zeng_solving_2024,
  title         = {Solving {High}-dimensional {Inverse} {Problems} {Using} {Amortized} {Likelihood}-free {Inference} with {Noisy} and {Incomplete} {Data}},
  author        = {Zeng, Jice and Wang, Yuanzhe and Tartakovsky, Alexandre M. and Barajas-Solano, David},
  year          = 2024,
  month         = dec,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2412.04565},
  url           = {http://arxiv.org/abs/2412.04565},
  urldate       = {2025-07-16},
  note          = {arXiv:2412.04565 [cs]},
  abstract      = {We present a likelihood-free probabilistic inversion method based on normalizing flows for high-dimensional inverse problems. The proposed method is composed of two complementary networks: a summary network for data compression and an inference network for parameter estimation. The summary network encodes raw observations into a fixed-size vector of summary features, while the inference network generates samples of the approximate posterior distribution of the model parameters based on these summary features. The posterior samples are produced in a deep generative fashion by sampling from a latent Gaussian distribution and passing these samples through an invertible transformation. We construct this invertible transformation by sequentially alternating conditional invertible neural network and conditional neural spline flow layers. The summary and inference networks are trained simultaneously. We apply the proposed method to an inversion problem in groundwater hydrology to estimate the posterior distribution of the log-conductivity field conditioned on spatially sparse time-series observations of the system's hydraulic head responses.The conductivity field is represented with 706 degrees of freedom in the considered problem.The comparison with the likelihood-based iterative ensemble smoother PEST-IES method demonstrates that the proposed method accurately estimates the parameter posterior distribution and the observations' predictive posterior distribution at a fraction of the inference time of PEST-IES.},
  keywords      = {Computer Science - Machine Learning}
}
@misc{zhang_self-attention_2019,
  title         = {Self-{Attention} {Generative} {Adversarial} {Networks}},
  author        = {Zhang, Han and Goodfellow, Ian and Metaxas, Dimitris and Odena, Augustus},
  year          = 2019,
  month         = jun,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.1805.08318},
  url           = {http://arxiv.org/abs/1805.08318},
  urldate       = {2025-07-17},
  note          = {arXiv:1805.08318 [stat]},
  abstract      = {In this paper, we propose the Self-Attention Generative Adversarial Network (SAGAN) which allows attention-driven, long-range dependency modeling for image generation tasks. Traditional convolutional GANs generate high-resolution details as a function of only spatially local points in lower-resolution feature maps. In SAGAN, details can be generated using cues from all feature locations. Moreover, the discriminator can check that highly detailed features in distant portions of the image are consistent with each other. Furthermore, recent work has shown that generator conditioning affects GAN performance. Leveraging this insight, we apply spectral normalization to the GAN generator and find that this improves training dynamics. The proposed SAGAN achieves the state-of-the-art results, boosting the best published Inception score from 36.8 to 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on the challenging ImageNet dataset. Visualization of the attention layers shows that the generator leverages neighborhoods that correspond to object shapes rather than local regions of fixed shape.},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning}
}
@article{Zhang2006AIntervals,
  title         = {A Modification for Bayesian Credible Intervals},
  author        = {Zhang, Tonglin},
  year          = 2006,
  month         = 9,
  journal       = {Communications in Statistics - Theory and Methods},
  publisher     = {Taylor {\&} Francis Group},
  volume        = 35,
  number        = 9,
  pages         = {1703--1711},
  doi           = {10.1080/03610920600683838},
  issn          = {03610926},
  url           = {https://www.tandfonline.com/doi/abs/10.1080/03610920600683838},
  keywords      = {62C10, Bayesian credible intervals, Frequentist coverage probability, Location parameters, Posterior coverage probability, Prior and posterior distributions, Unimodality}
}
@misc{zhao_large-scale_2024,
  title         = {Large-{Scale} {Pretraining} and {Finetuning} for {Efficient} {Jet} {Classification} in {Particle} {Physics}},
  author        = {Zhao, Zihan and Mokhtar, Farouk and Kansal, Raghav and Li, Haoyang and Duarte, Javier},
  year          = 2024,
  month         = aug,
  publisher     = {arXiv},
  doi           = {10.48550/arXiv.2408.09343},
  url           = {http://arxiv.org/abs/2408.09343},
  urldate       = {2025-07-17},
  note          = {arXiv:2408.09343 [hep-ex]},
  abstract      = {This study introduces an innovative approach to analyzing unlabeled data in high-energy physics (HEP) through the application of self-supervised learning (SSL). Faced with the increasing computational cost of producing high-quality labeled simulation samples at the CERN LHC, we propose leveraging large volumes of unlabeled data to overcome the limitations of supervised learning methods, which heavily rely on detailed labeled simulations. By pretraining models on these vast, mostly untapped datasets, we aim to learn generic representations that can be finetuned with smaller quantities of labeled data. Our methodology employs contrastive learning with augmentations on jet datasets to teach the model to recognize common representations of jets, addressing the unique challenges of LHC physics. Building on the groundwork laid by previous studies, our work demonstrates the critical ability of SSL to utilize large-scale unlabeled data effectively. We showcase the scalability and effectiveness of our models by gradually increasing the size of the pretraining dataset and assessing the resultant performance enhancements. Our results, obtained from experiments on two datasets -- JetClass, representing unlabeled data, and Top Tagging, serving as labeled simulation data -- show significant improvements in data efficiency, computational efficiency, and overall performance. These findings suggest that SSL can greatly enhance the adaptability of ML models to the HEP domain. This work opens new avenues for the use of unlabeled data in HEP and contributes to a better understanding the potential of SSL for scientific discovery.},
  keywords      = {High Energy Physics - Experiment, Physics - Data Analysis, Statistics and Probability}
}
@inproceedings{zhu2024multidimensional,
  title         = {Multidimensional Deconvolution with Profiling},
  author        = {Zhu, Huanbiao and Desai, Krish and Kuusela, Mikael and Mikuni, Vinicius and Nachman, Benjamin and Wasserman, Larry},
  year          = 2024,
  booktitle     = {Ml4ps},
  number        = 150,
  doi           = {https://doi.org/10.48550/arXiv.2409.10421},
  maintitle     = {NeurIPS},
  archiveprefix = {arXiv},
  eprint        = {0902.0885},
  primaryclass  = {hep-ph}
}

@article{Abbiendi2004Measurementalpha_s,
    title = {{Measurement of event shape distributions and moments in {\$}e{\^{}}{\{}+{\}}e{\^{}}{\{}-{\}} {\textbackslash}to{\$} hadrons at 91-209 GeV and a determination of {\$}{\textbackslash}alpha{\_}{\{}s{\}}{\$}}},
    year = {2004},
    journal = {Eur. Phys. J. C},
    author = {Abbiendi, G. and Schorner-Sadenius, T. and Geich-Gimbel, C. and Rozen, Y. and Boutemeur, M. and Burckhart, H.J. and Axen, D. and Wolf, E.A.De and Mattig, Peter and Sachs, K. and Fleck, I. and Giacomelli, G. and Mohr, W. and Meijers, F. and Boeriu, O. and Mori, T. and Gunther, P.O. and Mihara, S. and Shears, T.G. and Akesson, P.F. and Cuffiani, M. and Duckeck, G. and Keeler, R.K. and McPherson, R.A. and Tasevsky, M. and Torrence, E. and Tsur, E. and Gruwe, M. and Montanari, A. and Kluth, S. and Batley, R.J. and Tran, P. and Kupper, M. and Barlow, R.J. and Pater, J.R. and Zivkovic, Lidija and Braibant, S. and Roeck, A.De and Giunta, Marina and Yamashita, S. and Duerdoth, I.P. and Grunhaus, J. and Heuer, R.D. and Menges, W. and Alexander, G. and Seuster, R. and Soldner-Rembold, S. and Shen, B.C. and Hoffman, Kara Dion and Verzocchi, M. and Komamiya, S. and Schroder, Matthias and Saeki, T. and Herten, G. and Kawamoto, T. and Nanjo, H. and Bell, Kenneth Watson and Trigger, I. and Anderson, K.J. and Wilson, G.W. and Bethke, S. and Hanson, G.G. and Ueda, I. and Ujvari, B. and Jovanovic, P. and Campana, S. and Mashimo, T. and Roney, J.M. and Dado, S. and Igo-Kemenes, P. and Hajdu, C. and Wilson, J.A. and Hamann, M. and Carnegie, R.K. and Wyatt, T.R. and Bock, P. and Wengler, T. and Nisius, R. and Dienes, B. and Lu, J. and Behnke, T. and Bella, G. and Scharff-Hansen, P. and Ferrari, P. and Mikenberg, G. and Neal, H.A. and Sarkisyan, E.K.G. and Kobayashi, T. and Wermes, N. and Ludwig, J. and Levinson, L. and Sobie, R. and Lettso, J. and Marcellini, S. and O'Neale, S.W. and Biebel, O. and Rabbertz, K. and Mutter, A. and Martin, A.J. and Pooth, O. and Duchovni, E. and Bechtle, P. and Fabbri, F. and Krieger, P. and Kobel, M. and Hill, J.C. and Hauschild, M. and Turner-Watson, M.F. and Lillich, J. and Renkel, P. and Kanzaki, J. and Watson, A.T. and Bell, P.J. and Lloyd, S.L. and Barberio, E. and Anagnostou, G. and Gary, John William and Kennedy, B.W. and Vannerem, P. and Watkins, P.M. and Brown, Robert M. and Fiedler, F. and Bellerive, A. and Mader, W. and Hawkes, C.M. and Harel, A. and Loebinger, F.K. and Strohmer, R. and Dubbert, J. and Pasztor, G. and Ishii, K. and Przybycien, M. and Vertesi, R. and Rembser, C. and Lellouch, D. and Masetti, G. and Ludwig, A. and Stahl, A. and Charlton, D.G. and Spano, F. and Carter, J.R. and Ford, M. and Horvath, D. and Schumacher, M. and Schaile, A.D. and Gagnon, P. and Plane, David E. and Toya, D. and Donkers, M. and Oh, A. and Giacomelli, P. and Miller, D.J. and Gross, E. and Thomson, M.A. and Junk, T.R. and Kramer, T. and Sherwood, P. and Ward, C.P. and Ciocca, C. and Krogh, J.von and Ward, D.R. and Kellogg, R.G. and Kuhl, T. and Carter, A.A. and Mes, H. and Teuscher, R. and Asai, S. and Nakamura, I. and Chang, C.Y. and Tarem, S. and Lanske, D. and Quadt, A. and Etzion, E. and Pahl, C. and Hawkings, R. and Merritt, F.S. and Barillari, T. and Orito, S. and Wells, P.S. and Ainsley, C. and Runge, K. and Smith, A.M. and Csilling, A. and Pinfold, J. and Strom, David M. and Goldberg, J. and Vossebeld, J. and Schieck, J. and Desch, K. and Vollmer, C.F. and Gupta, A. and Nagai, K. and Benelli, G. and Bailey, I. and Karlen, D. and Amaral, P. and McKenna, J. and Oreglia, M.J. and Hemingway, R.J. and Jeremie, H. and Zer-Zion, D. and Voss, H. and Kawagoe, K. and Michelini, A. and Watson, N.K. and Landsman, H. and Schaile, O. and Allison, John and Meyer, Niels T. and Wolf, G. and Skuja, A. and Fanfani, A. and Lafferty, G.D. and Frey, A. and Trocsanyi, Z. and Pilcher, J.E.},
    number = {3},
    month = {8},
    pages = {287--316},
    volume = {40},
    url = {https://cds.cern.ch/record/802086},
    doi = {10.1140/EPJC/S2005-02120-6},
    issn = {14346044},
    keywords = {CERN Document Server, Experiment, High Energy Physics, OPAL Preprints, WebSearch}
}
@article{Ridder2009NNLOAnnihilation,
    title = {{NNLO moments of event shapes in e+e- annihilation}},
    year = {2009},
    journal = {Journal of High Energy Physics},
    author = {Ridder, A. Gehrmann-De and Gehrmann, T. and Glover, E. W. N. and Heinrich, G.},
    number = {5},
    month = {5},
    volume = {2009},
    publisher = {Springer Verlag},
    url = {http://arxiv.org/abs/0903.4658 http://dx.doi.org/10.1088/1126-6708/2009/05/106},
    doi = {10.1088/1126-6708/2009/05/106},
    arxivId = {0903.4658v2},
    keywords = {LEP and ILC Physics, NLO and NNLO Computations, QCD, QCD phenomenology}
}
@article{BuskulicTheCollaboration,
    title = {{The ALEPH Collaboration}},
    author = {Buskulic, D and Casper, D and De Bonis, I and Decamp, D and Ghez, P and Goy, C and Lees, J.-P and Lucotte, A and Minard, M.-N and Odier, P and Pietrzyk, B and Ariztizabal, F and Chmeissani, M and Crespo, J M and Efthymiopoulos, I and Fernandez, E and Fernandez-Bosman, M and Gaitan, V and Garrido, Ll and Martinez, M and Orteu, S and Pacheco, A and Padilla, C and Palla, F and Pascual, A and Perlas, J A and Sanchez, F and Colaleo, A and Creanza, D and De Palma, M and Farilla, A and Gelao, G and Girone, M and Iaselli, G and Maggi, G and Maggi, M and Marinelli, N and Natali, S and Nuzzo, S and Ranieri, A and Raso, G and Romano, F and Ruggieri, F and Selvaggi, G and Silvestris, L and Empesta, P T and Zito, G and Huang, X and Lin, J and Ouyang, Q and Wang, T and Xie, Y and Xu, R and Xue, S and Zhang, J and Zhang, L and Zhao, W and Bonvicini, G and Cattaneo, M and Comas, P and Drevermann, H and Engelhardt, A and Forty, R W and Rank, M F and Hagelberg, R and Harvey, J and Jacobsen, R and Janot, P and Knobloch, J and Lehraus, I and Markou, C and Martin, E B and Mato, P and Meinhard, H and Minten, A and Miquel, R and Oest, T and Alazzi, P P and Pater, J R and Pusztaszeri, J.-F and Ranjard, F and Rensing, P and Rolandi, L and Schlatter, D and Schmelling, M and Schneider, O and Tejessy, W and Tomalin, I R and Venturi, A and Wachsmuth, H and Wiedenmann, W and Wildish, T and Witzeling, W and Wotschack, J and Ajaltouni, Z and Bardadin-Otwinowska, M and Barres, A and Boyer, C and Falvard, A and Guicheney, C and Henrard, P and Jousset, J and Michel, B and Monteil, S and Montret, J-C and Pallin, D and Erret, P P and Podlyski, F and Proriol, J and Rossignol, J.-M and Saadi, F and Fearnley, T and Hansen, J B and Hansen, J D and Hansen, J R and Hansen, P H and Nilsson, B S and Kyriakis, A and Simopoulou, E and Siotis, I and Vayaki, A and Zachariadou, K and Blondel, A and Bonneaud, G and Brient, J C and Bourdon, P and Passalacqua, L and Roug, A and Rumpf, M and Tanaka, R and Valassi, A and Verderi, M and Videau, H and Candlin, D J and Parsons, M I and Focardi, E and Parrini, G and Corden, M and Delno, M and Georgiopoulos, C and Jae, D E and Antonelli, A and Bencivenni, G and Bologna, G and Bossi, F and Campana, P and Capon, G and Chiarella, V and Felici, G and Laurelli, P and Mannocchi, G and Murtas, F and Murtas, G P and Pepe-Altarelli, M}
}
@article{Achard2002Determination192s208GeV,
    title = {{Determination of {$\alpha$}s from hadronic event shapes in e+e− annihilation at 192⩽s⩽208 GeV}},
    year = {2002},
    journal = {Physics Letters B},
    author = {Achard, P. and Adriani, O. and Aguilar-Benitez, M. and Alcaraz, J. and Alemanni, G. and Allaby, J. and Aloisio, A. and Alviggi, M. G. and Anderhub, H. and Andreev, V. P. and Anselmo, F. and Arefiev, A. and Azemoon, T. and Aziz, T. and Bagnaia, P. and Bajo, A. and Baksay, G. and Baksay, L. and Baldew, S. V. and Banerjee, S. and Banerjee, S. W. and Barczyk, A. and Barill{\`{e}}re, R. and Bartalini, P. and Basile, M. and Batalova, N. and Battiston, R. and Bay, A. and Becattini, F. and Becker, U. and Behner, F. and Bellucci, L. and Berbeco, R. and Berdugo, J. and Berges, P. and Bertucci, B. and Betev, B. L. and Biasini, M. and Biglietti, M. and Biland, A. and Blaising, J. J. and Blyth, S. C. and Bobbink, G. J. and B{\"{o}}hm, A. and Boldizsar, L. and Borgia, B. and Bottai, S. and Bourilkov, D. and Bourquin, M. and Braccini, S. and Branson, J. G. and Brochu, F. and Burger, J. D. and Burger, W. J. and Cai, X. D. and Capell, M. and Cara Romeo, G. and Carlino, G. and Cartacci, A. and Casaus, J. and Cavallari, F. and Cavallo, N. and Cecchi, C. and Cerrada, M. and Chamizo, M. and Chang, Y. H. and Chemarin, M. and Chen, A. and Chen, G. and Chen, G. M. and Chen, H. F. and Chen, H. S. and Chiefari, G. and Cifarelli, L. and Cindolo, F. and Clare, I. and Clare, R. and Coignet, G. and Colino, N. and Costantini, S. and de la Cruz, B. and Cucciarelli, S. and van Dalen, J. A. and de Asmundis, R. and D{\'{e}}glon, P. and Debreczeni, J. and Degr{\'{e}}, A. and Deiters, K. and della Volpe, D. and Delmeire, E. and Denes, P. and DeNotaristefani, F. and De Salvo, A. and Diemoz, M. and Dierckxsens, M. and Dionisi, C. and Dittmar, M. and Doria, A. and Dova, M. T. and Duchesneau, D. and Echenard, B. and Eline, A. and El Mamouni, H. and Engler, A. and Eppling, F. J. and Ewers, A. and Extermann, P. and Falagan, M. A. and Falciano, S. and Favara, A. and Fay, J. and Fedin, O. and Felcini, M. and Ferguson, T. and Fesefeldt, H. and Fiandrini, E. and Field, J. H. and Filthaut, F. and Fisher, P. H. and Fisher, W. and Fisk, I. and Forconi, G. and Freudenreich, K. and Furetta, C. and Galaktionov, Y. and Ganguli, S. N. and Garcia-Abia, P. and Gataullin, M. and Gentile, S. and Giagu, S. and Gong, Z. F. and Grenier, G. and Grimm, O. and Gruenewald, M. W. and Guida, M. and van Gulik, R. and Gupta, V. K. and Gurtu, A. and Gutay, L. J. and Haas, D. and Hakobyan, R. S. and Hatzifotiadou, D. and Hebbeker, T. and Herv{\'{e}}, A. and Hirschfelder, J. and Hofer, H. and Hohlmann, M. and Holzner, G. and Hou, S. R. and Hu, Y. and Jin, B. N. and Jones, L. W. and de Jong, P. and Josa-Mutuberr{\'{i}}a, I. and K{\"{a}}fer, D. and Kaur, M. and Kienzle-Focacci, M. N. and Kim, J. K. and Kirkby, J. and Kittel, W. and Klimentov, A. and K{\"{o}}nig, A. C. and Kopal, M. and Koutsenko, V. and Kr{\"{a}}ber, M. and Kraemer, R. W. and Krenz, W. and Kr{\"{u}}ger, A. and Kunin, A. and Ladron de Guevara, P. and Laktineh, I. and Landi, G. and Lebeau, M. and Lebedev, A. and Lebrun, P. and Lecomte, P. and Lecoq, P. and Le Coultre, P. and Le Goff, J. M. and Leiste, R. and Levtchenko, M. and Levtchenko, P. and Li, C. and Likhoded, S. and Lin, C. H. and Lin, W. T. and Linde, F. L. and Lista, L. and Liu, Z. A. and Lohmann, W. and Longo, E. and Lu, Y. S. and L{\"{u}}belsmeyer, K. and Luci, C. and Luminari, L. and Lustermann, W. and Ma, W. G. and Malgeri, L. and Malinin, A. and Ma{\~{n}}a, C. and Mangeol, D. and Mans, J. and Martin, J. P. and Marzano, F. and Mazumdar, K. and McNeil, R. R. and Mele, S. and Merola, L. and Meschini, M. and Metzger, W. J. and Mihul, A. and Milcent, H. and Mirabelli, G. and Mnich, J. and Mohanty, G. B. and Muanza, G. S. and Muijs, A. J.M. and Musicar, B. and Musy, M. and Nagy, S. and Natale, S. and Napolitano, M. and Nessi-Tedaldi, F. and Newman, H. and Niessen, T. and Nisati, A. and Nowak, H. and Ofierzynski, R. and Organtini, G. and Palomares, C. and Pandoulas, D. and Paolucci, P. and Paramatti, R. and Passaleva, G. and Patricelli, S. and Paul, T. and Pauluzzi, M. and Paus, C. and Pauss, F. and Pedace, M. and Pensotti, S. and Perret-Gallix, D. and Petersen, B. and Piccolo, D. and Pierella, F. and Pioppi, M. and Pirou{\'{e}}, P. A. and Pistolesi, E. and Plyaskin, V. and Pohl, M. and Pojidaev, V. and Pothier, J. and Prokofiev, D. O. and Prokofiev, D. and Quartieri, J. and Rahal-Callot, G. and Rahaman, M. A. and Raics, P. and Raja, N. and Ramelli, R. and Rancoita, P. G. and Ranieri, R. and Raspereza, A. and Razis, P. and Ren, D. and Rescigno, M. and Reucroft, S. and Riemann, S. and Riles, K. and Roe, B. P. and Romero, L. and Rosca, A. and Rosier-Lees, S. and Roth, S. and Rosenbleck, C. and Roux, B. and Rubio, J. A. and Ruggiero, G. and Rykaczewski, H. and Sakharov, A. and Saremi, S. and Sarkar, S. and Salicio, J. and Sanchez, E. and Sanders, M. P. and Sch{\"{a}}fer, C. and Schegelsky, V. and Schmidt-Kaerst, S. and Schmitz, D. and Schopper, H. and Schotanus, D. J. and Schwering, G. and Sciacca, C. and Servoli, L. and Shevchenko, S. and Shivarov, N. and Shoutko, V. and Shumilov, E. and Shvorob, A. and Siedenburg, T. and Son, D. and Spillantini, P. and Steuer, M. and Stickland, D. P. and Stoyanov, B. and Straessner, A. and Sudhakar, K. and Sultanov, G. and Sun, L. Z. and Sushkov, S. and Suter, H. and Swain, J. D. and Szillasi, Z. and Tang, X. W. and Tarjan, P. and Tauscher, L. and Taylor, L. and Tellili, B. and Teyssier, D. and Timmermans, C. and Ting, S. C.C. and Ting, S. M. and Tonwar, S. C. and T{\'{o}}th, J. and Tully, C. and Tung, K. L. and Ulbricht, J. and Valente, E. and Van de Walle, R. T. and Veszpremi, V. and Vesztergombi, G. and Vetlitsky, I. and Vicinanza, D. and Viertel, G. and Villa, S. and Vivargent, M. and Vlachos, S. and Vodopianov, I. and Vogel, H. and Vogt, H. and Vorobiev, I. and Vorobyov, A. A. and Wadhwa, M. and Wallraff, W. and Wang, X. L. and Wang, Z. M. and Weber, M. and Wienemann, P. and Wilkens, H. and Wynhoff, S. and Xia, L. and Xu, Z. Z. and Yamamoto, J. and Yang, B. Z. and Yang, C. G. and Yang, H. J. and Yang, M. and Yeh, S. C. and Zalite, A. and Zalite, Y. and Zhang, Z. P. and Zhao, J. and Zhu, G. Y. and Zhu, R. Y. and Zhuang, H. L. and Zichichi, A. and Zilizi, G. and Zimmermann, B. and Z{\"{o}}ller, M.},
    number = {3-4},
    month = {6},
    pages = {217--228},
    volume = {536},
    publisher = {North-Holland},
    url = {https://www.sciencedirect.com/science/article/abs/pii/S0370269302018142?via%3Dihub},
    doi = {10.1016/S0370-2693(02)01814-2},
    issn = {0370-2693}
}
@article{Deur2016TheCoupling,
    title = {{The QCD running coupling}},
    year = {2016},
    journal = {Progress in Particle and Nuclear Physics},
    author = {Deur, Alexandre and Brodsky, Stanley J. and de T{\'{e}}ramond, Guy F.},
    month = {9},
    pages = {1--74},
    volume = {90},
    publisher = {Elsevier B.V.},
    doi = {10.1016/j.ppnp.2016.04.003},
    issn = {01466410},
    arxivId = {2502.06535},
    keywords = {Coupling constant, Hadron physics, Infrared properties, Non-perturbative, QCD, Renormalization}
}
@article{Dasgupta2004EventScattering,
    title = {{Event shapes in e+e- annihilation and deep inelastic scattering}},
    year = {2004},
    journal = {Journal of Physics G: Nuclear and Particle Physics},
    author = {Dasgupta, Mrinal and Salam, Gavin P.},
    number = {5},
    month = {5},
    volume = {30},
    doi = {10.1088/0954-3899/30/5/R01},
    issn = {09543899},
    arxivId = {hep-ph/0312283}
}
@article{Heister2004StudiesGeV,
    title = {{Studies of QCD at e+e- centre-of-mass energies between 91 and 209 GeV}},
    year = {2004},
    journal = {European Physical Journal C},
    author = {Heister, A. and Schael, S. and Barate, R. and Bruneli{\`{e}}re, R. and De Bonis, I. and Decamp, D. and Goy, C. and J{\'{e}}z{\'{e}}quel, S. and Lees, J. P. and Martin, F. and Merle, E. and Minard, M. N. and Pietrzyk, B. and Trocm{\'{e}}, B. and Bravo, S. and Casado, M. P. and Chmeissani, M. and Crespo, J. M. and Fernandez, E. and Fernandez-Bosman, M. and Garrido, Ll and Martinez, M. and Pacheco, A. and Ruiz, H. and Colaleo, A. and Creanza, D. and De Filippis, N. and De Palma, M. and Iaselli, G. and Maggi, G. and Maggi, M. and Nuzzo, S. and Ranieri, A. and Raso, G. and Ruggieri, F. and Selvaggi, G. and Silvestris, L. and Tempesta, P. and Tricomi, A. and Zito, G. and Huang, X. and Lin, J. and Ouyang, Q. and Wang, T. and Xie, Y. and Xu, R. and Xue, S. and Zhang, J. and Zhang, L. and Zhao, W. and Abbaneo, D. and Barklow, T. and Buchm{\"{u}}ller, O. and Cattaneo, M. and Clerbaux, B. and Drevermann, H. and Forty, R. W. and Frank, M. and Gianotti, F. and Hansen, J. B. and Harvey, J. and Hutchcroft, D. E. and Janot, P. and Jost, B. and Kado, M. and Mato, P. and Moutoussi, A. and Ranjard, F. and Rolandi, L. and Schlatter, D. and Sguazzoni, G. and Teubert, F. and Valassi, A. and Videau, I. and Badaud, F. and Dessagne, S. and Falvard, A. and Fayolle, D. and Gay, P. and Jousset, J. and Michel, B. and Monteil, S. and Pallin, D. and Pascolo, J. M. and Perret, P. and Hansen, J. D. and Hansen, J. R. and Hansen, P. H. and Kraan, A. C. and Nilsson, B. S. and Kyriakis, A. and Markou, C. and Simopoulou, E. and Vayaki, A. and Zachariadou, K. and Blondel, A. and Brient, J. C. and Machefert, F. and Roug{\'{e}}, A.},
    number = {4},
    pages = {457--486},
    volume = {35},
    doi = {10.1140/EPJC/S2004-01891-4},
    issn = {14346044}
}
@article{Adeva1990TheExperiment,
    title = {{The construction of the L3 experiment}},
    year = {1990},
    journal = {Nuclear Inst. and Methods in Physics Research, A},
    author = {Adeva, B. and Aguilar-Benitez, M. and Akbari, H. and Alcaraz, J. and Aloisio, A. and Alvarez-Taviel, J. and Alverson, G. and Alviggi, M. G. and Anderhub, H. and Anderson, A. L. and Angelov, A. M. and Angelov, T. H. and Antchev, G. H. and Antonov, L. and Antreasyan, D. and Arefiev, A. and Atanasov, I. H. and Auroy, B. and Ayad, R. and Ayranov, O. L. and Azemoon, T. and Aziz, T. and Bachmann, U. and B{\"{a}}hler, P. and Bakken, J. A. and Baksay, L. and Baldinger, H. and Ball, R. C. and Ballansat, J. and Banerjee, S. and Bao, J. and Barbier, G. and Barone, L. and Basti, G. and Bay, A. and Beauvais, F. and Becker, U. and Beissel, R. and Bendig, S. and B{\'{e}}n{\'{e}}, P. and Berdugo, J. and Berges, P. and Berthet, M. and Bertsch, Y. and Betev, B. L. and Biland, A. and Bischoff, A. and Bischops, M. and Bizzarri, R. and Blaising, J. J. and Blanc, M. and Bl{\"{o}}meke, P. and Blumenfeld, B. and Bobbink, G. J. and Bocciolini, M. and Boffin, K. D. and Bohlen, W. and B{\"{o}}hm, A. and B{\"{o}}hringer, T. and Bonnefon, H. and Bopp, C. and Borgia, B. and Bosseler, K. and Bottolier, J. F. and Bourquin, M. and Boutigny, D. and Bowditch, P. and Branson, J. G. and Braun, D. and Brock, I. C. and Bruyant, F. and Buchholz, M. and B{\"{u}}cken, B. and Bulgeroni, W. and Burel, R. and Burger, J. D. and Burgos, C. and Burq, J. P. and Caiazzo, L. and Caillat, M. and Camberlin, B. and Campana, D. and Camps, C. and Canale, V. and Capell, M. and Carbonara, F. and Carminati, F. and Cartacci, A. M. and Cerrada, M. and Cesaroni, F. and Chang, Y. H. and Chapman, J. W. and Chemarin, M. and Chen, A. and Chen, C. and Chen, H. F. and Chen, H. S. and Chen, M. and Chen, M. L. and Chendvankar, S. R. and Chevenier, G. and Chidzik, S. and Chiefari, G. and Chien, C. Y. and Chollet, F. and Chumakov, M. and Civinini, C. and Clare, I. and Clare, R. and Coignet, G. and Colino, N. and Commichau, V. and Conforto, G. and Cristofori, P. and Crijns, F. and Cui, X. Y. and Dai, T. S. and D'Alessandro, R. and Daniel, M. and De Bouard, X. and Debye, B. and Decreuse, G. and Degr{\'{e}}, A. and Deiters, K. and D{\'{e}}nes, E. and Denes, P. and DeNotaristefani, F. and Deutschmann, M. and Dhina, M. and Didierjean, B. and Diemoz, M. and Dietrich, M. and Dimitrov, H. A. and Dionisi, C. and Dittus, F. and Dohmen, M. and Dolin, R. and Donahue, J. F. and Donat, A. and Drago, E. and Dreger, K. H. and Driever, T. and Dromby, G. and Duinker, P. and Duran, I. and Elkacimi, M. and Elmamouni, H. and Engler, A. and Eppling, F. J. and Ern{\'{e}}, F. C. and Erne, I. and Esser, H. and Extermann, P. and Fabbretti, R. and Faber, G. and Falciano, S. and Falk, T. and Fan, S. J. and Favre, M. and Fay, J. and Feh{\'{e}}r, S. and Fehlmann, J. and Feldmann, M. and Fenker, H. and Ferguson, T. and Fernandez, M. and Ferroni, F. and Fesefeldt, H. and Field, J. and Figarola, J. M. and Figueroa, C. F. and Filipov, G. A. and Folign{\'{e}}, B. and Forconi, G. and Foreman, T. and Franzke, V. and Frei, W. and Freudenreich, K. and Friebel, W. and Fukushima, M. and Gaillard, G. and Gailloud, M. and Galaktionov, Yu and Gallo, E. and Ganguli, S. N. and Garelick, D. and Gau, S. S. and Gavrilov, G. and Gennari, E. and Gentile, S. and Gettner, M. and Girard, C. and Glaubman, M. and Goldfarb, S. and Gong, Z. F. and Gonzalez, E. and Gordeev, A. and Gorodkov, Yu and G{\"{o}}ttlicher, P. and Goy, C. and Goyot, M. and Gratta, G. and Grimes, A. and Grinnell, C. and Gruenewald, M. and Guanziroli, M. and Guerra, S. and Guillon, C. and Gurtu, A. and G{\"{u}}sewell, D. and Gustafson, H. R. and Haensli, M. and Haan, M. and Haller, C. and Hamacher, T. and Hammers, H. and Hangarter, K. and Hancke, S. and Harris, M. and Harting, D. and Hartjes, F. G. and He, C. F. and Heavey, A. and Hebbeker, T. and Hebert, M. and Heller, R. and Helmrath, Ch and Herrmann, J. and Herten, G. and Herten, U. and Herv{\'{e}}, A. and Hesser, H. and Hilgers, G. and Hilgers, K. and Hofer, H. and Hofer, H. and Hofer, M. and Hofer, T. and Hoffmann, F. and Horisberger, U. and Horvath, I. and Hsu, L. S. and Hu, G. Q. and Ille, B. and Ilyas, M. M. and Improta, G. and Innocente, V. and Isiksal, E. and Jagel, E. and Jin, B. N. and Jones, L. W. and Jongmanns, M. and Jung, H. and Kaaret, P. and Kaelin, O. and Kaestli, W. and Kamyshkov, Yu and Kaplan, D. and Karpinski, W. and Karyotakis, Y. and Kertzer, W. and Khoze, V. and Kirchhoff, G. and Kittel, W. and Klimentov, A. and Klok, P. F. and Kollek, M. and Koller, M. and K{\"{o}}nig, A. C. and Kornadt, O. and Koutsenko, V. and Kraemer, R. W. and Krastev, V. R. and Kratel, A. and Krenz, W. and Kuhn, A. and Kunin, A. and Kwan, S. and Lacotte, J. and LaMarra, M. and Landi, G. and Lange, W. and Lanius, K. and Lanske, D. and Lanzano, S. and Le Goff, J. M. and Le Marec, J. C. and Lea, D. and Lebeau, M. and Lebrun, P. and Lecomte, P. and Lecoq, J. and Le Coultre, P. and Leedom, I. and L{\'{e}}ger, A. and Lehmann, F. and Leistam, L. and Leiste, R. and Lejeune, E. and Leoni, B. and Lettry, J. and Leytens, X. and Li, C. and Li, H. T. and Li, L. and Li, P. J. and Li, X. G. and Liao, J. Y. and Lin, Z. Y. and Linde, F. L. and Linnh{\"{o}}fer, D. and Loftin, E. and Lohmann, W. and L{\"{o}}k{\"{o}}s, S. and Longo, E. and Lu, Y. S. and Lubbers, J. M. and L{\"{u}}belsmeyer, K. and Luci, C. and Luckey, D. and Lue, X. and Luminari, L. and Lunadei, G. and L{\"{u}}rken, F. and Ma, H. and Ma, W. G. and MacDermott, M. and Madjar, N. and Magahiz, R. and Maire, M. and Malhotra, P. K. and Malinin, A. and Mana, C. and Manna, F. and Manto, G. and Mao, Y. F. and Maolinbay, M. and Marchesini, P. and Marchionni, A. and Markwalder, M. and Marsden, P. and Martin, J. P. and Martinez, L. and Martyn, H. U. and Marzano, F. and Marzullo, V. and Masciocchi, F. and Massaro, G. G.G. and Massonnet, L. and Matsuda, T. and Maurelli, G. and Mazumdar, K. and McBride, P. and Medici, G. and Meier, H. and Meinholz, Th and Merk, M. and Mermod, R. and Merola, L. and Meschini, M. and Metzger, W. J. and Micke, M. and Micke, U. and Mills, G. B. and Mnich, J. and Moeller, M. and Molinero, A. and Montanet, L. and Monteleoni, B. and Montino, R. and Morand, G. and Morand, R. and Morganti, S. and Morgunov, V. and Mount, R. and Moynot, M. and Mugnier, P. and N{\"{a}}geli, W. and Nagy, E. and Napolitano, M. and Neboux, S. and Newman, H. and Neyer, Ch and Nguyen, K. and Niessen, L. and Nikitin, A. and Nowak, W. D. and Okle, M. and Olmos, P. and Onvlee, J. and Osborne, D. and Ossmann, J. and Pandoulas, D. and Paprotny, H. and Parmentola, A. and Passeggio, G. and Paternoster, G. and Patricelli, S. and Pei, Y. J. and Peng, Y. and Peng, Y. and Perret-Gallix, D. and Perrier, J. and Perrin, E. and Perrot, G. and Petitpas, P. and Petschner, P. and Pevsner, A. and Pier-Amory, J. and Pieri, M. and Pierschel, G. and Pirou{\'{e}}, P. A. and Plyaskin, V. and Pohl, M. and Pojidaev, V. and Pols, C. L.A. and Ponomareff, T. and Potyka, J. and Produit, N. and Prokofiev, P. and Pruja, F. and P{\"{u}}tz, G. and Qian, J. M. and Raghavan, R. and Razis, P. and Read, K. and Reddick, P. and Reissmann, K. and Ren, D. and Reucroft, S. and Rey, D. and Reynaud, M. and Ricadonna, X. and Richeux, J. P. and Rippich, C. and Rinsche, U. and Rocco, R. and Rodriguez, S. and Roe, B. P. and R{\"{o}}hner, M. and R{\"{o}}hner, S. and Rombach, Th and Romero, L. and Rose, J. and R{\"{o}}ser, U. and Rosier-Lees, S. and Rubio, J. A. and Ruckstuhl, W. and Rykaczewski, H. and Sahuc, P. and Salicio, J. and Saran, S. and Sauvage, G. and Savin, A. and Schaad, T. and Schafheitle, B. and Schegelsky, V. and Schetkovsky, A. and Schild, F. and Schillsott, R. and Schmitt, P. and Schmitz, D. and Schmitz, P. and Schneegans, M. and Schneider, M. and Schneevogt, E. and Sch{\"{o}}ntag, M. and Schotanus, D. J. and Schuijlenburg, H. and Schulte, R. and Von Dratzig, A. Schultz and Schultze, K. and Schwenke, J. and Schwering, G. and Sciacca, C. and Seiler, P. G. and Sens, J. C. and Sheer, I. and Shevchenko, V. and Shevchenko, S. and Shi, X. R. and Shmakov, K. and Shoutko, V. and Shumilov, E. and Siedling, R. and Smirnov, N. and Souvorov, V. and Souyri, C. and Spangler, I. and Spickermann, T. and Spiess, B. and Spillantini, P. and Starosta, R. and Steuer, M. and Stickland, D. P. and St{\"{o}}hr, B. and Stone, H. and Strauch, K. and Sudhakar, K. and Sumner, R. L. and Suter, H. and Sutton, R. B. and Szczesny, H. and Tang, J. and Tang, X. W. and Tarkovsky, E. and Tavenrath, A. and Tchudakov, V. and Thenard, J. M. and Thomas, E. and Thon, T. and Thuerig, H. and Thulen, M. and Timmermans, C. and Ting, Samuel C.C. and Ting, S. M. and Tonisch, F. and Tong, Y. P. and Tonutti, M. and Tonwar, S. C. and T{\`{o}}th, J. and Toth, W. and Trowitzsch, G. and Tung, K. L. and Ulbricht, J. and Urb{\`{a}}n, L. and Valente, E. and van de Walle, R. T. and van der Graaf, H. and Vanzanella, V. and Vergain, M. and Vetlitsky, I. and Vey, H. and Viertel, G. and Vivargent, M. and Vogel, H. and Volkov, S. and Vollmar, M. and von Gunten, H. P. and Vorobiev, I. and Vorobyov, A. and Vuilleumier, L. and Waldmeier, S. and Walk, W. and Wallraff, W. and Wang, C. Y. and Wang, G. H. and Wang, J. H. and Wang, Q. F. and Wang, X. L. and Wang, Y. F. and Wang, Z. M. and Wang, Z. M. and Wassenberg, D. and Wegmann, D. and Weill, R. and Wenaus, T. J. and Wenger, P. and Wenninger, J. and White, M. and Wilhelm, R. and Willmott, C. and Wirth, H. P. and Wittgenstein, F. and Wu, R. J. and Wu, S. X. and Wu, Y. G. and Wyslouch, B. and Xi, F. Y. and Xu, Z. Z. and Xue, Z. L. and Yan, D. S. and Yanev, K. D. and Yang, B. Z. and Yang, C. G. and Yang, K. S. and Yang, Q. Y. and Yang, Z. Q. and Ye, C. H. and Yeh, S. C. and Yin, Z. W. and Zabounidis, C. and Zehnder, L. and Zeng, Y. and Zhang, D. H. and Zhang, S. Y. and Zhang, Z. P. and Zhou, B. and Zhou, J. F. and Zhou, Z. P. and Zhu, R. Y. and Zichichi, A. and Zofka, M. and Zoll, J.},
    number = {1-2},
    month = {4},
    pages = {35--102},
    volume = {289},
    doi = {10.1016/0168-9002(90)90250-A},
    issn = {01689002}
}
@article{Acciarri1997StudyGeV,
    title = {{Study of hadronic events and measurements of {$\alpha$}s between 30 and 91 GeV}},
    year = {1997},
    journal = {Physics Letters, Section B: Nuclear, Elementary Particle and High-Energy Physics},
    author = {Acciarri, M. and Adriani, O. and Aguilar-Benitez, M. and Ahlen, S. and Alcaraz, J. and Alemanni, G. and Allaby, J. and Aloisio, A. and Alverson, G. and Alviggi, M. G. and Ambrosi, G. and Anderhub, H. and Andreev, Y. P. and Angelescu, T. and Anselmo, F. and Arefiev, A. and Azemoon, T. and Aziz, T. and Bagnaia, P. and Baksay, L. and Ball, R. C. and Baneqee, S. and Baneqee, S. and Banicz, K. and Barczyk, A. and Barill{\`{e}}re, R. and Barone, L. and Bartalini, P. and Baschirotto, A. and Basile, M. and Battiston, R. and Bay, A. and Becattini, F. and Becker, U. and Behner, F. and Berdugo, J. and Berges, P. and Bertucci, B. and Betev, B. L. and Bhattacharya, S. and Biasini, M. and Biland, A. and Bilei, G. M. and Blaising, J. J. and Blyth, S. C. and Bobbink, G. J. and Bock, R. and B{\"{o}}hm, A. and Boldizsar, L. and Borgia, B. and Boucham, A. and Bourilkov, D. and Bourquin, M. and Boutigny, D. and Braccini, S. and Branson, J. G. and Brigljevic, V. and Brock, I. C. and Buffini, A. and Buijs, A. and Burger, J. D. and Burger, W. J. and Busenitz, J. and Cai, X. D. and Campanelli, M. and Capell, M. and Cara Romeo, G. and Carlino, G. and Cartacci, A. M. and Casaus, J. and Castellini, G. and Cavallari, F. and Cavallo, N. and Cecchi, C. and Cerrada, M. and Cesaroni, F. and Chamizo, M. and Chang, Y. H. and Chaturvedi, U. K. and Chekanov, S. V. and Chemarin, M. and Chen, A. and Chen, G. and Chen, G. M. and Chen, H. F. and Chen, H. S. and Chen, M. and Chiefari, G. and Chien, C. Y. and Cifarelli, L. and Cindolo, F. and Civinini, C. and Clare, I. and Clare, R. and Cohn, H. O. and Coignet, G. and Colijn, A. P. and Colino, N. and Commichau, V. and Costantini, S. and Cotorobai, F. and de la Cruz, B. and Csilling, A. and Dai, T. S. and D'Alessandro, R. and de Asmundis, R. and Degr{\'{e}}, A. and Deiters, K. and Denes, P. and DeNotaristefani, F. and DiBitonto, D. and Diemoz, M. and van Dierendonck, D. and di Lodovico, F. and Dionisi, C. and Dittmar, M. and Dominguez, A. and Doria, A. and Dome, I. and Dova, M. T. and Drago, E. and Duchesneau, D. and Duinker, P. and Duran, I. and Dutta, S. and Easo, S. and Efremenko, Y. and El Mamouni, H. and Engler, A. and Eppling, F. J. and Ern{\'{e}}, F. C. and Ernenwein, J. P. and Extermann, P. and Fabre, M. and Faccini, R. and Falciano, S. and Favara, A. and Fay, J. and Fedin, O. and Felcini, M. and Fenyi, B. and Ferguson, T. and Ferroni, F. and Fesefeldt, H. and Fiandrini, E. and Field, J. H. and Filthaut, F. and Fisher, P. H. and Fisk, I. and Forconi, G. and Fredj, L. and Freudenreich, K. and Furetta, C. and Galaktionov, Y. and Ganguli, S. N. and Garcia-Abia, P. and Gau, S. S. and Gentile, S. and Gerald, J. and Gheordanescu, N. and Giagu, S. and Goldfarb, S. and Goldstein, J. and Gong, Z. F. and Gougas, A. and Gratta, G. and Gruenewald, M. W. and Gupta, V. K. and Gurtu, A. and Gutay, L. J. and Hartmann, B. and Hasan, A. and Hatzifotiadou, D. and Hebbeker, T. and Herv{\'{e}}, A. and van Hoek, W. C. and Hofer, H. and Hong, S. J. and Hoorani, H. and Hou, S. R. and Hu, G. and Innocente, V. and Janssen, H. and Jenkes, K. and Jin, B. N. and Jones, L. W. and de Jong, P. and Josa-Mutuberria, I. and Kasser, A. and Khan, R. A. and Kamrad, D. and Kamyshkov, Y. and Kapustinsky, J. S. and Karyotakis, Y. and Kaur, M. and Kienzle-Focacci, M. N. and Kim, D. and Kim, D. H. and Kim, J. K. and Kim, S. C. and Kim, Y. G. and Kinnison, W. W. and Kirkby, A. and Kirkby, D. and Kirkby, J. and Kiss, D. and Kittel, W. and Klimentov, A. and K{\"{o}}nig, A. C. and Kopp, A. and Korolko, I. and Koutsenko, V. and Kraemer, R. W. and Krenz, W. and Kunin, A. and Ladron de Guevara, P. and Landi, G. and Lapoint, C. and Lassila-Perini, K. and Laurikainen, P. and Lebeau, M. and Lebedev, A. and Lebrun, P. and Lecomte, P. and Lecoq, P. and Le Coultre, P. and Leggett, C. and Le Goff, J. M. and Leiste, R. and Leonardi, E. and Levtchenko, P. and Li, C. and Lin, C. H. and Lin, W. T. and Linde, F. L. and Lista, L. and Liu, Z. A. and Lohmann, W. and Longo, E. and Lu, W. and Lu, Y. S. and L{\"{u}}belsmeyer, K. and Luci, C. and Luckey, D. and Luminari, L. and Lustermann, W. and Ma, W. G. and Maity, M. and Majumder, G. and Malgeri, L. and Malinin, A. and Ma{\~{n}}a, C. and Mangeol, D. and Mangla, S. and Marchesini, P. and Marin, A. and Martin, J. P. and Marzano, F. and Massaro, G. G.G. and McNally, D. and Mele, S. and Merola, L. and Meschini, M. and Metzger, WJ and von der Mey, M. and Mi, Y. and Mihul, A. and van Mil, A. J.W. and Mirabelli, G. and Mnich, J. and Molnar, P. and Monteleoni, B. and Moore, R. and Morganti, S. and Moulik, T. and Mount, R. and M{\"{u}}ller, S. and Muheim, F. and Muijs, A. J.M. and Nahn, S. and Napolitano, M. and Nessi-Tedaldi, F. and Newman, H. and Niessen, T. and Nippe, A. and Nisati, A. and Nowak, H. and Oh, Y. D. and Opitz, H. and Organtini, G. and Ostonen, R. and Palomares, C. and Pandoulas, D. and Paoletti, S. and Paolucci, P. and Park, H. K. and Park, I. H. and Pascale, G. and Passaleva, G. and Patricelli, S. and Paul, T. and Pauluzzi, M. and Paus, C. and Pauss, F. and Peach, D. and Pei, Y. J. and Pensotti, S. and Perret-Gallix, D. and Petersen, B. and Petrak, S. and Pevsner, A. and Piccolo, D. and Pieri, M. and Pinto, J. C. and Pirou{\'{e}}, P. A. and Pistolesi, E. and Plyaskin, V. and Pohl, M. and Pojidaev, V. and Postema, H. and Produit, N. and Prokofiev, D. and Rahal-Callot, G. and Raja, N. and Rancoita, P. G. and Rattaggi, M. and Raven, G. and Razis, P. and Read, K. and Ren, D. and Rescigno, M. and Reucroft, S. and van Rhee, T. and Riemann, S. and Riles, K. and Rind, O. and Robohm, A. and Rodin, J. and Roe, B. P. and Romero, L. and Rosier-Lees, S. and Rosselet, P. and van Rossum, W. and Roth, S. and Rubio, J. A. and Ruschmeier, D. and Rykaczewski, H. and Salicio, J. and Sanchez, E. and Sanders, M. P. and Sarakinos, M. E. and Sarkar, S. and Sassowsky, M. and Sauvage, G. and Sch{\"{a}}fer, C. and Schegelsky, V. and Schmidt-Kaerst, S. and Schmitz, D. and Schmitz, P. and Schneegans, M. and Scholz, N. and Schopper, H. and Schotanus, D. J. and Schwenke, J. and Schwering, G. and Sciacca, C. and Sciarrino, D. and Servoli, L. and Shevchenko, S. and Shivarov, N. and Shoutko, V. and Shukla, J. and Shumilov, E. and Shvorob, A. and Siedenburg, T. and Son, D. and Sopczak, A. and Soulimov, V. and Smith, B. and Spillantini, P. and Steuer, M. and Stickland, D. P. and Stone, H. and Stoyanov, B. and Straessner, A. and Strauch, K. and Sudhakar, K. and Sultanov, G. and Sun, L. Z. and Susinno, G. F. and Suter, H. and Swain, J. D. and Tang, X. W. and Tauscher, L. and Taylor, L. and Ting, S. C.C. and Ting, S. M. and Tonutti, M. and Tonwar, S. C. and T{\'{o}}th, J. and Tully, C. and Tuchscherer, H. and Tung, K. L. and Uchida, Y. and Ulbricht, J. and Uwer, U. and Valente, E. and van de Walle, R. T. and Vesztergombi, G. and Vetlitsky, I. and Viertel, G. and Vivargent, M. and V{\"{o}}lkert, R. and Vogel, H. and Vogt, H. and Vorobiev, I. and Vorobyov, A. A. and Vorvolakos, A. and Wadhwa, M. and Wallraff, W. and Wang, J. C. and Wang, X. L. and Wang, Z. M. and Weber, A. and Wittgenstein, F. and Wu, S. X. and Wynhoff, S. and Xu, J. and Xu, Z. Z. and Yang, B. Z. and Yang, C. G. and Yao, X. Y. and Ye, J. B. and Yeh, S. C. and You, J. M. and Zalite, A. and Zalite, Y. and Zemp, P. and Zeng, Y. and Zhang, Z. and Zhang, Z. P. and Zhou, B. and Zhou, Y. and Zhu, G. Y. and Zhu, R. Y. and Zichichi, A. and Ziegler, F.},
    number = {3-4},
    month = {10},
    pages = {339--353},
    volume = {411},
    publisher = {Elsevier B.V.},
    doi = {10.1016/S0370-2693(97)01000-9},
    issn = {03702693}
}
@article{Acciarri1996StudyGeV,
    title = {{Study of the structure of hadronic events and determination of {$\alpha$}s at √s = 130 GeV and 136 GeV}},
    year = {1996},
    journal = {Physics Letters, Section B: Nuclear, Elementary Particle and High-Energy Physics},
    author = {Acciarri, M. and Adam, A. and Adriani, O. and Aguilar-Benitez, M. and Ahlen, S. and Alpat, B. and Alcaraz, J. and Allaby, J. and Aloisio, A. and Alverson, G. and Alviggi, M. G. and Ambrosi, G. and Anderhub, H. and Andreev, V. P. and Angelescu, T. and Antreasyan, D. and Arefiev, A. and Azemoon, T. and Aziz, T. and Bagnaia, P. and Baksay, L. and Ball, R. C. and Banerjee, S. and Banicz, K. and Barill{\`{e}}re, R. and Barone, L. and Bartalini, P. and Baschirotto, A. and Basile, M. and Battiston, R. and Bay, A. and Becattini, F. and Becker, U. and Behner, F. and Bencze, G. L. and Berdugo, J. and Berges, P. and Bertucci, B. and Betev, B. L. and Biasini, M. and Biland, A. and Bilei, G. M. and Blaising, JJ and Blyth, S. C. and Bobbink, G. J. and Bock, R. and B{\"{o}}hm, A. and Borgia, B. and Boucham, A. and Bourilkov, D. and Bourquin, M. and Boutigny, D. and Brambilla, E. and Branson, J. G. and Brigljevic, V. and Brock, I. C. and Buijs, A. and Bujak, A. and Burger, J. D. and Burger, W. J. and Burgos, C. and Busenitz, J. and Buytenhuijs, A. and Cai, X. D. and Campanelli, M. and Capell, M. and Cara Romeo, G. and Caria, M. and Carlino, G. and Cartacci, A. M. and Casaus, J. and Castellini, G. and Castello, R. and Cavallari, F. and Cavallo, N. and Cecchi, C. and Cerrada, M. and Cesaroni, F. and Chamizo, M. and Chan, A. and Chang, Y. H. and Chaturvedi, U. K. and Chemarin, M. and Chen, A. and Chen, C. and Chen, G. and Chen, G. M. and Chen, H. F. and Chen, H. S. and Chereau, X. and Chiefari, G. and Chien, C. Y. and Choi, M. T. and Cifarelli, L. and Cindolo, F. and Civinini, C. and Clare, I. and Clare, R. and Coan, T. E. and Cohn, H. O. and Coignet, G. and Colijn, A. P. and Colino, N. and Commichau, V. and Costantini, S. and Cotorobai, F. and de la Cruz, B. and Dai, T. S. and D'Alessandro, R. and de Asmundis, R. and de Boeck, H. and Degr{\'{e}}, A. and Deiters, K. and D{\'{e}}nes, E. and Denes, P. and DeNotaristefani, F. and DiBitonto, D. and Diemoz, M. and van Dierendonck, D. and di Lodovico, F. and Dionisi, C. and Dittmar, M. and Dominguez, A. and Doria, A. and Dorne, I. and Dova, M. T. and Drago, E. and Duchesneau, D. and Duinker, P. and Duran, I. and Dutta, S. and Easo, S. and Efremenko, Y. and El Mamouni, H. and Engler, A. and Eppling, F. J. and Ern{\'{e}}, F. C. and Ernenwein, J. P. and Extermann, P. and Fabbretti, R. and Fabre, M. and Faccini, R. and Falciano, S. and Favara, A. and Fay, J. and Felcini, M. and Ferguson, T. and Fernandez, D. and Fernandez, G. and Ferroni, F. and Fesefeldt, H. and Fiandrini, E. and Field, J. H. and Filthaut, F. and Fisher, P. H. and Forconi, G. and Fredj, L. and Freudenreich, K. and Gailloud, M. and Galaktionov, Y. and Ganguli, S. N. and Garcia-Abia, P. and Gau, S. S. and Gentile, S. and Gerald, J. and Gheordanescu, N. and Giagu, S. and Goldfarb, S. and Goldstein, J. and Gong, Z. F. and Gonzalez, E. and Gougas, A. and Goujon, D. and Gratta, G. and Gruenewald, M. W. and Gupta, V. K. and Gurtu, A. and Gustafson, H. R. and Gutay, L. J. and Hangarter, K. and Hartmann, B. and Hasan, A. and He, J. T. and Hebbeker, T. and Herv{\'{e}}, A. and van Hoek, W. C. and Hofer, H. and Hoorani, H. and Hou, S. R. and Hu, G. and Ilyas, M. M. and Innocente, V. and Janssen, H. and Jin, B. N. and Jones, L. W. and de Jong, R. and Josa-Mutuberria, I. and Kasser, A. and Khan, R. A. and Kamyshkov, Y. and Kapinos, P. and Kapustinsky, J. S. and Karyotakis, Y. and Kaur, M. and Kienzle-Focacci, M. N. and Kim, D. and Kim, J. K. and Kim, S. C. and Kim, Y. G. and Kinnison, W. W. and Kirkby, A. and Kirkby, D. and Kirkby, J. and Kittel, W. and Klimentov, A. and K{\"{o}}nig, A. C. and Koffeman, E. and K{\"{o}}ngeter, A. and Koutsenko, V. and Koulbardis, A. and Kraemer, R. W. and Kramer, T. and Krenz, W. and Kuijten, H. and Kunin, A. and Ladron de Guevara, P. and Landi, G. and Lapoint, C. and Lassila-Perini, K. and Laurikainen, P. and Lebeau, M. and Lebedev, A. and Lebrun, P. and Lecomte, P. and Lecoq, P. and Le Coultre, P. and Lee, J. S. and Lee, K. Y. and Leggett, C. and Le Goff, J. M. and Leiste, R. and Lenti, M. and Leonardi, E. and Levtchenko, P. and Li, C. and Lieb, E. and Lin, W. T. and Linde, F. L. and Lindemann, B. and Lista, L. and Liu, Z. A. and Lohmann, W. and Longo, E. and Lu, W. and Lu, Y. S. and L{\"{u}}belsmeyer, K. and Luci, C. and Luckey, D. and Ludovici, L. and Luminari, L. and Lustermann, W. and Ma, W. G. and Macchiolo, A. and Maity, M. and Majumder, G. and Malgeri, L. and Malinin, A. and Ma{\~{n}}a, C. and Mangla, S. and Maolinbay, M. and Marchesini, P. and Marin, A. and Martin, J. P. and Marzano, F. and Massaro, G. G.G. and Mazumdar, K. and McNally, D. and McNeil, R. R. and Mele, S. and Merola, L. and Meschini, M. and Metzger, W. J. and von der Mey, M. and Mi, Y. and Mihul, A. and van Mil, A. J.W. and Mirabelli, G. and Mnich, J. and M{\"{o}}ller, M. and Monteleoni, B. and Moore, R. and Morganti, S. and Mount, R. and M{\"{u}}ller, S. and Muheim, F. and Nagy, E. and Nahn, S. and Napolitano, M. and Nessi-Tedaldi, F. and Newman, H. and Nippe, A. and Nowak, H. and Organtini, G. and Ostonen, R. and Pandoulas, D. and Paoletti, S. and Paolucci, P. and Park, H. K. and Pascale, G. and Passaleva, G. and Patricelli, S. and Paul, T. and Pauluzzi, M. and Paus, C. and Pauss, F. and Pei, Y. J. and Pensotti, S. and Perret-Gallix, D. and Petrak, S. and Pevsner, A. and Piccolo, D. and Pieri, M. and Pinto, J. C. and Pirou{\'{e}}, PA and Pistolesi, P. and Plyaskin, V. and Pohl, M. and Pojidaev, V. and Postema, H. and Produit, N. and Raghavan, R. and Rahal-Callot, G. and Rancoita, P. G. and Rattaggi, M. and Raven, G. and Razis, P. and Read, K. and Redaelli, M. and Ren, D. and Rescigno, M. and Reucroft, S. and Ricker, A. and Riemann, S. and Riemers, B. C. and Riles, K. and Rind, O. and Ro, S. and Robohm, A. and Rodin, J. and Rodriguez, F. J. and Roe, B. P. and R{\"{o}}hner, S. and Romero, L. and Rosier-Lees, S. and Rosselet, P. and van Rossum, W. and Roth, S. and Rubio, J. A. and Rykaczewski, H. and Salicio, J. and Salicio, J. M. and Sanchez, E. and Santocchia, A. and Sarakinos, M. E. and Sarkar, S. and Sassowsky, M. and Sch{\"{a}}fer, C. and Schegelsky, V. and Schmidt-Kaerst, S. and Schmitz, D. and Schmitz, P. and Schneegans, M. and Schoeneich, B. and Scholz, N. and Schopper, H. and Schotanus, D. J. and Schulte, R. and Schultze, K. and Schwenke, J. and Schwering, G. and Sciacca, C. and Seiler, P. G. and Sens, J. C. and Servoli, L. and Shevchenko, S. and Shivarov, N. and Shoutko, V. and Shukla, J. and Shumilov, E. and Siedenburg, T. and Son, D. and Sopczak, A. and Soulimov, V. and Smith, B. and Spillantini, P. and Steuer, M. and Stickland, D. P. and Sticozzi, F. and Stone, H. and Stoyanov, B. and Straessner, A. and Strauch, K. and Sudhakar, K. and Sultanov, G. and Sun, L. Z. and Susinno, G. F. and Suter, H. and Swaint, J. D. and Tang, X. W. and Tauscher, L. and Taylor, L. and Ting, S. C.C. and Ting, S. M. and Toker, O. and Tonisch, F. and Tonutti, M. and Tonwar, S. C. and T{\'{o}}th, J. and Tsaregorodtsev, A. and Tully, C. and Tuchscherer, H. and Tung, K. L. and Ulbricht, J. and Urban, L. and Uwer, U. and Valente, E. and van de Walle, R. T. and Vetlitsky, I. and Viertel, G. and Vivargent, M. and V{\"{o}}lkert, R. and Vogel, H. and Vogt, H. and Vorobiev, I. and Vorobyov, A. A. and Vorobyov, A. A. and Vuilleumier, L. and Wadhwa, M. and Wallraff, W. and Wang, J. C. and Wang, X. L. and Wang, Y. F. and Wang, Z. M. and Weber, A. and Weill, R. and Willmott, C. and Wittgenstein, F. and Wu, S. X. and Wynhoff, S. and Xu, J. and Xu, Z. Z. and Yang, B. Z. and Yang, C. G. and Yao, X. Y. and Ye, J. B. and Yeh, S. C. and You, J. M. and Zaccardelli, C. and Zalite, A. and Zemp, P. and Zeng, J. Y. and Zeng, Y. and Zhang, Z. and Zhang, Z. P. and Zhou, B. and Zhou, G. J. and Zhou, Y. and Zhu, G. Y. and Zhu, R. Y. and Zichichi, A. and van der Zwaan, B. C.C.},
    number = {1-2},
    month = {3},
    pages = {137--148},
    volume = {371},
    publisher = {Elsevier B.V.},
    doi = {10.1016/0370-2693(96)00096-2},
    issn = {03702693}
}
@article{Acciarri1997QCDCollaboration,
    title = {{QCD studies and determination of {$\alpha$}s in e+e- collisions at √s = 161 GeV and 172 GeV L3 Collaboration}},
    year = {1997},
    journal = {Physics Letters, Section B: Nuclear, Elementary Particle and High-Energy Physics},
    author = {Acciarri, M. and Adriani, O. and Aguilar-Benitez, M. and Ahlen, S. and Alcaraz, J. and Alemanni, G. and Allaby, J. and Aloisio, A. and Alverson, G. and Alviggi, M. G. and Ambrosi, G. and Anderhub, H. and Andreev, V. P. and Angelescu, T. and Anselmo, F. and Arefiev, A. and Azemoon, T. and Aziz, T. and Bagnaia, P. and Baksay, L. and Banerjee, S. and Banerjee, S. and Banicz, K. and Barczyk, A. and Barill{\`{e}}re, R. and Barone, L. and Bartalini, P. and Baschirotto, A. and Basile, M. and Battiston, R. and Bay, A. and Becattini, F. and Becker, U. and Behner, F. and Berdugo, J. and Berges, P. and Bertucci, B. and Betev, B. L. and Bhattacharya, S. and Biasini, M. and Biland, A. and Bilei, G. M. and Blaising, J. J. and Blyth, S. C. and Bobbink, G. J. and Bock, R. and B{\"{o}}hm, A. and Boldizsar, L. and Borgia, B. and Bourilkov, D. and Bourquin, M. and Braccini, S. and Branson, J. G. and Brigljevic, V. and Brock, I. C. and Buffini, A. and Buijs, A. and Burger, J. D. and Burger, W. J. and Busenitz, J. and Button, A. and Cai, X. D. and Campanelli, M. and Capell, M. and Cara Romeo, G. and Carlino, G. and Cartacci, A. M. and Casaus, J. and Castellini, G. and Cavallari, F. and Cavallo, N. and Cecchi, C. and Cerrada, M. and Cesaroni, F. and Chamizo, M. and Chang, Y. H. and Chaturvedi, U. K. and Chekanov, S. V. and Chemarin, M. and Chen, A. and Chen, G. and Chen, G. M. and Chen, H. F. and Chen, H. S. and Chereau, X. and Chiefari, G. and Chien, C. Y. and Cifarelli, L. and Cindolo, F. and Civinini, C. and Clare, I. and Clare, R. and Cohn, H. O. and Coignet, G. and Colijn, A. P. and Colino, N. and Commichau, V. and Costantini, S. and Cotorobai, F. and de la Cruz, B. and Csilling, A. and Dai, T. S. and D'Alessandro, R. and de Asmundis, R. and Degr{\'{e}}, A. and Deiters, K. and della Volpe, D. and Denes, P. and DeNotaristefani, F. and DiBitonto, D. and Diemoz, M. and van Dierendonck, D. and di Lodovico, F. and Dionisi, C. and Dittmar, M. and Dominguez, A. and Doria, A. and Dova, M. T. and Duchesneau, D. and Duinker, P. and Duran, I. and Dutta, S. and Easo, S. and Efremenko, Y. and El Mamouni, H. and Engler, A. and Eppling, F. J. and Ern{\'{e}}, F. C. and Ernenwein, J. P. and Extermann, P. and Fabre, M. and Faccini, R. and Falciano, S. and Favara, A. and Fay, J. and Fedin, O. and Felcini, M. and Fenyi, B. and Ferguson, T. and Ferroni, F. and Fesefeldt, H. and Fiandrini, E. and Field, J. H. and Filthaut, F. and Fisher, P. H. and Fisk, I. and Forconi, G. and Fredj, L. and Freudenreich, K. and Furetta, C. and Galaktionov, Y. and Ganguli, S. N. and Garcia-Abia, P. and Gau, S. S. and Gentile, S. and Gheordanescu, N. and Giagu, S. and Goldfarb, S. and Goldstein, J. and Gong, Z. F. and Gougas, A. and Gratta, G. and Gruenewald, M. W. and Gupta, V. K. and Gurtu, A. and Gutay, L. J. and Hartmann, B. and Hasan, A. and Hatzifotiadou, D. and Hebbeker, T. and Herv{\'{e}}, A. and van Hoek, W. C. and Hofer, H. and Hong, S. J. and Hoorani, H. and Hou, S. R. and Hu, G. and Innocente, V. and Jenkes, K. and Jin, B. N. and Jones, L. W. and dfe Jong, R. and Josa-Mutuberria, I. and Kasser, A. and Khan, R. A. and Kamrad, D. and Kamyshkov, Y. and Kapustinsky, J. S. and Karyotakis, Y. and Kaur, M. and Kienzle-Focacci, M. N. and Kim, D. and Kim, D. H. and Kim, J. K. and Kim, S. C. and Kim, Y. G. and Kinnison, W. W. and Kirkby, A. and Kirkby, D. and Kirkby, J. and Kiss, D. and Kittel, W. and Klimentov, A. and K{\"{o}}nig, A. C. and Kopp, A. and Korolko, I. and Koutsenko, V. and Kraemer, R. W. and Krenz, W. and Kunin, A. and Ladron de Guevara, P. and Laktineh, I. and Landi, G. and Lapoint, C. and Lassila-Perini, K. and Laurikainen, P. and Lebeau, M. and Lebedev, A. and Lebrun, P. and Lecomte, P. and Lecoq, P. and Le Coultre, P. and Le Goff, J. M. and Leiste, R. and Leonardi, E. and Levtchenko, P. and Li, C. and Lin, C. H. and Lin, W. T. and Linde, F. L. and Lista, L. and Liu, Z. A. and Lohmann, W. and Longo, E. and Lu, W. and Lu, Y. S. and L{\"{u}}belsmeyer, K. and Luci, C. and Luckey, D. and Luminari, L. and Lustermann, W. and Ma, W. G. and Maity, M. and Majumder, G. and Malgeri, L. and Malinin, A. and Ma{\~{n}}a, C. and Mangeol, D. and Mangla, S. and Marchesini, P. and Marin, A. and Martin, J. P. and Marzano, F. and Massaro, G. G.G. and McNally, D. and McNeil, R. R. and Mele, S. and Merola, L. and Meschini, M. and Metzger, W. J. and von der Mey, M. and Mi, Y. and Mihul, A. and van Mil, A. J.W. and Mirabelli, G. and Mnich, J. and Molnar, P. and Monteleoni, B. and Moore, R. and Morganti, S. and Moulik, T. and Mount, R. and M{\"{u}}ller, S. and Muheim, F. and Muijs, A. J.M. and Nahn, S. and Napolitano, M. and Nessi-Tedaldi, F. and Newman, H. and Niessen, T. and Nippe, A. and Nisati, A. and Nowak, H. and Oh, YD and Opitz, H. and Organtini, G. and Ostonen, R. and Palomares, C. and Pandoulas, D. and Paoletti, S. and Paolucci, P. and Park, H. K. and Park, I. H. and Pascale, G. and Passaleva, G. and Patricelli, S. and Paul, T. and Pauluzzi, M. and Paus, C. and Pauss, F. and Peach, D. and Pei, YJ and Pensotti, S. and Perret-Gallix, D. and Petersen, B. and Petrak, S. and Pevsner, A. and Piccolo, D. and Pieri, M. and Pinto, J. C. and Pirou{\'{e}}, PA and Pistolesi, E. and Plyaskin, V. and Pohl, M. and Pojidaev, V. and Postema, H. and Produit, N. and Prokofiev, D. and Rahal-Callot, G. and Raja, N. and Rancoita, P. G. and Rattaggi, M. and Raven, G. and Razis, P. and Read, K. and Ren, D. and Rescigno, M. and Reucroft, S. and van Rhee, T. and Riemann, S. and Riles, K. and Robohm, A. and Rodin, J. and Roe, B. P. and Romero, L. and Rosier-Lees, S. and Rosselet, P. and van Rossum, W. and Roth, S. and Rubio, J. A. and Ruschmeier, D. and Rykaczewski, H. and Salicio, J. and Sanchez, E. and Sanders, M. P. and Sarakinos, M. E. and Sarkar, S. and Sassowsky, M. and Sch{\"{a}}fer, C. and Schegelsky, V. and Schmidt-Kaerst, S. and Schmitz, D. and Schmitz, P. and Scholz, N. and Schopper, H. and Schotanus, D. J. and Schwenke, J. and Schwering, G. and Sciacca, C. and Sciarrino, D. and Servoli, L. and Shevchenko, S. and Shivarov, N. and Shoutko, V. and Shukla, J. and Shumilov, E. and Shvorob, A. and Siedenburg, T. and Son, D. and Sopczak, A. and Smith, B. and Spillantini, P. and Steuer, M. and Stickland, D. P. and Stone, A. and Stone, H. and Stoyanov, B. and Straessner, A. and Strauch, K. and Sudhakar, K. and Sultanov, G. and Sun, L. Z. and Susinno, G. F. and Suter, H. and Swain, J. D. and Tang, X. W. and Tauscher, L. and Taylor, L. and Ting, S. C.C. and Ting, S. M. and Tonutti, M. and Tonwar, S. C. and T{\'{o}}th, J. and Tully, C. and Tuchscherer, H. and Tung, K. L. and Uchida, Y. and Ulbricht, J. and Uwer, U. and Valente, E. and van de Walle, R. T. and Vesztergombi, G. and Vetlitsky, I. and Viertel, G. and Vivargent, M. and V{\"{o}}lkert, R. and Vogel, H. and Vogt, H. and Vorobiev, I. and Vorobyov, A. A. and Vorvolakos, A. and Wadhwa, M. and Wallraff, W. and Wang, J. C. and Wang, X. L. and Wang, Z. M. and Weber, A. and Wittgenstein, F. and Wu, S. X. and Wynhoff, S. and Xu, J. and Xu, Z. Z. and Yang, B. Z. and Yang, C. G. and Yao, X. Y. and Ye, J. B. and Yeh, S. C. and You, J. M. and Zalite, A. and Zalite, Y. and Zemp, P. and Zeng, Y. and Zhang, Z. and Zhang, Z. P. and Zhou, B. and Zhu, G. Y. and Zhu, R. Y. and Zichichi, A. and Ziegler, F.},
    number = {3-4},
    month = {7},
    pages = {390--402},
    volume = {404},
    publisher = {Elsevier B.V.},
    doi = {10.1016/S0370-2693(97)00647-3},
    issn = {03702693}
}
@article{Chandramohan1981ConsequencesAnnihilation,
    title = {{Consequences of 2nd order QCD for jet structure in e+e- annihilation}},
    year = {1981},
    journal = {Nuclear Physics, Section B},
    author = {Chandramohan, T. and Clavelli, L.},
    number = {C},
    pages = {365--380},
    volume = {184},
    doi = {10.1016/0550-3213(81)90224-8},
    issn = {05503213}
}
@article{Bohm2001MeasurementLeptons,
    title = {{Measurement of the tau branching fractions into leptons}},
    year = {2001},
    journal = {Physics Letters, Section B: Nuclear, Elementary Particle and High-Energy Physics},
    author = {B{\"{o}}hm, A. and Ewers, A. and Fesefeldt, H. and K{\"{a}}fer, D. and Krenz, W. and L{\"{u}}belsmeyer, W. and von{\'{e}}der{\'{e}}Mey, M. and Mnich, J. and Niessen, T. and Pandoulas, D. and Roth, S. and Rosenbleck, C. and Schmidt-Kaerst, S. and Schmitz, D. and Schwering, G. and Siedenburg, T. and Wallraff, W. and Weber, A. and Weber, M. and Wienemann, P. and Z{\"{o}}ller, M. and B{\"{o}}hm, A. and Ewers, A. and Fesefeldt, H. and K{\"{a}}fer, D. and Krenz, W. and L{\"{u}}belsmeyer, W. and von{\'{e}}der{\'{e}}Mey, M. and Mnich, J. and Niessen, T. and Pandoulas, D. and Rosenbleck, C. and Schmidt-Kaerst, S. and Schmitz, D. and Schwering, G. and Siedenburg, T. and Wallraff, W. and Weber, A. and Weber, M. and Wienemann, P. and Z{\"{o}}ller, M. and Baldew, S. V. and Bobbink, G. J. and Colijn, A. P. and Colijn, M. and Dierckxsens, M. and van{\'{e}}Dierendonck, D. and Duinker, P. and Ern{\'{e}}, P. and van{\'{e}}Gulik, R. and de{\'{e}}Jong, P. and Linde, F. L. and Muijs, A. J.M. and Azemoon, T. and Berbeco, R. and Jones, L. W. and Moore, R. and Riles, K. and Roe, B. P. and Yamamoto, J. and Balandras, A. and Banerjee, S. and Blaising, J. J. and Brochu, F. and Coignet, G. and Degr{\'{a}}, A. and Duchesneau, D. and Dufournaud, D. and Perret-Gallix, D. and Rosier-Lees, S. and Vivargent, M. and Costantini, S. and Garcia-Abia, P. and Haas, D. and Tauscher, L. and Vlachos, S. and Wadhwa, M. and Andreev, V. P. and McNeil, R. R. and Saremi, S. and Stone, A. and Chen, G. and Chen, G. M. and Chen, H. S. and Jin, B. N. and Liu, Z. A. and Lu, Y. S. and Tang, X. W. and Tung, K. L. and Yang, C. G. and Yang, H. J. and Yang, M. and Zhu, G. Y. and Gruenewald, M. W. and Hebbeker, T. and Lee, H. J. and Rosca, A. and Sushkov, S. and Anselmo, F. and Basile, M. and Cara{\'{e}}Romeo, G. and Cindolo, F. and Hatzifotiadou, D. and Pierella, F. and Seganti, A. and Zichichi, A. and Aziz, T. and Banerjee, S. and Bhattacharya, S. and Ganguli, S. N. and Gurtu, A. and Maity, M. and Mazumdar, K. and Mohanty, G. B. and Moulik, T. and Rahaman, M. A. and Raja, N. and Sudhakar, K. and Tonwar, S. C. and Gau, S. S. and Paul, T. and Reucroft, S. and Taylor, L. and Angelescu, T. and Cotorobai, F. and Gheordanescu, N. and Mihul, A. and Boldizsar, L. and Csilling, A. and Hidas, P. and Kiss, D. and T{\'{o}}th, J. and Vesztergombi, G. and Becker, U. and Berges, P. and Burger, J. D. and Cai, X. D. and Capell, M. and Clare, I. and Dai, T. S. and Eppling, F. J. and Fisher, P. H. and Forconi, G. and Galaktionov, Yu and Klimentov, A. and Koutsenko, V. and Kunin, A. and Lebedev, A. and Luckey, D. and Postema, H. and Steuer, M. and Ting, SamueléC C.C. and Ting, S. M. and Uchida, Y. and Wang, M. and Wu, S. X. and Marian, G. and Raics, P. and Bertucci, B. and Buffini, A. and Cartacci, A. M. and Adriani, O. and Allaby, J. and Barill{\`{e}}re, R. and Falciano, S. and Favara, A. and Filthaut, F. and Gentile, S. and Herv{\'{e}}, A. and Kirkby, J. and Lebeau, M. and Lecoq, P. and Le Goff, J. M. and Luci, C. and Malinin, A. and Mele, S. and Milcent, H. and Paoletti, S. and Passaleva, G. and Paus, C. and Pothier, J. and Rahal-Callot, G. and Rubio, J. A. and Salicio, J. and Sanchez, E. and Sch{\"{a}}fer, C. and Straessner, A. and Tully, C. and Wynhoff, S. and Zichichi, A. and Chaturvedi, U. K. and Dova, M. T. and Khan, R. A. and Kaur, M. and Sultanov, G. and Swain, J. D. and Zichichi, A. and Z{\"{o}}ller, M. and Achard, P. and Ambrosi, G. and Bourquin, M. and Braccini, S. and Chamizo, M. and D{\'{e}}glon, P. and Delmeire, E. and Extermann, P. and Field, J. H. and Kienzle-Focacci, M. N. and Malgeri, L. and Pohl, M. and Chen, H. F. and Gong, Z. F. and Li, C. and Ma, W. G. and Sun, L. Z. and Wang, X. L. and Wang, Z. M. and Xu, Z. Z. and Yang, B. Z. and Ye, J. B. and Zhang, Z. P. and Alemanni, G. and Bartalini, P. and Bay, A. and Cesaroni, F. and Chemarin, M. and El{\'{e}}Mamouni, H. and Fay, J. and Grenier, G. and Laktineh, I. and Lebrun, P. and Lugnier, L. and Martin, J. P. and Muanza, G. S. and Tellili, B. and Teyssier, D. and Aguilar-Benitez, M. and Alcaraz, J. and Bajo, A. and Berdugo, J. and Casaus, J. and Cerrada, M. and Colino, N. and De{\'{e}}la{\'{e}}Cruz, B. and Falagan, M. A. and Josa-Mutuberr{\'{i}}a, I. and Ladron{\'{e}}de{\'{e}}Guevara, P. and Ma{\~{n}}a, C. and Palomares, C. and Romero, L. and Acciarri, M. and Furetta, C. and Pensotti, S. and Pistolesi, E. and Rancoita, P. G. and Arefiev, A. and Galaktionov, Yu and Klimentov, A. and Koutsenko, V. and Kunin, A. and Oulianov, A. and Plyaskin, V. and Pojidaev, V. and Shoutko, V. and Shumilov, E. and Vetlitsky, I. and Aloisio, A. and Alviggi, A. G. and Carlino, G. and Chiefari, G. and d{\'{e}}{\'{e}}Asmundis, R. and Doria, A. and Lista, L. and Merola, L. and Napolitano, M. and Paolucci, P. and Patricelli, S. and Piccolo, D. and Sciacca, S. and Hasan, A. and Razis, P. and Vorvolakos, A. and va{\~{n}}{\'{e}}Dalen, J. A. and Hu, Y. and Kittel, W. and K{\"{a}}nig, A. C. and Mangeol, D. and Metzger, W. J. and Petersen, B. and Roux, B. and Sanders, M. P. and Schotanus, D. J. and Timmermans, C. and Wilkens, P. and Gataullin, M. and Newman, H. and Shevchenko, S. and Shvorob, A. and Zhu, R. Y. and Xia, L. and Battiston, R. and Bertucci, B. and Biasini, M. and Burger, W. J. and Cecchi, C. and Cucciarelli, S. and Fiandrini, E. and Pauluzzi, M. and Servoli, L. and Andreev, V. P. and Fedin, O. and Levtchenko, P. and Prokofiev, D. and Schegelsky, V. and Zhu, Y. and Zalite, A. and Vorobyov, A. A. and Vodopianov, I. and Blyth, S. C. and Engler, A. and Ferguson, T. and Hirschfelder, J. and Hoorani, H. and Kraemer, R. W. and Park, H. K. and Smith, B. and Vorobiev, I. and Vogel, H. and Cavallo, N. and Denes, P. and Gupta, V. K. and Mans, J. and Piro{\'{o}}, P. A. and Stickland, D. P. and Clare, R. and Villa, S. and Bagnaia, P. and Borgia, B. and Cavallari, F. and De Notaristefani, F. and Diemoz, M. and Dionisi, C. and Falciano, S. and Gentile, S. and Giagu, S. and Kim, D. and Longo, E. and Luci, C. and Luminari, L. and Marzano, F. and Mirabelli, G. and Musy, M. and Nisati, A. and Organtini, G. and Paoletti, S. and Paramatti, R. and Pedace, M. and Rescigno, M. and Sarkar, S. and Valente, E. and Cifarelli, L. and Guida, M. and Quartieri, J. and Vicinanza, D. and Branson, J. G. and Dominguez, A. and Fisk, I. and Musicar, B. and Raven, G. and Shivarov, N. and Stoyanov, B. and Kim, J. K. and Park, I. H. and Son, D. and Baksay, L. and Rodin, J. and Szillasi, Z. and Sztaricskai, T. and Zilizi, P. and Buijs, A. S. and Batalova, N. and Gutay, L. J. and Prokofiev, D. O. and Barczyk, A. and Deiters, K. and Fabre, M. and Iashvili, I. and Kopp, A. and Kr{\"{a}}ger, A. and Lacentre, P. and Leiste, R. and Likhoded, S. and Lohmann, W. and Nowak, H. and Raspereza, A. and Riemann, S. and Ziegler, F. and Vogt, H. and Anderhub, H. and Barczyk, A. and Behner, F. and Betev, B. L. and Biland, A. and Bourilkov, D. and D{\'{e}}{\'{e}}Salvo, A. and Dittmar, M. and Felcini, M. and Freudenreich, K. and Hofer, H. and Holzner, G. and Kr{\~{a}}ber, M. and Lecomte, P. and L{\'{e}}{\'{e}}Coultre, P. and Lustermann, W. and Nessi-Tedaldi, F. and Ofierzynski, R. and Pauss, F. and Rahal-Callot, G. and Ramelli, R. and Ren, D. and Rykaczewski, H. and Suter, H. and Ulbricht, J. and Zimmermann, B. and Viertel, G. and Schopper, H. and Chang, Y. H. and Chen, A. and Hou, S. R. and Lin, C. H. and Lin, W. T. and Yeh, S. C.},
    number = {1-4},
    month = {5},
    pages = {47--60},
    volume = {507},
    publisher = {Elsevier B.V.},
    doi = {10.1016/S0370-2693(01)00294-5},
    issn = {03702693}
}
@article{TheDELPHICollaboration2004TheEnergies,
    title = {{The measurement of alpha{\_}s from event shapes with the DELPHI detector at the highest LEP energies}},
    year = {2004},
    journal = {European Physical Journal C},
    author = {{The DELPHI Collaboration} and Abdallah, J.},
    number = {1},
    month = {6},
    pages = {1--23},
    volume = {37},
    publisher = {Springer Science and Business Media, LLC},
    url = {http://arxiv.org/abs/hep-ex/0406011 http://dx.doi.org/10.1140/epjc/s2004-01889-x},
    doi = {10.1140/epjc/s2004-01889-x},
    arxivId = {hep-ex/0406011v1}
}
@article{2005Measurementensuremathalpha_mathrms,
    title = {{Measurement of event shape distributions and moments in e + e {\$}{\^{}}-{\textbackslash}rightarrow {\textbackslash}mathrm{\{}hadrons{\}}{\$} at 91-209 GeV and a determination of {\$}{\textbackslash}ensuremath{\{}{\textbackslash}alpha{\_}{\{}{\textbackslash}mathrm{\{}s{\}}{\}}{\}}{\$}}},
    year = {2005},
    journal = {The European Physical Journal C - Particles and Fields 2005 40:3},
    number = {3},
    month = {4},
    pages = {287--316},
    volume = {40},
    publisher = {Springer},
    url = {https://link.springer.com/article/10.1140/epjc/s2005-02120-6},
    doi = {10.1140/EPJC/S2005-02120-6},
    issn = {1434-6052},
    keywords = {Astronomy, Astrophysics and Cosmology, Elementary Particles, Hadrons, Heavy Ions, Measurement Science and Instrumentation, Nuclear Energy, Nuclear Physics, Quantum Field Theories, Quantum Field Theory, String Theory}
}
@article{Alexander1996QCDGeV,
    title = {{QCD studies with e+e- annihilation data at 130 and 136 GeV}},
    year = {1996},
    journal = {Z. Phys. C},
    author = {Alexander, G. and Allison, J. and Altekamp, N. and Ametewee, K. and Anderson, K. J. and Anderson, S. and Arcelli, S. and Asai, S. and Axen, D. and Azuelos, G. and Ball, A. H. and Barberio, E. and Barlow, R. J. and Bartoldus, R. and Batley, J. R. and Beaudoin, G. and Bechtluft, J. and Beeston, C. and Bebnke, T. and Bell, A. N. and Bell, K. W. and Bella, G. and Bentvelsen, S. and Berlich, P. and Bethke, S. and Biebel, O. and Blobel, V. and Bloodworth, I. J. and Bloomer, J. E. and Bock, P. and Bosch, H. M. and Boutemeur, M. and Bouwens, B. T. and Braibant, S. and Brown, R. M. and Burckhart, H. J. and Burgard, C. and B{\"{u}}irgin, R. and Capiluppi, P. and Carnegie, R. K. and Carter, A. A. and Carter, J. R. and Chang, C. Y. and Charlesworth, C. and Charlton, D. G. and Chrisman, D. and Chu, S. L. and Clarke, P. E.L. and Cohen, I. and Conboy, J. E. and Cooke, O. C. and Cuffiani, M. and Dado, S. and Dallapiccola, C. and Dallavalle, G. M. and De Jong, S. and Del Pozo, L. A. and Desch, K. and Dixit, M. S. and Do Couto E Silva, E. and Doucet, M. and Duchovni, E. and Duckeck, G. and Duerdoth, I. P. and Edwards, J. E.G. and Estabrooks, P. G. and Evans, H. G. and Evans, M. and Fabbri, F. and Fath, P. and Fiedler, F. and Fierro, M. and Fischer, H. M. and Folman, R. and Fong, D. G. and Foucher, M. and Fukui, H. and F{\"{u}}irtjes, A. and Gagnon, P. and Gaidot, A. and Gary, J. W. and Gascon, J. and Gascon-Shotkin, S. M. and Geddes, N. I. and Geich-Gimbel, C. and Gentit, F. X. and Geralis, T. and Giacomelli, G. and Giacomelli, P. and Giacomelli, R. and Gibson, V. and Gibson, W. R. and Gingrich, D. M. and Goldberg, J. and Goodrick, M. J. and Gorn, W. and Grandi, C. and Gross, E. and Gruw{\'{e}}, M. and Hajdu, C. and Hanson, G. G. and Hansroul, M. and Hapke, M. and Hargrove, C. K. and Hart, P. A. and Hartmann, C. and Hauschild, M. and Hawkes, C. M. and Hawkings, R. and Hemingway, R. J. and Herten, G. and Heuer, R. D. and Hildreth, M. D. and Hill, J. C. and Hillier, S. J. and Hilse, T. and Hoare, J. and Hobson, P. R. and Homer, R. J. and Honma, A. K. and Horv{\'{a}}th, D. and Howard, R. and Hughes-Jones, R. E. and Hutchcroft, D. E. and Igo-Kemenes, P. and Imrie, D. C. and Ingram, M. R. and Jawahery, A. and Jeffreys, P. W. and Jeremie, H. and Jimack, M. and Joly, A. and Jones, C. R. and Jones, G. and Jones, M. and Jones, R. W.L. and Jost, U. and Jovanovic, P. and Junk, T. R. and Karlen, D. and Kawagoe, K. and Kawamoto, T. and Keeler, R. K. and Kellogg, R. G. and Kennedy, B. W. and King, B. J. and Kirk, J. and Klutb, S. and Kobayashi, T. and Kobel, M. and Koetke, D. S. and Kokott, T. P. and Komamiya, S. and Kowalewski, R. and Kress, T. and Krieger, P. and Von Krogh, J. and Kyberd, P. and Lafferty, G. D. and Lafoux, H. and Lahmann, R. and Lai, W. P. and Lanske, D. and Lauber, J. and Lautenschlager, S. R. and Layter, J. G. and Lazic, D. and Lee, A. M. and Lefebvre, E. and Lellouch, D. and Letts, J. and Levinson, L. and Lewis, C. and Lloyd, S. L. and Loebinger, F. K. and Long, G. D. and Losty, M. J. and Ludwig, J. and Luig, A. and Malik, A. and Mannelli, M. and Marcellini, S. and Markus, C. and Martin, A. J. and Martin, J. P. and Martinez, G. and Mashimo, T. and Matthews, W. and M{\"{a}}ittig, P. and McDonald, W. J. and McKenna, J. and Mckigney, E. A. and McMahon, T. J. and McNab, A. I. and McPherson, R. A. and Meijers, F. and Menke, S. and Merritt, F. S. and Mes, H. and Meyer, J. and Michelini, A. and Mikenberg, G. and Miller, D. J. and Mir, R. and Mohr, W. and Montanari, A. and Mori, T. and Morii, M. and M{\"{u}}llers, U. and Neal, H. A. and Nellen, B. and Nijjhar, B. and Nisius, R. and O'Neale, S. W. and Oakham, F. G. and Odorici, F. and Ogren, H. O. and Omori, T. and Oreglia, M. J. and Orito, S. and P{\'{a}}link{\'{a}}s, J. and Pansart, J. P. and Pasztor, G. and Pater, J. R. and Patrick, G. N. and Pearce, M. J. and Petzold, S. and Pfeifenschneider, P. and Pilcher, J. E. and Pinfold, J. and Plane, D. E. and Poffenberger, P. and Poli, B. and Posthaus, A. and Przysiezniak, H. and Rees, D. L. and Rigby, D. and Robins, S. A. and Rodning, N. and Roney, J. M. and Rooke, A. and Ros, E. and Rossi, A. M. and Rosvick, M. and Routenburg, P. and Rozen, Y. and Runge, K. and Runolfsson, O. and Ruppel, U. and Rust, D. R. and Rylko, R. and Sarkisyan, E. K.G. and Sasaki, M. and Sbarra, C. and Schaile, A. D. and Schaile, O. and Scharf, F. and Scharff-Hansen, P. and Schenk, P. and Schmitt, B. and Schmitt, S. and Schr{\"{o}}der, M. and Schultz-Coulon, H. C. and Schulz, M. and Sch{\"{u}}itz, P. and Scott, W. G. and Shears, T. G. and Shen, B. C. and Shepherd-Themistocleous, C. H. and Sherwood, P. and Siroli, G. P. and Sittler, A. and Skillman, A. and Skuja, A. and Smith, A. M. and Smith, T. J. and Snow, G. A. and Sobie, R. and S{\"{o}}ldner-Rembold, S. and Springer, R. W. and Sproston, M. and Stahl, A. and Starks, M. and Steiert, M. and Stephens, K. and Steuerer, J. and Stockhausen, B. and Strom, D. and Strumia, F. and Szymanski, P. and Tafirout, R. and Talbot, S. D. and Tanaka, S. and Taras, P. and Tarem, S. and Tecchio, M. and Thiergen, M. and Thomson, M. A. and Von T{\"{o}}rne, E. and Towers, S. and Tscheulin, M. and Tsukamoto, T. and Tsur, E. and Turcot, A. S. and Turner-Watson, M. F. and Utzat, P. and Van Kooten, R. and Vasseur, G. and Verzocchi, M. and Vikas, P. and Vincter, M. and Vokurka, E. H. and W{\"{a}}ckerle, F. and Wagner, A. and Ward, C. P. and Ward, D. R. and Ward, J. J. and Watkins, P. M. and Watson, A. T. and Watson, N. K. and Weber, P. and Wells, P. S. and Wermes, N. and White, J. S. and Wilkens, B. and Wilson, G. W. and Wilson, J. A. and Wlodek, T. and Wolf, G. and Wotton, S. and Wyatt, T. R. and Yamashita, S. and Yekutieli, G. and Zacek, V.},
    number = {2},
    pages = {191},
    volume = {72},
    publisher = {Springer Verlag},
    doi = {10.1007/s002880050237},
    issn = {01709739}
}
@article{Ackerstaff1997QCDGeV,
    title = {{QCD studies with e+e- annihilation data at 161 GeV}},
    year = {1997},
    journal = {Z. Phys. C},
    author = {Ackerstaff, K. and Alexander, G. and Allison, J. and Altekamp, N. and Ametewee, K. and Anderson, K. J. and Anderson, S. and Arcelli, S. and Asai, S. and Axen, D. and Azuelos, G. and Ball, A. H. and Barberio, E. and Barlow, R. J. and Bartoldus, R. and Batley, J. R. and Bechtluft, J. and Beeston, C. and Behnke, T. and Bell, A. N. and Bell, K. W. and Bella, G. and Bentvelsen, S. and Berlich, P. and Bethke, S. and Biebel, O. and Biguzzi, A. and Bird, S. D. and Blobel, V. and Bloodworth, L. J. and Bloomer, J. E. and Bobinski, M. and Bock, P. and Bonacorsi, D. and Bosch, H. M. and Boutemeur, M. and Bouwens, B. T. and Braibant, S. and Brown, R. M. and Burckhart, H. J. and Burgard, C. and B{\"{u}}rgin, R. and Capiluppi, P. and Carnegie, R. K. and Carter, A. A. and Carter, J. R. and Chang, C. Y. and Charlton, D. G. and Chrisman, D. and Clarke, P. E.L. and Cohen, I. and Conboy, J. E. and Cooke, O. C. and Cuffiani, M. and Dado, S. and Dallapiccola, C. and Dallavalle, G. M. and De Jong, S. and Del Pozo, L. A. and Desch, K. and Dixit, M. S. and Do Couto E Silva, E. and Doucet, M. and Duchovni, E. and Duckeck, G. and Duerdoth, I. P. and Eatough, D. and Edwards, J. E.G. and Estabrooks, P. O. and Evans, H. G. and Evans, M. and Fabbri, F. and Fanti, M. and Fath, P. and Faust, A. A. and Fiedler, F. and Fierro, M. and Fischer, H. M. and Folman, R. and Fong, D. G. and Foucher, M. and F{\"{u}}rtjes, A. and Gagnon, P. and Gary, J. W. and Gascon, J. and Gascon-Shotkin, S. M. and Geddes, N. I. and Geich-Gimbel, C. and Geralis, T. and Giacomelli, G. and Giacomelli, P. and Giacomelli, R. and Gibson, V. and Gibson, W. R. and Gingrich, D. M. and Glenzinski, D. and Goldberg, J. and Goodrick, M. J. and Gorn, W. and Grandi, C. and Gross, E. and Grunhaus, J. and Gruw{\'{e}}, M. and Hajdu, C. and Hanson, G. G. and Hansroul, M. and Hapke, M. and Hargrove, C. K. and Hart, P. A. and Hartmann, C. and Hauschild, M. and Hawkes, C. M. and Hawkings, R. and Hemingway, R. J. and Herndon, M. and Herten, G. and Heuer, R. D. and Hildreth, M. D. and Hill, J. C. and Hillier, S. J. and Hilse, T. and Hobson, P. R. and Homer, R. J. and Honma, A. K. and Horv{\'{a}}th, D. and Howard, R. and Hughes-Jones, R. E. and Hutchcroft, D. E. and Igo-Kemenes, P. and Imrie, D. C. and Ingram, M. R. and Ishii, K. and Jawahery, A. and Jeffreys, P. W. and Jeremie, H. and Jimack, M. and Joly, A. and Jones, C. R. and Jones, G. and Jones, M. and Jones, R. W.L. and Jost, U. and Jovanovic, P. and Junk, T. R. and Karlen, D. and Kawagoe, K. and Kawamoto, T. and Keeler, R. K. and Kellogg, R. G. and Kennedy, B. W. and Kirk, J. and Kluth, S. and Kobayashi, T. and Kobel, M. and Koetke, D. S. and Kokott, T. P. and Kolrep, M. and Komamiya, S. and Kress, T. and Krieger, P. and Von Krogh, J. and Kyberd, P. and Lafferty, G. D. and Lahmann, R. and Lai, W. P. and Lanske, D. and Lauber, J. and Lautenschlager, S. R. and Layter, J. G. and Lazic, D. and Lee, A. M. and Lefebvre, E. and Lellouch, D. and Letts, J. and Levinson, L. and Lewis, C. and Lloyd, S. L. and Loebinger, F. K. and Long, G. D. and Losty, M. J. and Ludwig, J. and Macchiolo, A. and Macpherson, A. and Mannelli, M. and Marcellini, S. and Markus, C. and Martin, A. J. and Martin, J. P. and Martinez, G. and Mashimo, T. and Matthews, W. and M{\"{a}}ttig, P. and McDonald, W. J. and McKenna, J. and Mckigney, E. A. and McMahon, T. J. and McNab, A. I. and McPherson, R. A. and Meijers, F. and Menke, S. and Merritt, F. S. and Mes, H. and Meyer, J. and Michelini, A. and Mikenberg, G. and Miller, D. J. and Mir, R. and Mohr, W. and Montanari, A. and Mori, T. and Morii, M. and M{\"{u}}ller, U. and Nagai, K. and Nakamura, I. and Neal, H. A. and Nellen, B. and Nijjhar, B. and Nisius, R. and O'Neale, S. W. and Oakham, F. G. and Odorici, F. and Ogren, H. O. and Oldershaw, N. J. and Omori, T. and Oreglia, M. J. and Orito, S. and P{\'{a}}link{\'{a}}s, J. and P{\'{a}}sztor, G. and Pater, J. R. and Patrick, G. N. and Patt, J. and Pearce, M. J. and Petzold, S. and Pfeifenschneider, P. and Pilcher, J. E. and Pinfold, J. and Plane, D. E. and Poffenberger, P. and Poli, B. and Posthaus, A. and Przysiezniak, H. and Rees, D. L. and Rigby, D. and Robertson, S. and Robins, S. A. and Rodning, N. and Roney, J. M. and Rooke, A. and Ros, E. and Rossi, A. M. and Rosvick, M. and Routenburg, P. and Rozen, Y. and Runge, K. and Runolfsson, O. and Ruppel, U. and Rust, D. R. and Rylko, R. and Sachs, K. and Sarkisyan, E. K.G. and Sasaki, M. and Sbarra, C. and Schaile, A. D. and Schaile, O. and Scharf, F. and Scharff-Hansen, P. and Schenk, P. and Schmitt, B. and Schmitt, S. and Schr{\"{o}}der, M. and Schultz-Coulon, H. C. and Schulz, M. and Schumacher, M. and Sch{\"{u}}tz, P. and Scott, W. G. and Shears, T. G. and Shen, B. C. and Shepherd-Themistocleous, C. H. and Sherwood, P. and Siroli, G. P. and Sittler, A. and Skillman, A. and Skuja, A. and Smith, A. M. and Smith, T. J. and Snow, G. A. and Sobie, R. and S{\"{o}}ldner-Rembold, S. and Springer, R. W. and Sproston, M. and Stahl, A. and Steiert, M. and Stephens, K. and Steuerer, J. and Stockhausen, B. and Strom, D. and Szymanski, P. and Tafirout, R. and Talbot, S. D. and Tanaka, S. and Taras, P. and Tarem, S. and Thiergen, M. and Thomson, M. A. and Von T{\"{o}}rne, E. and Towers, S. and Trigger, I. and Tsukamoto, T. and Tsur, E. and Turcot, A. S. and Turner-Watson, M. F. and Utzat, P. and Van Kooten, R. and Verzocchi, M. and Vikas, P. and Vincter, M. and Vokurka, E. H. and W{\"{a}}ckerle, F. and Wagner, A. and Ward, C. P. and Ward, D. R. and Ward, J. J. and Watkins, P. M. and Watson, A. T. and Watson, N. K. and Wells, P. S. and Wermes, N. and White, J. S. and Wilkens, B. and Wilson, G. W. and Wilson, J. A. and Wolf, G. and Wotton, S. and Wyatt, T. R. and Yamashita, S. and Yekutieli, G. and Zacek, V. and Zer-Zion, D.},
    number = {2},
    month = {6},
    pages = {193},
    volume = {75},
    publisher = {Springer Verlag},
    doi = {10.1007/s002880050462},
    issn = {01709739}
}
@article{Buskulic1997StudiesGeV,
    title = {{Studies of QCD in e+e- → hadrons at Ecm = 130 and 136 GeV}},
    year = {1997},
    journal = {Z. Phys. C},
    author = {Buskulic, D. and De Bonis, I. and Decamp, D. and Ghez, P. and Goy, C. and Lees, J. P. and Lucotte, A. and Minard, M. N. and Odier, P. and Pietrzyk, B. and Casado, M. P. and Chmeissani, M. and Crespo, J. M. and Delfino, M. and Efthymiopoulos, I. and Fernandez, E. and Fernandez-Bosnian, M. and Garrido, Ll and Juste, A. and Martinez, M. and Orteu, S. and Pacheco, A. and Padilla, C. and Pascual, A. and Perlas, J. A. and Riu, I. and Sanchez, F. and Teubert, F. and Colaleo, A. and Creanza, D. and De Palma, M. and Gelao, G. and Girone, M. and Iaselli, G. and Maggi, G. and Maggi, M. and Marinelli, N. and Nuzzo, S. and Ranieri, A. and Raso, G. and Ruggieri, F. and Selvaggi, G. and Silvestris, L. and Tempesta, P. and Zito, G. and Huang, X. and Lin, J. and Ouyang, Q. and Wang, T. and Xie, Y. and Xu, R. and Xue, S. and Zhang, J. and Zhang, L. and Zhao, W. and Alemany, R. and Bazarko, A. O. and Cattaneo, M. and Comas, P. and Coyle, P. and Drevermann, H. and Forty, R. W. and Frank, M. and Hagelberg, R. and Harvey, J. and Janot, P. and Jost, B. and Kneringer, E. and Knobloch, J. and Lehraus, I. and Lutters, G. and Martin, E. B. and Mato, P. and Minten, A. and Miquel, R. and Mir, Ll M. and Moneta, L. and Oest, T. and Pusztaszeri, J. F. and Ranjard, F. and Rensing, P. and Rolandi, L. and Schlatter, D. and Schmelling, M. and Schneider, O. and Tejessy, W. and Tomalin, I. R. and Venturi, A. and Wachsmuth, H. and Wagner, A. and Ajaltouni, Z. and Barr{\`{e}}s, A. and Boyer, C. and Falvard, A. and Gay, P. and Guicheney, C. and Henrard, P. and Jousset, J. and Michel, B. and Monteil, S. and Montret, J. C. and Pallin, D. and Perret, P. and Podlyski, F. and Proriol, J. and Rossignol, J. M. and Fearnley, T. and Hansen, J. B. and Hansen, J. D. and Hansen, J. R. and Hansen, P. H. and Nilsson, B. S. and W{\"{a}}{\"{a}}n{\"{a}}nen, A. and Kyriakis, A. and Markou, C. and Simopoulou, E. and Siotis, I. and Vayaki, A. and Zachariadou, K. and Blondel, A. and Brient, J. C. and Roug{\'{e}}, A. and Rumpf, M. and Valassi, A. and Videau, H. and Focardi, E. and Parrini, G. and Corden, M. and Georgiopoulos, C. and Jaffe, D. E. and Antonelli, A. and Bencivenni, G. and Bologna, G. and Bossi, F. and Campana, P. and Capon, G. and Casper, D. and Chiarella, V. and Felici, G. and Laurelli, P. and Mannocchi, G. and Murtas, F. and Murtas, G. P. and Passalacqua, L. and Pepe-Altarelli, M. and Curtis, L. and Dorris, S. J. and Halley, A. W. and Knowles, I. G. and Lynch, J. G. and O'Shea, V. and Raine, C. and Reeves, P. and Scarr, J. M. and Smith, K. and Thompson, A. S. and Thomson, F. and Thorn, S. and Turnbull, R. M. and Becker, U. and Geweniger, C. and Graefe, G. and Hanke, P. and Hansper, G. and Hepp, V. and Kluge, E. E. and Putzer, A. and Rensch, B. and Schmidt, M. and Sommer, J. and Stenzel, H. and Tittel, K. and Werner, S. and Wunsch, M. and Abbaneo, D. and Beuselinck, R. and Binnie, D. M. and Cameron, W. and Dornan, P. J. and Moutoussi, A. and Nash, J. and Sedgbeer, J. K. and Stacey, A. M. and Williams, M. D. and Dissertori, G. and Girtler, P. and Kuhn, D. and Rudolph, G. and Betteridge, A. P. and Bowdery, C. K. and Colrain, P. and Crawford, G. and Finch, A. J. and Foster, F. and Hughes, G. and Sloan, T. and Whelan, E. P. and Williams, M. I. and Galla, A. and Greene, A. M. and Hoffmann, C. and Kleinknecht, K. and Quast, G. and Renk, B. and Rohne, E. and Sander, H. G. and Van Gemmeren, P. and Zeitnitz, C. and Aubert, J. J. and Bencheikh, A. M. and Benchouk, C. and Bonissent, A. and Bujosa, G. and Calvet, D. and Carr, J. and Diaconu, C. and Konstantinidis, N. and Payre, P. and Rousseau, D. and Talby, M. and Sadouki, A. and Thulasidas, M. and Tilquin, A. and Trabelsi, K. and Aleppo, M. and Ragusa, F. and Abt, I. and Assmann, R. and Bauer, C. and Blum, W. and Dietl, H. and Dydak, F. and Ganis, G. and Gotzhein, C. and Jakobs, K. and Kroha, H. and L{\"{u}}tjens, G. and Lutz, G. and M{\"{a}}nner, W. and Moser, H. G. and Richter, R. and Rosado-Schlosser, A. and Schael, S. and Settles, R. and Seywerd, H. and St. Denis, R. and Wiedenmann, W. and Wolf, G. and Boucrot, J. and Callot, O. and Cordier, A. and Davier, M. and Duflot, L. and Grivaz, J. F. and Heusse, Ph and H{\"{o}}cker, A. and Jacquet, M. and Kim, D. W. and Le Diberder, F. and Lefran{\c{c}}ois, J. and Lutz, A. M. and Nikolic, I. and Park, H. J. and Park, I. C. and Schune, M. H. and Simion, S. and Veillet, J. J. and Videau, I. and Zerwas, D. and Azzurri, P. and Bagliesi, G. and Batignani, G. and Bettarini, S. and Bozzi, C. and Calderini, G. and Carpinelli, M. and Ciocci, M. A. and Ciulli, V. and Dell'Orso, R. and Fantechi, R. and Ferrante, I. and Giassi, A. and Gregorio, A. and Ligabue, F. and Lusiani, A. and Marrocchesi, P. S. and Messineo, A. and Palla, F. and Rizzo, G. and Sanguinetti, G. and Sciab{\`{a}}, A. and Spagnolo, P. and Steinberger, J. and Tenchini, R. and Tonelli, G. and Vannini, C. and Verdini, P. G. and Walsh, J. and Blair, G. A. and Bryant, L. M. and Cerutti, F. and Chambers, J. T. and Gao, Y. and Green, M. G. and Medcalf, T. and Perrodo, P. and Strong, J. A. and Von Wimmersperg-Toeller, J. H. and Botterill, D. R. and Clifft, R. W. and Edgecock, T. R. and Haywood, S. and Maley, P. and Norton, P. R. and Thompson, J. C. and Wright, A. E. and Bloch-Devaux, B. and Colas, P. and Emery, S. and Kozanecki, W. and Lan{\c{c}}on, E. and Lemaire, M. C. and Locci, E. and Marx, B. and Perez, P. and Rander, J. and Renardy, J. F. and Roussarie, A. and Schuller, J. P. and Schwindling, J. and Trabelsi, A. and Vallage, B. and Black, S. N. and Dann, J. H. and Johnson, R. P. and Kim, H. Y. and Litke, A. M. and McNeil, M. A. and Taylor, G. and Booth, C. N. and Boswell, R. and Brew, C. A.J. and Cartwright, S. and Combley, F. and Koksal, A. and Letho, M. and Newton, W. M. and Reeve, J. and Thompson, L. F. and B{\"{o}}hrer, A. and Brandt, S. and B{\"{u}}scher, V. and Cowan, G. and Grupen, C. and Saraiva, P. and Smolik, L. and Stephan, F. and Apollonio, M. and Bosisio, L. and Della Marina, R. and Giannini, G. and Gobbo, B. and Musolino, G. and Putz, J. and Rothberg, J. and Wasserbaech, S. and Williams, R. W. and Armstrong, S. R. and Bellantoni, L. and Elmer, P. and Feng, Z. and Ferguson, D. P.S. and Gao, Y. S. and Gonz{\'{a}}lez, S. and Grahl, J. and Greening, T. C. and Harton, J. L. and Hayes, O. J. and Hu, H. and McNamara, P. A. and Nachtman, J. M. and Orejudos, W. and Pan, Y. B. and Saadi, Y. and Schmitt, M. and Scott, I. J. and Sharma, V. and Walsh, A. M. and Wu, Sau Lan and Wu, X. and Yamartino, J. M. and Zheng, M. and Zobernig, G.},
    number = {3},
    pages = {409},
    volume = {73},
    publisher = {Springer Verlag},
    doi = {10.1007/s002880050330},
    issn = {01709739}
}
@article{Acciarri2000QCDGeV,
    title = {{QCD studies in e+e- annihilation from 30 GeV to 189 GeV}},
    year = {2000},
    journal = {Phys. Lett. B},
    author = {Acciarri, M. and Achard, P. and Adriani, O. and Aguilar-Benitez, M. and Alcaraz, J. and Alemanni, G. and Allaby, J. and Aloisio, A. and Alviggi, M. G. and Ambrosi, G. and Anderhub, H. and Andreev, V. P. and Angelescu, T. and Anselmo, F. and Arefiev, A. and Azemoon, T. and Aziz, T. and Bagnaia, P. and Bajo, A. and Baksay, L. and Balandras, A. and Baldew, S. V. and Banerjee, S. and Banerjee, S. and Barczyk, A. and Barill{\`{e}}re, R. and Barone, L. and Bartalini, P. and Basile, M. and Battiston, R. and Bay, A. and Becattini, F. and Becker, U. and Behner, F. and Bellucci, L. and Berbeco, R. and Berdugo, J. and Berges, P. and Bertucci, B. and Betev, B. L. and Bhattacharya, S. and Biasini, M. and Biland, A. and Blaising, J. J. and Blyth, S. C. and Bobbink, G. J. and B{\"{o}}hm, A. and Boldizsar, L. and Borgia, B. and Bourilkov, D. and Bourquin, M. and Braccini, S. and Branson, J. G. and Brigljevic, V. and Brochu, F. and Buffini, A. and Buijs, A. and Burger, J. D. and Burger, W. J. and Cai, X. D. and Campanelli, M. and Capell, M. and Cara Romeo, G. and Carlino, G. and Cartacci, A. M. and Casaus, J. and Castellini, G. and Cavallari, F. and Cavallo, N. and Cecchi, C. and Cerrada, M. and Cesaroni, F. and Chamizo, M. and Chang, Y. H. and Chaturvedi, U. K. and Chemarin, M. and Chen, A. and Chen, G. and Chen, G. M. and Chen, H. F. and Chen, H. S. and Chiefari, G. and Cifarelli, L. and Cindolo, F. and Civinini, C. and Clare, I. and Clare, R. and Coignet, G. and Colino, N. and Costantini, S. and Cotorobai, F. and de la Cruz, B. and Csilling, A. and Cucciarelli, S. and Dai, T. S. and van Dalen, J. A. and D'Alessandro, R. and de Asmundis, R. and D{\'{e}}glon, P. and Degr{\'{e}}, A. and Deiters, K. and della Volpe, D. and Delmeire, E. and Denes, P. and DeNotaristefani, F. and de Salvo, A. and Diemoz, M. and Dierckxsens, M. and van Dierendonck, D. and di Lodovico, F. and Dionisi, C. and Dittmar, M. and Dominguez, A. and Doria, A. and Dova, M. T. and Duchesneau, D. and Dufournaud, D. and Duinker, P. and Duran, I. and El Mamouni, H. and Engler, A. and Eppling, F. J. and Ern{\'{e}}, F. C. and Extermann, P. and Fabre, M. and Faccini, R. and Falagan, M. A. and Falciano, S. and Favara, A. and Fay, J. and Fedin, O. and Felcini, M. and Ferguson, T. and Ferroni, F. and Fesefeldt, H. and Fiandrini, E. and Field, J. H. and Filthaut, F. and Fisher, P. H. and Fisk, I. and Forconi, G. and Freudenreich, K. and Furetta, C. and Galaktionov, Y. and Ganguli, S. N. and Garcia-Abia, P. and Gataullin, M. and Gau, S. S. and Gentile, S. and Gheordanescu, N. and Giagu, S. and Gong, Z. F. and Grenier, G. and Grimm, O. and Gruenewald, M. W. and Guida, M. and van Gulik, R. and Gupta, V. K. and Gurtu, A. and Gutay, L. J. and Haas, D. and Hasan, A. and Hatzifotiadou, D. and Hebbeker, T. and Herv{\'{e}}, A. and Hidas, P. and Hirschfelder, J. and Hofer, H. and Holzner, G. and Hoorani, H. and Hou, S. R. and Hu, Y. and Iashvili, I. and Jin, B. N. and Jones, L. W. and de Jong, P. and Josa-Mutuberr{\'{i}}a, I. and Khan, R. A. and Kaur, M. and Kienzle-Focacci, M. N. and Kim, D. and Kim, J. K. and Kirkby, J. and Kiss, D. and Kittel, W. and Klimentov, A. and K{\"{o}}nig, A. C. and Kopp, A. and Koutsenko, V. and Kr{\"{a}}ber, M. and Kraemer, R. W. and Krenz, W. and Kr{\"{u}}ger, A. and Kunin, A. and Ladron de Guevara, P. and Laktineh, I. and Landi, G. and Lassila-Perini, K. and Lebeau, M. and Lebedev, A. and Lebrun, P. and Lecomte, P. and Lecoq, P. and Le Coultre, P. and Lee, H. J. and Le Goff, J. M. and Leiste, R. and Leonardi, E. and Levtchenko, P. and Li, C. and Likhoded, S. and Lin, C. H. and Lin, W. T. and Linde, F. L. and Lista, L. and Liu, Z. A. and Lohmann, W. and Longo, E. and Lu, Y. S. and L{\"{u}}belsmeyer, K. and Luci, C. and Luckey, D. and Lugnier, L. and Luminari, L. and Lustermann, W. and Ma, W. G. and Maity, M. and Malgeri, L. and Malinin, A. and Ma{\~{n}}a, C. and Mangeol, D. and Mans, J. and Marchesini, P. and Marian, G. and Martin, J. P. and Marzano, F. and Mazumdar, K. and McNeil, R. R. and Mele, S. and Merola, L. and Meschini, M. and Metzger, W. J. and von der Mey, M. and Mihul, A. and Milcent, H. and Mirabelli, G. and Mnich, J. and Mohanty, G. B. and Molnar, P. and Moulik, T. and Muanza, G. S. and Muijs, A. J.M. and Musicar, B. and Musy, M. and Napolitano, M. and Nessi-Tedaldi, F. and Newman, H. and Niessen, T. and Nisati, A. and Nowak, H. and Organtini, G. and Oulianov, A. and Palomares, C. and Pandoulas, D. and Paoletti, S. and Paolucci, P. and Paramatti, R. and Park, H. K. and Park, I. H. and Passaleva, G. and Patricelli, S. and Paul, T. and Pauluzzi, M. and Paus, C. and Pauss, F. and Pedace, M. and Pensotti, S. and Perret-Gallix, D. and Petersen, B. and Piccolo, D. and Pierella, F. and Pieri, M. and Pirou{\'{e}}, P. A. and Pistolesi, E. and Plyaskin, V. and Pohl, M. and Pojidaev, V. and Postema, H. and Pothier, J. and Prokofiev, D. O. and Prokofiev, D. and Quartieri, J. and Rahal-Callot, G. and Rahaman, M. A. and Raics, P. and Raja, N. and Ramelli, R. and Rancoita, P. G. and Raspereza, A. and Raven, G. and Razis, P. and Ren, D. and Rescigno, M. and Reucroft, S. and Riemann, S. and Riles, K. and Robohm, A. and Rodin, J. and Roe, B. P. and Romero, L. and Rosca, A. and Rosier-Lees, S. and Rubio, J. A. and Ruggiero, G. and Ruschmeier, D. and Rykaczewski, H. and Saremi, S. and Sarkar, S. and Salicio, J. and Sanchez, E. and Sanders, M. P. and Sarakinos, M. E. and Sch{\"{a}}fer, C. and Schegelsky, V. and Schmidt-Kaerst, S. and Schmitz, D. and Schopper, H. and Schotanus, D. J. and Schwering, G. and Sciacca, C. and Sciarrino, D. and Seganti, A. and Servoli, L. and Shevchenko, S. and Shivarov, N. and Shoutko, V. and Shumilov, E. and Shvorob, A. and Siedenburg, T. and Son, D. and Smith, B. and Spillantini, P. and Steuer, M. and Stickland, D. P. and Stone, A. and Stoyanov, B. and Straessner, A. and Sudhakar, K. and Sultanov, G. and Sun, L. Z. and Suter, H. and Swain, J. D. and Szillasi, Z. and Sztaricskai, T. and Tang, X. W. and Tauscher, L. and Taylor, L. and Tellili, B. and Timmermans, C. and Samuel Ting, C. C. and Ting, S. M. and Tonwar, S. C. and T{\'{o}}th, J. and Tully, C. and Tung, K. L. and Uchida, Y. and Ulbricht, J. and Valente, E. and Vesztergombi, G. and Vetlitsky, I. and Vicinanza, D. and Viertel, G. and Villa, S. and Vivargent, M. and Vlachos, S. and Vodopianov, I. and Vogel, H. and Vogt, H. and Vorobiev, I. and Vorobyov, A. A. and Vorvolakos, A. and Wadhwa, M. and Wallraff, W. and Wang, M. and Wang, X. L. and Wang, Z. M. and Weber, A. and Weber, M. and Wienemann, P. and Wilkens, H. and Wu, S. X. and Wynhoff, S. and Xia, L. and Xu, Z. Z. and Yamamoto, J. and Yang, B. Z. and Yang, C. G. and Yang, H. J. and Yang, M. and Ye, J. B. and Yeh, S. C. and Zalite, A. and Zalite, Y. and Zhang, Z. P. and Zhu, G. Y. and Zhu, R. Y. and Zichichi, A. and Zilizi, G. and Z{\"{o}}ller, M.},
    number = {1-2},
    month = {9},
    pages = {65},
    volume = {489},
    publisher = {Elsevier B.V.},
    doi = {10.1016/s0370-2693(00)00891-1},
    issn = {03702693}
}
@article{Achard2002DeterminationGeV,
    title = {{Determination of {$\alpha$}s from hadronic event shapes in e+e- annihilation at 192 ≤ √s ≤ 208 GeV}},
    year = {2002},
    journal = {Phys. Lett. B},
    author = {Achard, P. and Adriani, O. and Aguilar-Benitez, M. and Alcaraz, J. and Alemanni, G. and Allaby, J. and Aloisio, A. and Alviggi, M. G. and Anderhub, H. and Andreev, V. P. and Anselmo, F. and Arefiev, A. and Azemoon, T. and Aziz, T. and Bagnaia, P. and Bajo, A. and Baksay, G. and Baksay, L. and Baldew, S. V. and Banerjee, S. and Banerjee, S. W. and Barczyk, A. and Barill{\`{e}}re, R. and Bartalini, P. and Basile, M. and Batalova, N. and Battiston, R. and Bay, A. and Becattini, F. and Becker, U. and Behner, F. and Bellucci, L. and Berbeco, R. and Berdugo, J. and Berges, P. and Bertucci, B. and Betev, B. L. and Biasini, M. and Biglietti, M. and Biland, A. and Blaising, J. J. and Blyth, S. C. and Bobbink, G. J. and B{\"{o}}hm, A. and Boldizsar, L. and Borgia, B. and Bottai, S. and Bourilkov, D. and Bourquin, M. and Braccini, S. and Branson, J. G. and Brochu, F. and Burger, J. D. and Burger, W. J. and Cai, X. D. and Capell, M. and Cara Romeo, G. and Carlino, G. and Cartacci, A. and Casaus, J. and Cavallari, F. and Cavallo, N. and Cecchi, C. and Cerrada, M. and Chamizo, M. and Chang, Y. H. and Chemarin, M. and Chen, A. and Chen, G. and Chen, G. M. and Chen, H. F. and Chen, H. S. and Chiefari, G. and Cifarelli, L. and Cindolo, F. and Clare, I. and Clare, R. and Coignet, G. and Colino, N. and Costantini, S. and de la Cruz, B. and Cucciarelli, S. and van Dalen, J. A. and de Asmundis, R. and D{\'{e}}glon, P. and Debreczeni, J. and Degr{\'{e}}, A. and Deiters, K. and della Volpe, D. and Delmeire, E. and Denes, P. and DeNotaristefani, F. and De Salvo, A. and Diemoz, M. and Dierckxsens, M. and Dionisi, C. and Dittmar, M. and Doria, A. and Dova, M. T. and Duchesneau, D. and Echenard, B. and Eline, A. and El Mamouni, H. and Engler, A. and Eppling, F. J. and Ewers, A. and Extermann, P. and Falagan, M. A. and Falciano, S. and Favara, A. and Fay, J. and Fedin, O. and Felcini, M. and Ferguson, T. and Fesefeldt, H. and Fiandrini, E. and Field, J. H. and Filthaut, F. and Fisher, P. H. and Fisher, W. and Fisk, I. and Forconi, G. and Freudenreich, K. and Furetta, C. and Galaktionov, Y. and Ganguli, S. N. and Garcia-Abia, P. and Gataullin, M. and Gentile, S. and Giagu, S. and Gong, Z. F. and Grenier, G. and Grimm, O. and Gruenewald, M. W. and Guida, M. and van Gulik, R. and Gupta, V. K. and Gurtu, A. and Gutay, L. J. and Haas, D. and Hakobyan, R. S. and Hatzifotiadou, D. and Hebbeker, T. and Herv{\'{e}}, A. and Hirschfelder, J. and Hofer, H. and Hohlmann, M. and Holzner, G. and Hou, S. R. and Hu, Y. and Jin, B. N. and Jones, L. W. and de Jong, P. and Josa-Mutuberr{\'{i}}a, I. and K{\"{a}}fer, D. and Kaur, M. and Kienzle-Focacci, M. N. and Kim, J. K. and Kirkby, J. and Kittel, W. and Klimentov, A. and K{\"{o}}nig, A. C. and Kopal, M. and Koutsenko, V. and Kr{\"{a}}ber, M. and Kraemer, R. W. and Krenz, W. and Kr{\"{u}}ger, A. and Kunin, A. and Ladron de Guevara, P. and Laktineh, I. and Landi, G. and Lebeau, M. and Lebedev, A. and Lebrun, P. and Lecomte, P. and Lecoq, P. and Le Coultre, P. and Le Goff, J. M. and Leiste, R. and Levtchenko, M. and Levtchenko, P. and Li, C. and Likhoded, S. and Lin, C. H. and Lin, W. T. and Linde, F. L. and Lista, L. and Liu, Z. A. and Lohmann, W. and Longo, E. and Lu, Y. S. and L{\"{u}}belsmeyer, K. and Luci, C. and Luminari, L. and Lustermann, W. and Ma, W. G. and Malgeri, L. and Malinin, A. and Ma{\~{n}}a, C. and Mangeol, D. and Mans, J. and Martin, J. P. and Marzano, F. and Mazumdar, K. and McNeil, R. R. and Mele, S. and Merola, L. and Meschini, M. and Metzger, W. J. and Mihul, A. and Milcent, H. and Mirabelli, G. and Mnich, J. and Mohanty, G. B. and Muanza, G. S. and Muijs, A. J.M. and Musicar, B. and Musy, M. and Nagy, S. and Natale, S. and Napolitano, M. and Nessi-Tedaldi, F. and Newman, H. and Niessen, T. and Nisati, A. and Nowak, H. and Ofierzynski, R. and Organtini, G. and Palomares, C. and Pandoulas, D. and Paolucci, P. and Paramatti, R. and Passaleva, G. and Patricelli, S. and Paul, T. and Pauluzzi, M. and Paus, C. and Pauss, F. and Pedace, M. and Pensotti, S. and Perret-Gallix, D. and Petersen, B. and Piccolo, D. and Pierella, F. and Pioppi, M. and Pirou{\'{e}}, P. A. and Pistolesi, E. and Plyaskin, V. and Pohl, M. and Pojidaev, V. and Pothier, J. and Prokofiev, D. O. and Prokofiev, D. and Quartieri, J. and Rahal-Callot, G. and Rahaman, M. A. and Raics, P. and Raja, N. and Ramelli, R. and Rancoita, P. G. and Ranieri, R. and Raspereza, A. and Razis, P. and Ren, D. and Rescigno, M. and Reucroft, S. and Riemann, S. and Riles, K. and Roe, B. P. and Romero, L. and Rosca, A. and Rosier-Lees, S. and Roth, S. and Rosenbleck, C. and Roux, B. and Rubio, J. A. and Ruggiero, G. and Rykaczewski, H. and Sakharov, A. and Saremi, S. and Sarkar, S. and Salicio, J. and Sanchez, E. and Sanders, M. P. and Sch{\"{a}}fer, C. and Schegelsky, V. and Schmidt-Kaerst, S. and Schmitz, D. and Schopper, H. and Schotanus, D. J. and Schwering, G. and Sciacca, C. and Servoli, L. and Shevchenko, S. and Shivarov, N. and Shoutko, V. and Shumilov, E. and Shvorob, A. and Siedenburg, T. and Son, D. and Spillantini, P. and Steuer, M. and Stickland, D. P. and Stoyanov, B. and Straessner, A. and Sudhakar, K. and Sultanov, G. and Sun, L. Z. and Sushkov, S. and Suter, H. and Swain, J. D. and Szillasi, Z. and Tang, X. W. and Tarjan, P. and Tauscher, L. and Taylor, L. and Tellili, B. and Teyssier, D. and Timmermans, C. and Ting, S. C.C. and Ting, S. M. and Tonwar, S. C. and T{\'{o}}th, J. and Tully, C. and Tung, K. L. and Ulbricht, J. and Valente, E. and Van de Walle, R. T. and Veszpremi, V. and Vesztergombi, G. and Vetlitsky, I. and Vicinanza, D. and Viertel, G. and Villa, S. and Vivargent, M. and Vlachos, S. and Vodopianov, I. and Vogel, H. and Vogt, H. and Vorobiev, I. and Vorobyov, A. A. and Wadhwa, M. and Wallraff, W. and Wang, X. L. and Wang, Z. M. and Weber, M. and Wienemann, P. and Wilkens, H. and Wynhoff, S. and Xia, L. and Xu, Z. Z. and Yamamoto, J. and Yang, B. Z. and Yang, C. G. and Yang, H. J. and Yang, M. and Yeh, S. C. and Zalite, A. and Zalite, Y. and Zhang, Z. P. and Zhao, J. and Zhu, G. Y. and Zhu, R. Y. and Zhuang, H. L. and Zichichi, A. and Zilizi, G. and Zimmermann, B. and Z{\"{o}}ller, M.},
    number = {3-4},
    month = {6},
    pages = {217},
    volume = {536},
    publisher = {Elsevier B.V.},
    doi = {10.1016/s0370-2693(02)01814-2},
    issn = {03702693}
}
@article{Ohnishi1993MeasurementsTRISTAN,
    title = {{Measurements of alpha-s in e+ e- annihilation at TRISTAN}},
    year = {1993},
    journal = {Phys.Lett.B},
    author = {Ohnishi, Y. and Adachi, I. and Fujimoto, J. and Itoh, R. and Sugiyama, A. and Yamauchi, M. and Abe, K. and Abe, T. and Aoki, M. and Awa, S. and Belusevic, R. and Emi, K. and Enomoto, R. and Fujii, H. and Fujii, T. and Fujita, K. and Fujiwara, N. and Hayashii, H. and Howell, B. and Iida, N. and Ikeda, H. and Iwasaki, H. and Iwasaki, M. and Kajikawa, R. and Kato, S. and Kawabata, S. and Kichimi, H. and Kobayashi, M. and Koltick, D. and Levine, I. and Miyabayashi, K. and Miyamoto, A. and Muramatsu, K. and Nagai, K. and Nagira, T. and Nakano, E. and Nakabayashi, K. and Nitoh, O. and Noguchi, S. and Ochiai, F. and Okuno, H. and Okusawa, T. and Shimozawa, K. and Shinohara, T. and Sugiyama, N. and Suzuki, S. and Takahashi, K. and Takahashi, T. and Takemoto, M. and Tanimori, T. and Tauchi, T. and Teramae, F. and Teramoto, Y. and Toomi, N. and Toyama, T. and Tsukamoto, T. and Uno, S. and Watanabe, Y. and Yamaguchi, A. and Yamamoto, A.},
    number = {3-4},
    month = {9},
    pages = {475--482},
    volume = {313},
    doi = {10.1016/0370-2693(93)90022-A},
    issn = {03702693}
}
@article{Kato1989Double-cascadeAnnihilation,
    title = {{Double-cascade scheme for QCD jets in e+e- annihilation}},
    year = {1989},
    journal = {Physical Review D},
    author = {Kato, Kiyoshi and Munehisa, Tomo},
    number = {1},
    pages = {156--162},
    volume = {39},
    doi = {10.1103/PHYSREVD.39.156},
    issn = {05562821}
}
@article{Abe1990DeterminationApproximation,
    title = {{Determination of the QCD scale parameter {$\Lambda$}MS with QCD cascade on the basis of the next-to-leading logarithmic approximation}},
    year = {1990},
    journal = {Physics Letters B},
    author = {Abe, K. and Amako, K. and Arai, Y. and Asano, Y. and Chiba, M. and Chiba, Y. and Daigo, M. and Emura, T. and Fukawa, M. and Fukui, T. and Fukushima, Y. and Haba, J. and Haidt, D. and Hayashibara, I. and Hemmi, Y. and Higuchi, M. and Hirose, T. and Hojo, Y. and Homma, Y. and Hoshi, Y. and Ikegami, Y. and Ishihara, N. and Kamitani, T. and Kanematsu, N. and Kanzaki, J. and Kikuchi, R. and Kondo, T. and Koseki, T. and Kurashige, H. and Matsui, T. and Minami, M. and Miyake, K. and Mori, S. and Nagashima, Y. and Nakamura, T. and Nakano, I. and Narita, Y. and Odaka, S. and Ogawa, K. and Ohama, T. and Ohsugi, T. and Okamoto, A. and Ono, A. and Osabe, H. and Oyama, T. and Saito, H. and Sakae, H. and Sakamoto, H. and Sakamoto, S. and Sakano, M. and Sakuda, M. and Sasao, N. and Sato, M. and Shioden, M. and Shirai, J. and Shirakata, M. and Sugimoto, S. and Sumiyoshi, T. and Suzuki, A. and Suzuki, Y. and Takada, Y. and Takasaki, F. and Taketani, A. and Takita, M. and Tamura, N. and Tanaka, R. and Terunuma, N. and Tobimatsu, K. and Tsuboyama, T. and Tsukamoto, A. and Uehara, S. and Unno, Y. and Utsumi, M. and Wakai, M. and Watanabe, T. and Watase, Y. and Yabuki, F. and Yamada, Y. and Yamagata, T. and Yamashita, T. and Yonezawa, Y. and Yoshida, H.},
    number = {1-2},
    month = {4},
    pages = {232--236},
    volume = {240},
    doi = {10.1016/0370-2693(90)90440-H},
    issn = {03702693}
}
@article{Catani1991ThrustAnnihilation,
    title = {{Thrust distribution in e+e- annihilation}},
    year = {1991},
    journal = {Physics Letters B},
    author = {Catani, S. and Turnock, G. and Webber, B. R. and Trentadue, L.},
    number = {3-4},
    month = {7},
    pages = {491--497},
    volume = {263},
    doi = {10.1016/0370-2693(91)90494-B},
    issn = {03702693}
}
@article{Catani1991HeavyAnnihilation,
    title = {{Heavy jet mass distribution in e+e- annihilation}},
    year = {1991},
    journal = {Physics Letters B},
    author = {Catani, S. and Turnock, G. and Webber, B. R.},
    number = {3-4},
    month = {12},
    pages = {368--372},
    volume = {272},
    doi = {10.1016/0370-2693(91)91845-M},
    issn = {03702693}
}
@article{Farhi1977QuantumJets,
    title = {{Quantum Chromodynamics Test for Jets}},
    year = {1977},
    journal = {Physical Review Letters},
    author = {Farhi, Edward},
    number = {25},
    pages = {1587--1588},
    volume = {39},
    doi = {10.1103/PHYSREVLETT.39.1587},
    issn = {00319007}
}
@article{Decamp1992MeasurementPredictions,
    title = {{Measurement of {$\alpha$}s in hadronic Z decays using all-orders resummed predictions}},
    year = {1992},
    journal = {Physics Letters B},
    author = {Decamp, D. and Deschizeaux, B. and Goy, C. and Lees, J. P. and Minard, M. N. and Alemany, R. and Ariztizabal, F. and Comas, P. and Crespo, J. M. and Delfino, M. and Fernandez, E. and Gaitan, V. and Garrido, Ll and Mir, Ll M. and Pacheco, A. and Pascual, A. and Creanza, D. and de Palma, M. and Farilla, A. and Iaselli, G. and Maggi, G. and Maggi, M. and Natali, S. and Nuzzo, S. and Quattromini, M. and Ranieri, A. and Raso, G. and Romano, F. and Ruggieri, F. and Selvaggi, G. and Silvestris, L. and Tempesta, P. and Zito, G. and Gao, Y. and Hu, H. and Huang, D. and Huang, X. and Lin, J. and Lou, J. and Qiao, C. and Wang, T. and Xie, Y. and Xu, D. and Xu, R. and Zhang, J. and Zhao, W. and Atwood, W. B. and Bauerdick, L. A.T. and Blucher, E. and Bonvicini, G. and Bossi, F. and Boudreau, J. and Burnett, T. H. and Drevermann, H. and Forty, R. W. and Hagelberg, R. and Haywood, S. and Hilgart, J. and Jacobsen, R. and Jost, B. and Kasemann, M. and Knobloch, J. and Lan{\c{c}}on, E. and Lehraus, I. and Lohse, T. and Lusiani, A. and Martinez, M. and Mato, P. and Mattison, T. and Meinhard, H. and Menary, S. and Meyer, T. and Minten, A. and Miotto, A. and Miquel, R. and Moser, H. G. and Nash, J. and Palazzi, P. and Perlas, J. A. and Ranjard, F. and Redlinger, G. and Rolandi, L. and Roth, A. and Rothberg, J. and Ruan, T. and Saich, M. and Schlatter, D. and Schmelling, M. and Sefkow, F. and Tejessy, W. and Wachsmuth, H. and Wiedenmann, W. and Wildish, T. and Witzeling, W. and Wotschack, J. and Ajaltouni, Z. and Badaud, F. and Bardadin-Otwinowska, M. and Bencheikh, A. M. and El Fellous, R. and Falvard, A. and Gay, P. and Guicheney, C. and Henrard, P. and Jousset, J. and Michel, B. and Montret, J. C. and Pallin, D. and Perret, P. and Pietrzyk, B. and Proriol, J. and Prulhi{\`{e}}re, F. and Stimpfl, G. and Hansen, J. D. and Hansen, J. R. and Hansen, P. H. and M{\o}llerud, R. and Nilsson, B. S. and Efthymiopoulos, I. and Kyriakis, A. and Simopoulou, E. and Vayaki, A. and Zachariadou, K. and Badier, J. and Blondel, A. and Bonneaud, G. and Brient, J. C. and Fouque, G. and Gamess, A. and Harvey, J. and Orteu, S. and Rosowsky, A. and Roug{\'{e}}, A. and Rumpf, M. and Tanaka, R. and Videau, H. and Candlin, D. J. and Parsons, M. I. and Veitch, E. and Moneta, L. and Parrini, G. and Corden, M. and Georgipoulos, C. and Ikeda, M. and Lannutti, J. and Levinthal, D. and Mermikides, M. and Sawyer, L. and Wasserbaech, S. and Antonelli, A. and Baldini, R. and Bencivenni, G. and Bologna, G. and Campana, P. and Capon, G. and Cerutti, F. and Chiarella, V. and D'Ettorre-Piazzoli, B. and Felici, G. and Laurelli, P. and Mannocchi, G. and Murtas, F. and Murtas, G. P. and Passalacqua, L. and Pepe-Artarelli, M. and Picchi, P. and Altoon, B. and Boyle, O. and Colrain, P. and ten Have, I. and Lynch, J. G. and Maitland, W. and Morton, W. T. and Raine, C. and Scarr, J. M. and Smith, K. and Thompson, A. S. and Turnbull, R. M. and Brandl, B. and Braun, O. and Geiges, R. and Geweniger, C. and Hanke, P. and Hepp, V. and Kluge, E. E. and Maumary, Y. and Putzer, A. and Rensch, B. and Stahl, A. and Tittel, K. and Wunsch, M. and Belk, A. T. and Beuselinck, R. and Binnie, D. M. and Cameron, W. and Cattaneo, M. and Colling, D. J. and Dornan, P. J. and Dugeay, S. and Greene, A. M. and Hassard, J. F. and Lieske, N. M. and Patton, S. J. and Payne, D. G. and Phillips, M. J. and Sedgbeer, J. K. and Taylor, G. and Tomalin, I. R. and Wright, A. G. and Girtler, P. and Kuhn, D. and Rudolph, G. and Bowdery, C. K. and Brodbeck, T. J. and Finch, A. J. and Foster, F. and Hughes, G. and Jackson, D. and Keemer, N. R. and Nuttall, M. and Patel, A. and Sloan, T. and Snow, S. W. and Whelan, E. P. and Barczewski, T. and Kleinknecht, K. and Raab, J. and Renk, B. and Roehn, S. and Sander, H. G. and Schmidt, H. and Steeg, F. and Walther, S. M. and Wolf, B. and Aubert, J. J. and Benchouk, C. and Bernard, V. and Bonissent, A. and Carr, J. and Coyle, P. and Drinkard, J. and Etienne, F. and Papalexiou, S. and Payre, P. and Qian, Z. and Rousseau, D. and Schwemling, P. and Talby, M. and Adlung, S. and Becker, H. and Blum, W. and Brown, D. and Cattaneo, P. and Cowan, G. and Dehning, B. and Dietl, H. and Dydak, F. and Fernandez-Bosman, M. and Frank, M. and Halley, A. W. and Hansl-Kozanecka, T. and Lauber, J. and L{\"{u}}tjens, G. and Lutz, G. and M{\"{a}}nner, W. and Pan, Y. and Richter, R. and Rotscheidt, H. and Schr{\"{o}}der, J. and Schwarz, A. S. and Settles, R. and Stierlin, U. and Stiegler, U. and St. Denis, R. and Takashima, M. and Thomas, J. and Wolf, G. and Bertin, V. and Boucrot, J. and Callot, O. and Chen, X. and Cordier, A. and Davier, M. and Grivaz, J. F. and Heusse, Ph and Janot, P. and Kim, D. W. and Le Diberder, F. and Lefran{\c{c}}ois, J. and Lutz, A. M. and Schune, M. H. and Veillet, J. J. and Videau, I. and Zhang, Z. and Zomer, F. and Abbaneo, D. and Amendolia, S. R. and Bagliesi, G. and Batignani, G. and Bosisio, L. and Bottigli, U. and Bradaschia, C. and Carpinelli, M. and Ciocco, M. A. and Dell'Orso, R. and Ferrante, I. and Fidecaro, F. and Fo{\`{a}}, L. and Focardi, E. and Forti, F. and Gatto, C. and Giassi, A. and Giorgi, M. A. and Ligabue, F. and Mannelli, E. B. and Marrocchesi, P. S. and Messineo, A. and Palla, F. and Rizzo, G. and Sanguinetti, G. and Steinberger, J. and Tenchini, R. and Tonelli, G. and Triggiani, G. and Vannini, C. and Venturi, A. and Verdini, P. G. and Walsh, J. and Carter, J. M. and Green, M. G. and March, P. V. and Medcalf, T. and Quazi, I. S. and Strong, J. A. and West, L. R. and Botterill, D. R. and Clifft, R. W. and Edgecock, T. R. and Edwards, M. and Fisher, S. M. and Jones, T. J. and Norton, P. R. and Salmon, D. P. and Thompson, J. C. and Bloch-Devaux, B. and Colas, P. and Kozanecki, W. and Lemaire, M. C. and Locci, E. and Loucatos, S. and Monnier, E. and Perez, P. and Perrier, F. and Rander, J. and Renardy, J. F. and Roussarie, A. and Schuller, J. P. and Schwindling, J. and Si Mohand, D. and Vallage, B. and Johnson, R. P. and Litke, A. M. and Wear, J. and Ashman, J. G. and Babbage, W. and Booth, C. N. and Buttar, C. and Carney, R. E. and Cartwright, S. and Combley, F. and Hatfield, F. and Martin, J. and Parker, D. and Reeves, P. and Thompson, L. F. and Barberio, E. and Brandt, S. and Grupen, C. and Mirabito, L. and Sch{\"{a}}fer, U. and Seywerd, H. and Ganis, G. and Giannini, G. and Gobbo, B. and Ragusa, F. and Bellantoni, L. and Cinabro, D. and Conway, J. S. and Cowen, D. F. and Feng, Z. and Ferguson, D. P.S. and Gao, Y. S. and Grahl, J. and Harton, J. L. and Jared, R. C. and LeClaire, B. W. and Lishka, C. and Pan, Y. B. and Pater, J. R. and Saadi, Y. and Sharma, V. and Schmitt, M. and Shi, Z. H. and Tang, Y. H. and Walsh, A. M. and Weber, F. V. and Whitney, M. H. and Lan Wu, Sau and Wu, X. and Zobernig, G.},
    number = {1-2},
    month = {6},
    pages = {163--176},
    volume = {284},
    doi = {10.1016/0370-2693(92)91942-3},
    issn = {03702693}
}
@misc{SkachkovJinr1994OnCollaborations,
    title = {{On the determination of alpha s from the QCD analysis of the scaling violation in the fragmentation functions of the process  e+e- -{\&}gt; h + X  studied by DELPHI, TASSO and other collaborations}},
    year = {1994},
    author = {Skachkov Jinr, N B and Dubna, Russia},
    month = {6},
    url = {https://cds.cern.ch/record/2627790},
    keywords = {CERN Document Server, DELPHI Preprints, WebSearch}
}
@article{Althoff1984DeterminationHadrons,
    title = {{Determination of {$\alpha$}s in first and second order QCD from e+e- annihilation into hadrons}},
    year = {1984},
    journal = {Zeitschrift f{\"{u}}r Physik C Particles and Fields},
    author = {Althoff, M. and Braunschweig, W. and Kirschfink, F. J. and L{\"{u}}belsmeyer, K. and Martyn, H. U. and Rosskamp, P. and Sander, H. G. and Schmitz, D. and Siebke, H. and Wallraff, W. and Eisenmann, J. and Fischer, H. M. and Hartmann, H. and Jocksch, A. and Knop, G. and K{\"{o}}pke, L. and Kolanoski, H. and K{\"{u}}ck, H. and Mertens, V. and Wedemeyer, R. and Eskreys, A. and Gather, K. and Hultschig, H. and Joos, P. and K{\"{o}}tz, U. and Kowalski, H. and Ladage, A. and L{\"{o}}hr, B. and L{\"{u}}ke, D. and M{\"{a}}ttig, P. and Notz, D. and Nowak, R. J. and Pyrlik, J. and Rushton, M. and Sch{\"{u}}tte, W. and Trines, D. and Tymieniecka, T. and Wolf, G. and Yekutieli, G. and Xiao, Ch and Fohrmann, R. and Hilger, E. and Kracht, T. and Krasemann, H. L. and Leu, P. and Lohrmann, E. and Pandoulas, D. and Poelz, G. and P{\"{o}}snecker, K. U. and Wiik, B. H. and Beuselinck, R. and Binnie, D. M. and Dornan, P. J. and Foster, B. and Garbutt, D. A. and Jenkins, C. and Jones, T. D. and Jones, W. G. and McCardle, J. and Sedgbeer, K. J. and Thomas, J. and Wan Abdullah, W. A.T. and Bell, K. W. and Bowler, M. G. and Bull, P. and Cashmore, R. J. and Clarke, P. E.L. and Devenish, R. and Grossmann, P. and Hawkes, C. M. and Lloyd, S. L. and Youngman, C. and Forden, G. E. and Hart, J. C. and Harvey, J. and Hasell, D. K. and Saxon, D. H. and Barreiro, F. and Brandt, S. and Dittmar, M. and Holder, M. and Kreutz, G. and Neumann, B. and Duchovni, E. and Eisenberg, Y. and Karshon, U. and Mikenberg, G. and Mir, R. and Revel, D. and Ronat, E. and Shapira, A. and Winik, M. and Baranko, G. and Barklow, T. and Caldwell, A. and Cherney, M. and Izen, J. M. and Mermikides, M. and Rudolph, G. and Strom, D. and Takashima, M. and Venkataramania, H. and Wicklund, E. and Wu, Sau Lan and Zobernig, G.},
    number = {2},
    pages = {157--174},
    volume = {26},
    publisher = {Springer-Verlag},
    url = {https://link.springer.com/article/10.1007/BF01421751},
    doi = {10.1007/BF01421751/METRICS},
    issn = {14346052},
    keywords = {Elementary Particles, Hadrons, Heavy Ions, Nuclear Physics, Quantum Field Theories, Quantum Field Theory, String Theory}
}
@article{Hoyer1979QuantumE+e-,
    title = {{Quantum chromodynamics and jets in e+e-}},
    year = {1979},
    journal = {Nucl. Phys. B},
    author = {Hoyer, P. and Osland, P. and Sander, H. G. and Walsh, T. F. and Zerwas, P. M.},
    number = {2-3},
    pages = {349},
    volume = {161},
    doi = {10.1016/0550-3213(79)90217-7},
    issn = {05503213}
}
@article{Adeva1983Model-independents,
    title = {{Model-independent second-order determination of the strong-coupling constant {$\alpha$}s}},
    year = {1983},
    journal = {Phys. Rev. Lett.},
    author = {Adeva, B. and Barber, D. P. and Becker, U. and Berdugo, J. and Berghoff, G. and B{\"{o}}hm, A. and Branson, J. G. and Burger, J. D. and Capell, M. and Cerrada, M. and Chang, C. C. and Chen, H. S. and Chen, M. and Chen, M. L. and Chen, M. Y. and Chu, Y. S. and Clare, R. and Deffur, E. and Demarteau, M. and Duinker, P. and Feng, Z. Y. and Fesefeldt, H. S. and Fong, D. and Fukushima, M. and Harting, D. and Hebbeker, T. and Herten, G. and Ho, M. C. and Ilyas, M. M. and Jiang, D. Z. and Krenz, W. and Kuijer, P. and Li, Q. Z. and Luckey, D. and Luit, E. J. and Mana, C. and Marquina, M. A. and Massaro, G. G.G. and Mount, R. and Newman, H. and Pohl, M. and Poschmann, F. P. and Rau, R. R. and Revol, J. P. and Rodriguez, S. and Rohde, M. and Rubio, J. A. and Rykaczewski, H. and Salicio, J. and Schulz, I. and Sinram, K. and Steuer, M. and Swider, G. M. and Tang, H. W. and Teuchert, D. and Ting, Samuel C.C. and Tung, K. L. and Wang, M. Q. and White, M. and Wu, H. G. and Wu, S. X. and Wyslouch, B. and Zhou, B. and Zhu, R. Y. and Zhu, Y. C.},
    number = {26},
    pages = {2051},
    volume = {50},
    doi = {10.1103/physrevlett.50.2051},
    issn = {00319007}
}
@article{CrispimRomao2024JetAnalysis,
    title = {{Jet substructure observables for jet quenching in quark gluon plasma: A machine learning driven analysis}},
    year = {2024},
    journal = {SciPost Phys},
    author = {Crispim Rom{\~{a}}o, Miguel and Guilherme Milhano, José and van Leeuwen, Marco},
    pages = {15},
    volume = {16},
    doi = {10.21468/SciPostPhys.16.1.015}
}
@article{Dasgupta2015Small-radiusQCD,
    title = {{Small-radius jets to all orders in QCD}},
    year = {2015},
    journal = {Journal of High Energy Physics},
    author = {Dasgupta, Mrinal and Dreyer, Frédéric and Salam, Gavin P. and Soyez, Gregory},
    number = {4},
    month = {8},
    volume = {2015},
    publisher = {Springer Verlag},
    url = {http://arxiv.org/abs/1411.5182 http://dx.doi.org/10.1007/JHEP04(2015)039},
    doi = {10.1007/JHEP04(2015)039},
    arxivId = {1411.5182v2},
    keywords = {Jets, QCD Phenomenology}
}
@article{ManganoINTRODUCTIONQCD,
    title = {{INTRODUCTION TO QCD}},
    author = {Mangano, Michelangelo L}
}
@article{Kodaira1978HowQCD,
    title = {{How Can We Define Properly the {\$}Q{\^{}}2{\$} Dependent Parton Distribution Function in {\{}QCD{\}}?}},
    year = {1978},
    journal = {Nucl.Phys.B},
    author = {Kodaira, Jiro and Uematsu, Tsunea},
    number = {4},
    month = {9},
    pages = {497--506},
    volume = {141},
    doi = {10.1016/0550-3213(78)90042-1},
    issn = {05503213}
}
@article{Butter2023PerformanceTagging,
    title = {{Performance versus resilience in modern quark-gluon tagging}},
    year = {2023},
    journal = {SciPost Phys. Core},
    author = {Butter, Anja and Dillon, Barry M and Plehn, Tilman and Vogel, Lorenz},
    pages = {85},
    volume = {6},
    doi = {10.21468/SciPostPhysCore.6.4.085}
}
@article{Ali2011JETSQCD,
    title = {{JETS and QCD: a historical review of the discovery of the quark and gluon jets and its impact on QCD}},
    year = {2011},
    journal = {The European Physical Journal H 2011 36:2},
    author = {Ali, A. and Kramer, G.},
    number = {2},
    month = {9},
    pages = {245--326},
    volume = {36},
    publisher = {Springer},
    url = {https://link.springer.com/article/10.1140/epjh/e2011-10047-1},
    doi = {10.1140/EPJH/E2011-10047-1},
    issn = {2102-6467},
    arxivId = {1012.2288},
    keywords = {Astronomy, Astrophysics and Cosmology, History and Philosophical Foundations of Physics, History of Science, Measurement Science and Instrumentation, Physics, Quantum Physics, general}
}
@article{SalehMoghaddam2022ComparisonConstant,
    title = {{Comparison of quark jets with gluon jets and measurement of the coupling constant}},
    year = {2022},
    journal = {Indian Journal of Physics},
    author = {Saleh Moghaddam, R. and Zomorrodian, M. E.},
    number = {11},
    month = {9},
    pages = {3311--3319},
    volume = {96},
    publisher = {Springer},
    doi = {10.1007/S12648-022-02290-7},
    issn = {09749845},
    keywords = {Hadron mass models and calculations, Perturbative calculations, Quantum chromodynamics}
}
@article{Dokshitzer1996DispersiveProcesses,
    title = {{Dispersive approach to power-behaved contributions in QCD hard processes}},
    year = {1996},
    journal = {Nuclear Physics B},
    author = {Dokshitzer, Yu L. and Marchesini, G. and Webber, B. R.},
    number = {1-2},
    month = {6},
    pages = {93--142},
    volume = {469},
    publisher = {Elsevier},
    url = {http://arxiv.org/abs/hep-ph/9512336 http://dx.doi.org/10.1016/0550-3213(96)00155-1},
    doi = {10.1016/0550-3213(96)00155-1},
    issn = {05503213},
    arxivId = {hep-ph/9512336}
}
@article{Salam2001HadronShapes,
    title = {{Hadron masses and power corrections to event shapes}},
    year = {2001},
    journal = {Journal of High Energy Physics},
    author = {Salam, G. P. and Wicke, D.},
    number = {5},
    month = {6},
    volume = {5},
    publisher = {Springer Verlag},
    url = {http://arxiv.org/abs/hep-ph/0102343 http://dx.doi.org/10.1088/1126-6708/2001/05/061},
    doi = {10.1088/1126-6708/2001/05/061},
    arxivId = {hep-ph/0102343v2},
    keywords = {Jets, QCD}
}
@article{Chien2014JetTheory,
    title = {{Jet Shape Resummation Using Soft-Collinear Effective Theory}},
    year = {2014},
    journal = {Journal of High Energy Physics},
    author = {Chien, Yang-Ting and Vitev, Ivan},
    number = {12},
    month = {12},
    volume = {2014},
    publisher = {Springer Verlag},
    url = {http://arxiv.org/abs/1405.4293 http://dx.doi.org/10.1007/JHEP12(2014)061},
    doi = {10.1007/JHEP12(2014)061},
    arxivId = {1405.4293v2},
    keywords = {Jets, QCD Phenomenology}
}
@article{Ellis2010JetSCET,
    title = {{Jet shapes and jet algorithms in SCET}},
    year = {2010},
    journal = {Journal of High Energy Physics},
    author = {Ellis, Stephen D. and Vermilion, Christopher K. and Walsh, Jonathan R. and Hornig, Andrew and Lee, Christopher},
    number = {11},
    month = {11},
    pages = {1--83},
    volume = {2010},
    publisher = {Springer},
    url = {https://link.springer.com/article/10.1007/JHEP11(2010)101},
    doi = {10.1007/JHEP11(2010)101/METRICS},
    issn = {11266708},
    arxivId = {1001.0014},
    keywords = {Jets, QCD}
}
@article{Lee2006MomentumTheory,
    title = {{Momentum Flow Correlations from Event Shapes: Factorized Soft Gluons and Soft-Collinear Effective Theory}},
    year = {2006},
    journal = {Physical Review D - Particles, Fields, Gravitation and Cosmology},
    author = {Lee, Christopher and Sterman, George},
    number = {1},
    month = {11},
    volume = {75},
    url = {http://arxiv.org/abs/hep-ph/0611061 http://dx.doi.org/10.1103/PhysRevD.75.014022},
    doi = {10.1103/PhysRevD.75.014022},
    arxivId = {hep-ph/0611061v1}
}
@article{Buterus2023SomeDistributions,
    title = {{Some notes on moment inequalities for heavy-tailed distributions}},
    year = {2023},
    author = {Buterus, Paul and Sambale, Holger},
    month = {8},
    url = {https://arxiv.org/pdf/2308.14410},
    arxivId = {2308.14410}
}
@article{GomezAmbrosio:2022mpm,
    author = "Gomez Ambrosio, Raquel and ter Hoeve, Jaco and Madigan, Maeve and Rojo, Juan and Sanz, Veronica",
    title = "{Unbinned multivariate observables for global SMEFT analyses from machine learning}",
    eprint = "2211.02058",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    reportNumber = "Nikhef-2022-015",
    doi = "10.1007/JHEP03(2023)033",
    journal = "JHEP",
    volume = "03",
    pages = "033",
    year = "2023"
}
@phdthesis{Fiorendi:2014klw,
    author = "Fiorendi, Sara",
    title = "{Measurement of the branching fraction of $B_c \to J/\psi  \pi^+\pi^+\pi^- $relative to $B_c \to J/\psi  \pi^+$ and of the production cross-section of $B_c \to J/\psi  \pi^+$ relative to $B^+ \to J/\psi  K^+$ with the CMS experiment}",
    reportNumber = "CERN-THESIS-2014-456",
    school = "Milan Bicocca U.",
    year = "2014"
}
@article{KLOE-2:2025ggc,
    author = "Babusci, D. and others",
    collaboration = "KLOE-2",
    title = "{Measurement of $\eta\to\pi^{0}\gamma\gamma$ branching fraction with the KLOE detector}",
    eprint = "2505.09285",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    month = "5",
    year = "2025"
}
@article{Ressegotti:2024szk,
    author = "Ressegotti, Martina",
    collaboration = "ATLAS",
    title = "{Search for heavy, long-lived, charged particles with large ionisation energy loss and time-of-flight with the ATLAS experiment}",
    reportNumber = "ATL-PHYS-PROC-2023-072",
    doi = "10.22323/1.449.0484",
    journal = "PoS",
    volume = "EPS-HEP2023",
    pages = "484",
    year = "2024"
}
@article{LHCb:2025eyf,
    author = "Aaij, Roel and others",
    collaboration = "LHCb",
    title = "{Search for the lepton-flavour-violating decays $B^0 \to K^{*0} τ^\pm e^\mp$}",
    eprint = "2506.15347",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    reportNumber = "LHCb-PAPER-2025-005, CERN-EP-2025-107",
    month = "6",
    year = "2025"
}
@article{alhroobSingleTopQuark,
  title = {Single Top Quark Production Cross Section Using the {{ATLAS}} Detector at the {{LHC}}},
  author = {Alhroob, Muhammad},
  doi = {10.22323/1.364.0658},
  langid = {english},
  file = {/Users/t-krishdesai/Zotero/storage/UM7XWRPH/Alhroob - Single top quark production cross section using the ATLAS detector at the LHC.pdf}
}

@article{ATLAS:2017dhr,
  title = {Measurement of Lepton Differential Distributions and the Top Quark Mass in \$\$t{\textbackslash}bar\{t\}\$\$production in Pp Collisions at \$\${\textbackslash}sqrt\{s\}=8\$\$~{{TeV}} with the {{ATLAS}} Detector},
  author = {Aaboud, M. and Aad, G. and Abbott, B. and Abdinov, O. and Abeloos, B. and Abidi, S. H. and AbouZeid, O. S. and Abraham, N. L. and Abramowicz, H. and Abreu, H. and Abreu, R. and Abulaiti, Y. and Acharya, B. S. and Adachi, S. and Adamczyk, L. and Adelman, J. and Adersberger, M. and Adye, T. and Affolder, A. A. and Afik, Y. and {Agatonovic-Jovin}, T. and Agheorghiesei, C. and {Aguilar-Saavedra}, J. A. and Ahlen, S. P. and Ahmadov, F. and Aielli, G. and Akatsuka, S. and Akerstedt, H. and {\AA}kesson, T. P. A. and Akilli, E. and Akimov, A. V. and Alberghi, G. L. and Albert, J. and Albicocco, P. and Alconada Verzini, M. J. and Alderweireldt, S. C. and Aleksa, M. and Aleksandrov, I. N. and Alexa, C. and Alexander, G. and Alexopoulos, T. and Alhroob, M. and Ali, B. and Aliev, M. and Alimonti, G. and Alison, J. and Alkire, S. P. and Allbrooke, B. M. M. and Allen, B. W. and Allport, P. P. and Aloisio, A. and Alonso, A. and Alonso, F. and Alpigiani, C. and Alshehri, A. A. and Alstaty, M. I. and Alvarez Gonzalez, B. and {\'A}lvarez Piqueras, D. and Alviggi, M. G. and Amadio, B. T. and Amaral Coutinho, Y. and Amelung, C. and Amidei, D. and Amor Dos Santos, S. P. and Amoroso, S. and Amundsen, G. and Anastopoulos, C. and Ancu, L. S. and Andari, N. and Andeen, T. and Anders, C. F. and Anders, J. K. and Anderson, K. J. and Andreazza, A. and Andrei, V. and Angelidakis, S. and Angelozzi, I. and Angerami, A. and Anisenkov, A. V. and Anjos, N. and Annovi, A. and Antel, C. and Antonelli, M. and Antonov, A. and Antrim, D. J. and Anulli, F. and Aoki, M. and Aperio Bella, L. and Arabidze, G. and Arai, Y. and Araque, J. P. and Araujo Ferraz, V. and Arce, A. T. H. and Ardell, R. E. and Arduh, F. A. and Arguin, J-F. and Argyropoulos, S. and Arik, M. and Armbruster, A. J. and Armitage, L. J. and Arnaez, O. and Arnold, H. and Arratia, M. and Arslan, O. and Artamonov, A. and Artoni, G. and Artz, S. and Asai, S. and Asbah, N. and Ashkenazi, A. and Asquith, L. and Assamagan, K. and Astalos, R. and Atkinson, M. and Atlay, N. B. and Augsten, K. and Avolio, G. and Axen, B. and Ayoub, M. K. and Azuelos, G. and Baas, A. E. and Baca, M. J. and Bachacou, H. and Bachas, K. and Backes, M. and Bagnaia, P. and Bahmani, M. and Bahrasemani, H. and Baines, J. T. and Bajic, M. and Baker, O. K. and Bakker, P. J. and Baldin, E. M. and Balek, P. and Balli, F. and Balunas, W. K. and Banas, E. and Bandyopadhyay, A. and Banerjee, {\relax Sw}. and Bannoura, A. A. E. and Barak, L. and Barberio, E. L. and Barberis, D. and Barbero, M. and Barillari, T. and Barisits, M-S and Barkeloo, J. T. and Barklow, T. and Barlow, N. and Barnes, S. L. and Barnett, B. M. and Barnett, R. M. and {Barnovska-Blenessy}, Z. and Baroncelli, A. and Barone, G. and Barr, A. J. and Barranco Navarro, L. and Barreiro, F. and {Barreiro Guimar{\~a}es da Costa}, J. and Bartoldus, R. and Barton, A. E. and Bartos, P. and Basalaev, A. and Bassalat, A. and Bates, R. L. and Batista, S. J. and Batley, J. R. and Battaglia, M. and Bauce, M. and Bauer, F. and Bawa, H. S. and Beacham, J. B. and Beattie, M. D. and Beau, T. and Beauchemin, P. H. and Bechtle, P. and Beck, H. P. and Beck, H. C. and Becker, K. and Becker, M. and Becot, C. and Beddall, A. J. and Beddall, A. and Bednyakov, V. A. and Bedognetti, M. and Bee, C. P. and Beermann, T. A. and Begalli, M. and Begel, M. and Behr, J. K. and Bell, A. S. and Bella, G. and Bellagamba, L. and Bellerive, A. and Bellomo, M. and Belotskiy, K. and Beltramello, O. and Belyaev, N. L. and Benary, O. and Benchekroun, D. and Bender, M. and Benekos, N. and Benhammou, Y. and Benhar Noccioli, E. and Benitez, J. and Benjamin, D. P. and Benoit, M. and Bensinger, J. R. and Bentvelsen, S. and Beresford, L. and Beretta, M. and Berge, D. and Bergeaas Kuutmann, E. and Berger, N. and Beringer, J. and Berlendis, S. and Bernard, N. R. and Bernardi, G. and Bernius, C. and Bernlochner, F. U. and Berry, T. and Berta, P. and Bertella, C. and Bertoli, G. and Bertram, I. A. and Bertsche, C. and Bertsche, D. and Besjes, G. J. and Bessidskaia Bylund, O. and Bessner, M. and Besson, N. and Bethani, A. and Bethke, S. and Betti, A. and Bevan, A. J. and Beyer, J. and Bianchi, R. M. and Biebel, O. and Biedermann, D. and Bielski, R. and Bierwagen, K. and Biesuz, N. V. and Biglietti, M. and Billoud, T. R. V. and Bilokon, H. and Bindi, M. and Bingul, A. and Bini, C. and Biondi, S. and Bisanz, T. and Bittrich, C. and Bjergaard, D. M. and Black, J. E. and Black, K. M. and Blair, R. E. and Blazek, T. and Bloch, I. and Blocker, C. and Blue, A. and Blumenschein, U. and Blunier, S. and Bobbink, G. J. and Bobrovnikov, V. S. and Bocchetta, S. S. and Bocci, A. and Bock, C. and Boehler, M. and Boerner, D. and Bogavac, D. and Bogdanchikov, A. G. and Bohm, C. and Boisvert, V. and Bokan, P. and Bold, T. and Boldyrev, A. S. and Bolz, A. E. and Bomben, M. and Bona, M. and Boonekamp, M. and Borisov, A. and Borissov, G. and Bortfeldt, J. and Bortoletto, D. and Bortolotto, V. and Boscherini, D. and Bosman, M. and Bossio Sola, J. D. and Boudreau, J. and {Bouhova-Thacker}, E. V. and Boumediene, D. and Bourdarios, C. and Boutle, S. K. and Boveia, A. and Boyd, J. and Boyko, I. R. and Bozson, A. J. and Bracinik, J. and Brandt, A. and Brandt, G. and Brandt, O.},
  year = {2017},
  month = nov,
  journal = {The European Physical Journal C},
  volume = {77},
  number = {11},
  eprint = {1709.09407},
  primaryclass = {hep-ex},
  pages = {804},
  issn = {1434-6052},
  doi = {10.1140/epjc/s10052-017-5349-9},
  urldate = {2025-07-19},
  abstract = {This paper presents single lepton and dilepton kinematic distributions measured in dileptonic \$t{\textbackslash}bar\{t\}\$ events produced in 20.2 fb\${\textasciicircum}\{-1\}\$ of \${\textbackslash}sqrt\{s\}=8\$ TeV \$pp\$ collisions recorded by the ATLAS experiment at the LHC. Both absolute and normalised differential cross-sections are measured, using events with an opposite-charge \$e{\textbackslash}mu\$ pair and one or two \$b\$-tagged jets. The cross-sections are measured in a fiducial region corresponding to the detector acceptance for leptons, and are compared to the predictions from a variety of Monte Carlo event generators, as well as fixed-order QCD calculations, exploring the sensitivity of the cross-sections to the gluon parton distribution function. Some of the distributions are also sensitive to the top quark pole mass; a combined fit of NLO fixed-order predictions to all the measured distributions yields a top quark mass value of \$m\_t{\textasciicircum}\{{\textbackslash}rm pole\}=173.2{\textbackslash}pm 0.9{\textbackslash}pm0.8{\textbackslash}pm1.2\$ GeV, where the three uncertainties arise from data statistics, experimental systematics, and theoretical sources.},
  archiveprefix = {arXiv},
  collaboration = {ATLAS},
  langid = {english},
  keywords = {Accelerator Physics,Experimental Nuclear Physics,Experimental Particle Physics,Nuclear and Particle Physics,Particle Physics,Theoretical Particle Physics},
  annotation = {95 citations (INSPIRE 2025/7/19)\\
34 citations w/o self (INSPIRE 2025/7/19)\\
Citations: 22 (Crossref) [2025-07-19]\\
Citations: 14 (SemanticScholar) [2025-07-19]}
}

@article{Benato:2025rgo,
  title = {Unbinned Inclusive Cross-Section Measurements with Machine-Learned Systematic Uncertainties},
  author = {Benato, Lisa and Giordano, Cristina and Krause, Claudius and Li, Ang and Sch{\"o}fbeck, Robert and Schwarz, Dennis and Shooshtari, Maryam and Wang, Daohan},
  year = {2025},
  month = may,
  eprint = {2505.05544},
  primaryclass = {hep-ph},
  doi = {10.48550/arXiv.2505.05544},
  urldate = {2025-07-19},
  abstract = {We introduce a novel methodology for addressing systematic uncertainties in unbinned inclusive cross-section measurements and related collider-based inference problems. Our approach incorporates known analytic dependencies on parameters of interest, including signal strengths and nuisance parameters. When these dependencies are unknown, as is frequently the case for systematic uncertainties, dedicated neural network parametrizations provide an approximation that is trained on simulated data. The resulting machine-learned surrogate captures the complete parameter dependence of the likelihood ratio, providing a near-optimal test statistic. As a case study, we perform a first-principles inclusive cross-section measurement of \${\textbackslash}textrm\{H\}{\textbackslash}rightarrow{\textbackslash}tau{\textbackslash}tau\$ in the single-lepton channel, utilizing simulated data from the FAIR Universe Higgs Uncertainty Challenge. Results in Asimov data, from large-scale toy studies, and using the Fisher information demonstrate significant improvements over traditional binned methods. Our computer code ``Guaranteed Optimal Log-Likelihood-based Unbinned Method'' (GOLLUM) for machine-learning and inference is publicly available.},
  archiveprefix = {arXiv},
  keywords = {High Energy Physics - Experiment,High Energy Physics - Phenomenology,Physics - Data Analysis Statistics and Probability},
  annotation = {0 citations (INSPIRE 2025/7/19)\\
0 citations w/o self (INSPIRE 2025/7/19)\\
Citations: 0 (SemanticScholar) [2025-07-19]}
}

@misc{chenCDEGANCooperativeDual2021,
  title = {{{CDE-GAN}}: {{Cooperative Dual Evolution Based Generative Adversarial Network}}},
  shorttitle = {{{CDE-GAN}}},
  author = {Chen, Shiming and Wang, Wenjie and Xia, Beihao and You, Xinge and Cao, Zehong and Ding, Weiping},
  year = {2021},
  month = mar,
  number = {arXiv:2008.09388},
  eprint = {2008.09388},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2008.09388},
  urldate = {2025-07-20},
  abstract = {Generative adversarial networks (GANs) have been a popular deep generative model for real-world applications. Despite many recent efforts on GANs that have been contributed, mode collapse and instability of GANs are still open problems caused by their adversarial optimization difficulties. In this paper, motivated by the cooperative co-evolutionary algorithm, we propose a Cooperative Dual Evolution based Generative Adversarial Network (CDE-GAN) to circumvent these drawbacks. In essence, CDE-GAN incorporates dual evolution with respect to the generator(s) and discriminators into a unified evolutionary adversarial framework to conduct effective adversarial multi-objective optimization. Thus it exploits the complementary properties and injects dual mutation diversity into training to steadily diversify the estimated density in capturing multi-modes and improve generative performance. Specifically, CDE-GAN decomposes the complex adversarial optimization problem into two subproblems (generation and discrimination), and each subproblem is solved with a separated subpopulation (E-Generator\vphantom\{\} and E-Discriminators), evolved by its own evolutionary algorithm. Additionally, we further propose a Soft Mechanism to balance the trade-off between E-Generators and E-Discriminators to conduct steady training for CDE-GAN. Extensive experiments on one synthetic dataset and three real-world benchmark image datasets demonstrate that the proposed CDE-GAN achieves a competitive and superior performance in generating good quality and diverse samples over baselines. The code and more generated results are available at our project homepage: https://shiming-chen.github.io/CDE-GAN-website/CDE-GAN.html.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  annotation = {Citations: 34 (SemanticScholar) [2025-07-20]},
  file = {/Users/t-krishdesai/Zotero/storage/VJILL6V9/Chen et al. - 2021 - CDE-GAN Cooperative Dual Evolution Based Generative Adversarial Network.pdf;/Users/t-krishdesai/Zotero/storage/C4M75J4U/2008.html}
}

@misc{cuiKnowledgeaugmentedDeepLearning2022,
  title = {Knowledge-Augmented {{Deep Learning}} and {{Its Applications}}: {{A Survey}}},
  shorttitle = {Knowledge-Augmented {{Deep Learning}} and {{Its Applications}}},
  author = {Cui, Zijun and Gao, Tian and Talamadupula, Kartik and Ji, Qiang},
  year = {2022},
  month = nov,
  number = {arXiv:2212.00017},
  eprint = {2212.00017},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2212.00017},
  urldate = {2025-07-20},
  abstract = {Deep learning models, though having achieved great success in many different fields over the past years, are usually data hungry, fail to perform well on unseen samples, and lack of interpretability. Various prior knowledge often exists in the target domain and their use can alleviate the deficiencies with deep learning. To better mimic the behavior of human brains, different advanced methods have been proposed to identify domain knowledge and integrate it into deep models for data-efficient, generalizable, and interpretable deep learning, which we refer to as knowledge-augmented deep learning (KADL). In this survey, we define the concept of KADL, and introduce its three major tasks, i.e., knowledge identification, knowledge representation, and knowledge integration. Different from existing surveys that are focused on a specific type of knowledge, we provide a broad and complete taxonomy of domain knowledge and its representations. Based on our taxonomy, we provide a systematic review of existing techniques, different from existing works that survey integration approaches agnostic to taxonomy of knowledge. This survey subsumes existing works and offers a bird's-eye view of research in the general area of knowledge-augmented deep learning. The thorough and critical reviews of numerous papers help not only understand current progresses but also identify future directions for the research on knowledge-augmented deep learning.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {Citations: 20 (SemanticScholar) [2025-07-20]},
  file = {/Users/t-krishdesai/Zotero/storage/9YJRKQUC/Cui et al. - 2022 - Knowledge-augmented Deep Learning and Its Applications A Survey.pdf;/Users/t-krishdesai/Zotero/storage/LVILUDTI/2212.html}
}

@misc{dangeloWhyWeNeed2024,
  title = {Why {{Do We Need Weight Decay}} in {{Modern Deep Learning}}?},
  author = {D'Angelo, Francesco and Andriushchenko, Maksym and Varre, Aditya and Flammarion, Nicolas},
  year = {2024},
  month = nov,
  number = {arXiv:2310.04415},
  eprint = {2310.04415},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.04415},
  urldate = {2025-07-20},
  abstract = {Weight decay is a broadly used technique for training state-of-the-art deep networks from image classification to large language models. Despite its widespread usage and being extensively studied in the classical literature, its role remains poorly understood for deep learning. In this work, we highlight that the role of weight decay in modern deep learning is different from its regularization effect studied in classical learning theory. For deep networks on vision tasks trained with multipass SGD, we show how weight decay modifies the optimization dynamics enhancing the ever-present implicit regularization of SGD via the loss stabilization mechanism. In contrast, for large language models trained with nearly one-epoch training, we describe how weight decay balances the bias-variance tradeoff in stochastic optimization leading to lower training loss and improved training stability. Overall, we present a unifying perspective from ResNets on vision tasks to LLMs: weight decay is never useful as an explicit regularizer but instead changes the training dynamics in a desirable way. The code is available at https://github.com/tml-epfl/why-weight-decay},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/t-krishdesai/Zotero/storage/7B2DYYW8/D'Angelo et al. - 2024 - Why Do We Need Weight Decay in Modern Deep Learning.pdf;/Users/t-krishdesai/Zotero/storage/4INPI8SX/2310.html}
}

@misc{delattreEfficientBoundLipschitz2023,
  title = {Efficient {{Bound}} of {{Lipschitz Constant}} for {{Convolutional Layers}} by {{Gram Iteration}}},
  author = {Delattre, Blaise and Barth{\'e}lemy, Quentin and Araujo, Alexandre and Allauzen, Alexandre},
  year = {2023},
  month = jun,
  number = {arXiv:2305.16173},
  eprint = {2305.16173},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.16173},
  urldate = {2025-07-20},
  abstract = {Since the control of the Lipschitz constant has a great impact on the training stability, generalization, and robustness of neural networks, the estimation of this value is nowadays a real scientific challenge. In this paper we introduce a precise, fast, and differentiable upper bound for the spectral norm of convolutional layers using circulant matrix theory and a new alternative to the Power iteration. Called the Gram iteration, our approach exhibits a superlinear convergence. First, we show through a comprehensive set of experiments that our approach outperforms other state-of-the-art methods in terms of precision, computational cost, and scalability. Then, it proves highly effective for the Lipschitz regularization of convolutional neural networks, with competitive results against concurrent approaches. Code is available at https://github.com/blaisedelattre/lip4conv.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {Citations: 13 (SemanticScholar) [2025-07-20]}
}

@misc{doanImageGenerationMinimizing2020,
  title = {Image {{Generation Via Minimizing Fr{\'e}chet Distance}} in {{Discriminator Feature Space}}},
  author = {Doan, Khoa D. and Manchanda, Saurav and Wang, Fengjiao and Keerthi, Sathiya and Bhowmik, Avradeep and Reddy, Chandan K.},
  year = {2020},
  month = mar,
  number = {arXiv:2003.11774},
  eprint = {2003.11774},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2003.11774},
  urldate = {2025-07-20},
  abstract = {For a given image generation problem, the intrinsic image manifold is often low dimensional. We use the intuition that it is much better to train the GAN generator by minimizing the distributional distance between real and generated images in a small dimensional feature space representing such a manifold than on the original pixel-space. We use the feature space of the GAN discriminator for such a representation. For distributional distance, we employ one of two choices: the Fr{\textbackslash}'\{e\}chet distance or direct optimal transport (OT); these respectively lead us to two new GAN methods: Fr{\textbackslash}'\{e\}chet-GAN and OT-GAN. The idea of employing Fr{\textbackslash}'\{e\}chet distance comes from the success of Fr{\textbackslash}'\{e\}chet Inception Distance as a solid evaluation metric in image generation. Fr{\textbackslash}'\{e\}chet-GAN is attractive in several ways. We propose an efficient, numerically stable approach to calculate the Fr{\textbackslash}'\{e\}chet distance and its gradient. The Fr{\textbackslash}'\{e\}chet distance estimation requires a significantly less computation time than OT; this allows Fr{\textbackslash}'\{e\}chet-GAN to use much larger mini-batch size in training than OT. More importantly, we conduct experiments on a number of benchmark datasets and show that Fr{\textbackslash}'\{e\}chet-GAN (in particular) and OT-GAN have significantly better image generation capabilities than the existing representative primal and dual GAN approaches based on the Wasserstein distance.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  annotation = {Citations: 6 (SemanticScholar) [2025-07-20]},
  file = {/Users/t-krishdesai/Zotero/storage/B3Z84QWL/Doan et al. - 2020 - Image Generation Via Minimizing Fréchet Distance in Discriminator Feature Space.pdf}
}

@article{doppDatadrivenScienceMachine2023,
  title = {Data-Driven Science and Machine Learning Methods in Laser--Plasma Physics},
  author = {D{\"o}pp, Andreas and Eberle, Christoph and Howard, Sunny and Irshad, Faran and Lin, Jinpu and Streeter, Matthew},
  year = {2023},
  month = jan,
  journal = {High Power Laser Science and Engineering},
  volume = {11},
  pages = {e55},
  issn = {2095-4719, 2052-3289},
  doi = {10.1017/hpl.2023.47},
  urldate = {2025-07-20},
  abstract = {Laser-plasma physics has developed rapidly over the past few decades as lasers have become both more powerful and more widely available. Early experimental and numerical research in this field was dominated by single-shot experiments with limited parameter exploration. However, recent technological improvements make it possible to gather data for hundreds or thousands of different settings in both experiments and simulations. This has sparked interest in using advanced techniques from mathematics, statistics and computer science to deal with, and benefit from, big data. At the same time, sophisticated modeling techniques also provide new ways for researchers to deal effectively with situation where still only sparse data are available. This paper aims to present an overview of relevant machine learning methods with focus on applicability to laser-plasma physics and its important sub-fields of laser-plasma acceleration and inertial confinement fusion.},
  langid = {english},
  keywords = {deep learning,laser-plasma interaction,machine learning},
  annotation = {Citations: 68 (Crossref) [2025-07-20]\\
Citations: 72 (SemanticScholar) [2025-07-20]}
}

@article{GomezAmbrosio:2022mpm,
  title = {Unbinned Multivariate Observables for Global {{SMEFT}} Analyses from Machine Learning},
  author = {Ambrosio, Raquel Gomez and {ter Hoeve}, Jaco and Madigan, Maeve and Rojo, Juan and Sanz, Veronica},
  year = {2023},
  month = mar,
  journal = {Journal of High Energy Physics},
  volume = {03},
  number = {3},
  eprint = {2211.02058},
  primaryclass = {hep-ph},
  pages = {033},
  issn = {1029-8479},
  doi = {10.1007/JHEP03(2023)033},
  urldate = {2025-07-19},
  abstract = {Theoretical interpretations of particle physics data, such as the determination of the Wilson coefficients of the Standard Model Effective Field Theory (SMEFT), often involve the inference of multiple parameters from a global dataset. Optimizing such interpretations requires the identification of observables that exhibit the highest possible sensitivity to the underlying theory parameters. In this work we develop a flexible open source framework, ML4EFT, enabling the integration of unbinned multivariate observables into global SMEFT fits. As compared to traditional measurements, such observables enhance the sensitivity to the theory parameters by preventing the information loss incurred when binning in a subset of final-state kinematic variables. Our strategy combines machine learning regression and classification techniques to parameterize high-dimensional likelihood ratios, using the Monte Carlo replica method to estimate and propagate methodological uncertainties. As a proof of concept we construct unbinned multivariate observables for top-quark pair and Higgs+\$Z\$ production at the LHC, demonstrate their impact on the SMEFT parameter space as compared to binned measurements, and study the improved constraints associated to multivariate inputs. Since the number of neural networks to be trained scales quadratically with the number of parameters and can be fully parallelized, the ML4EFT framework is well-suited to construct unbinned multivariate observables which depend on up to tens of EFT coefficients, as required in global fits.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Data-driven Science Modeling and Theory Building,Higgs Properties,Machine Learning,Model Theory,Particle Physics,SMEFT,String Theory,Theoretical Particle Physics},
  annotation = {26 citations (INSPIRE 2025/7/19)\\
18 citations w/o self (INSPIRE 2025/7/19)\\
Citations: 13 (Crossref) [2025-07-19]\\
Citations: 17 (SemanticScholar) [2025-07-19]}
}

@phdthesis{howardAdvancingParticlePhysics2022,
  title = {Advancing {{Particle Physics}} with {{Sophisticated Computational Frameworks}}},
  author = {Howard, Jessica Nicole},
  year = {2022},
  urldate = {2025-07-20},
  abstract = {The Standard Model (SM) of particle physics is one of the most complete mathematical models of physical phenomena to date. Even so, it cannot explain experimental results like the existence of particle dark matter and the fact that neutrino masses are non-zero. Explaining such results will necessitate developing a beyond the SM (BSM) theoretical description of particle physics. What form this BSM physics will take has become increasingly unclear; many elegant theories which were expected to appear in recent experiments have not emerged. Thus, we find ourselves at a cross-roads, in need of new perspectives and new computational frameworks to push our theoretical description of physics forward.New perspectives will come from challenging previously-held assumptions in the pursuit of fundamentally new descriptions, but challenging such assumptions often presents practical computational challenges. Therefore, these new perspectives must also be accompanied by new computational frameworks. Computational frameworks can come in many forms, from the purely mathematical to the largely numerical. In particular, in recent years machine learning (ML) has become an increasingly accessible and powerful computational tool for scientific applications. Crafting novel BSM theories will require us to investigate and embrace the full spectrum of computational frameworks. Additionally, one of the best ways to spark new insights is to closely collaborate with and draw inspiration from other fields, such as mathematics and computer science.In this thesis, we present two examples of how advanced computational frameworks can be used to aid in investigating new physics perspectives. In one example, we see how the purely mathematical framework of optimal transport (OT) theory can be used in tandem with advanced ML methods to enable a new perspective on particle physics simulations. The result is a novel strategy which lays the foundations for a completely data-driven, end-to-end simulation of particle collisions at the Large Hadron Collider. In a second example, we see work which considers a new perspective on what the history of our universe might have looked like. In particular, we consider how the abundance of a WIMP dark matter candidate could be altered by considering a phase of electroweak force confinement early in the universe. Considering this model while making relatively few assumptions was aided by the application of advanced numerical computational tools.We begin with both high-level and technical background on the topics relevant to these works. We conclude by discussing future directions for these works, as well as briefly giving general thoughts on strategies for applying the computational framework of ML to problems in theoretical particle physics more broadly.},
  langid = {english},
  school = {UC Irvine}
}

@article{Humble:2022vtm,
  title = {Snowmass {{White Paper}}: {{Quantum Computing Systems}} and {{Software}} for {{High-energy Physics Research}}},
  shorttitle = {Snowmass {{White Paper}}},
  author = {Humble, Travis S. and Delgado, Andrea and Pooser, Raphael and Seck, Christopher and Bennink, Ryan and {Leyton-Ortega}, Vicente and Wang, C.-C. Joseph and Dumitrescu, Eugene and Morris, Titus and Hamilton, Kathleen and Lyakh, Dmitry and Date, Prasanna and Wang, Yan and Peters, Nicholas A. and Evans, Katherine J. and Demarteau, Marcel and McCaskey, Alex and Nguyen, Thien and Clark, Susan and Reville, Melissa and Meglio, Alberto Di and Grossi, Michele and Vallecorsa, Sofia and Borras, Kerstin and Jansen, Karl and Kr{\"u}cker, Dirk},
  year = {2022},
  month = mar,
  eprint = {2203.07091},
  primaryclass = {quant-ph},
  doi = {10.48550/arXiv.2203.07091},
  urldate = {2025-07-20},
  abstract = {Quantum computing offers a new paradigm for advancing high-energy physics research by enabling novel methods for representing and reasoning about fundamental quantum mechanical phenomena. Realizing these ideals will require the development of novel computational tools for modeling and simulation, detection and classification, data analysis, and forecasting of high-energy physics (HEP) experiments. While the emerging hardware, software, and applications of quantum computing are exciting opportunities, significant gaps remain in integrating such techniques into the HEP community research programs. Here we identify both the challenges and opportunities for developing quantum computing systems and software to advance HEP discovery science. We describe opportunities for the focused development of algorithms, applications, software, hardware, and infrastructure to support both practical and theoretical applications of quantum computing to HEP problems within the next 10 years.},
  archiveprefix = {arXiv},
  keywords = {Quantum Physics},
  annotation = {21 citations (INSPIRE 2025/7/20)\\
17 citations w/o self (INSPIRE 2025/7/20)\\
Citations: 15 (SemanticScholar) [2025-07-20]},
  file = {/Users/t-krishdesai/Zotero/storage/9R4JNBFZ/Humble et al. - 2022 - Snowmass White Paper Quantum Computing Systems and Software for High-energy Physics Research.pdf;/Users/t-krishdesai/Zotero/storage/96I7PXHL/2203.html}
}

@article{lagraveEquivariantNeuralNetworks2022,
  title = {Equivariant {{Neural Networks}} and {{Differential Invariants Theory}} for {{Solving Partial Differential Equations}}},
  author = {Lagrave, Pierre-Yves and Tron, Eliot},
  year = {2022},
  journal = {Physical Sciences Forum},
  volume = {5},
  number = {1},
  pages = {13},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2673-9984},
  doi = {10.3390/psf2022005013},
  urldate = {2025-07-20},
  abstract = {This paper discusses the use of Equivariant Neural Networks (ENN) for solving Partial Differential Equations by exploiting their underlying symmetry groups. We first show that Group-Convolutionnal Neural Networks can be used to generalize Physics-Informed Neural Networks and then consider the use of ENN to approximate differential invariants of a given symmetry group, hence allowing to build symmetry-preserving Finite Difference methods without the need to formally derivate corresponding numerical invariantizations. The benefit of our approach is illustrated on the 2D heat equation through the instantiation of an SE(2) symmetry-preserving discretization.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {differential invariants,equivariant neural networks,geometric deep learning,partial differential equations,physics informed machine learning},
  annotation = {Citations: 1 (Crossref) [2025-07-20]\\
Citations: 6 (SemanticScholar) [2025-07-20]}
}

@inproceedings{mehtaEffectsSpectralNormalization2023,
  title = {Effects of {{Spectral Normalization}} in {{Multi-Agent Reinforcement Learning}}},
  booktitle = {2023 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Mehta, Kinal and Mahajan, Anuj and Kumar, Pawan},
  year = {2023},
  month = jun,
  pages = {1--8},
  issn = {2161-4407},
  doi = {10.1109/IJCNN54540.2023.10191226},
  urldate = {2025-07-20},
  abstract = {A reliable critic is central to on-policy actor-critic learning. But it becomes challenging to learn a reliable critic in a multi-agent sparse reward scenario due to two factors: 1) The joint action space grows exponentially with the number of agents 2) This, combined with the reward sparseness and environment noise, leads to large sample requirements for accurate learning. We show that regularising the critic with spectral normalization (SN) enables it to learn more robustly, even in multi-agent on-policy sparse reward scenarios. Our experiments show that the regularised critic is quickly able to learn from the sparse rewarding experience in the complex SMAC and RWARE domains. These findings highlight the importance of regularisation in the critic for stable learning.},
  keywords = {MARL,Multi-Agent Reinforcement Learning,Neural networks,Optimization,Reinforcement learning,Reliability,Spectral Normalization},
  annotation = {Citations: 1 (Crossref) [2025-07-20]\\
Citations: 7 (SemanticScholar) [2025-07-20]},
  file = {/Users/t-krishdesai/Zotero/storage/PZHHZV84/Mehta et al. - 2023 - Effects of Spectral Normalization in Multi-Agent Reinforcement Learning.pdf;/Users/t-krishdesai/Zotero/storage/3ESGLC38/10191226.html}
}

@misc{meunierDynamicalSystemPerspective2022,
  title = {A {{Dynamical System Perspective}} for {{Lipschitz Neural Networks}}},
  author = {Meunier, Laurent and Delattre, Blaise and Araujo, Alexandre and Allauzen, Alexandre},
  year = {2022},
  month = feb,
  number = {arXiv:2110.12690},
  eprint = {2110.12690},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2110.12690},
  urldate = {2025-07-20},
  abstract = {The Lipschitz constant of neural networks has been established as a key quantity to enforce the robustness to adversarial examples. In this paper, we tackle the problem of building \$1\$-Lipschitz Neural Networks. By studying Residual Networks from a continuous time dynamical system perspective, we provide a generic method to build \$1\$-Lipschitz Neural Networks and show that some previous approaches are special cases of this framework. Then, we extend this reasoning and show that ResNet flows derived from convex potentials define \$1\$-Lipschitz transformations, that lead us to define the \{{\textbackslash}em Convex Potential Layer\} (CPL). A comprehensive set of experiments on several datasets demonstrates the scalability of our architecture and the benefits as an \${\textbackslash}ell\_2\$-provable defense against adversarial examples.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  annotation = {Citations: 56 (SemanticScholar) [2025-07-20]}
}

@misc{pazosUniversalUnfoldingDetector2024,
  title = {Towards {{Universal Unfolding}} of {{Detector Effects}} in {{High-Energy Physics}} Using {{Denoising Diffusion Probabilistic Models}}},
  author = {Pazos, Camila and Aeron, Shuchin and Beauchemin, Pierre-Hugues and Croft, Vincent and Huan, Zhengyan and Klassen, Martin and Wongjirad, Taritree},
  year = {2024},
  month = nov,
  number = {arXiv:2406.01507},
  eprint = {2406.01507},
  primaryclass = {physics},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.01507},
  urldate = {2025-07-20},
  abstract = {Correcting for detector effects in experimental data, particularly through unfolding, is critical for enabling precision measurements in high-energy physics. However, traditional unfolding methods face challenges in scalability, flexibility, and dependence on simulations. We introduce a novel approach to multidimensional object-wise unfolding using conditional Denoising Diffusion Probabilistic Models (cDDPM). Our method utilizes the cDDPM for a non-iterative, flexible posterior sampling approach, incorporating distribution moments as conditioning information, which exhibits a strong inductive bias that allows it to generalize to unseen physics processes without explicitly assuming the underlying distribution. Our results highlight the potential of this method as a step towards a "universal" unfolding tool that reduces dependence on truth-level assumptions, while enabling the unfolding of a wide range of measured distributions with improved adaptability and accuracy.},
  archiveprefix = {arXiv},
  keywords = {High Energy Physics - Experiment,High Energy Physics - Phenomenology,Physics - Data Analysis Statistics and Probability},
  annotation = {Citations: 1 (SemanticScholar) [2025-07-20]},
  file = {/Users/t-krishdesai/Zotero/storage/XXPQGBHB/Pazos et al. - 2024 - Towards Universal Unfolding of Detector Effects in High-Energy Physics using Denoising Diffusion Pro.pdf;/Users/t-krishdesai/Zotero/storage/5WYHZ4YG/2406.html}
}

@book{radonTheorieUndAnwendungen1913,
  title = {Theorie Und Anwendungen Der Absolut Additiven Mengenfunktionen ...},
  author = {Radon, Johann},
  year = {1913},
  publisher = {H{\"o}lder},
  address = {Wien},
  urldate = {2025-07-20},
  keywords = {authorities,http:,id.loc.gov,Integral equations,sh85067088,subjects}
}

@misc{roscaCaseNewNeural2021,
  title = {A Case for New Neural Network Smoothness Constraints},
  author = {Rosca, Mihaela and Weber, Theophane and Gretton, Arthur and Mohamed, Shakir},
  year = {2021},
  month = jul,
  number = {arXiv:2012.07969},
  eprint = {2012.07969},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2012.07969},
  urldate = {2025-07-20},
  abstract = {How sensitive should machine learning models be to input changes? We tackle the question of model smoothness and show that it is a useful inductive bias which aids generalization, adversarial robustness, generative modeling and reinforcement learning. We explore current methods of imposing smoothness constraints and observe they lack the flexibility to adapt to new tasks, they don't account for data modalities, they interact with losses, architectures and optimization in ways not yet fully understood. We conclude that new advances in the field are hinging on finding ways to incorporate data, tasks and learning into our definitions of smoothness.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {Citations: 50 (SemanticScholar) [2025-07-20]}
}

@misc{scamanLipschitzRegularityDeep2019,
  title = {Lipschitz Regularity of Deep Neural Networks: Analysis and Efficient Estimation},
  shorttitle = {Lipschitz Regularity of Deep Neural Networks},
  author = {Scaman, Kevin and Virmaux, Aladin},
  year = {2019},
  month = oct,
  number = {arXiv:1805.10965},
  eprint = {1805.10965},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1805.10965},
  urldate = {2025-07-20},
  abstract = {Deep neural networks are notorious for being sensitive to small well-chosen perturbations, and estimating the regularity of such architectures is of utmost importance for safe and robust practical applications. In this paper, we investigate one of the key characteristics to assess the regularity of such methods: the Lipschitz constant of deep learning architectures. First, we show that, even for two layer neural networks, the exact computation of this quantity is NP-hard and state-of-art methods may significantly overestimate it. Then, we both extend and improve previous estimation methods by providing AutoLip, the first generic algorithm for upper bounding the Lipschitz constant of any automatically differentiable function. We provide a power method algorithm working with automatic differentiation, allowing efficient computations even on large convolutions. Second, for sequential neural networks, we propose an improved algorithm named SeqLip that takes advantage of the linear computation graph to split the computation per pair of consecutive layers. Third we propose heuristics on SeqLip in order to tackle very large networks. Our experiments show that SeqLip can significantly improve on the existing upper bounds. Finally, we provide an implementation of AutoLip in the PyTorch environment that may be used to better estimate the robustness of a given neural network to small perturbations or regularize it using more precise Lipschitz estimations.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/t-krishdesai/Zotero/storage/38RLH8FA/Scaman and Virmaux - 2019 - Lipschitz regularity of deep neural networks analysis and efficient estimation.pdf;/Users/t-krishdesai/Zotero/storage/9NEUXAUB/1805.html}
}

@article{srivastavaDropoutSimpleWay2014,
  title = {Dropout: {{A Simple Way}} to {{Prevent Neural Networks}} from {{Overfitting}}},
  shorttitle = {Dropout},
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  year = {2014},
  journal = {Journal of Machine Learning Research},
  volume = {15},
  number = {56},
  pages = {1929--1958},
  issn = {1533-7928},
  urldate = {2025-07-20},
  abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different thinned networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
  keywords = {No DOI found},
  file = {/Users/t-krishdesai/Zotero/storage/ERJIT97R/Srivastava et al. - 2014 - Dropout A Simple Way to Prevent Neural Networks from Overfitting.pdf}
}

@article{stoneGeneralizedWeierstrassApproximation1948,
  title = {The {{Generalized Weierstrass Approximation Theorem}}},
  author = {Stone, M. H.},
  year = {1948},
  journal = {Mathematics Magazine},
  volume = {21},
  number = {4},
  eprint = {3029750},
  eprinttype = {jstor},
  pages = {167--184},
  publisher = {[Mathematical Association of America, Taylor \& Francis, Ltd.]},
  issn = {0025-570X},
  doi = {10.2307/3029750},
  urldate = {2025-07-19},
  annotation = {Citations: 231 (Crossref) [2025-07-19]}
}

@book{taylorMethodusIncrementorumDirecta1715,
  title = {{Methodus incrementorum directa \& inversa. Auctore Brook Taylor, LL. D. \& Regiae Societatis Secretario.}},
  author = {Taylor, Brook},
  year = {1715},
  publisher = {typis Pearsonianis: prostant apud Gul. Innys ad Insignia Principis in Coemeterio Paulino},
  address = {Londini},
  langid = {lat},
  keywords = {Calculus,Difference equations,Series Taylor's}
}

@article{unkeMachineLearningForce2021,
  title = {Machine {{Learning Force Fields}}},
  author = {Unke, Oliver T. and Chmiela, Stefan and Sauceda, Huziel E. and Gastegger, Michael and Poltavsky, Igor and Sch{\"u}tt, Kristof T. and Tkatchenko, Alexandre and M{\"u}ller, Klaus-Robert},
  year = {2021},
  month = aug,
  journal = {Chemical Reviews},
  volume = {121},
  number = {16},
  pages = {10142--10186},
  publisher = {American Chemical Society},
  issn = {0009-2665},
  doi = {10.1021/acs.chemrev.0c01111},
  urldate = {2025-07-20},
  abstract = {In recent years, the use of machine learning (ML) in computational chemistry has enabled numerous advances previously out of reach due to the computational complexity of traditional electronic-structure methods. One of the most promising applications is the construction of ML-based force fields (FFs), with the aim to narrow the gap between the accuracy of ab initio methods and the efficiency of classical FFs. The key idea is to learn the statistical relation between chemical structure and potential energy without relying on a preconceived notion of fixed chemical bonds or knowledge about the relevant interactions. Such universal ML approximations are in principle only limited by the quality and quantity of the reference data used to train them. This review gives an overview of applications of ML-FFs and the chemical insights that can be obtained from them. The core concepts underlying ML-FFs are described in detail, and a step-by-step guide for constructing and testing them from scratch is given. The text concludes with a discussion of the challenges that remain to be overcome by the next generation of ML-FFs.},
  annotation = {Citations: 970 (Crossref) [2025-07-20]\\
Citations: 940 (SemanticScholar) [2025-07-20]}
}

@book{weierstrassUeberAnalytischeDarstellbarkeit1885,
  title = {{{\"U}ber die analytische Darstellbarkeit sogenannter willk{\"u}rlicher Functionen einer reellen Ver{\"a}nderlichen}},
  author = {Weierstra{\ss}, Karl},
  year = {1885},
  series = {{Sitzungsberichte der Preussischen Akademie der Wissenschaften Jg. 1885, 34 ; Jg. 1885, 38}},
  publisher = {:},
  address = {Berlin},
  langid = {german},
  lccn = {-}
}

@misc{wiatrakStabilizingGenerativeAdversarial2020,
  title = {Stabilizing {{Generative Adversarial Networks}}: {{A Survey}}},
  shorttitle = {Stabilizing {{Generative Adversarial Networks}}},
  author = {Wiatrak, Maciej and Albrecht, Stefano V. and Nystrom, Andrew},
  year = {2020},
  month = mar,
  number = {arXiv:1910.00927},
  eprint = {1910.00927},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1910.00927},
  urldate = {2025-07-20},
  abstract = {Generative Adversarial Networks (GANs) are a type of generative model which have received much attention due to their ability to model complex real-world data. Despite their recent successes, the process of training GANs remains challenging, suffering from instability problems such as non-convergence, vanishing or exploding gradients, and mode collapse. In recent years, a diverse set of approaches have been proposed which focus on stabilizing the GAN training procedure. The purpose of this survey is to provide a comprehensive overview of the GAN training stabilization methods which can be found in the literature. We discuss the advantages and disadvantages of each approach, offer a comparative summary, and conclude with a discussion of open problems.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  annotation = {Citations: 88 (SemanticScholar) [2025-07-20]}
}
@article{alhroobSingleTopQuark,
  title = {Single Top Quark Production Cross Section Using the {{ATLAS}} Detector at the {{LHC}}},
  author = {Alhroob, Muhammad},
  doi = {10.22323/1.364.0658},
  langid = {english},
  file = {/Users/t-krishdesai/Zotero/storage/UM7XWRPH/Alhroob - Single top quark production cross section using the ATLAS detector at the LHC.pdf}
}

@article{ATLAS:2017dhr,
  title = {Measurement of Lepton Differential Distributions and the Top Quark Mass in \$\$t{\textbackslash}bar\{t\}\$\$production in Pp Collisions at \$\${\textbackslash}sqrt\{s\}=8\$\$~{{TeV}} with the {{ATLAS}} Detector},
  author = {Aaboud, M. and Aad, G. and Abbott, B. and Abdinov, O. and Abeloos, B. and Abidi, S. H. and AbouZeid, O. S. and Abraham, N. L. and Abramowicz, H. and Abreu, H. and Abreu, R. and Abulaiti, Y. and Acharya, B. S. and Adachi, S. and Adamczyk, L. and Adelman, J. and Adersberger, M. and Adye, T. and Affolder, A. A. and Afik, Y. and {Agatonovic-Jovin}, T. and Agheorghiesei, C. and {Aguilar-Saavedra}, J. A. and Ahlen, S. P. and Ahmadov, F. and Aielli, G. and Akatsuka, S. and Akerstedt, H. and {\AA}kesson, T. P. A. and Akilli, E. and Akimov, A. V. and Alberghi, G. L. and Albert, J. and Albicocco, P. and Alconada Verzini, M. J. and Alderweireldt, S. C. and Aleksa, M. and Aleksandrov, I. N. and Alexa, C. and Alexander, G. and Alexopoulos, T. and Alhroob, M. and Ali, B. and Aliev, M. and Alimonti, G. and Alison, J. and Alkire, S. P. and Allbrooke, B. M. M. and Allen, B. W. and Allport, P. P. and Aloisio, A. and Alonso, A. and Alonso, F. and Alpigiani, C. and Alshehri, A. A. and Alstaty, M. I. and Alvarez Gonzalez, B. and {\'A}lvarez Piqueras, D. and Alviggi, M. G. and Amadio, B. T. and Amaral Coutinho, Y. and Amelung, C. and Amidei, D. and Amor Dos Santos, S. P. and Amoroso, S. and Amundsen, G. and Anastopoulos, C. and Ancu, L. S. and Andari, N. and Andeen, T. and Anders, C. F. and Anders, J. K. and Anderson, K. J. and Andreazza, A. and Andrei, V. and Angelidakis, S. and Angelozzi, I. and Angerami, A. and Anisenkov, A. V. and Anjos, N. and Annovi, A. and Antel, C. and Antonelli, M. and Antonov, A. and Antrim, D. J. and Anulli, F. and Aoki, M. and Aperio Bella, L. and Arabidze, G. and Arai, Y. and Araque, J. P. and Araujo Ferraz, V. and Arce, A. T. H. and Ardell, R. E. and Arduh, F. A. and Arguin, J-F. and Argyropoulos, S. and Arik, M. and Armbruster, A. J. and Armitage, L. J. and Arnaez, O. and Arnold, H. and Arratia, M. and Arslan, O. and Artamonov, A. and Artoni, G. and Artz, S. and Asai, S. and Asbah, N. and Ashkenazi, A. and Asquith, L. and Assamagan, K. and Astalos, R. and Atkinson, M. and Atlay, N. B. and Augsten, K. and Avolio, G. and Axen, B. and Ayoub, M. K. and Azuelos, G. and Baas, A. E. and Baca, M. J. and Bachacou, H. and Bachas, K. and Backes, M. and Bagnaia, P. and Bahmani, M. and Bahrasemani, H. and Baines, J. T. and Bajic, M. and Baker, O. K. and Bakker, P. J. and Baldin, E. M. and Balek, P. and Balli, F. and Balunas, W. K. and Banas, E. and Bandyopadhyay, A. and Banerjee, {\relax Sw}. and Bannoura, A. A. E. and Barak, L. and Barberio, E. L. and Barberis, D. and Barbero, M. and Barillari, T. and Barisits, M-S and Barkeloo, J. T. and Barklow, T. and Barlow, N. and Barnes, S. L. and Barnett, B. M. and Barnett, R. M. and {Barnovska-Blenessy}, Z. and Baroncelli, A. and Barone, G. and Barr, A. J. and Barranco Navarro, L. and Barreiro, F. and {Barreiro Guimar{\~a}es da Costa}, J. and Bartoldus, R. and Barton, A. E. and Bartos, P. and Basalaev, A. and Bassalat, A. and Bates, R. L. and Batista, S. J. and Batley, J. R. and Battaglia, M. and Bauce, M. and Bauer, F. and Bawa, H. S. and Beacham, J. B. and Beattie, M. D. and Beau, T. and Beauchemin, P. H. and Bechtle, P. and Beck, H. P. and Beck, H. C. and Becker, K. and Becker, M. and Becot, C. and Beddall, A. J. and Beddall, A. and Bednyakov, V. A. and Bedognetti, M. and Bee, C. P. and Beermann, T. A. and Begalli, M. and Begel, M. and Behr, J. K. and Bell, A. S. and Bella, G. and Bellagamba, L. and Bellerive, A. and Bellomo, M. and Belotskiy, K. and Beltramello, O. and Belyaev, N. L. and Benary, O. and Benchekroun, D. and Bender, M. and Benekos, N. and Benhammou, Y. and Benhar Noccioli, E. and Benitez, J. and Benjamin, D. P. and Benoit, M. and Bensinger, J. R. and Bentvelsen, S. and Beresford, L. and Beretta, M. and Berge, D. and Bergeaas Kuutmann, E. and Berger, N. and Beringer, J. and Berlendis, S. and Bernard, N. R. and Bernardi, G. and Bernius, C. and Bernlochner, F. U. and Berry, T. and Berta, P. and Bertella, C. and Bertoli, G. and Bertram, I. A. and Bertsche, C. and Bertsche, D. and Besjes, G. J. and Bessidskaia Bylund, O. and Bessner, M. and Besson, N. and Bethani, A. and Bethke, S. and Betti, A. and Bevan, A. J. and Beyer, J. and Bianchi, R. M. and Biebel, O. and Biedermann, D. and Bielski, R. and Bierwagen, K. and Biesuz, N. V. and Biglietti, M. and Billoud, T. R. V. and Bilokon, H. and Bindi, M. and Bingul, A. and Bini, C. and Biondi, S. and Bisanz, T. and Bittrich, C. and Bjergaard, D. M. and Black, J. E. and Black, K. M. and Blair, R. E. and Blazek, T. and Bloch, I. and Blocker, C. and Blue, A. and Blumenschein, U. and Blunier, S. and Bobbink, G. J. and Bobrovnikov, V. S. and Bocchetta, S. S. and Bocci, A. and Bock, C. and Boehler, M. and Boerner, D. and Bogavac, D. and Bogdanchikov, A. G. and Bohm, C. and Boisvert, V. and Bokan, P. and Bold, T. and Boldyrev, A. S. and Bolz, A. E. and Bomben, M. and Bona, M. and Boonekamp, M. and Borisov, A. and Borissov, G. and Bortfeldt, J. and Bortoletto, D. and Bortolotto, V. and Boscherini, D. and Bosman, M. and Bossio Sola, J. D. and Boudreau, J. and {Bouhova-Thacker}, E. V. and Boumediene, D. and Bourdarios, C. and Boutle, S. K. and Boveia, A. and Boyd, J. and Boyko, I. R. and Bozson, A. J. and Bracinik, J. and Brandt, A. and Brandt, G. and Brandt, O.},
  year = {2017},
  month = nov,
  journal = {The European Physical Journal C},
  volume = {77},
  number = {11},
  eprint = {1709.09407},
  primaryclass = {hep-ex},
  pages = {804},
  issn = {1434-6052},
  doi = {10.1140/epjc/s10052-017-5349-9},
  urldate = {2025-07-19},
  abstract = {This paper presents single lepton and dilepton kinematic distributions measured in dileptonic \$t{\textbackslash}bar\{t\}\$ events produced in 20.2 fb\${\textasciicircum}\{-1\}\$ of \${\textbackslash}sqrt\{s\}=8\$ TeV \$pp\$ collisions recorded by the ATLAS experiment at the LHC. Both absolute and normalised differential cross-sections are measured, using events with an opposite-charge \$e{\textbackslash}mu\$ pair and one or two \$b\$-tagged jets. The cross-sections are measured in a fiducial region corresponding to the detector acceptance for leptons, and are compared to the predictions from a variety of Monte Carlo event generators, as well as fixed-order QCD calculations, exploring the sensitivity of the cross-sections to the gluon parton distribution function. Some of the distributions are also sensitive to the top quark pole mass; a combined fit of NLO fixed-order predictions to all the measured distributions yields a top quark mass value of \$m\_t{\textasciicircum}\{{\textbackslash}rm pole\}=173.2{\textbackslash}pm 0.9{\textbackslash}pm0.8{\textbackslash}pm1.2\$ GeV, where the three uncertainties arise from data statistics, experimental systematics, and theoretical sources.},
  archiveprefix = {arXiv},
  collaboration = {ATLAS},
  langid = {english},
  keywords = {Accelerator Physics,Experimental Nuclear Physics,Experimental Particle Physics,Nuclear and Particle Physics,Particle Physics,Theoretical Particle Physics},
  annotation = {95 citations (INSPIRE 2025/7/19)\\
34 citations w/o self (INSPIRE 2025/7/19)\\
Citations: 22 (Crossref) [2025-07-19]\\
Citations: 14 (SemanticScholar) [2025-07-19]}
}

@article{Benato:2025rgo,
  title = {Unbinned Inclusive Cross-Section Measurements with Machine-Learned Systematic Uncertainties},
  author = {Benato, Lisa and Giordano, Cristina and Krause, Claudius and Li, Ang and Sch{\"o}fbeck, Robert and Schwarz, Dennis and Shooshtari, Maryam and Wang, Daohan},
  year = {2025},
  month = may,
  eprint = {2505.05544},
  primaryclass = {hep-ph},
  doi = {10.48550/arXiv.2505.05544},
  urldate = {2025-07-19},
  abstract = {We introduce a novel methodology for addressing systematic uncertainties in unbinned inclusive cross-section measurements and related collider-based inference problems. Our approach incorporates known analytic dependencies on parameters of interest, including signal strengths and nuisance parameters. When these dependencies are unknown, as is frequently the case for systematic uncertainties, dedicated neural network parametrizations provide an approximation that is trained on simulated data. The resulting machine-learned surrogate captures the complete parameter dependence of the likelihood ratio, providing a near-optimal test statistic. As a case study, we perform a first-principles inclusive cross-section measurement of \${\textbackslash}textrm\{H\}{\textbackslash}rightarrow{\textbackslash}tau{\textbackslash}tau\$ in the single-lepton channel, utilizing simulated data from the FAIR Universe Higgs Uncertainty Challenge. Results in Asimov data, from large-scale toy studies, and using the Fisher information demonstrate significant improvements over traditional binned methods. Our computer code ``Guaranteed Optimal Log-Likelihood-based Unbinned Method'' (GOLLUM) for machine-learning and inference is publicly available.},
  archiveprefix = {arXiv},
  keywords = {High Energy Physics - Experiment,High Energy Physics - Phenomenology,Physics - Data Analysis Statistics and Probability},
  annotation = {0 citations (INSPIRE 2025/7/19)\\
0 citations w/o self (INSPIRE 2025/7/19)\\
Citations: 0 (SemanticScholar) [2025-07-19]}
}

@misc{chenCDEGANCooperativeDual2021,
  title = {{{CDE-GAN}}: {{Cooperative Dual Evolution Based Generative Adversarial Network}}},
  shorttitle = {{{CDE-GAN}}},
  author = {Chen, Shiming and Wang, Wenjie and Xia, Beihao and You, Xinge and Cao, Zehong and Ding, Weiping},
  year = {2021},
  month = mar,
  number = {arXiv:2008.09388},
  eprint = {2008.09388},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2008.09388},
  urldate = {2025-07-20},
  abstract = {Generative adversarial networks (GANs) have been a popular deep generative model for real-world applications. Despite many recent efforts on GANs that have been contributed, mode collapse and instability of GANs are still open problems caused by their adversarial optimization difficulties. In this paper, motivated by the cooperative co-evolutionary algorithm, we propose a Cooperative Dual Evolution based Generative Adversarial Network (CDE-GAN) to circumvent these drawbacks. In essence, CDE-GAN incorporates dual evolution with respect to the generator(s) and discriminators into a unified evolutionary adversarial framework to conduct effective adversarial multi-objective optimization. Thus it exploits the complementary properties and injects dual mutation diversity into training to steadily diversify the estimated density in capturing multi-modes and improve generative performance. Specifically, CDE-GAN decomposes the complex adversarial optimization problem into two subproblems (generation and discrimination), and each subproblem is solved with a separated subpopulation (E-Generator\vphantom\{\} and E-Discriminators), evolved by its own evolutionary algorithm. Additionally, we further propose a Soft Mechanism to balance the trade-off between E-Generators and E-Discriminators to conduct steady training for CDE-GAN. Extensive experiments on one synthetic dataset and three real-world benchmark image datasets demonstrate that the proposed CDE-GAN achieves a competitive and superior performance in generating good quality and diverse samples over baselines. The code and more generated results are available at our project homepage: https://shiming-chen.github.io/CDE-GAN-website/CDE-GAN.html.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  annotation = {Citations: 34 (SemanticScholar) [2025-07-20]},
  file = {/Users/t-krishdesai/Zotero/storage/VJILL6V9/Chen et al. - 2021 - CDE-GAN Cooperative Dual Evolution Based Generative Adversarial Network.pdf;/Users/t-krishdesai/Zotero/storage/C4M75J4U/2008.html}
}

@misc{cuiKnowledgeaugmentedDeepLearning2022,
  title = {Knowledge-Augmented {{Deep Learning}} and {{Its Applications}}: {{A Survey}}},
  shorttitle = {Knowledge-Augmented {{Deep Learning}} and {{Its Applications}}},
  author = {Cui, Zijun and Gao, Tian and Talamadupula, Kartik and Ji, Qiang},
  year = {2022},
  month = nov,
  number = {arXiv:2212.00017},
  eprint = {2212.00017},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2212.00017},
  urldate = {2025-07-20},
  abstract = {Deep learning models, though having achieved great success in many different fields over the past years, are usually data hungry, fail to perform well on unseen samples, and lack of interpretability. Various prior knowledge often exists in the target domain and their use can alleviate the deficiencies with deep learning. To better mimic the behavior of human brains, different advanced methods have been proposed to identify domain knowledge and integrate it into deep models for data-efficient, generalizable, and interpretable deep learning, which we refer to as knowledge-augmented deep learning (KADL). In this survey, we define the concept of KADL, and introduce its three major tasks, i.e., knowledge identification, knowledge representation, and knowledge integration. Different from existing surveys that are focused on a specific type of knowledge, we provide a broad and complete taxonomy of domain knowledge and its representations. Based on our taxonomy, we provide a systematic review of existing techniques, different from existing works that survey integration approaches agnostic to taxonomy of knowledge. This survey subsumes existing works and offers a bird's-eye view of research in the general area of knowledge-augmented deep learning. The thorough and critical reviews of numerous papers help not only understand current progresses but also identify future directions for the research on knowledge-augmented deep learning.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {Citations: 20 (SemanticScholar) [2025-07-20]},
  file = {/Users/t-krishdesai/Zotero/storage/9YJRKQUC/Cui et al. - 2022 - Knowledge-augmented Deep Learning and Its Applications A Survey.pdf;/Users/t-krishdesai/Zotero/storage/LVILUDTI/2212.html}
}

@misc{dangeloWhyWeNeed2024,
  title = {Why {{Do We Need Weight Decay}} in {{Modern Deep Learning}}?},
  author = {D'Angelo, Francesco and Andriushchenko, Maksym and Varre, Aditya and Flammarion, Nicolas},
  year = {2024},
  month = nov,
  number = {arXiv:2310.04415},
  eprint = {2310.04415},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.04415},
  urldate = {2025-07-20},
  abstract = {Weight decay is a broadly used technique for training state-of-the-art deep networks from image classification to large language models. Despite its widespread usage and being extensively studied in the classical literature, its role remains poorly understood for deep learning. In this work, we highlight that the role of weight decay in modern deep learning is different from its regularization effect studied in classical learning theory. For deep networks on vision tasks trained with multipass SGD, we show how weight decay modifies the optimization dynamics enhancing the ever-present implicit regularization of SGD via the loss stabilization mechanism. In contrast, for large language models trained with nearly one-epoch training, we describe how weight decay balances the bias-variance tradeoff in stochastic optimization leading to lower training loss and improved training stability. Overall, we present a unifying perspective from ResNets on vision tasks to LLMs: weight decay is never useful as an explicit regularizer but instead changes the training dynamics in a desirable way. The code is available at https://github.com/tml-epfl/why-weight-decay},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/t-krishdesai/Zotero/storage/7B2DYYW8/D'Angelo et al. - 2024 - Why Do We Need Weight Decay in Modern Deep Learning.pdf;/Users/t-krishdesai/Zotero/storage/4INPI8SX/2310.html}
}

@misc{delattreEfficientBoundLipschitz2023,
  title = {Efficient {{Bound}} of {{Lipschitz Constant}} for {{Convolutional Layers}} by {{Gram Iteration}}},
  author = {Delattre, Blaise and Barth{\'e}lemy, Quentin and Araujo, Alexandre and Allauzen, Alexandre},
  year = {2023},
  month = jun,
  number = {arXiv:2305.16173},
  eprint = {2305.16173},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.16173},
  urldate = {2025-07-20},
  abstract = {Since the control of the Lipschitz constant has a great impact on the training stability, generalization, and robustness of neural networks, the estimation of this value is nowadays a real scientific challenge. In this paper we introduce a precise, fast, and differentiable upper bound for the spectral norm of convolutional layers using circulant matrix theory and a new alternative to the Power iteration. Called the Gram iteration, our approach exhibits a superlinear convergence. First, we show through a comprehensive set of experiments that our approach outperforms other state-of-the-art methods in terms of precision, computational cost, and scalability. Then, it proves highly effective for the Lipschitz regularization of convolutional neural networks, with competitive results against concurrent approaches. Code is available at https://github.com/blaisedelattre/lip4conv.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {Citations: 13 (SemanticScholar) [2025-07-20]}
}

@misc{doanImageGenerationMinimizing2020,
  title = {Image {{Generation Via Minimizing Fr{\'e}chet Distance}} in {{Discriminator Feature Space}}},
  author = {Doan, Khoa D. and Manchanda, Saurav and Wang, Fengjiao and Keerthi, Sathiya and Bhowmik, Avradeep and Reddy, Chandan K.},
  year = {2020},
  month = mar,
  number = {arXiv:2003.11774},
  eprint = {2003.11774},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2003.11774},
  urldate = {2025-07-20},
  abstract = {For a given image generation problem, the intrinsic image manifold is often low dimensional. We use the intuition that it is much better to train the GAN generator by minimizing the distributional distance between real and generated images in a small dimensional feature space representing such a manifold than on the original pixel-space. We use the feature space of the GAN discriminator for such a representation. For distributional distance, we employ one of two choices: the Fr{\textbackslash}'\{e\}chet distance or direct optimal transport (OT); these respectively lead us to two new GAN methods: Fr{\textbackslash}'\{e\}chet-GAN and OT-GAN. The idea of employing Fr{\textbackslash}'\{e\}chet distance comes from the success of Fr{\textbackslash}'\{e\}chet Inception Distance as a solid evaluation metric in image generation. Fr{\textbackslash}'\{e\}chet-GAN is attractive in several ways. We propose an efficient, numerically stable approach to calculate the Fr{\textbackslash}'\{e\}chet distance and its gradient. The Fr{\textbackslash}'\{e\}chet distance estimation requires a significantly less computation time than OT; this allows Fr{\textbackslash}'\{e\}chet-GAN to use much larger mini-batch size in training than OT. More importantly, we conduct experiments on a number of benchmark datasets and show that Fr{\textbackslash}'\{e\}chet-GAN (in particular) and OT-GAN have significantly better image generation capabilities than the existing representative primal and dual GAN approaches based on the Wasserstein distance.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  annotation = {Citations: 6 (SemanticScholar) [2025-07-20]},
  file = {/Users/t-krishdesai/Zotero/storage/B3Z84QWL/Doan et al. - 2020 - Image Generation Via Minimizing Fréchet Distance in Discriminator Feature Space.pdf}
}

@article{doppDatadrivenScienceMachine2023,
  title = {Data-Driven Science and Machine Learning Methods in Laser--Plasma Physics},
  author = {D{\"o}pp, Andreas and Eberle, Christoph and Howard, Sunny and Irshad, Faran and Lin, Jinpu and Streeter, Matthew},
  year = {2023},
  month = jan,
  journal = {High Power Laser Science and Engineering},
  volume = {11},
  pages = {e55},
  issn = {2095-4719, 2052-3289},
  doi = {10.1017/hpl.2023.47},
  urldate = {2025-07-20},
  abstract = {Laser-plasma physics has developed rapidly over the past few decades as lasers have become both more powerful and more widely available. Early experimental and numerical research in this field was dominated by single-shot experiments with limited parameter exploration. However, recent technological improvements make it possible to gather data for hundreds or thousands of different settings in both experiments and simulations. This has sparked interest in using advanced techniques from mathematics, statistics and computer science to deal with, and benefit from, big data. At the same time, sophisticated modeling techniques also provide new ways for researchers to deal effectively with situation where still only sparse data are available. This paper aims to present an overview of relevant machine learning methods with focus on applicability to laser-plasma physics and its important sub-fields of laser-plasma acceleration and inertial confinement fusion.},
  langid = {english},
  keywords = {deep learning,laser-plasma interaction,machine learning},
  annotation = {Citations: 68 (Crossref) [2025-07-20]\\
Citations: 72 (SemanticScholar) [2025-07-20]}
}

@article{GomezAmbrosio:2022mpm,
  title = {Unbinned Multivariate Observables for Global {{SMEFT}} Analyses from Machine Learning},
  author = {Ambrosio, Raquel Gomez and {ter Hoeve}, Jaco and Madigan, Maeve and Rojo, Juan and Sanz, Veronica},
  year = {2023},
  month = mar,
  journal = {Journal of High Energy Physics},
  volume = {03},
  number = {3},
  eprint = {2211.02058},
  primaryclass = {hep-ph},
  pages = {033},
  issn = {1029-8479},
  doi = {10.1007/JHEP03(2023)033},
  urldate = {2025-07-19},
  abstract = {Theoretical interpretations of particle physics data, such as the determination of the Wilson coefficients of the Standard Model Effective Field Theory (SMEFT), often involve the inference of multiple parameters from a global dataset. Optimizing such interpretations requires the identification of observables that exhibit the highest possible sensitivity to the underlying theory parameters. In this work we develop a flexible open source framework, ML4EFT, enabling the integration of unbinned multivariate observables into global SMEFT fits. As compared to traditional measurements, such observables enhance the sensitivity to the theory parameters by preventing the information loss incurred when binning in a subset of final-state kinematic variables. Our strategy combines machine learning regression and classification techniques to parameterize high-dimensional likelihood ratios, using the Monte Carlo replica method to estimate and propagate methodological uncertainties. As a proof of concept we construct unbinned multivariate observables for top-quark pair and Higgs+\$Z\$ production at the LHC, demonstrate their impact on the SMEFT parameter space as compared to binned measurements, and study the improved constraints associated to multivariate inputs. Since the number of neural networks to be trained scales quadratically with the number of parameters and can be fully parallelized, the ML4EFT framework is well-suited to construct unbinned multivariate observables which depend on up to tens of EFT coefficients, as required in global fits.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Data-driven Science Modeling and Theory Building,Higgs Properties,Machine Learning,Model Theory,Particle Physics,SMEFT,String Theory,Theoretical Particle Physics},
  annotation = {26 citations (INSPIRE 2025/7/19)\\
18 citations w/o self (INSPIRE 2025/7/19)\\
Citations: 13 (Crossref) [2025-07-19]\\
Citations: 17 (SemanticScholar) [2025-07-19]}
}

@phdthesis{howardAdvancingParticlePhysics2022,
  title = {Advancing {{Particle Physics}} with {{Sophisticated Computational Frameworks}}},
  author = {Howard, Jessica Nicole},
  year = {2022},
  urldate = {2025-07-20},
  abstract = {The Standard Model (SM) of particle physics is one of the most complete mathematical models of physical phenomena to date. Even so, it cannot explain experimental results like the existence of particle dark matter and the fact that neutrino masses are non-zero. Explaining such results will necessitate developing a beyond the SM (BSM) theoretical description of particle physics. What form this BSM physics will take has become increasingly unclear; many elegant theories which were expected to appear in recent experiments have not emerged. Thus, we find ourselves at a cross-roads, in need of new perspectives and new computational frameworks to push our theoretical description of physics forward.New perspectives will come from challenging previously-held assumptions in the pursuit of fundamentally new descriptions, but challenging such assumptions often presents practical computational challenges. Therefore, these new perspectives must also be accompanied by new computational frameworks. Computational frameworks can come in many forms, from the purely mathematical to the largely numerical. In particular, in recent years machine learning (ML) has become an increasingly accessible and powerful computational tool for scientific applications. Crafting novel BSM theories will require us to investigate and embrace the full spectrum of computational frameworks. Additionally, one of the best ways to spark new insights is to closely collaborate with and draw inspiration from other fields, such as mathematics and computer science.In this thesis, we present two examples of how advanced computational frameworks can be used to aid in investigating new physics perspectives. In one example, we see how the purely mathematical framework of optimal transport (OT) theory can be used in tandem with advanced ML methods to enable a new perspective on particle physics simulations. The result is a novel strategy which lays the foundations for a completely data-driven, end-to-end simulation of particle collisions at the Large Hadron Collider. In a second example, we see work which considers a new perspective on what the history of our universe might have looked like. In particular, we consider how the abundance of a WIMP dark matter candidate could be altered by considering a phase of electroweak force confinement early in the universe. Considering this model while making relatively few assumptions was aided by the application of advanced numerical computational tools.We begin with both high-level and technical background on the topics relevant to these works. We conclude by discussing future directions for these works, as well as briefly giving general thoughts on strategies for applying the computational framework of ML to problems in theoretical particle physics more broadly.},
  langid = {english},
  school = {UC Irvine}
}

@article{Humble:2022vtm,
  title = {Snowmass {{White Paper}}: {{Quantum Computing Systems}} and {{Software}} for {{High-energy Physics Research}}},
  shorttitle = {Snowmass {{White Paper}}},
  author = {Humble, Travis S. and Delgado, Andrea and Pooser, Raphael and Seck, Christopher and Bennink, Ryan and {Leyton-Ortega}, Vicente and Wang, C.-C. Joseph and Dumitrescu, Eugene and Morris, Titus and Hamilton, Kathleen and Lyakh, Dmitry and Date, Prasanna and Wang, Yan and Peters, Nicholas A. and Evans, Katherine J. and Demarteau, Marcel and McCaskey, Alex and Nguyen, Thien and Clark, Susan and Reville, Melissa and Meglio, Alberto Di and Grossi, Michele and Vallecorsa, Sofia and Borras, Kerstin and Jansen, Karl and Kr{\"u}cker, Dirk},
  year = {2022},
  month = mar,
  eprint = {2203.07091},
  primaryclass = {quant-ph},
  doi = {10.48550/arXiv.2203.07091},
  urldate = {2025-07-20},
  abstract = {Quantum computing offers a new paradigm for advancing high-energy physics research by enabling novel methods for representing and reasoning about fundamental quantum mechanical phenomena. Realizing these ideals will require the development of novel computational tools for modeling and simulation, detection and classification, data analysis, and forecasting of high-energy physics (HEP) experiments. While the emerging hardware, software, and applications of quantum computing are exciting opportunities, significant gaps remain in integrating such techniques into the HEP community research programs. Here we identify both the challenges and opportunities for developing quantum computing systems and software to advance HEP discovery science. We describe opportunities for the focused development of algorithms, applications, software, hardware, and infrastructure to support both practical and theoretical applications of quantum computing to HEP problems within the next 10 years.},
  archiveprefix = {arXiv},
  keywords = {Quantum Physics},
  annotation = {21 citations (INSPIRE 2025/7/20)\\
17 citations w/o self (INSPIRE 2025/7/20)\\
Citations: 15 (SemanticScholar) [2025-07-20]},
  file = {/Users/t-krishdesai/Zotero/storage/9R4JNBFZ/Humble et al. - 2022 - Snowmass White Paper Quantum Computing Systems and Software for High-energy Physics Research.pdf;/Users/t-krishdesai/Zotero/storage/96I7PXHL/2203.html}
}

@article{lagraveEquivariantNeuralNetworks2022,
  title = {Equivariant {{Neural Networks}} and {{Differential Invariants Theory}} for {{Solving Partial Differential Equations}}},
  author = {Lagrave, Pierre-Yves and Tron, Eliot},
  year = {2022},
  journal = {Physical Sciences Forum},
  volume = {5},
  number = {1},
  pages = {13},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2673-9984},
  doi = {10.3390/psf2022005013},
  urldate = {2025-07-20},
  abstract = {This paper discusses the use of Equivariant Neural Networks (ENN) for solving Partial Differential Equations by exploiting their underlying symmetry groups. We first show that Group-Convolutionnal Neural Networks can be used to generalize Physics-Informed Neural Networks and then consider the use of ENN to approximate differential invariants of a given symmetry group, hence allowing to build symmetry-preserving Finite Difference methods without the need to formally derivate corresponding numerical invariantizations. The benefit of our approach is illustrated on the 2D heat equation through the instantiation of an SE(2) symmetry-preserving discretization.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {differential invariants,equivariant neural networks,geometric deep learning,partial differential equations,physics informed machine learning},
  annotation = {Citations: 1 (Crossref) [2025-07-20]\\
Citations: 6 (SemanticScholar) [2025-07-20]}
}

@inproceedings{mehtaEffectsSpectralNormalization2023,
  title = {Effects of {{Spectral Normalization}} in {{Multi-Agent Reinforcement Learning}}},
  booktitle = {2023 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Mehta, Kinal and Mahajan, Anuj and Kumar, Pawan},
  year = {2023},
  month = jun,
  pages = {1--8},
  issn = {2161-4407},
  doi = {10.1109/IJCNN54540.2023.10191226},
  urldate = {2025-07-20},
  abstract = {A reliable critic is central to on-policy actor-critic learning. But it becomes challenging to learn a reliable critic in a multi-agent sparse reward scenario due to two factors: 1) The joint action space grows exponentially with the number of agents 2) This, combined with the reward sparseness and environment noise, leads to large sample requirements for accurate learning. We show that regularising the critic with spectral normalization (SN) enables it to learn more robustly, even in multi-agent on-policy sparse reward scenarios. Our experiments show that the regularised critic is quickly able to learn from the sparse rewarding experience in the complex SMAC and RWARE domains. These findings highlight the importance of regularisation in the critic for stable learning.},
  keywords = {MARL,Multi-Agent Reinforcement Learning,Neural networks,Optimization,Reinforcement learning,Reliability,Spectral Normalization},
  annotation = {Citations: 1 (Crossref) [2025-07-20]\\
Citations: 7 (SemanticScholar) [2025-07-20]},
  file = {/Users/t-krishdesai/Zotero/storage/PZHHZV84/Mehta et al. - 2023 - Effects of Spectral Normalization in Multi-Agent Reinforcement Learning.pdf;/Users/t-krishdesai/Zotero/storage/3ESGLC38/10191226.html}
}

@misc{meunierDynamicalSystemPerspective2022,
  title = {A {{Dynamical System Perspective}} for {{Lipschitz Neural Networks}}},
  author = {Meunier, Laurent and Delattre, Blaise and Araujo, Alexandre and Allauzen, Alexandre},
  year = {2022},
  month = feb,
  number = {arXiv:2110.12690},
  eprint = {2110.12690},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2110.12690},
  urldate = {2025-07-20},
  abstract = {The Lipschitz constant of neural networks has been established as a key quantity to enforce the robustness to adversarial examples. In this paper, we tackle the problem of building \$1\$-Lipschitz Neural Networks. By studying Residual Networks from a continuous time dynamical system perspective, we provide a generic method to build \$1\$-Lipschitz Neural Networks and show that some previous approaches are special cases of this framework. Then, we extend this reasoning and show that ResNet flows derived from convex potentials define \$1\$-Lipschitz transformations, that lead us to define the \{{\textbackslash}em Convex Potential Layer\} (CPL). A comprehensive set of experiments on several datasets demonstrates the scalability of our architecture and the benefits as an \${\textbackslash}ell\_2\$-provable defense against adversarial examples.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  annotation = {Citations: 56 (SemanticScholar) [2025-07-20]}
}

@misc{pazosUniversalUnfoldingDetector2024,
  title = {Towards {{Universal Unfolding}} of {{Detector Effects}} in {{High-Energy Physics}} Using {{Denoising Diffusion Probabilistic Models}}},
  author = {Pazos, Camila and Aeron, Shuchin and Beauchemin, Pierre-Hugues and Croft, Vincent and Huan, Zhengyan and Klassen, Martin and Wongjirad, Taritree},
  year = {2024},
  month = nov,
  number = {arXiv:2406.01507},
  eprint = {2406.01507},
  primaryclass = {physics},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.01507},
  urldate = {2025-07-20},
  abstract = {Correcting for detector effects in experimental data, particularly through unfolding, is critical for enabling precision measurements in high-energy physics. However, traditional unfolding methods face challenges in scalability, flexibility, and dependence on simulations. We introduce a novel approach to multidimensional object-wise unfolding using conditional Denoising Diffusion Probabilistic Models (cDDPM). Our method utilizes the cDDPM for a non-iterative, flexible posterior sampling approach, incorporating distribution moments as conditioning information, which exhibits a strong inductive bias that allows it to generalize to unseen physics processes without explicitly assuming the underlying distribution. Our results highlight the potential of this method as a step towards a "universal" unfolding tool that reduces dependence on truth-level assumptions, while enabling the unfolding of a wide range of measured distributions with improved adaptability and accuracy.},
  archiveprefix = {arXiv},
  keywords = {High Energy Physics - Experiment,High Energy Physics - Phenomenology,Physics - Data Analysis Statistics and Probability},
  annotation = {Citations: 1 (SemanticScholar) [2025-07-20]},
  file = {/Users/t-krishdesai/Zotero/storage/XXPQGBHB/Pazos et al. - 2024 - Towards Universal Unfolding of Detector Effects in High-Energy Physics using Denoising Diffusion Pro.pdf;/Users/t-krishdesai/Zotero/storage/5WYHZ4YG/2406.html}
}

@book{radonTheorieUndAnwendungen1913,
  title = {Theorie Und Anwendungen Der Absolut Additiven Mengenfunktionen ...},
  author = {Radon, Johann},
  year = {1913},
  publisher = {H{\"o}lder},
  address = {Wien},
  urldate = {2025-07-20},
  keywords = {authorities,http:,id.loc.gov,Integral equations,sh85067088,subjects}
}

@misc{roscaCaseNewNeural2021,
  title = {A Case for New Neural Network Smoothness Constraints},
  author = {Rosca, Mihaela and Weber, Theophane and Gretton, Arthur and Mohamed, Shakir},
  year = {2021},
  month = jul,
  number = {arXiv:2012.07969},
  eprint = {2012.07969},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2012.07969},
  urldate = {2025-07-20},
  abstract = {How sensitive should machine learning models be to input changes? We tackle the question of model smoothness and show that it is a useful inductive bias which aids generalization, adversarial robustness, generative modeling and reinforcement learning. We explore current methods of imposing smoothness constraints and observe they lack the flexibility to adapt to new tasks, they don't account for data modalities, they interact with losses, architectures and optimization in ways not yet fully understood. We conclude that new advances in the field are hinging on finding ways to incorporate data, tasks and learning into our definitions of smoothness.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {Citations: 50 (SemanticScholar) [2025-07-20]}
}

@misc{scamanLipschitzRegularityDeep2019,
  title = {Lipschitz Regularity of Deep Neural Networks: Analysis and Efficient Estimation},
  shorttitle = {Lipschitz Regularity of Deep Neural Networks},
  author = {Scaman, Kevin and Virmaux, Aladin},
  year = {2019},
  month = oct,
  number = {arXiv:1805.10965},
  eprint = {1805.10965},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1805.10965},
  urldate = {2025-07-20},
  abstract = {Deep neural networks are notorious for being sensitive to small well-chosen perturbations, and estimating the regularity of such architectures is of utmost importance for safe and robust practical applications. In this paper, we investigate one of the key characteristics to assess the regularity of such methods: the Lipschitz constant of deep learning architectures. First, we show that, even for two layer neural networks, the exact computation of this quantity is NP-hard and state-of-art methods may significantly overestimate it. Then, we both extend and improve previous estimation methods by providing AutoLip, the first generic algorithm for upper bounding the Lipschitz constant of any automatically differentiable function. We provide a power method algorithm working with automatic differentiation, allowing efficient computations even on large convolutions. Second, for sequential neural networks, we propose an improved algorithm named SeqLip that takes advantage of the linear computation graph to split the computation per pair of consecutive layers. Third we propose heuristics on SeqLip in order to tackle very large networks. Our experiments show that SeqLip can significantly improve on the existing upper bounds. Finally, we provide an implementation of AutoLip in the PyTorch environment that may be used to better estimate the robustness of a given neural network to small perturbations or regularize it using more precise Lipschitz estimations.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/t-krishdesai/Zotero/storage/38RLH8FA/Scaman and Virmaux - 2019 - Lipschitz regularity of deep neural networks analysis and efficient estimation.pdf;/Users/t-krishdesai/Zotero/storage/9NEUXAUB/1805.html}
}

@article{srivastavaDropoutSimpleWay2014,
  title = {Dropout: {{A Simple Way}} to {{Prevent Neural Networks}} from {{Overfitting}}},
  shorttitle = {Dropout},
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  year = {2014},
  journal = {Journal of Machine Learning Research},
  volume = {15},
  number = {56},
  pages = {1929--1958},
  issn = {1533-7928},
  urldate = {2025-07-20},
  abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different thinned networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
  keywords = {No DOI found},
  file = {/Users/t-krishdesai/Zotero/storage/ERJIT97R/Srivastava et al. - 2014 - Dropout A Simple Way to Prevent Neural Networks from Overfitting.pdf}
}

@article{stoneGeneralizedWeierstrassApproximation1948,
  title = {The {{Generalized Weierstrass Approximation Theorem}}},
  author = {Stone, M. H.},
  year = {1948},
  journal = {Mathematics Magazine},
  volume = {21},
  number = {4},
  eprint = {3029750},
  eprinttype = {jstor},
  pages = {167--184},
  publisher = {[Mathematical Association of America, Taylor \& Francis, Ltd.]},
  issn = {0025-570X},
  doi = {10.2307/3029750},
  urldate = {2025-07-19},
  annotation = {Citations: 231 (Crossref) [2025-07-19]}
}

@book{taylorMethodusIncrementorumDirecta1715,
  title = {{Methodus incrementorum directa \& inversa. Auctore Brook Taylor, LL. D. \& Regiae Societatis Secretario.}},
  author = {Taylor, Brook},
  year = {1715},
  publisher = {typis Pearsonianis: prostant apud Gul. Innys ad Insignia Principis in Coemeterio Paulino},
  address = {Londini},
  langid = {lat},
  keywords = {Calculus,Difference equations,Series Taylor's}
}

@article{unkeMachineLearningForce2021,
  title = {Machine {{Learning Force Fields}}},
  author = {Unke, Oliver T. and Chmiela, Stefan and Sauceda, Huziel E. and Gastegger, Michael and Poltavsky, Igor and Sch{\"u}tt, Kristof T. and Tkatchenko, Alexandre and M{\"u}ller, Klaus-Robert},
  year = {2021},
  month = aug,
  journal = {Chemical Reviews},
  volume = {121},
  number = {16},
  pages = {10142--10186},
  publisher = {American Chemical Society},
  issn = {0009-2665},
  doi = {10.1021/acs.chemrev.0c01111},
  urldate = {2025-07-20},
  abstract = {In recent years, the use of machine learning (ML) in computational chemistry has enabled numerous advances previously out of reach due to the computational complexity of traditional electronic-structure methods. One of the most promising applications is the construction of ML-based force fields (FFs), with the aim to narrow the gap between the accuracy of ab initio methods and the efficiency of classical FFs. The key idea is to learn the statistical relation between chemical structure and potential energy without relying on a preconceived notion of fixed chemical bonds or knowledge about the relevant interactions. Such universal ML approximations are in principle only limited by the quality and quantity of the reference data used to train them. This review gives an overview of applications of ML-FFs and the chemical insights that can be obtained from them. The core concepts underlying ML-FFs are described in detail, and a step-by-step guide for constructing and testing them from scratch is given. The text concludes with a discussion of the challenges that remain to be overcome by the next generation of ML-FFs.},
  annotation = {Citations: 970 (Crossref) [2025-07-20]\\
Citations: 940 (SemanticScholar) [2025-07-20]}
}

@book{weierstrassUeberAnalytischeDarstellbarkeit1885,
  title = {{{\"U}ber die analytische Darstellbarkeit sogenannter willk{\"u}rlicher Functionen einer reellen Ver{\"a}nderlichen}},
  author = {Weierstra{\ss}, Karl},
  year = {1885},
  series = {{Sitzungsberichte der Preussischen Akademie der Wissenschaften Jg. 1885, 34 ; Jg. 1885, 38}},
  publisher = {:},
  address = {Berlin},
  langid = {german},
  lccn = {-}
}

@misc{wiatrakStabilizingGenerativeAdversarial2020,
  title = {Stabilizing {{Generative Adversarial Networks}}: {{A Survey}}},
  shorttitle = {Stabilizing {{Generative Adversarial Networks}}},
  author = {Wiatrak, Maciej and Albrecht, Stefano V. and Nystrom, Andrew},
  year = {2020},
  month = mar,
  number = {arXiv:1910.00927},
  eprint = {1910.00927},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1910.00927},
  urldate = {2025-07-20},
  abstract = {Generative Adversarial Networks (GANs) are a type of generative model which have received much attention due to their ability to model complex real-world data. Despite their recent successes, the process of training GANs remains challenging, suffering from instability problems such as non-convergence, vanishing or exploding gradients, and mode collapse. In recent years, a diverse set of approaches have been proposed which focus on stabilizing the GAN training procedure. The purpose of this survey is to provide a comprehensive overview of the GAN training stabilization methods which can be found in the literature. We discuss the advantages and disadvantages of each approach, offer a comparative summary, and conclude with a discussion of open problems.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  annotation = {Citations: 88 (SemanticScholar) [2025-07-20]}
}

@misc{xiaPenaltyGradientNormalization2023,
  title = {Penalty {{Gradient Normalization}} for {{Generative Adversarial Networks}}},
  author = {Xia, Tian},
  year = {2023},
  month = jun,
  number = {arXiv:2306.13576},
  eprint = {2306.13576},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2306.13576},
  urldate = {2025-07-20},
  abstract = {In this paper, we propose a novel normalization method called penalty gradient normalization (PGN) to tackle the training instability of Generative Adversarial Networks (GANs) caused by the sharp gradient space. Unlike existing work such as gradient penalty and spectral normalization, the proposed PGN only imposes a penalty gradient norm constraint on the discriminator function, which increases the capacity of the discriminator. Moreover, the proposed penalty gradient normalization can be applied to different GAN architectures with little modification. Extensive experiments on three datasets show that GANs trained with penalty gradient normalization outperform existing methods in terms of both Frechet Inception and Distance and Inception Score.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  annotation = {Citations: 1 (SemanticScholar) [2025-07-20]},
  file = {/Users/t-krishdesai/Zotero/storage/TEZEJGQF/Xia - 2023 - Penalty Gradient Normalization for Generative Adve.pdf;/Users/t-krishdesai/Zotero/storage/EKNMF62A/Xia - 2023 - Penalty Gradient Normalization for Generative Adve.html}
}


@misc{xiaPenaltyGradientNormalization2023,
  title = {Penalty {{Gradient Normalization}} for {{Generative Adversarial Networks}}},
  author = {Xia, Tian},
  year = {2023},
  month = jun,
  number = {arXiv:2306.13576},
  eprint = {2306.13576},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2306.13576},
  urldate = {2025-07-20},
  abstract = {In this paper, we propose a novel normalization method called penalty gradient normalization (PGN) to tackle the training instability of Generative Adversarial Networks (GANs) caused by the sharp gradient space. Unlike existing work such as gradient penalty and spectral normalization, the proposed PGN only imposes a penalty gradient norm constraint on the discriminator function, which increases the capacity of the discriminator. Moreover, the proposed penalty gradient normalization can be applied to different GAN architectures with little modification. Extensive experiments on three datasets show that GANs trained with penalty gradient normalization outperform existing methods in terms of both Frechet Inception and Distance and Inception Score.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  annotation = {Citations: 1 (SemanticScholar) [2025-07-20]},
  file = {/Users/t-krishdesai/Zotero/storage/TEZEJGQF/Xia - 2023 - Penalty Gradient Normalization for Generative Adve.pdf;/Users/t-krishdesai/Zotero/storage/EKNMF62A/Xia - 2023 - Penalty Gradient Normalization for Generative Adve.html}
}

@article{Grosso:2024nho,
    author = "Grosso, Gaia",
    title = "{Anomaly-aware summary statistic from data batches}",
    eprint = "2407.01249",
    archivePrefix = "arXiv",
    primaryClass = "hep-ex",
    doi = "10.1007/JHEP12(2024)093",
    journal = "JHEP",
    volume = "12",
    pages = "093",
    year = "2024"
}
@article{Brehmer:2018hga,
    author = "Brehmer, Johann and Louppe, Gilles and Pavez, Juan and Cranmer, Kyle",
    title = "{Mining gold from implicit models to improve likelihood-free inference}",
    eprint = "1805.12244",
    archivePrefix = "arXiv",
    primaryClass = "stat.ML",
    doi = "10.1073/pnas.1915980117",
    journal = "Proc. Nat. Acad. Sci.",
    volume = "117",
    number = "10",
    pages = "5242--5249",
    year = "2020"
}
@article{Li2022MomentsPhysics,
    title = {{Moments for positivity: using Drell-Yan data to test positivity bounds and reverse-engineer new physics}},
    year = {2022},
    journal = {Journal of High Energy Physics},
    author = {Li, Xu and Mimasu, Ken and Yamashita, Kimiko and Yang, Chengjie and Zhang, Cen and Zhou, Shuang-Yong},
    number = {10},
    month = {10},
    volume = {2022},
    publisher = {Springer Science and Business Media Deutschland GmbH},
    url = {http://arxiv.org/abs/2204.13121 http://dx.doi.org/10.1007/JHEP10(2022)107},
    doi = {10.1007/JHEP10(2022)107},
    arxivId = {2204.13121v2},
    keywords = {SMEFT, Specific BSM Phenomenology}
}
@article{Metodiev2024AnomalyObservables,
    title = {{Anomaly detection in collider physics via factorized observables}},
    year = {2024},
    journal = {Physical Review D},
    author = {Metodiev, Eric M. and Thaler, Jesse and Wynne, Raymond},
    number = {5},
    month = {9},
    pages = {055012},
    volume = {110},
    publisher = {American Physical Society},
    url = {https://journals.aps.org/prd/abstract/10.1103/PhysRevD.110.055012},
    doi = {10.1103/PHYSREVD.110.055012/SUPPLEMENTAL.PDF},
    issn = {24700029},
    arxivId = {2312.00119},
    keywords = {doi:10.1103/PhysRevD.110.055012 url:https://doi.org/10.1103/PhysRevD.110.055012}
}
@article{Romao2021FindingColliders,
    title = {{Finding New Physics without learning about it: Anomaly Detection as a tool for Searches at Colliders}},
    year = {2021},
    journal = {European Physical Journal C},
    author = {Romao, M. Crispim and Castro, N. F. and Pedro, R.},
    number = {1},
    month = {11},
    volume = {81},
    publisher = {Springer Science and Business Media Deutschland GmbH},
    url = {http://arxiv.org/abs/2006.05432 http://dx.doi.org/10.1140/epjc/s10052-020-08807-w},
    doi = {10.1140/epjc/s10052-020-08807-w},
    arxivId = {2006.05432v3}
}
@article{Boltzmann1978AbleitungLichttheorie,
    title = {{Ableitung des Stefanschen Gesetzes, 1) betreffend die Abh{\"{a}}ngigkeit der W{\"{a}}rmestrahlung von der Temperatur aus der elektromagnetischen Lichttheorie}},
    year = {1978},
    journal = {Von Kirchhoff bis Planck},
    author = {Boltzmann, Ludwig},
    pages = {152--156},
    publisher = {Vieweg+Teubner Verlag, Wiesbaden},
    url = {https://link.springer.com/chapter/10.1007/978-3-663-13885-3_11},
    isbn = {978-3-663-13885-3},
    doi = {10.1007/978-3-663-13885-3{\_}11}
}
@article{Sharp2015Translation1909,
    title = {{Translation of Ludwig Boltzmann’s Paper “On the Relationship between the Second Fundamental Theorem of the Mechanical Theory of Heat and Probability Calculations Regarding the Conditions for Thermal Equilibrium” Sitzungberichte der Kaiserlichen Akademie der Wissenschaften. Mathematisch-Naturwissen Classe. Abt. II, LXXVI 1877, pp 373-435 (Wien. Ber. 1877, 76:373-435). Reprinted in Wiss. Abhandlungen, Vol. II, reprint 42, p. 164-223, Barth, Leipzig, 1909}},
    year = {2015},
    journal = {Entropy 2015, Vol. 17, Pages 1971-2009},
    author = {Sharp, Kim and Matschinsky, Franz},
    number = {4},
    month = {4},
    pages = {1971--2009},
    volume = {17},
    publisher = {Multidisciplinary Digital Publishing Institute},
    url = {https://www.mdpi.com/1099-4300/17/4/1971/htm https://www.mdpi.com/1099-4300/17/4/1971},
    doi = {10.3390/E17041971},
    issn = {1099-4300},
    keywords = {Ludwig Boltzmann, entropy, second law of thermodynamics}
}
@article{Lee2022BigVGAN:Training,
    title = {{BigVGAN: A Universal Neural Vocoder with Large-Scale Training}},
    year = {2022},
    journal = {11th International Conference on Learning Representations, ICLR 2023},
    author = {Lee, Sang Gil and Ping, Wei and Ginsburg, Boris and Catanzaro, Bryan and Yoon, Sungroh},
    month = {6},
    publisher = {International Conference on Learning Representations, ICLR},
    url = {https://arxiv.org/pdf/2206.04658},
    arxivId = {2206.04658}
}
@article{Householder1941ALemmas,
    title = {{A theory of steady-state activity in nerve-fiber networks: I. Definitions and preliminary lemmas}},
    year = {1941},
    journal = {The Bulletin of Mathematical Biophysics},
    author = {Householder, Alston S.},
    number = {2},
    month = {6},
    pages = {63--69},
    volume = {3},
    publisher = {Kluwer Academic Publishers},
    url = {https://link.springer.com/article/10.1007/BF02478220},
    doi = {10.1007/BF02478220/METRICS},
    issn = {00074985},
    keywords = {Cell Biology, Life Sciences, Mathematical and Computational Biology, general}
}
@article{Stoye2018Likelihood-freeEstimator,
    title = {{Likelihood-free inference with an improved cross-entropy estimator}},
    year = {2018},
    author = {Stoye, Markus and Brehmer, Johann and Louppe, Gilles and Pavez, Juan and Cranmer, Kyle},
    month = {8},
    url = {https://arxiv.org/pdf/1808.00973},
    arxivId = {1808.00973}
}
@article{Ioffe2015BatchShift,
    title = {{Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift}},
    year = {2015},
    journal = {32nd International Conference on Machine Learning, ICML 2015},
    author = {Ioffe, Sergey and Szegedy, Christian},
    month = {2},
    pages = {448--456},
    volume = {1},
    publisher = {International Machine Learning Society (IMLS)},
    url = {https://arxiv.org/pdf/1502.03167},
    isbn = {9781510810587},
    arxivId = {1502.03167},
    keywords = {()}
}
@article{Abadi2016TensorFlow:Learning,
    title = {{TensorFlow: A system for large-scale machine learning}},
    year = {2016},
    journal = {Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2016},
    author = {Abadi, Martín and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
    month = {5},
    pages = {265--283},
    publisher = {USENIX Association},
    url = {https://arxiv.org/pdf/1605.08695},
    isbn = {9781931971331},
    arxivId = {1605.08695}
}
@article{Harris2020ArrayNumPy,
    title = {{Array programming with NumPy}},
    year = {2020},
    journal = {Nature 2020 585:7825},
    author = {Harris, Charles R. and Millman, K. Jarrod and van der Walt, Stéfan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and del R{\'{i}}o, Jaime Fernández and Wiebe, Mark and Peterson, Pearu and G{\'{e}}rard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
    number = {7825},
    month = {9},
    pages = {357--362},
    volume = {585},
    publisher = {Nature Publishing Group},
    url = {https://www.nature.com/articles/s41586-020-2649-2},
    doi = {10.1038/s41586-020-2649-2},
    issn = {1476-4687},
    pmid = {32939066},
    arxivId = {2006.10256},
    keywords = {Computational neuroscience, Computational science, Computer science, Software, Solar physics}
}
@article{Hunter2007Matplotlib:Environment,
    title = {{Matplotlib: A 2D graphics environment}},
    year = {2007},
    journal = {Computing in Science and Engineering},
    author = {Hunter, John D.},
    number = {3},
    pages = {90--95},
    volume = {9},
    publisher = {IEEE Computer Society},
    doi = {10.1109/MCSE.2007.55},
    issn = {15219615}
}
@misc{HEP-GAN/MomentUnfolding:Method,
    title = {{HEP-GAN/MomentUnfolding: Deconvoluting the statistical moments of collider data using a GAN like method}},
    url = {https://github.com/HEP-GAN/MomentUnfolding}
}
@article{AndreassenPythia/HerwigUnfolding,
    title = {{Pythia/Herwig + Delphes Jet Datasets for OmniFold Unfolding}},
    author = {Andreassen, Anders and Komiske, Patrick and Metodiev, Eric and Nachman, Benjamin and Thaler, Jesse},
    url = {https://zenodo.org/records/3548091},
    doi = {10.5281/ZENODO.3548091},
    keywords = {delphes, energyflow, herwig, jet, omnifold, pythia, unfolding}
}
@article{Krohn2013JetLHC,
    title = {{Jet charge at the LHC}},
    year = {2013},
    journal = {Physical Review Letters},
    author = {Krohn, David and Schwartz, Matthew D. and Lin, Tongyan and Waalewijn, Wouter J.},
    number = {21},
    month = {5},
    volume = {110},
    doi = {10.1103/PHYSREVLETT.110.212001},
    issn = {00319007}
}
@article{Waalewijn2012CalculatingJet,
    title = {{Calculating the charge of a jet}},
    year = {2012},
    journal = {Physical Review D - Particles, Fields, Gravitation and Cosmology},
    author = {Waalewijn, Wouter J.},
    number = {9},
    month = {11},
    volume = {86},
    doi = {10.1103/PHYSREVD.86.094030},
    issn = {15507998}
}
@article{Li2020JetMatter,
    title = {{Jet charge modification in finite QCD matter}},
    year = {2020},
    journal = {Physical Review D},
    author = {Li, Hai Tao and Vitev, Ivan},
    number = {7},
    month = {4},
    volume = {101},
    publisher = {American Physical Society},
    doi = {10.1103/PHYSREVD.101.076020},
    issn = {24700029},
    arxivId = {1908.06979}
}
@article{Kang2020JetCollider,
    title = {{Jet Charge: A Flavor Prism for Spin Asymmetries at the Electron-Ion Collider}},
    year = {2020},
    journal = {Physical Review Letters},
    author = {Kang, Zhong Bo and Liu, Xiaohui and Mantry, Sonny and Shao, Ding Yu},
    number = {24},
    month = {12},
    volume = {125},
    publisher = {American Physical Society},
    doi = {10.1103/PHYSREVLETT.125.242003},
    issn = {10797114},
    pmid = {33412017}
}
@article{Larkoski:2015lea,
    title = {Sudakov {Safety} in {Perturbative} {QCD}},
    volume = {91},
    issn = {1550-7998, 1550-2368},
    url = {http://arxiv.org/abs/1502.01719},
    doi = {10.1103/PhysRevD.91.111501},
    abstract = {Traditional calculations in perturbative quantum chromodynamics (pQCD) are based on an order-by-order expansion in the strong coupling \${\textbackslash}alpha\_s\$. Observables that are calculable in this way are known as "safe". Recently, a class of unsafe observables was discovered that do not have a valid \${\textbackslash}alpha\_s\$ expansion but are nevertheless calculable in pQCD using all-orders resummation. These observables are called "Sudakov safe" since singularities at each \${\textbackslash}alpha\_s\$ order are regulated by an all-orders Sudakov form factor. In this letter, we give a concrete definition of Sudakov safety based on conditional probability distributions, and we study a one-parameter family of momentum sharing observables that interpolate between the safe and unsafe regimes. The boundary between these regimes is particularly interesting, as the resulting distribution can be understood as the ultraviolet fixed point of a generalized fragmentation function, yielding a leading behavior that is independent of \${\textbackslash}alpha\_s\$.},
    number = {11},
    urldate = {2025-07-19},
    journal = {Physical Review D},
    author = {Larkoski, Andrew J. and Marzani, Simone and Thaler, Jesse},
    month = jun,
    year = {2015},
    note = {168 citations (INSPIRE 2025/7/19)
124 citations w/o self (INSPIRE 2025/7/19)
arXiv:1502.01719 [hep-ph]
Citations: 92 (Crossref) [2025-07-19]
Citations: 159 (SemanticScholar) [2025-07-19]},
    keywords = {High Energy Physics - Phenomenology, High Energy Physics - Theory},
    pages = {111501},
}
@article{ALargeIonColliderExperiment:2021mqf,
    title = {Measurement of the groomed jet radius and momentum splitting fraction in pp and {Pb}\$-\${Pb} collisions at \${\textbackslash}sqrt\{s\_\{{\textbackslash}rm {NN}\}\} = 5.02\$ {TeV}},
    volume = {128},
    issn = {0031-9007, 1079-7114},
    url = {http://arxiv.org/abs/2107.12984},
    doi = {10.1103/PhysRevLett.128.102001},
    abstract = {This article presents groomed jet substructure measurements in pp and Pb\$-\$Pb collisions at \${\textbackslash}sqrt\{s\_\{{\textbackslash}rm NN\}\} = 5.02\$ TeV with the ALICE detector. The Soft Drop grooming algorithm provides access to the hard parton splittings inside a jet by removing soft wide-angle radiation. We report the groomed jet momentum splitting fraction, \$z\_\{{\textbackslash}rm g\}\$, and the (scaled) groomed jet radius, \${\textbackslash}theta\_\{{\textbackslash}rm g\}\$. Charged-particle jets are reconstructed at midrapidity using the anti-kT algorithm with resolution parameters \$R = 0.2\$ and \$R = 0.4\$. In heavy-ion collisions, the large underlying event poses a challenge for the reconstruction of groomed jet observables, since fluctuations in the background can cause groomed parton splittings to be misidentified. By using strong grooming conditions to reduce this background, we report these observables fully corrected for detector effects and background fluctuations for the first time. A narrowing of the \${\textbackslash}theta\_\{{\textbackslash}rm g\}\$ distribution in Pb\$-\$Pb collisions compared to pp collisions is seen, which provides direct evidence of the modification of the angular structure of jets in the quark\$-\$gluon plasma. No significant modification of the \$z\_\{{\textbackslash}rm g\}\$ distribution in Pb\$-\$Pb collisions compared to pp collisions is observed. These results are compared with a variety of theoretical models of jet quenching, and provide constraints on jet energy-loss mechanisms and coherence effects in the quark\$-\$gluon plasma.},
    number = {10},
    urldate = {2025-07-19},
    journal = {Physical Review Letters},
    author = {Collaboration, ALICE},
    month = mar,
    year = {2022},
    note = {105 citations (INSPIRE 2025/7/19)
45 citations w/o self (INSPIRE 2025/7/19)
arXiv:2107.12984 [nucl-ex]
Citations: 32 (Crossref) [2025-07-19]
Citations: 38 (SemanticScholar) [2025-07-19]
tex.collaboration: A Large Ion Collider Experiment, ALICE},
    keywords = {High Energy Physics - Experiment, Nuclear Experiment},
    pages = {102001},
}
@article{Kang:2023ptt,
    title = {Towards a {Nonperturbative} {Formulation} of the {Jet} {Charge}},
    volume = {130},
    issn = {0031-9007, 1079-7114},
    url = {https://link.aps.org/doi/10.1103/PhysRevLett.130.151901},
    doi = {10.1103/PhysRevLett.130.151901},
    abstract = {The jet charge is an old observable that has proven uniquely useful for discrimination of jets initiated by different flavors of light quarks, for example. In this Letter, we propose an approach to understanding the jet charge by establishing simple, robust assumptions that hold to good approximation non-perturbatively, such as isospin conservation and large particle multiplicity in the jets, forgoing any attempt at a perturbative analysis. From these assumptions, the jet charge distribution with fixed particle multiplicity takes the form of a Gaussian by the central limit theorem and whose mean and variance are related to fractional-power moments of single particle energy distributions. These results make several concrete predictions for the scaling of the jet charge with the multiplicity, explaining many of the results already in the literature, and new results we validate in Monte Carlo simulation.},
    language = {en},
    number = {15},
    urldate = {2025-07-19},
    journal = {Physical Review Letters},
    author = {Kang, Zhong-Bo and Larkoski, Andrew J. and Yang, Jinghong},
    month = apr,
    year = {2023},
    note = {15 citations (INSPIRE 2025/7/19)
8 citations w/o self (INSPIRE 2025/7/19)
Citations: 9 (Crossref) [2025-07-19]
Citations: 8 (SemanticScholar) [2025-07-19]
arXiv:2301.09649 [hep-ph]},
    pages = {151901},
}
@article{ParticleDataGroup:2020ssz,
    title = {Review of {Particle} {Physics}},
    volume = {2020},
    issn = {2050-3911},
    url = {https://doi.org/10.1093/ptep/ptaa104},
    doi = {10.1093/ptep/ptaa104},
    abstract = {The Review summarizes much of particle physics and cosmology. Using data from previous editions, plus 3,324 new measurements from 878 papers, we list, evaluate, and average measured properties of gauge bosons and the recently discovered Higgs boson, leptons, quarks, mesons, and baryons. We summarize searches for hypothetical particles such as supersymmetric particles, heavy bosons, axions, dark photons, etc. Particle properties and search limits are listed in Summary Tables. We give numerous tables, figures, formulae, and reviews of topics such as Higgs Boson Physics, Supersymmetry, Grand Unified Theories, Neutrino Mixing, Dark Energy, Dark Matter, Cosmology, Particle Detectors, Colliders, Probability and Statistics. Among the 120 reviews are many that are new or heavily revised, including a new review on High Energy Soft QCD and Diffraction and one on the Determination of CKM Angles from B Hadrons.},
    number = {8},
    urldate = {2025-07-19},
    journal = {Progress of Theoretical and Experimental Physics},
    author = {Zyla, P.A. and Barnett, R.M. and Beringer, J. and {others}},
    month = aug,
    year = {2020},
    note = {6408 citations (INSPIRE 2025/7/19)
5475 citations w/o self (INSPIRE 2025/7/19)
Citations: 3502 (Crossref) [2025-07-19]
Citations: 2800 (SemanticScholar) [2025-07-19]
tex.collaboration: Particle Data Group},
    pages = {083C01},
}
@article{Czakon:2021mjy,
    title = {Next-to-{Next}-to-{Leading} {Order} {Study} of {Three}-{Jet} {Production} at the {LHC}},
    volume = {127},
    url = {https://link.aps.org/doi/10.1103/PhysRevLett.127.152001},
    doi = {10.1103/PhysRevLett.127.152001},
    abstract = {Multi-jet rates at hadron colliders provide a unique possibility for probing Quantum Chromodynamics (QCD), the theory of strong interactions. By comparing theory predictions with collider data, one can directly test perturbative QCD, extract fundamental parameters like the strong coupling \${\textbackslash}alpha\_s\$ and search for physics beyond the Standard Model. In this work we calculate, for the first time, the next-to-next-to-leading (NNLO) QCD corrections to typical three-jet observables and to differential three-to-two jet ratios. We demonstrate that the inclusion of the NNLO corrections significantly reduces the dependence of those observables on the factorization and renormalization scales. Besides its phenomenological value, this proof-of-principle computation represents a milestone in perturbative QCD.},
    number = {15},
    urldate = {2025-07-19},
    journal = {Physical Review Letters},
    author = {Czakon, Michał and Mitov, Alexander and Poncelet, Rene},
    month = oct,
    year = {2021},
    note = {114 citations (INSPIRE 2025/7/19)
102 citations w/o self (INSPIRE 2025/7/19)
Publisher: American Physical Society
arXiv:2106.05331 [hep-ph]},
    pages = {152001},
}
@article{CMS:2019fak,
    title = {Measurement of the {Jet} {Mass} {Distribution} and {Top} {Quark} {Mass} in {Hadronic} {Decays} of {Boosted} {Top} {Quarks} in \$pp\$ {Collisions} at \${\textbackslash}sqrt\{s\}=13{\textbackslash}text\{ \}{\textbackslash}text\{ \}{\textbackslash}mathrm\{{TeV}\}\$},
    volume = {124},
    url = {https://link.aps.org/doi/10.1103/PhysRevLett.124.202001},
    doi = {10.1103/PhysRevLett.124.202001},
    abstract = {A measurement is reported of the jet mass distribution in hadronic decays of boosted top quarks produced in pp collisions at \${\textbackslash}sqrt\{s\} =\$ 13 TeV. The data were collected with the CMS detector at the LHC and correspond to an integrated luminosity of 35.9 fb\${\textasciicircum}\{-1\}\$. The measurement is performed in the lepton+jets channel of \${\textbackslash}mathrm\{t{\textbackslash}bar\{t\}\}\$ events, where the lepton is an electron or muon. The products of the hadronic top quark decay t \${\textbackslash}to\$ bW \${\textbackslash}to\$ bq\${\textbackslash}mathrm\{{\textbackslash}bar\{q\}\}'\$ are reconstructed as a single jet with transverse momentum larger than 400 GeV. The \${\textbackslash}mathrm\{t{\textbackslash}bar\{t\}\}\$ cross section as a function of the jet mass is unfolded at the particle level and used to extract a value of the top quark mass of 172.6 \${\textbackslash}pm\$ 2.5 GeV. A novel jet reconstruction technique is used for the first time at the LHC, which improves the precision by a factor of three relative to an earlier measurement. This highlights the potential of measurements using boosted top quarks, where the new technique will enable future precision measurements.},
    number = {20},
    urldate = {2025-07-19},
    journal = {Physical Review Letters},
    author = {Sirunyan, Albert M and Tumasyan, Armen and Adam, Wolfgang and {others}},
    month = may,
    year = {2020},
    note = {68 citations (INSPIRE 2025/7/19)
22 citations w/o self (INSPIRE 2025/7/19)
Publisher: American Physical Society
Citations: 16 (Crossref) [2025-07-19]
Citations: 16 (SemanticScholar) [2025-07-19]
arXiv:1911.03800 [hep-ex]
tex.collaboration: CMS},
    pages = {202001},
}
@article{ALICE:2020pga,
    title = {Jet fragmentation transverse momentum distributions in pp and p-{Pb} collisions at \${\textbackslash}sqrt\{s\_\{{\textbackslash}rm {NN}\}\}\$ = 5.02 {TeV}},
    volume = {09},
    issn = {1029-8479},
    url = {http://arxiv.org/abs/2011.05904},
    doi = {10.1007/JHEP09(2021)211},
    abstract = {Jet fragmentation transverse momentum (\$j\_\{{\textbackslash}rm T\}\$) distributions are measured in proton-proton (pp) and proton-lead (p-Pb) collisions at \${\textbackslash}sqrt\{s\_\{{\textbackslash}rm NN\}\}\$ = 5.02 TeV with the ALICE experiment at the LHC. Jets are reconstructed with the ALICE tracking detectors and electromagnetic calorimeter using the anti-\$k\_\{{\textbackslash}rm T\}\$ algorithm with resolution parameter \$R=0.4\$ in the pseudorapidity range \${\textbar}{\textbackslash}eta{\textbar}{\textless}0.25\$. The \$j\_\{{\textbackslash}rm T\}\$ values are calculated for charged particles inside a fixed cone with a radius \$R = 0.4\$ around the reconstructed jet axis. The measured \$j\_\{{\textbackslash}rm T\}\$ distributions are compared with a variety of parton-shower models. Herwig and PYTHIA 8 based models describe the data well for the higher \$j\_\{{\textbackslash}rm T\}\$ region, while they underestimate the lower \$j\_\{{\textbackslash}rm T\}\$ region. The \$j\_\{{\textbackslash}rm T\}\$ distributions are further characterised by fitting them with a function composed of an inverse gamma function for higher \$j\_\{{\textbackslash}rm T\}\$ values (called the "wide component"), related to the perturbative component of the fragmentation process, and with a Gaussian for lower \$j\_\{{\textbackslash}rm T\}\$ values (called the "narrow component"), predominantly connected to the hadronisation process. The width of the Gaussian has only a weak dependence on jet transverse momentum, while that of the inverse gamma function increases with increasing jet transverse momentum. For the narrow component, the measured trends are successfully described by all models except for Herwig. For the wide component, Herwig and PYTHIA 8 based models slightly underestimate the data for the higher jet transverse momentum region. These measurements set constraints on models of jet fragmentation and hadronisation.},
    number = {9},
    urldate = {2025-07-19},
    journal = {Journal of High Energy Physics},
    author = {Collaboration, ALICE},
    month = sep,
    year = {2021},
    note = {11 citations (INSPIRE 2025/7/19)
3 citations w/o self (INSPIRE 2025/7/19)
arXiv:2011.05904 [nucl-ex]
Citations: 5 (Crossref) [2025-07-19]
Citations: 0 (SemanticScholar) [2025-07-19]
tex.collaboration: ALICE},
    keywords = {High Energy Physics - Experiment, Nuclear Experiment},
    pages = {211},
}
@article{ALICE:2021njq,
    title = {Measurements of the groomed and ungroomed jet angularities in pp collisions at \${\textbackslash}sqrt\{s\} = 5.02\$ {TeV}},
    volume = {05},
    issn = {1029-8479},
    url = {http://arxiv.org/abs/2107.11303},
    doi = {10.1007/JHEP05(2022)061},
    abstract = {The jet angularities are a class of jet substructure observables which characterize the angular and momentum distribution of particles within jets. These observables are sensitive to momentum scales ranging from perturbative hard scatterings to nonperturbative fragmentation into final-state hadrons. We report measurements of several groomed and ungroomed jet angularities in pp collisions at \${\textbackslash}sqrt\{s\}=5.02\$ TeV with the ALICE detector. Jets are reconstructed using charged particle tracks at midrapidity (\${\textbar}{\textbackslash}eta{\textbar} {\textless} 0.9\$). The anti-\$k\_\{{\textbackslash}rm T\}\$ algorithm is used with jet resolution parameters \$R=0.2\$ and \$R=0.4\$ for several transverse momentum \$p\_\{{\textbackslash}rm T\}{\textasciicircum}\{{\textbackslash}text\{ch jet\}\}\$ intervals in the 20\$-\$100 GeV/\$c\$ range. Using the jet grooming algorithm Soft Drop, the sensitivity to softer, wide-angle processes, as well as the underlying event, can be reduced in a way which is well-controlled in theoretical calculations. We report the ungroomed jet angularities, \${\textbackslash}lambda\_\{{\textbackslash}alpha\}\$, and groomed jet angularities, \${\textbackslash}lambda\_\{{\textbackslash}alpha{\textbackslash}text\{,g\}\}\$, to investigate the interplay between perturbative and nonperturbative effects at low jet momenta. Various angular exponent parameters \${\textbackslash}alpha = 1\$, 1.5, 2, and 3 are used to systematically vary the sensitivity of the observable to collinear and soft radiation. Results are compared to analytical predictions at next-to-leading-logarithmic accuracy, which provide a generally good description of the data in the perturbative regime but exhibit discrepancies in the nonperturbative regime. Moreover, these measurements serve as a baseline for future ones in heavy-ion collisions by providing new insight into the interplay between perturbative and nonperturbative effects in the angular and momentum substructure of jets. They supply crucial guidance on the selection of jet resolution parameter, jet transverse momentum, and angular scaling variable for jet quenching studies.},
    number = {5},
    urldate = {2025-07-19},
    journal = {Journal of High Energy Physics},
    author = {Collaboration, ALICE},
    month = may,
    year = {2022},
    note = {68 citations (INSPIRE 2025/7/19)
37 citations w/o self (INSPIRE 2025/7/19)
arXiv:2107.11303 [nucl-ex]
Citations: 16 (Crossref) [2025-07-19]
Citations: 0 (SemanticScholar) [2025-07-19]
tex.collaboration: ALICE},
    keywords = {High Energy Physics - Experiment, Nuclear Experiment},
    pages = {061},
}
@article{Dasgupta:2022fim,
    title = {{QCD} resummation for groomed jet observables at {NNLL}+{NLO}},
    volume = {01},
    issn = {1029-8479},
    url = {http://arxiv.org/abs/2211.03820},
    doi = {10.1007/JHEP01(2023)045},
    abstract = {We use a direct QCD approach to carry out the next-to-next-to-leading logarithmic (NNLL) resummation for observables groomed with the modified mass-drop tagger (Soft Drop \${\textbackslash}beta=0\$). We focus on observables which are additive given an arbitrary number of soft-collinear emissions. For this class of observables, we arrange the structure of the NNLL terms into two distinct categories. The first defines a simplified inclusive tagger, whereby the NNLL collinear structure is directly related to ungroomed observables. The second defines a clustering correction which takes a particularly simple form when the Cambridge-Aachen (C/A) algorithm is used to cluster the jets. We provide, in addition to the QCD resummation of groomed jet mass, the first NNLL resummed predictions, matched to NLO, for a range of groomed jet angularities with mMDT grooming. Moreover, we also include for the first time in the same calculation, finite \$z\_\{{\textbackslash}mathrm\{cut\}\}\$ effects computed at NLL level alongside the small \$z\_\{{\textbackslash}mathrm\{cut\}\}\$ NNLL results which simultaneously improves upon both of the calculations used for groomed jet mass phenomenological studies to date. While for simplicity we focus on \$e{\textasciicircum}\{+\}e{\textasciicircum}\{-\}\$ collisions, the essential NNLL resummation we develop is process independent and hence with the appropriate NLO matching our results are also applicable for hadron collider phenomenology.},
    number = {1},
    urldate = {2025-07-19},
    journal = {Journal of High Energy Physics},
    author = {Dasgupta, Mrinal and El-Menoufi, Basem Kamal and Helliwell, Jack},
    month = jan,
    year = {2023},
    note = {16 citations (INSPIRE 2025/7/19)
10 citations w/o self (INSPIRE 2025/7/19)
arXiv:2211.03820 [hep-ph]
Citations: 14 (Crossref) [2025-07-19]
Citations: 11 (SemanticScholar) [2025-07-19]},
    keywords = {High Energy Physics - Phenomenology},
    pages = {045},
}
@article{ATLAS:2014hvo,
    title = {Jet energy measurement and its systematic uncertainty in proton–proton collisions at \$\${\textbackslash}sqrt\{s\}=7\$\$ {TeV} with the {ATLAS} detector},
    volume = {75},
    issn = {1434-6052},
    url = {https://doi.org/10.1140/epjc/s10052-014-3190-y},
    doi = {10.1140/epjc/s10052-014-3190-y},
    abstract = {The jet energy scale (JES) and its systematic uncertainty are determined for jets measured with the ATLAS detector using proton-proton collision data with a centre-of-mass energy of \${\textbackslash}sqrt\{s\}=7\$ TeV corresponding to an integrated luminosity of 4.7 fb\${\textasciicircum}\{-1\}\$. Jets are reconstructed from energy deposits forming topological clusters of calorimeter cells using the anti-k\$\_t\$ algorithm with distance parameters \$R=0.4\$ or \$R=0.6\$, and are calibrated using MC simulations. A residual JES correction is applied to account for differences between data and MC simulations. This correction and its systematic uncertainty are estimated using a combination of in situ techniques exploiting the transverse momentum balance between a jet and a reference object such as a photon or a Z boson, for \$20 {\textless} p\_T {\textless} 1000\$ GeV and pseudorapidities \${\textbar}{\textbackslash}eta{\textbar}{\textless}4.5\$. The effect of multiple proton-proton interactions is corrected for, and an uncertainty is evaluatedusing in situ techniques. The smallest JES uncertainty of less than \$1 \%\$ is found in the central calorimeter region(\${\textbar}{\textbackslash}eta{\textbar}{\textless}1.2\$) for jets with \$55{\textless} p\_T{\textless} 500\$ GeV. For central jets at lower \$p\_T\$, the uncertainty is about \$3 \%\$. A consistent JES estimate is found using measurements of the calorimeter response of single hadrons in proton-proton collisionsand test-beam data, which also provide the estimate for \$p\_\{T,jet\} {\textgreater} 1\$ TeV. The calibration of forward jets is derived from dijet \$p\_T\$ balance measurements. The resulting uncertainty reaches its largest value of \$6\%\$ for low-\$p\_T\$ jets at \${\textbar}{\textbackslash}eta{\textbar}=4.5\$. Additional JES uncertainties due to specific event topologies, such as close-by jets or selections of event samples with an enhanced content of jets originating from light quarks or gluons, are also discussed. The magnitude of these uncertainties depends on the event sample used in a given physics analysis, but typically amounts to \$0.5\%\$ to \$3\%\$.},
    language = {en},
    number = {1},
    urldate = {2025-07-19},
    journal = {The European Physical Journal C},
    author = {Aad, G. and Abajyan, T. and Abbott, B. and Abdallah, J. and Abdel Khalek, S. and Abdinov, O. and Aben, R. and Abi, B. and Abolins, M. and AbouZeid, O. S. and Abramowicz, H. and Abreu, H. and Abulaiti, Y. and Acharya, B. S. and Adamczyk, L. and Adams, D. L. and Addy, T. N. and Adelman, J. and Adomeit, S. and Adye, T. and Aefsky, S. and Agatonovic-Jovin, T. and Aguilar-Saavedra, J. A. and Agustoni, M. and Ahlen, S. P. and Ahmad, A. and Ahmadov, F. and Aielli, G. and Åkesson, T. P. A. and Akimoto, G. and Akimov, A. V. and Alam, M. A. and Albert, J. and Albrand, S. and Alconada Verzini, M. J. and Aleksa, M. and Aleksandrov, I. N. and Alessandria, F. and Alexa, C. and Alexander, G. and Alexandre, G. and Alexopoulos, T. and Alhroob, M. and Aliev, M. and Alimonti, G. and Alio, L. and Alison, J. and Allbrooke, B. M. M. and Allison, L. J. and Allport, P. P. and Allwood-Spiers, S. E. and Almond, J. and Aloisio, A. and Alon, R. and Alonso, A. and Alonso, F. and Altheimer, A. and Alvarez Gonzalez, B. and Alviggi, M. G. and Amako, K. and Amaral Coutinho, Y. and Amelung, C. and Ammosov, V. V. and Amor Dos Santos, S. P. and Amorim, A. and Amoroso, S. and Amram, N. and Amundsen, G. and Anastopoulos, C. and Ancu, L. S. and Andari, N. and Andeen, T. and Anders, C. F. and Anders, G. and Anderson, K. J. and Andreazza, A. and Andrei, V. and Anduaga, X. S. and Angelidakis, S. and Anger, P. and Angerami, A. and Anghinolfi, F. and Anisenkov, A. V. and Anjos, N. and Annovi, A. and Antonaki, A. and Antonelli, M. and Antonov, A. and Antos, J. and Anulli, F. and Aoki, M. and Aperio Bella, L. and Apolle, R. and Arabidze, G. and Aracena, I. and Arai, Y. and Arce, A. T. H. and Arfaoui, S. and Arguin, J-F. and Argyropoulos, S. and Arik, E. and Arik, M. and Armbruster, A. J. and Arnaez, O. and Arnal, V. and Arslan, O. and Artamonov, A. and Artoni, G. and Asai, S. and Asbah, N. and Ask, S. and Åsman, B. and Asquith, L. and Assamagan, K. and Astalos, R. and Astbury, A. and Atkinson, M. and Atlay, N. B. and Auerbach, B. and Auge, E. and Augsten, K. and Aurousseau, M. and Avolio, G. and Azuelos, G. and Azuma, Y. and Baak, M. A. and Bacci, C. and Bach, A. M. and Bachacou, H. and Bachas, K. and Backes, M. and Backhaus, M. and Backus Mayes, J. and Badescu, E. and Bagiacchi, P. and Bagnaia, P. and Bai, Y. and Bailey, D. C. and Bain, T. and Baines, J. T. and Baker, O. K. and Baker, S. and Balek, P. and Balli, F. and Banas, E. and Banerjee, Sw. and Banfi, D. and Bangert, A. and Bansal, V. and Bansil, H. S. and Barak, L. and Baranov, S. P. and Barber, T. and Barberio, E. L. and Barberis, D. and Barbero, M. and Barillari, T. and Barisonzi, M. and Barklow, T. and Barlow, N. and Barnett, B. M. and Barnett, R. M. and Baroncelli, A. and Barone, G. and Barr, A. J. and Barreiro, F. and Barreiro Guimarães da Costa, J. and Bartoldus, R. and Barton, A. E. and Bartos, P. and Bartsch, V. and Bassalat, A. and Basye, A. and Bates, R. L. and Batkova, L. and Batley, J. R. and Battistin, M. and Bauer, F. and Bawa, H. S. and Beau, T. and Beauchemin, P. H. and Beccherle, R. and Bechtle, P. and Beck, H. P. and Becker, K. and Becker, S. and Beckingham, M. and Beddall, A. J. and Beddall, A. and Bedikian, S. and Bednyakov, V. A. and Bee, C. P. and Beemster, L. J. and Beermann, T. A. and Begel, M. and Behr, K. and Belanger-Champagne, C. and Bell, P. J. and Bell, W. H. and Bella, G. and Bellagamba, L. and Bellerive, A. and Bellomo, M. and Belloni, A. and Beloborodova, O. L. and Belotskiy, K. and Beltramello, O. and Benary, O. and Benchekroun, D. and Bendtz, K. and Benekos, N. and Benhammou, Y. and Benhar Noccioli, E. and Benitez Garcia, J. A. and Benjamin, D. P. and Bensinger, J. R. and Benslama, K. and Bentvelsen, S. and Berge, D. and Bergeaas Kuutmann, E. and Berger, N. and Berghaus, F. and Berglund, E. and Beringer, J. and Bernard, C. and Bernat, P. and Bernhard, R. and Bernius, C. and Bernlochner, F. U. and Berry, T. and Berta, P. and Bertella, C. and Bertolucci, F. and Besana, M. I. and Besjes, G. J. and Bessidskaia, O. and Besson, N. and Bethke, S. and Bhimji, W. and Bianchi, R. M. and Bianchini, L. and Bianco, M. and Biebel, O. and Bieniek, S. P. and Bierwagen, K. and Biesiada, J. and Biglietti, M. and Bilbao De Mendizabal, J. and Bilokon, H. and Bindi, M. and Binet, S. and Bingul, A. and Bini, C. and Bittner, B. and Black, C. W. and Black, J. E. and Black, K. M. and Blackburn, D. and Blair, R. E. and Blanchard, J.-B. and Blazek, T. and Bloch, I. and Blocker, C. and Blocki, J. and Blum, W. and Blumenschein, U. and Bobbink, G. J. and Bobrovnikov, V. S. and Bocchetta, S. S. and Bocci, A. and Boddy, C. R. and Boehler, M. and Boek, J. and Boek, T. T. and Boelaert, N. and Bogaerts, J. A. and Bogdanchikov, A. G. and Bogouch, A. and Bohm, C. and Bohm, J. and Boisvert, V. and Bold, T. and Boldea, V. and Boldyrev, A. S. and Bolnet, N. M. and Bomben, M. and Bona, M. and Boonekamp, M. and Bordoni, S. and Borer, C. and Borisov, A. and Borissov, G. and Borri, M. and Borroni, S. and Bortfeldt, J. and Bortolotto, V. and Bos, K. and Boscherini, D. and Bosman, M. and {Atlas Collaboration}},
    month = jan,
    year = {2015},
    note = {778 citations (INSPIRE 2025/7/19)
193 citations w/o self (INSPIRE 2025/7/19)
Citations: 197 (Crossref) [2025-07-19]
Citations: 429 (SemanticScholar) [2025-07-19]
arXiv:1406.0076 [hep-ex]
tex.collaboration: ATLAS},
    keywords = {Experimental Nuclear Physics, Experimental Particle Physics, Metrology, Metrology and Fundamental Constants, Particle Physics, Tomography},
    pages = {17},
}
@article{ATLAS:2020bbn,
    title = {Measurement of the {Lund} {Jet} {Plane} {Using} {Charged} {Particles} in 13 {TeV} {Proton}-{Proton} {Collisions} with the {ATLAS} {Detector}},
    volume = {124},
    url = {https://link.aps.org/doi/10.1103/PhysRevLett.124.222002},
    doi = {10.1103/PhysRevLett.124.222002},
    abstract = {The prevalence of hadronic jets at the LHC requires that a deep understanding of jet formation and structure is achieved in order to reach the highest levels of experimental and theoretical precision. There have been many measurements of jet substructure at the LHC and previous colliders, but the targeted observables mix physical effects from various origins. Based on a recent proposal to factorize physical effects, this Letter presents a double-differential cross-section measurement of the Lund jet plane using 139 fb\${\textasciicircum}\{-1\}\$ of \${\textbackslash}sqrt\{s\}=13\$ TeV proton-proton collision data collected with the ATLAS detector using jets with transverse momentum above 675 GeV. The measurement uses charged particles to achieve a fine angular resolution and is corrected for acceptance and detector effects. Several parton shower Monte Carlo models are compared with the data. No single model is found to be in agreement with the measured data across the entire plane.},
    number = {22},
    urldate = {2025-07-19},
    journal = {Physical Review Letters},
    author = {Aad, Georges and Abbott, Brad and Abbott, Dale Charles and {others}},
    month = jun,
    year = {2020},
    note = {108 citations (INSPIRE 2025/7/19)
52 citations w/o self (INSPIRE 2025/7/19)
Publisher: American Physical Society
Citations: 29 (Crossref) [2025-07-19]
Citations: 0 (SemanticScholar) [2025-07-19]
arXiv:2004.03540 [hep-ex]
tex.collaboration: ATLAS},
    pages = {222002},
}
@article{CMS:2020poo,
    title = {Identification of heavy, energetic, hadronically decaying particles using machine-learning techniques},
    volume = {15},
    issn = {1748-0221},
    url = {http://arxiv.org/abs/2004.08262},
    doi = {10.1088/1748-0221/15/06/P06005},
    abstract = {Machine-learning (ML) techniques are explored to identify and classify hadronic decays of highly Lorentz-boosted W/Z/Higgs bosons and top quarks. Techniques without ML have also been evaluated and are included for comparison. The identification performances of a variety of algorithms are characterized in simulated events and directly compared with data. The algorithms are validated using proton-proton collision data at \${\textbackslash}sqrt\{s\} =\$ 13 TeV, corresponding to an integrated luminosity of 35.9 fb\${\textasciicircum}\{-1\}\$. Systematic uncertainties are assessed by comparing the results obtained using simulation and collision data. The new techniques studied in this paper provide significant performance improvements over non-ML techniques, reducing the background rate by up to an order of magnitude at the same signal efficiency.},
    number = {06},
    urldate = {2025-07-19},
    journal = {Journal of Instrumentation},
    author = {Collaboration, C. M. S.},
    month = jun,
    year = {2020},
    note = {260 citations (INSPIRE 2025/7/19)
84 citations w/o self (INSPIRE 2025/7/19)
arXiv:2004.08262 [hep-ex]
Citations: 78 (Crossref) [2025-07-19]
Citations: 20 (SemanticScholar) [2025-07-19]
tex.collaboration: CMS},
    keywords = {High Energy Physics - Experiment, Physics - Instrumentation and Detectors},
    pages = {P06005},
}
@article{ATLASCollaboration2025ElectroweakLHC,
    title = {{Electroweak, QCD and flavour physics studies with ATLAS data from Run 2 of the LHC}},
    year = {2025},
    journal = {Physics Reports},
    author = {{ATLAS Collaboration}},
    month = {4},
    pages = {57--126},
    volume = {1116},
    publisher = {Elsevier B.V.},
    url = {http://arxiv.org/abs/2404.06829 http://dx.doi.org/10.1016/j.physrep.2024.12.003},
    doi = {10.1016/j.physrep.2024.12.003},
    arxivId = {2404.06829v2}
}
@book{taylor_methodus_1715,
    address = {Londini},
    title = {Methodus incrementorum directa \& inversa. {Auctore} {Brook} {Taylor}, {LL}. {D}. \& {Regiae} {Societatis} {Secretario}.},
    language = {lat},
    publisher = {typis Pearsonianis: prostant apud Gul. Innys ad Insignia Principis in Coemeterio Paulino},
    author = {Taylor, Brook},
    year = {1715},
    keywords = {Calculus, Difference equations, Series, Taylor's},
}
@book{weierstras_uber_1885,
    address = {Berlin},
    series = {Sitzungsberichte der {Preussischen} {Akademie} der {Wissenschaften} {Jg}. 1885, 34 ; {Jg}. 1885, 38},
    title = {Über die analytische {Darstellbarkeit} sogenannter willkürlicher {Functionen} einer reellen {Veränderlichen}},
    language = {ger},
    publisher = {:},
    author = {Weierstraß, Karl},
    year = {1885},
}
@techreport{Matzke:275528,
      author        = "Matzke, M",
      title         = "{Unfolding of pulse height spectra}",
      institution   = "Braunschweig Univ. Phys.-Tech. Bundesanst",
      reportNumber  = "PTB-N-19",
      address       = "Braunschweig",
      year          = "1994",
      url           = "https://cds.cern.ch/record/275528",
}
@article{NikodymSurRadon,
    title = {{Sur une g{\'{e}}n{\'{e}}ralisation des int{\'{e}}grales de M. J. Radon}},
    journal = {Fundamenta Mathematicae},
    author = {Nikodym, Otton},
    number = {1},
    pages = {131--179},
    volume = {15},
    issn = {0016-2736}
}
@book{radon_theorie_1913,
    address = {Wien},
    title = {Theorie und anwendungen der absolut additiven mengenfunktionen ...},
    url = {https://catalog.hathitrust.org/Record/008892713},
    urldate = {2025-07-20},
    publisher = {Hölder},
    author = {Radon, Johann},
    year = {1913},
    keywords = {Integral equations, authorities, http:, id.loc.gov, sh85067088, subjects},
}
@misc{dangelo_why_2024,
    title = {Why {Do} {We} {Need} {Weight} {Decay} in {Modern} {Deep} {Learning}?},
    url = {http://arxiv.org/abs/2310.04415},
    doi = {10.48550/arXiv.2310.04415},
    abstract = {Weight decay is a broadly used technique for training state-of-the-art deep networks from image classification to large language models. Despite its widespread usage and being extensively studied in the classical literature, its role remains poorly understood for deep learning. In this work, we highlight that the role of weight decay in modern deep learning is different from its regularization effect studied in classical learning theory. For deep networks on vision tasks trained with multipass SGD, we show how weight decay modifies the optimization dynamics enhancing the ever-present implicit regularization of SGD via the loss stabilization mechanism. In contrast, for large language models trained with nearly one-epoch training, we describe how weight decay balances the bias-variance tradeoff in stochastic optimization leading to lower training loss and improved training stability. Overall, we present a unifying perspective from ResNets on vision tasks to LLMs: weight decay is never useful as an explicit regularizer but instead changes the training dynamics in a desirable way. The code is available at https://github.com/tml-epfl/why-weight-decay},
    urldate = {2025-07-20},
    publisher = {arXiv},
    author = {D'Angelo, Francesco and Andriushchenko, Maksym and Varre, Aditya and Flammarion, Nicolas},
    month = nov,
    year = {2024},
    note = {arXiv:2310.04415 [cs]},
    keywords = {Computer Science - Machine Learning},
}
@article{srivastava_dropout_2014,
    title = {Dropout: {A} {Simple} {Way} to {Prevent} {Neural} {Networks} from {Overfitting}},
    volume = {15},
    issn = {1533-7928},
    shorttitle = {Dropout},
    url = {http://jmlr.org/papers/v15/srivastava14a.html},
    abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different thinned networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
    number = {56},
    urldate = {2025-07-20},
    journal = {Journal of Machine Learning Research},
    author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
    year = {2014},
    keywords = {⛔ No DOI found},
    pages = {1929--1958},
}
@misc{cui_knowledge-augmented_2022,
    title = {Knowledge-augmented {Deep} {Learning} and {Its} {Applications}: {A} {Survey}},
    shorttitle = {Knowledge-augmented {Deep} {Learning} and {Its} {Applications}},
    url = {http://arxiv.org/abs/2212.00017},
    doi = {10.48550/arXiv.2212.00017},
    abstract = {Deep learning models, though having achieved great success in many different fields over the past years, are usually data hungry, fail to perform well on unseen samples, and lack of interpretability. Various prior knowledge often exists in the target domain and their use can alleviate the deficiencies with deep learning. To better mimic the behavior of human brains, different advanced methods have been proposed to identify domain knowledge and integrate it into deep models for data-efficient, generalizable, and interpretable deep learning, which we refer to as knowledge-augmented deep learning (KADL). In this survey, we define the concept of KADL, and introduce its three major tasks, i.e., knowledge identification, knowledge representation, and knowledge integration. Different from existing surveys that are focused on a specific type of knowledge, we provide a broad and complete taxonomy of domain knowledge and its representations. Based on our taxonomy, we provide a systematic review of existing techniques, different from existing works that survey integration approaches agnostic to taxonomy of knowledge. This survey subsumes existing works and offers a bird's-eye view of research in the general area of knowledge-augmented deep learning. The thorough and critical reviews of numerous papers help not only understand current progresses but also identify future directions for the research on knowledge-augmented deep learning.},
    urldate = {2025-07-20},
    publisher = {arXiv},
    author = {Cui, Zijun and Gao, Tian and Talamadupula, Kartik and Ji, Qiang},
    month = nov,
    year = {2022},
    note = {arXiv:2212.00017 [cs]
Citations: 20 (SemanticScholar) [2025-07-20]},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}
@misc{hepmllivingreview,
    Author = "{HEP ML Community}",
    title = "{A Living Review of Machine Learning for Particle Physics}",
    url={https://iml-wg.github.io/HEPML-LivingReview/}
}
@phdthesis{howard_advancing_2022,
    title = {Advancing {Particle} {Physics} with {Sophisticated} {Computational} {Frameworks}},
    url = {https://escholarship.org/uc/item/4cs3f5fp},
    abstract = {The Standard Model (SM) of particle physics is one of the most complete mathematical models of physical phenomena to date. Even so, it cannot explain experimental results like the existence of particle dark matter and the fact that neutrino masses are non-zero. Explaining such results will necessitate developing a beyond the SM (BSM) theoretical description of particle physics. What form this BSM physics will take has become increasingly unclear; many elegant theories which were expected to appear in recent experiments have not emerged. Thus, we find ourselves at a cross-roads, in need of new perspectives and new computational frameworks to push our theoretical description of physics forward.New perspectives will come from challenging previously-held assumptions in the pursuit of fundamentally new descriptions, but challenging such assumptions often presents practical computational challenges. Therefore, these new perspectives must also be accompanied by new computational frameworks. Computational frameworks can come in many forms, from the purely mathematical to the largely numerical. In particular, in recent years machine learning (ML) has become an increasingly accessible and powerful computational tool for scientific applications. Crafting novel BSM theories will require us to investigate and embrace the full spectrum of computational frameworks. Additionally, one of the best ways to spark new insights is to closely collaborate with and draw inspiration from other fields, such as mathematics and computer science.In this thesis, we present two examples of how advanced computational frameworks can be used to aid in investigating new physics perspectives. In one example, we see how the purely mathematical framework of optimal transport (OT) theory can be used in tandem with advanced ML methods to enable a new perspective on particle physics simulations. The result is a novel strategy which lays the foundations for a completely data-driven, end-to-end simulation of particle collisions at the Large Hadron Collider. In a second example, we see work which considers a new perspective on what the history of our universe might have looked like. In particular, we consider how the abundance of a WIMP dark matter candidate could be altered by considering a phase of electroweak force confinement early in the universe. Considering this model while making relatively few assumptions was aided by the application of advanced numerical computational tools.We begin with both high-level and technical background on the topics relevant to these works. We conclude by discussing future directions for these works, as well as briefly giving general thoughts on strategies for applying the computational framework of ML to problems in theoretical particle physics more broadly.},
    language = {en},
    urldate = {2025-07-20},
    school = {UC Irvine},
    author = {Howard, Jessica Nicole},
    year = {2022},
}
 @article{rieger_rwth aachen university (germany). fakultät für mathematik, informatik und naturwissenschaften_2019, title={Search for Higgs boson production in association with top quarks and decaying into bottom quarks using deep learning techniques with the CMS experiment}, DOI={10.18154/RWTH-2019-06415}, abstractNote={After the discovery of the Higgs boson during the first run of the Large Hadron Collider (LHC), precise measurements of its properties and couplings to other particles are conducted by the ATLAS and CMS experiments. Due to its high mass, the Standard Model of particle physics (SM) predicts that the top quark, among all fermions, exhibits the strongest coupling to the Higgs boson with a Yukawa coupling constant close to unity. Therefore, the accurate measurement of Higgs-top coupling is essential for probing predictions of the SM and to constrain theories that reach beyond it. This thesis presents a search for the associated production of a Higgs boson with a top quark pair at a center-of-mass energy of s = 13 TeV. The data from proton-proton collisions of the second run of the LHC was recorded by the CMS detector in 2016 and corresponds to an integrated luminosity of 35.9 fb−1. The analysis focuses on events where the Higgs boson decays into a pair of bottom quarks and the decay of the tt¯ system involves one or two electrons or muons with opposite charge. In addition to the lepton requirements, events are selected to have missing transverse energy and at least four energetic jets of, which at least three must have a b tag. The analysis is dominated by systematic uncertainties in the normalization of tt¯ background contributions with additional heavy-flavor jets, especially from tt¯+bb¯, tt¯+bb¯, tt¯+2b, and tt¯+cc¯ production. To reduce their impact on the analysis, a novel event categorization scheme based on deep neural networks is introduced. In contrast to binary classification, the networks perform a multi-class classification, which attributes events with a probability to originate from either the signal process or a particular background process. The information of the highest probability is exploited to create mutually exclusive categories that are enriched with events of one of the considered physics processes. As the tt¯ +heavy-flavor normalization uncertainties are treated as uncorrelated in the signal extraction procedure, the simultaneous isolation of backgrounds using this approach leads to more accurate background constraints and, in turn, to a gain in signal sensitivity. Results are obtained in a simultaneous measurement over 24 orthogonal categories defined by the lepton channel, the number of jets, and the most probable process as attributed by the deep neural networks. In each category, the distribution of the network output unit that corresponds to the assigned process category is fitted to data. The best fit value of the tt¯H signal strength modifier μ = σ/σSM is extracted in a profile likelihood fit with systematic uncertainties incorporated as nuisance parameters. Upper limits on μ are computed using the asymptotic CLS method at 95% confidence level. The SM predicts a tt¯H production cross section of σSM = 507−50+35 fb with NLO QCD accuracy and NLO electroweak corrections. This analysis measures an observed upper limit on the tt¯H signal strength modifier of μobs< 1.85, which excludes greater values with 95% confidence given the measured data. The background-only hypothesis is disfavored due to an expected limit of μexp< 0.99−0.29+0.42 in case of a signal strength as predicted by the SM. The observed best fit value is measured as μobs = 0.98−0.48+0.50 = 0.98−0.25+0.26 (stat.)−0.41+0.43 (syst.). A value of μexp = 1.00−0.49+0.55 is expected from simulation. The corresponding observed (expected) significance amounts to 2.04 (1.92) standard deviations above the expected background. The total uncertainty predominantly originates from systematic effects. The analysis in the semi-lepton channel as presented in this thesis contributed to the first observations of both tt¯H production and Higgs bosons decaying into bottom quarks, performed with the CMS experiment.}, author={Rieger, Marcel and RWTH Aachen University (Germany). Fakultät für Mathematik, Informatik und Naturwissenschaften}, year={2019}, month={Jun} }
@article{lagrave_equivariant_2022,
    title = {Equivariant {Neural} {Networks} and {Differential} {Invariants} {Theory} for {Solving} {Partial} {Differential} {Equations}},
    volume = {5},
    copyright = {http://creativecommons.org/licenses/by/3.0/},
    issn = {2673-9984},
    url = {https://www.mdpi.com/2673-9984/5/1/13},
    doi = {10.3390/psf2022005013},
    abstract = {This paper discusses the use of Equivariant Neural Networks (ENN) for solving Partial Differential Equations by exploiting their underlying symmetry groups. We first show that Group-Convolutionnal Neural Networks can be used to generalize Physics-Informed Neural Networks and then consider the use of ENN to approximate differential invariants of a given symmetry group, hence allowing to build symmetry-preserving Finite Difference methods without the need to formally derivate corresponding numerical invariantizations. The benefit of our approach is illustrated on the 2D heat equation through the instantiation of an SE(2) symmetry-preserving discretization.},
    language = {en},
    number = {1},
    urldate = {2025-07-20},
    journal = {Physical Sciences Forum},
    author = {Lagrave, Pierre-Yves and Tron, Eliot},
    year = {2022},
    note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute
Citations: 1 (Crossref) [2025-07-20]
Citations: 6 (SemanticScholar) [2025-07-20]},
    keywords = {differential invariants, equivariant neural networks, geometric deep learning, partial differential equations, physics informed machine learning},
    pages = {13},
}
@misc{pazos_towards_2024,
    title = {Towards {Universal} {Unfolding} of {Detector} {Effects} in {High}-{Energy} {Physics} using {Denoising} {Diffusion} {Probabilistic} {Models}},
    url = {http://arxiv.org/abs/2406.01507},
    doi = {10.48550/arXiv.2406.01507},
    abstract = {Correcting for detector effects in experimental data, particularly through unfolding, is critical for enabling precision measurements in high-energy physics. However, traditional unfolding methods face challenges in scalability, flexibility, and dependence on simulations. We introduce a novel approach to multidimensional object-wise unfolding using conditional Denoising Diffusion Probabilistic Models (cDDPM). Our method utilizes the cDDPM for a non-iterative, flexible posterior sampling approach, incorporating distribution moments as conditioning information, which exhibits a strong inductive bias that allows it to generalize to unseen physics processes without explicitly assuming the underlying distribution. Our results highlight the potential of this method as a step towards a "universal" unfolding tool that reduces dependence on truth-level assumptions, while enabling the unfolding of a wide range of measured distributions with improved adaptability and accuracy.},
    urldate = {2025-07-20},
    publisher = {arXiv},
    author = {Pazos, Camila and Aeron, Shuchin and Beauchemin, Pierre-Hugues and Croft, Vincent and Huan, Zhengyan and Klassen, Martin and Wongjirad, Taritree},
    month = nov,
    year = {2024},
    note = {arXiv:2406.01507 [physics]
Citations: 1 (SemanticScholar) [2025-07-20]},
    keywords = {High Energy Physics - Experiment, High Energy Physics - Phenomenology, Physics - Data Analysis, Statistics and Probability},
}
@article{unke_machine_2021,
    title = {Machine {Learning} {Force} {Fields}},
    volume = {121},
    issn = {0009-2665},
    url = {https://doi.org/10.1021/acs.chemrev.0c01111},
    doi = {10.1021/acs.chemrev.0c01111},
    abstract = {In recent years, the use of machine learning (ML) in computational chemistry has enabled numerous advances previously out of reach due to the computational complexity of traditional electronic-structure methods. One of the most promising applications is the construction of ML-based force fields (FFs), with the aim to narrow the gap between the accuracy of ab initio methods and the efficiency of classical FFs. The key idea is to learn the statistical relation between chemical structure and potential energy without relying on a preconceived notion of fixed chemical bonds or knowledge about the relevant interactions. Such universal ML approximations are in principle only limited by the quality and quantity of the reference data used to train them. This review gives an overview of applications of ML-FFs and the chemical insights that can be obtained from them. The core concepts underlying ML-FFs are described in detail, and a step-by-step guide for constructing and testing them from scratch is given. The text concludes with a discussion of the challenges that remain to be overcome by the next generation of ML-FFs.},
    number = {16},
    urldate = {2025-07-20},
    journal = {Chemical Reviews},
    author = {Unke, Oliver T. and Chmiela, Stefan and Sauceda, Huziel E. and Gastegger, Michael and Poltavsky, Igor and Schütt, Kristof T. and Tkatchenko, Alexandre and Müller, Klaus-Robert},
    month = aug,
    year = {2021},
    note = {Publisher: American Chemical Society
Citations: 970 (Crossref) [2025-07-20]
Citations: 940 (SemanticScholar) [2025-07-20]},
    pages = {10142--10186},
}
@article{dopp_data-driven_2023,
    title = {Data-driven science and machine learning methods in laser–plasma physics},
    volume = {11},
    issn = {2095-4719, 2052-3289},
    url = {https://www.cambridge.org/core/journals/high-power-laser-science-and-engineering/article/datadriven-science-and-machine-learning-methods-in-laserplasma-physics/B50C69868941B26062ECF6AFCF2BF3B9#},
    doi = {10.1017/hpl.2023.47},
    abstract = {Laser-plasma physics has developed rapidly over the past few decades as lasers have become both more powerful and more widely available. Early experimental and numerical research in this field was dominated by single-shot experiments with limited parameter exploration. However, recent technological improvements make it possible to gather data for hundreds or thousands of different settings in both experiments and simulations. This has sparked interest in using advanced techniques from mathematics, statistics and computer science to deal with, and benefit from, big data. At the same time, sophisticated modeling techniques also provide new ways for researchers to deal effectively with situation where still only sparse data are available. This paper aims to present an overview of relevant machine learning methods with focus on applicability to laser-plasma physics and its important sub-fields of laser-plasma acceleration and inertial confinement fusion.},
    language = {en},
    urldate = {2025-07-20},
    journal = {High Power Laser Science and Engineering},
    author = {Döpp, Andreas and Eberle, Christoph and Howard, Sunny and Irshad, Faran and Lin, Jinpu and Streeter, Matthew},
    month = jan,
    year = {2023},
    note = {Citations: 68 (Crossref) [2025-07-20]
Citations: 72 (SemanticScholar) [2025-07-20]},
    keywords = {deep learning, laser–plasma interaction, machine learning},
    pages = {e55},
}
@article{Ackerschott2023ReturningBelong,
    title = {{Returning CP-Observables to The Frames They Belong}},
    year = {2023},
    journal = {SciPost Physics},
    author = {Ackerschott, Jona and Barman, Rahool Kumar and Gon{\c{c}}alves, Dorival and Heimel, Theo and Plehn, Tilman},
    number = {1},
    month = {7},
    volume = {17},
    publisher = {SciPost Foundation},
    url = {http://arxiv.org/abs/2308.00027 http://dx.doi.org/10.21468/SciPostPhys.17.1.001},
    doi = {10.21468/SciPostPhys.17.1.001},
    arxivId = {2308.00027v1}
}
@article{Butter2020GANplifyingSamples,
    title = {{GANplifying Event Samples}},
    year = {2020},
    journal = {SciPost Physics},
    author = {Butter, Anja and Diefenbacher, Sascha and Kasieczka, Gregor and Nachman, Benjamin and Plehn, Tilman},
    number = {6},
    month = {8},
    volume = {10},
    publisher = {SciPost Foundation},
    url = {https://arxiv.org/abs/2008.06545v3},
    doi = {10.21468/scipostphys.10.6.139},
    issn = {25424653},
    arxivId = {2008.06545}
}
@article{Humble:2022vtm,
    title = {Snowmass {White} {Paper}: {Quantum} {Computing} {Systems} and {Software} for {High}-energy {Physics} {Research}},
    shorttitle = {Snowmass {White} {Paper}},
    url = {http://arxiv.org/abs/2203.07091},
    doi = {10.48550/arXiv.2203.07091},
    abstract = {Quantum computing offers a new paradigm for advancing high-energy physics research by enabling novel methods for representing and reasoning about fundamental quantum mechanical phenomena. Realizing these ideals will require the development of novel computational tools for modeling and simulation, detection and classification, data analysis, and forecasting of high-energy physics (HEP) experiments. While the emerging hardware, software, and applications of quantum computing are exciting opportunities, significant gaps remain in integrating such techniques into the HEP community research programs. Here we identify both the challenges and opportunities for developing quantum computing systems and software to advance HEP discovery science. We describe opportunities for the focused development of algorithms, applications, software, hardware, and infrastructure to support both practical and theoretical applications of quantum computing to HEP problems within the next 10 years.},
    urldate = {2025-07-20},
    author = {Humble, Travis S. and Delgado, Andrea and Pooser, Raphael and Seck, Christopher and Bennink, Ryan and Leyton-Ortega, Vicente and Wang, C.-C. Joseph and Dumitrescu, Eugene and Morris, Titus and Hamilton, Kathleen and Lyakh, Dmitry and Date, Prasanna and Wang, Yan and Peters, Nicholas A. and Evans, Katherine J. and Demarteau, Marcel and McCaskey, Alex and Nguyen, Thien and Clark, Susan and Reville, Melissa and Meglio, Alberto Di and Grossi, Michele and Vallecorsa, Sofia and Borras, Kerstin and Jansen, Karl and Krücker, Dirk},
    month = mar,
    year = {2022},
    note = {21 citations (INSPIRE 2025/7/20)
17 citations w/o self (INSPIRE 2025/7/20)
arXiv:2203.07091 [quant-ph]
Citations: 15 (SemanticScholar) [2025-07-20]},
    keywords = {Quantum Physics},
}
@article{Huetsch2024TheLearning,
    title = {{The Landscape of Unfolding with Machine Learning}},
    year = {2024},
    journal = {SciPost Physics},
    author = {Huetsch, Nathan and Villadamigo, Javier Mariño and Shmakov, Alexander and Diefenbacher, Sascha and Mikuni, Vinicius and Heimel, Theo and Fenton, Michael and Greif, Kevin and Nachman, Benjamin and Whiteson, Daniel and Butter, Anja and Plehn, Tilman},
    number = {2},
    month = {5},
    volume = {18},
    publisher = {SciPost Foundation},
    url = {http://arxiv.org/abs/2404.18807 http://dx.doi.org/10.21468/SciPostPhys.18.2.070},
    doi = {10.21468/SciPostPhys.18.2.070},
    arxivId = {2404.18807v2}
}
@misc{xia_penalty_2023,
    title = {Penalty {Gradient} {Normalization} for {Generative} {Adversarial} {Networks}},
    url = {http://arxiv.org/abs/2306.13576},
    doi = {10.48550/arXiv.2306.13576},
    abstract = {In this paper, we propose a novel normalization method called penalty gradient normalization (PGN) to tackle the training instability of Generative Adversarial Networks (GANs) caused by the sharp gradient space. Unlike existing work such as gradient penalty and spectral normalization, the proposed PGN only imposes a penalty gradient norm constraint on the discriminator function, which increases the capacity of the discriminator. Moreover, the proposed penalty gradient normalization can be applied to different GAN architectures with little modification. Extensive experiments on three datasets show that GANs trained with penalty gradient normalization outperform existing methods in terms of both Frechet Inception and Distance and Inception Score.},
    urldate = {2025-07-20},
    publisher = {arXiv},
    author = {Xia, Tian},
    month = jun,
    year = {2023},
    note = {arXiv:2306.13576 [cs]},
    keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}
@article{OptimalDistance,
    title = {{Optimal Transport and Wasserstein Distance}}
}
@misc{rosca_case_2021,
    title = {A case for new neural network smoothness constraints},
    url = {http://arxiv.org/abs/2012.07969},
    doi = {10.48550/arXiv.2012.07969},
    abstract = {How sensitive should machine learning models be to input changes? We tackle the question of model smoothness and show that it is a useful inductive bias which aids generalization, adversarial robustness, generative modeling and reinforcement learning. We explore current methods of imposing smoothness constraints and observe they lack the flexibility to adapt to new tasks, they don't account for data modalities, they interact with losses, architectures and optimization in ways not yet fully understood. We conclude that new advances in the field are hinging on finding ways to incorporate data, tasks and learning into our definitions of smoothness.},
    urldate = {2025-07-20},
    publisher = {arXiv},
    author = {Rosca, Mihaela and Weber, Theophane and Gretton, Arthur and Mohamed, Shakir},
    month = jul,
    year = {2021},
    note = {arXiv:2012.07969 [stat]},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}
@misc{doan_image_2020,
    title = {Image {Generation} {Via} {Minimizing} {Fréchet} {Distance} in {Discriminator} {Feature} {Space}},
    url = {http://arxiv.org/abs/2003.11774},
    doi = {10.48550/arXiv.2003.11774},
    abstract = {For a given image generation problem, the intrinsic image manifold is often low dimensional. We use the intuition that it is much better to train the GAN generator by minimizing the distributional distance between real and generated images in a small dimensional feature space representing such a manifold than on the original pixel-space. We use the feature space of the GAN discriminator for such a representation. For distributional distance, we employ one of two choices: the Fr{\textbackslash}'\{e\}chet distance or direct optimal transport (OT); these respectively lead us to two new GAN methods: Fr{\textbackslash}'\{e\}chet-GAN and OT-GAN. The idea of employing Fr{\textbackslash}'\{e\}chet distance comes from the success of Fr{\textbackslash}'\{e\}chet Inception Distance as a solid evaluation metric in image generation. Fr{\textbackslash}'\{e\}chet-GAN is attractive in several ways. We propose an efficient, numerically stable approach to calculate the Fr{\textbackslash}'\{e\}chet distance and its gradient. The Fr{\textbackslash}'\{e\}chet distance estimation requires a significantly less computation time than OT; this allows Fr{\textbackslash}'\{e\}chet-GAN to use much larger mini-batch size in training than OT. More importantly, we conduct experiments on a number of benchmark datasets and show that Fr{\textbackslash}'\{e\}chet-GAN (in particular) and OT-GAN have significantly better image generation capabilities than the existing representative primal and dual GAN approaches based on the Wasserstein distance.},
    urldate = {2025-07-20},
    publisher = {arXiv},
    author = {Doan, Khoa D. and Manchanda, Saurav and Wang, Fengjiao and Keerthi, Sathiya and Bhowmik, Avradeep and Reddy, Chandan K.},
    month = mar,
    year = {2020},
    note = {arXiv:2003.11774 [cs]
Citations: 6 (SemanticScholar) [2025-07-20]},
    keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
}
@misc{scaman_lipschitz_2019,
    title = {Lipschitz regularity of deep neural networks: analysis and efficient estimation},
    shorttitle = {Lipschitz regularity of deep neural networks},
    url = {http://arxiv.org/abs/1805.10965},
    doi = {10.48550/arXiv.1805.10965},
    abstract = {Deep neural networks are notorious for being sensitive to small well-chosen perturbations, and estimating the regularity of such architectures is of utmost importance for safe and robust practical applications. In this paper, we investigate one of the key characteristics to assess the regularity of such methods: the Lipschitz constant of deep learning architectures. First, we show that, even for two layer neural networks, the exact computation of this quantity is NP-hard and state-of-art methods may significantly overestimate it. Then, we both extend and improve previous estimation methods by providing AutoLip, the first generic algorithm for upper bounding the Lipschitz constant of any automatically differentiable function. We provide a power method algorithm working with automatic differentiation, allowing efficient computations even on large convolutions. Second, for sequential neural networks, we propose an improved algorithm named SeqLip that takes advantage of the linear computation graph to split the computation per pair of consecutive layers. Third we propose heuristics on SeqLip in order to tackle very large networks. Our experiments show that SeqLip can significantly improve on the existing upper bounds. Finally, we provide an implementation of AutoLip in the PyTorch environment that may be used to better estimate the robustness of a given neural network to small perturbations or regularize it using more precise Lipschitz estimations.},
    urldate = {2025-07-20},
    publisher = {arXiv},
    author = {Scaman, Kevin and Virmaux, Aladin},
    month = oct,
    year = {2019},
    note = {arXiv:1805.10965 [stat]},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}
@misc{delattre_efficient_2023,
    title = {Efficient {Bound} of {Lipschitz} {Constant} for {Convolutional} {Layers} by {Gram} {Iteration}},
    url = {http://arxiv.org/abs/2305.16173},
    doi = {10.48550/arXiv.2305.16173},
    abstract = {Since the control of the Lipschitz constant has a great impact on the training stability, generalization, and robustness of neural networks, the estimation of this value is nowadays a real scientific challenge. In this paper we introduce a precise, fast, and differentiable upper bound for the spectral norm of convolutional layers using circulant matrix theory and a new alternative to the Power iteration. Called the Gram iteration, our approach exhibits a superlinear convergence. First, we show through a comprehensive set of experiments that our approach outperforms other state-of-the-art methods in terms of precision, computational cost, and scalability. Then, it proves highly effective for the Lipschitz regularization of convolutional neural networks, with competitive results against concurrent approaches. Code is available at https://github.com/blaisedelattre/lip4conv.},
    urldate = {2025-07-20},
    publisher = {arXiv},
    author = {Delattre, Blaise and Barthélemy, Quentin and Araujo, Alexandre and Allauzen, Alexandre},
    month = jun,
    year = {2023},
    note = {arXiv:2305.16173 [cs]
Citations: 13 (SemanticScholar) [2025-07-20]},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}
@inproceedings{mehta_effects_2023,
    title = {Effects of {Spectral} {Normalization} in {Multi}-{Agent} {Reinforcement} {Learning}},
    url = {https://ieeexplore.ieee.org/document/10191226},
    doi = {10.1109/IJCNN54540.2023.10191226},
    abstract = {A reliable critic is central to on-policy actor-critic learning. But it becomes challenging to learn a reliable critic in a multi-agent sparse reward scenario due to two factors: 1) The joint action space grows exponentially with the number of agents 2) This, combined with the reward sparseness and environment noise, leads to large sample requirements for accurate learning. We show that regularising the critic with spectral normalization (SN) enables it to learn more robustly, even in multi-agent on-policy sparse reward scenarios. Our experiments show that the regularised critic is quickly able to learn from the sparse rewarding experience in the complex SMAC and RWARE domains. These findings highlight the importance of regularisation in the critic for stable learning.},
    urldate = {2025-07-20},
    booktitle = {2023 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
    author = {Mehta, Kinal and Mahajan, Anuj and Kumar, Pawan},
    month = jun,
    year = {2023},
    note = {ISSN: 2161-4407
Citations: 1 (Crossref) [2025-07-20]
Citations: 7 (SemanticScholar) [2025-07-20]},
    keywords = {MARL, Multi-Agent Reinforcement Learning, Neural networks, Optimization, Reinforcement learning, Reliability, Spectral Normalization},
    pages = {1--8},
}
@misc{meunier_dynamical_2022,
    title = {A {Dynamical} {System} {Perspective} for {Lipschitz} {Neural} {Networks}},
    url = {http://arxiv.org/abs/2110.12690},
    doi = {10.48550/arXiv.2110.12690},
    abstract = {The Lipschitz constant of neural networks has been established as a key quantity to enforce the robustness to adversarial examples. In this paper, we tackle the problem of building \$1\$-Lipschitz Neural Networks. By studying Residual Networks from a continuous time dynamical system perspective, we provide a generic method to build \$1\$-Lipschitz Neural Networks and show that some previous approaches are special cases of this framework. Then, we extend this reasoning and show that ResNet flows derived from convex potentials define \$1\$-Lipschitz transformations, that lead us to define the \{{\textbackslash}em Convex Potential Layer\} (CPL). A comprehensive set of experiments on several datasets demonstrates the scalability of our architecture and the benefits as an \${\textbackslash}ell\_2\$-provable defense against adversarial examples.},
    urldate = {2025-07-20},
    publisher = {arXiv},
    author = {Meunier, Laurent and Delattre, Blaise and Araujo, Alexandre and Allauzen, Alexandre},
    month = feb,
    year = {2022},
    note = {arXiv:2110.12690 [cs]
Citations: 56 (SemanticScholar) [2025-07-20]},
    keywords = {Computer Science - Machine Learning},
}
@misc{wiatrak_stabilizing_2020,
    title = {Stabilizing {Generative} {Adversarial} {Networks}: {A} {Survey}},
    shorttitle = {Stabilizing {Generative} {Adversarial} {Networks}},
    url = {http://arxiv.org/abs/1910.00927},
    doi = {10.48550/arXiv.1910.00927},
    abstract = {Generative Adversarial Networks (GANs) are a type of generative model which have received much attention due to their ability to model complex real-world data. Despite their recent successes, the process of training GANs remains challenging, suffering from instability problems such as non-convergence, vanishing or exploding gradients, and mode collapse. In recent years, a diverse set of approaches have been proposed which focus on stabilizing the GAN training procedure. The purpose of this survey is to provide a comprehensive overview of the GAN training stabilization methods which can be found in the literature. We discuss the advantages and disadvantages of each approach, offer a comparative summary, and conclude with a discussion of open problems.},
    urldate = {2025-07-20},
    publisher = {arXiv},
    author = {Wiatrak, Maciej and Albrecht, Stefano V. and Nystrom, Andrew},
    month = mar,
    year = {2020},
    note = {arXiv:1910.00927 [cs]
Citations: 88 (SemanticScholar) [2025-07-20]},
    keywords = {Computer Science - Machine Learning},
}
@article{Qian2021SelfNetworks,
    title = {{Self Sparse Generative Adversarial Networks}},
    year = {2021},
    journal = {CAAI Artificial Intelligence Research},
    author = {Qian, Wenliang and Xu, Yang and Zuo, Wangmeng and Li, Hui},
    number = {1},
    month = {1},
    pages = {68--78},
    volume = {1},
    publisher = {Tsinghua University Press},
    url = {http://arxiv.org/abs/2101.10556 http://dx.doi.org/10.26599/AIR.2022.9150005},
    doi = {10.26599/AIR.2022.9150005},
    arxivId = {2101.10556v1}
}
@misc{chen_cde-gan_2021,
    title = {{CDE}-{GAN}: {Cooperative} {Dual} {Evolution} {Based} {Generative} {Adversarial} {Network}},
    shorttitle = {{CDE}-{GAN}},
    url = {http://arxiv.org/abs/2008.09388},
    doi = {10.48550/arXiv.2008.09388},
    abstract = {Generative adversarial networks (GANs) have been a popular deep generative model for real-world applications. Despite many recent efforts on GANs that have been contributed, mode collapse and instability of GANs are still open problems caused by their adversarial optimization difficulties. In this paper, motivated by the cooperative co-evolutionary algorithm, we propose a Cooperative Dual Evolution based Generative Adversarial Network (CDE-GAN) to circumvent these drawbacks. In essence, CDE-GAN incorporates dual evolution with respect to the generator(s) and discriminators into a unified evolutionary adversarial framework to conduct effective adversarial multi-objective optimization. Thus it exploits the complementary properties and injects dual mutation diversity into training to steadily diversify the estimated density in capturing multi-modes and improve generative performance. Specifically, CDE-GAN decomposes the complex adversarial optimization problem into two subproblems (generation and discrimination), and each subproblem is solved with a separated subpopulation (E-Generator\vphantom{\{}\} and E-Discriminators), evolved by its own evolutionary algorithm. Additionally, we further propose a Soft Mechanism to balance the trade-off between E-Generators and E-Discriminators to conduct steady training for CDE-GAN. Extensive experiments on one synthetic dataset and three real-world benchmark image datasets demonstrate that the proposed CDE-GAN achieves a competitive and superior performance in generating good quality and diverse samples over baselines. The code and more generated results are available at our project homepage: https://shiming-chen.github.io/CDE-GAN-website/CDE-GAN.html.},
    urldate = {2025-07-20},
    publisher = {arXiv},
    author = {Chen, Shiming and Wang, Wenjie and Xia, Beihao and You, Xinge and Cao, Zehong and Ding, Weiping},
    month = mar,
    year = {2021},
    note = {arXiv:2008.09388 [cs]
Citations: 34 (SemanticScholar) [2025-07-20]},
    keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}
@misc{houlsby_parameter-efficient_2019,
    title = {Parameter-{Efficient} {Transfer} {Learning} for {NLP}},
    url = {http://arxiv.org/abs/1902.00751},
    doi = {10.48550/arXiv.1902.00751},
    abstract = {Fine-tuning large pre-trained models is an effective transfer mechanism in NLP. However, in the presence of many downstream tasks, fine-tuning is parameter inefficient: an entire new model is required for every task. As an alternative, we propose transfer with adapter modules. Adapter modules yield a compact and extensible model; they add only a few trainable parameters per task, and new tasks can be added without revisiting previous ones. The parameters of the original network remain fixed, yielding a high degree of parameter sharing. To demonstrate adapter's effectiveness, we transfer the recently proposed BERT Transformer model to 26 diverse text classification tasks, including the GLUE benchmark. Adapters attain near state-of-the-art performance, whilst adding only a few parameters per task. On GLUE, we attain within 0.4\% of the performance of full fine-tuning, adding only 3.6\% parameters per task. By contrast, fine-tuning trains 100\% of the parameters per task.},
    urldate = {2025-07-21},
    publisher = {arXiv},
    author = {Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and Laroussilhe, Quentin de and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
    month = jun,
    year = {2019},
    note = {arXiv:1902.00751 [cs]
Citations: 4558 (SemanticScholar) [2025-07-20]},
    keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}
@misc{pan_idinit_2025,
    title = {{IDInit}: {A} {Universal} and {Stable} {Initialization} {Method} for {Neural} {Network} {Training}},
    shorttitle = {{IDInit}},
    url = {http://arxiv.org/abs/2503.04626},
    doi = {10.48550/arXiv.2503.04626},
    abstract = {Deep neural networks have achieved remarkable accomplishments in practice. The success of these networks hinges on effective initialization methods, which are vital for ensuring stable and rapid convergence during training. Recently, initialization methods that maintain identity transition within layers have shown good efficiency in network training. These techniques (e.g., Fixup) set specific weights to zero to achieve identity control. However, settings of remaining weight (e.g., Fixup uses random values to initialize non-zero weights) will affect the inductive bias that is achieved only by a zero weight, which may be harmful to training. Addressing this concern, we introduce fully identical initialization (IDInit), a novel method that preserves identity in both the main and sub-stem layers of residual networks. IDInit employs a padded identity-like matrix to overcome rank constraints in non-square weight matrices. Furthermore, we show the convergence problem of an identity matrix can be solved by stochastic gradient descent. Additionally, we enhance the universality of IDInit by processing higher-order weights and addressing dead neuron problems. IDInit is a straightforward yet effective initialization method, with improved convergence, stability, and performance across various settings, including large-scale datasets and deep models.},
    urldate = {2025-07-21},
    publisher = {arXiv},
    author = {Pan, Yu and Wang, Chaozheng and Wu, Zekai and Wang, Qifan and Zhang, Min and Xu, Zenglin},
    month = mar,
    year = {2025},
    note = {arXiv:2503.04626 [cs]
Citations: 2 (SemanticScholar) [2025-07-20]},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}
@misc{zhao_zero_2022,
    title = {{ZerO} {Initialization}: {Initializing} {Neural} {Networks} with only {Zeros} and {Ones}},
    shorttitle = {{ZerO} {Initialization}},
    url = {http://arxiv.org/abs/2110.12661},
    doi = {10.48550/arXiv.2110.12661},
    abstract = {Deep neural networks are usually initialized with random weights, with adequately selected initial variance to ensure stable signal propagation during training. However, selecting the appropriate variance becomes challenging especially as the number of layers grows. In this work, we replace random weight initialization with a fully deterministic initialization scheme, viz., ZerO, which initializes the weights of networks with only zeros and ones (up to a normalization factor), based on identity and Hadamard transforms. Through both theoretical and empirical studies, we demonstrate that ZerO is able to train networks without damaging their expressivity. Applying ZerO on ResNet achieves state-of-the-art performance on various datasets, including ImageNet, which suggests random weights may be unnecessary for network initialization. In addition, ZerO has many benefits, such as training ultra deep networks (without batch-normalization), exhibiting low-rank learning trajectories that result in low-rank and sparse solutions, and improving training reproducibility.},
    urldate = {2025-07-21},
    publisher = {arXiv},
    author = {Zhao, Jiawei and Schäfer, Florian and Anandkumar, Anima},
    month = nov,
    year = {2022},
    note = {arXiv:2110.12661 [cs]
Citations: 26 (SemanticScholar) [2025-07-20]},
    keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}
@article{Caselle2022StochasticTheory,
    title = {{Stochastic normalizing flows for lattice field theory}},
    year = {2022},
    author = {Caselle, Michele and Cellini, Elia and Nada, Alessandro and Panero, Marco},
    month = {10},
    pages = {8--13},
    url = {https://arxiv.org/abs/2210.03139v1},
    arxivId = {2210.03139}
}
@misc{jiang_algorithmic_2022,
    title = {Algorithmic {Regularization} in {Model}-free {Overparametrized} {Asymmetric} {Matrix} {Factorization}},
    url = {http://arxiv.org/abs/2203.02839},
    doi = {10.48550/arXiv.2203.02839},
    abstract = {We study the asymmetric matrix factorization problem under a natural nonconvex formulation with arbitrary overparametrization. The model-free setting is considered, with minimal assumption on the rank or singular values of the observed matrix, where the global optima provably overfit. We show that vanilla gradient descent with small random initialization sequentially recovers the principal components of the observed matrix. Consequently, when equipped with proper early stopping, gradient descent produces the best low-rank approximation of the observed matrix without explicit regularization. We provide a sharp characterization of the relationship between the approximation error, iteration complexity, initialization size and stepsize. Our complexity bound is almost dimension-free and depends logarithmically on the approximation error, with significantly more lenient requirements on the stepsize and initialization compared to prior work. Our theoretical results provide accurate prediction for the behavior gradient descent, showing good agreement with numerical experiments.},
    urldate = {2025-07-21},
    publisher = {arXiv},
    author = {Jiang, Liwei and Chen, Yudong and Ding, Lijun},
    month = sep,
    year = {2022},
    note = {arXiv:2203.02839 [cs]
Citations: 27 (SemanticScholar) [2025-07-20]},
    keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
}
@inproceedings{dugas_incorporating_2000,
    title = {Incorporating {Second}-{Order} {Functional} {Knowledge} for {Better} {Option} {Pricing}},
    volume = {13},
    url = {https://papers.nips.cc/paper_files/paper/2000/hash/44968aece94f667e4095002d140b5896-Abstract.html},
    abstract = {Incorporating prior knowledge of a particular task into the  architecture  of a learning algorithm can greatly improve generalization performance.  We  study  here  a case where we  know  that the  function  to be learned is  non-decreasing in two of its  arguments and convex in  one of them.  For  this purpose we propose a class of functions similar to multi-layer neural  networks but (1) that has those properties, (2) is a universal approximator  of continuous functions  with  these  and  other properties.  We  apply  this  new class  of functions  to  the task of modeling the price of call  options.  Experiments show improvements on regressing the price of call options  using the new types of function classes that incorporate the a priori con(cid:173) straints.},
    urldate = {2025-07-21},
    booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
    publisher = {MIT Press},
    author = {Dugas, Charles and Bengio, Yoshua and Bélisle, François and Nadeau, Claude and Garcia, René},
    year = {2000},
    keywords = {⛔ No DOI found},
}
@inproceedings{glorot_deep_2011,
    title = {Deep {Sparse} {Rectifier} {Neural} {Networks}},
    url = {https://proceedings.mlr.press/v15/glorot11a.html},
    abstract = {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabeled data, deep rectifier networks can reach their best performance without requiring any unsupervised pre-training on purely supervised tasks with large labeled datasets. Hence, these results can be seen as a new milestone in the attempts at understanding the difficulty in training deep but purely supervised neural networks, and closing the performance gap between neural networks learnt with and without unsupervised pre-training.},
    language = {en},
    urldate = {2025-07-21},
    booktitle = {Proceedings of the {Fourteenth} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
    publisher = {JMLR Workshop and Conference Proceedings},
    author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
    month = jun,
    year = {2011},
    note = {ISSN: 1938-7228},
    pages = {315--323},
}
@misc{rybakov_methods_2024,
    title = {Methods of improving {LLM} training stability},
    url = {http://arxiv.org/abs/2410.16682},
    doi = {10.48550/arXiv.2410.16682},
    abstract = {Training stability of large language models(LLMs) is an important research topic. Reproducing training instabilities can be costly, so we use a small language model with 830M parameters and experiment with higher learning rates to force models to diverge. One of the sources of training instability is the growth of logits in attention layers. We extend the focus of the previous work and look not only at the magnitude of the logits but at all outputs of linear layers in the Transformer block. We observe that with a high learning rate the L2 norm of all linear layer outputs can grow with each training step and the model diverges. Specifically we observe that QKV, Proj and FC2 layers have the largest growth of the output magnitude. This prompts us to explore several options: 1) apply layer normalization not only after QK layers but also after Proj and FC2 layers too; 2) apply layer normalization after the QKV layer (and remove pre normalization). 3) apply QK layer normalization together with softmax capping. We show that with the last two methods we can increase learning rate by 1.5x (without model divergence) in comparison to an approach based on QK layer normalization only. Also we observe significant perplexity improvements for all three methods in comparison to the baseline model.},
    urldate = {2025-07-21},
    publisher = {arXiv},
    author = {Rybakov, Oleg and Chrzanowski, Mike and Dykas, Peter and Xue, Jinze and Lanir, Ben},
    month = oct,
    year = {2024},
    note = {arXiv:2410.16682 [cs]},
    keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}
@misc{dai_rethinking_2022,
    title = {Rethinking {Multidimensional} {Discriminator} {Output} for {Generative} {Adversarial} {Networks}},
    url = {http://arxiv.org/abs/2109.03378},
    doi = {10.48550/arXiv.2109.03378},
    abstract = {The study of multidimensional discriminator (critic) output for Generative Adversarial Networks has been underexplored in the literature. In this paper, we generalize the Wasserstein GAN framework to take advantage of multidimensional critic output and explore its properties. We also introduce a square-root velocity transformation (SRVT) block which favors training in the multidimensional setting. Proofs of properties are based on our proposed maximal p-centrality discrepancy, which is bounded above by p-Wasserstein distance and fits the Wasserstein GAN framework with multidimensional critic output n. Especially when n = 1 and p = 1, the proposed discrepancy equals 1-Wasserstein distance. Theoretical analysis and empirical evidence show that high-dimensional critic output has its advantage on distinguishing real and fake distributions, and benefits faster convergence and diversity of results.},
    urldate = {2025-07-21},
    publisher = {arXiv},
    author = {Dai, Mengyu and Hang, Haibin and Srivastava, Anuj},
    month = jul,
    year = {2022},
    note = {arXiv:2109.03378 [stat]
Citations: 3 (SemanticScholar) [2025-07-20]},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}
@misc{henderson_where_2018,
    title = {Where {Did} {My} {Optimum} {Go}?: {An} {Empirical} {Analysis} of {Gradient} {Descent} {Optimization} in {Policy} {Gradient} {Methods}},
    shorttitle = {Where {Did} {My} {Optimum} {Go}?},
    url = {http://arxiv.org/abs/1810.02525},
    doi = {10.48550/arXiv.1810.02525},
    abstract = {Recent analyses of certain gradient descent optimization methods have shown that performance can degrade in some settings - such as with stochasticity or implicit momentum. In deep reinforcement learning (Deep RL), such optimization methods are often used for training neural networks via the temporal difference error or policy gradient. As an agent improves over time, the optimization target changes and thus the loss landscape (and local optima) change. Due to the failure modes of those methods, the ideal choice of optimizer for Deep RL remains unclear. As such, we provide an empirical analysis of the effects that a wide range of gradient descent optimizers and their hyperparameters have on policy gradient methods, a subset of Deep RL algorithms, for benchmark continuous control tasks. We find that adaptive optimizers have a narrow window of effective learning rates, diverging in other cases, and that the effectiveness of momentum varies depending on the properties of the environment. Our analysis suggests that there is significant interplay between the dynamics of the environment and Deep RL algorithm properties which aren't necessarily accounted for by traditional adaptive gradient methods. We provide suggestions for optimal settings of current methods and further lines of research based on our findings.},
    urldate = {2025-07-21},
    publisher = {arXiv},
    author = {Henderson, Peter and Romoff, Joshua and Pineau, Joelle},
    month = oct,
    year = {2018},
    note = {arXiv:1810.02525 [cs]
Citations: 34 (SemanticScholar) [2025-07-20]},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}